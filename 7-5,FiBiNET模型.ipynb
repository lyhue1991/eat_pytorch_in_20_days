{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827f51d5",
   "metadata": {},
   "source": [
    "\n",
    "# 7-5ï¼ŒFiBiNETæ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fccfc16",
   "metadata": {},
   "source": [
    "ç¥ç»ç½‘ç»œçš„ç»“æ„è®¾è®¡æœ‰3ä¸ªä¸»æµçš„é«˜çº§æŠ€å·§ï¼š\n",
    "\n",
    "* 1ï¼Œé«˜ä½èåˆ (å°†é«˜å±‚æ¬¡ç‰¹å¾ä¸ä½å±‚æ¬¡ç‰¹å¾èåˆï¼Œæå‡ç‰¹å¾ç»´åº¦çš„ä¸°å¯Œæ€§å’Œå¤šæ ·æ€§ï¼Œåƒäººä¸€æ ·åŒæ—¶è€ƒè™‘æ•´ä½“å’Œç»†èŠ‚)\n",
    "* 2ï¼Œæƒå€¼å…±äº« (ä¸€ä¸ªæƒå€¼çŸ©é˜µå‚ä¸å¤šä¸ªä¸åŒçš„è®¡ç®—ï¼Œé™ä½å‚æ•°è§„æ¨¡å¹¶åŒæ—¶ç¼“è§£æ ·æœ¬ç¨€ç–æ€§ï¼Œåƒäººä¸€æ ·ä¸€æ¡çŸ¥è¯†å¤šå¤„è¿ç”¨)\n",
    "* 3ï¼ŒåŠ¨æ€é€‚åº” (ä¸åŒçš„è¾“å…¥æ ·æœ¬ä½¿ç”¨ä¸åŒçš„æƒå€¼çŸ©é˜µï¼ŒåŠ¨æ€åœ°è¿›è¡Œç‰¹å¾é€‰æ‹©å¹¶èµ‹äºˆç‰¹å¾é‡è¦åº¦è§£é‡Šæ€§ï¼Œåƒäººä¸€æ ·èšç„¦é‡è¦ä¿¡æ¯æ’é™¤å¹²æ‰°ä¿¡æ¯)\n",
    "\n",
    "æŠ€å·§åº”ç”¨èŒƒä¾‹ï¼š\n",
    "\n",
    "* 1ï¼Œé«˜ä½èåˆ (DeepWide,UNet,ç‰¹å¾é‡‘å­—å¡”FPN...)\n",
    "* 2ï¼Œæƒå€¼å…±äº« (CNN,RNN,FM,DeepFM,BlinearFFM...)\n",
    "* 3ï¼ŒåŠ¨æ€é€‚åº” (å„ç§Attentionæœºåˆ¶...)\n",
    "\n",
    "æ–°æµªå¾®åšå¹¿å‘Šæ¨èæŠ€æœ¯å›¢é˜Ÿ2019å¹´å‘å¸ƒçš„CTRé¢„ä¼°æ¨¡å‹FiBiNETåŒæ—¶å·§å¦™åœ°è¿ç”¨äº†ä»¥ä¸Š3ç§æŠ€å·§ï¼Œæ˜¯ç¥ç»ç½‘ç»œç»“æ„è®¾è®¡çš„æ•™ç§‘ä¹¦çº§çš„èŒƒä¾‹ã€‚\n",
    "\n",
    "åœ¨æ­¤ä»‹ç»ç»™å¤§å®¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582eca22",
   "metadata": {},
   "source": [
    "å‚è€ƒèµ„æ–™ï¼š\n",
    "* FiBiNETè®ºæ–‡ï¼šhttps://arxiv.org/pdf/1905.09433.pdf\n",
    "* FiBiNET-ç»“åˆç‰¹å¾é‡è¦æ€§å’ŒåŒçº¿æ€§ç‰¹å¾äº¤äº’è¿›è¡ŒCTRé¢„ä¼°ï¼šhttps://zhuanlan.zhihu.com/p/72931811\n",
    "* ä»£ç å®ç°ï¼šhttps://github.com/xue-pai/FuxiCTR/blob/main/fuxictr/pytorch/models/FiBiNET.py \n",
    "* SENetåŸç†ï¼šhttps://zhuanlan.zhihu.com/p/65459972"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e24de6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=\"red\">\n",
    " \n",
    "å…¬ä¼—å· **ç®—æ³•ç¾é£Ÿå±‹** å›å¤å…³é”®è¯ï¼š**pytorch**ï¼Œ è·å–æœ¬é¡¹ç›®æºç å’Œæ‰€ç”¨æ•°æ®é›†ç™¾åº¦äº‘ç›˜ä¸‹è½½é“¾æ¥ã€‚\n",
    "    \n",
    "</font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8828a0e5",
   "metadata": {},
   "source": [
    "## ä¸€ï¼ŒFiBiNETåŸç†è§£æ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca95583d",
   "metadata": {},
   "source": [
    "FiBiNETå…¨ç§°ä¸ºFeature Importance and Bilinear Interaction Network.\n",
    "\n",
    "é¡¾åæ€ä¹‰ï¼Œå…¶ä¸»è¦çš„åˆ›æ„æœ‰2ä¸ªã€‚\n",
    "\n",
    "ç¬¬ä¸€ä¸ªæ˜¯Feature Importanceï¼Œé€šè¿‡å€Ÿé‰´SENetï¼ˆSqueeze-and-Excitationï¼‰Attentionæœºåˆ¶å®ç°ç‰¹å¾é€‰æ‹©å’Œé‡è¦åº¦è§£é‡Šã€‚\n",
    "\n",
    "ç¬¬äºŒä¸ªæ˜¯Bilinear Interaction Networkï¼Œè¿™æ˜¯åº”ç”¨æƒå€¼å…±äº«æŠ€å·§å¯¹ FFM(Field-Aware FM)ç»“æ„è¿›è¡Œæ”¹è¿›çš„ä¸€ç§ç»“æ„ã€‚\n",
    "\n",
    "åŒæ—¶ï¼ŒFiBiNETä¿ç•™äº†DeepWideçš„é«˜ä½èåˆçš„ç½‘ç»œæ¶æ„ã€‚\n",
    "\n",
    "æ‰€ä»¥å®ƒç»¼åˆä½¿ç”¨äº† é«˜ä½èåˆã€æƒå€¼å…±äº«ã€åŠ¨æ€é€‚åº” è¿™3ç§ç¥ç»ç½‘ç»œç»“æ„è®¾è®¡çš„é«˜çº§æŠ€å·§ã€‚ä¸€ä¸ªä¸è½ï¼ŒTriple kill!\n",
    "\n",
    "æˆ‘ä»¬é‡ç‚¹ä»‹ç»ä¸€ä¸‹ SENet Attention å’Œ Bilinear Interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400a738",
   "metadata": {},
   "source": [
    "### 1, SENet Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf342b7",
   "metadata": {},
   "source": [
    "SENet å…¨ç§°ä¸º Squeeze-and-Excitation Networkï¼Œæ˜¯ä¸€ç§é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—ç‰¹å¾é‡è¦åº¦çš„ç½‘ç»œæ¨¡å—ã€‚\n",
    "\n",
    "æœ€æ—©æ˜¯åœ¨CVé¢†åŸŸå¼•å…¥ï¼Œé€šè¿‡åœ¨ResNetç»“æ„ä¸Šæ·»åŠ SENet Attentionæ¨¡å—ï¼Œèµ¢å¾—äº†ImageNet 2017ç«èµ›åˆ†ç±»ä»»åŠ¡çš„å† å†›ã€‚\n",
    "\n",
    "å¦‚ä½•è®¡ç®—å„ä¸ªFeature Map(é€šé“)çš„ç‰¹å¾é‡è¦åº¦(æ³¨æ„åŠ›æƒé‡)å‘¢ï¼Ÿ\n",
    "\n",
    "SENetçš„æ€æƒ³éå¸¸ç®€æ´ã€‚\n",
    "\n",
    "step1: é€šè¿‡å…¨å±€æ± åŒ–å°†å„ä¸ªFeature Mapç”±ä¸€ä¸ªä¸€ä¸ªçš„çŸ©é˜µæ±‡æ€»æˆä¸€ä¸ªä¸€ä¸ªçš„æ ‡é‡ã€‚æ­¤å³Squeezeæ“ä½œã€‚\n",
    "\n",
    "step2ï¼šé€šè¿‡ä¸€ä¸ª2å±‚MLPå°†æ±‡æ€»æˆå¾—åˆ°çš„ä¸€ä¸ªä¸€ä¸ªçš„æ ‡é‡æ‰€æ„æˆçš„å‘é‡è¿›è¡Œå˜æ¢ï¼Œå¾—åˆ°æ³¨æ„åŠ›æƒé‡ã€‚æ­¤å³Excitationæ“ä½œã€‚ \n",
    "ç»†èŠ‚ä¸€ç‚¹åœ°è¯´ï¼Œè¿™ä¸ª2å±‚çš„MLPçš„ç¬¬1å±‚å°†é€šé“æ•°é‡ç¼©å‡æˆåŸæ¥çš„1/3, ç¬¬2å±‚å†å°†é€šé“æ•°æ¢å¤ã€‚å¹¶ä¸”æ¯å±‚åé¢éƒ½æ¥å…¥äº†æ¿€æ´»å‡½æ•°ã€‚\n",
    "\n",
    "step3ï¼šç”¨æ³¨æ„åŠ›æƒé‡ä¹˜ä»¥åŸå§‹çš„Feature Mapã€‚è¿™ä¸ªæ˜¯Re-Weightæ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f634cfe",
   "metadata": {},
   "source": [
    "å›¾ç‰‡ç¤ºæ„å¦‚ä¸‹ã€‚\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2sfkkfcy3j208w06fgll.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79f99ba",
   "metadata": {},
   "source": [
    "pytorchä»£ç å®ç°å¦‚ä¸‹ï¼Œå¯èƒ½æ¯”å›¾ç‰‡æ›´åŠ å¥½æ‡‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a704b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "class SENetAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation Attention\n",
    "    è¾“å…¥shape: [batch_size, num_fields, d_embed]   #num_fieldså³num_features\n",
    "    è¾“å‡ºshape: [batch_size, num_fields, d_embed]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_fields, reduction_ratio=3):\n",
    "        super().__init__()\n",
    "        reduced_size = max(1, int(num_fields / reduction_ratio))\n",
    "        self.excitation = nn.Sequential(nn.Linear(num_fields, reduced_size, bias=False),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(reduced_size, num_fields, bias=False),\n",
    "                                        nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        Z = torch.mean(x, dim=-1, out=None) #1,Sequeeze\n",
    "        A = self.excitation(Z) #2,Excitation\n",
    "        V = x * A.unsqueeze(-1) #3,Re-Weight\n",
    "        return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ab325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57638416",
   "metadata": {},
   "source": [
    "### 2, Bilinear Interaction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f049c68c",
   "metadata": {},
   "source": [
    "Bilinear Interactionå®é™…ä¸Šæ˜¯FFMåœ¨æƒå€¼å…±äº«æ€æƒ³ä¸‹çš„ä¸€ç§æ”¹è¿›ï¼Œä¹Ÿå¯ä»¥ç§°ä¹‹ä¸ºBilinear FFMã€‚\n",
    "\n",
    "æˆ‘ä»¬å…ˆè¯´è¯´FFM(Field-Aware FM)ï¼Œå†çœ‹çœ‹è¿™ä¸ªBilinear FFM æ€ä¹ˆæ”¹è¿›çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a745eac",
   "metadata": {},
   "source": [
    "FMç”¨éšå‘é‡ä¹‹é—´çš„ç‚¹ç§¯æ¥è®¡ç®—ç‰¹å¾ä¹‹é—´çš„äº¤å‰ï¼Œå¹¶ä¸”ä¸€ä¸ªç‰¹å¾ç”¨ä¸€ä¸ªéšå‘é‡æ¥è¡¨ç¤ºã€‚\n",
    "\n",
    "FFMè®¤ä¸ºä¸€ä¸ªç‰¹å¾ç”¨ä¸€ä¸ªéšå‘é‡æ¥è¡¨è¾¾å¤ªç²—ç³™äº†ï¼Œå¦‚æœè¿™ä¸ªç‰¹å¾å’Œä¸åŒåˆ†ç»„(Field)çš„ç‰¹å¾æ¥åšäº¤å‰ï¼Œåº”è¯¥ç”¨ä¸åŒçš„éšå‘é‡ã€‚\n",
    "\n",
    "ä¸¾ä¾‹æ¥è¯´ï¼Œè€ƒè™‘ä¸€ä¸ªå¹¿å‘Šç‚¹å‡»é¢„æµ‹çš„åœºæ™¯ï¼Œå¹¿å‘Šç±»åˆ« å’Œ ç”¨æˆ·æ‰€åœ¨åŸå¸‚ã€ç”¨æˆ·èŒä¸šä¹‹é—´çš„äº¤å‰ã€‚\n",
    "\n",
    "åœ¨FMä¸­ ä¸€ä¸ªç¡®å®šçš„å¹¿å‘Šç±»åˆ« æ¯”å¦‚æ¸¸æˆå¹¿å‘Š ä¸è®ºæ˜¯å’Œç”¨æˆ·æ‰€åœ¨åŸå¸‚ï¼Œè¿˜æ˜¯ç”¨æˆ·èŒä¸šäº¤å‰ï¼Œéƒ½ç”¨åŒä¸€ä¸ªéšå‘é‡ã€‚\n",
    "\n",
    "ä½†æ˜¯FFMè®¤ä¸ºï¼Œç”¨æˆ·æ‰€åœ¨åŸå¸‚å’Œç”¨æˆ·èŒä¸šæ˜¯ä¸¤ç±»å®Œå…¨ä¸åŒçš„ç‰¹å¾(ä¸åŒField)ï¼Œæè¿°å®ƒä»¬çš„å‘é‡ç©ºé—´åº”è¯¥æ˜¯å®Œå…¨ä¸ç›¸å…³çš„ï¼ŒFMç”¨ä¸€ä¸ªç›¸åŒçš„éšå‘é‡æ¥å’Œå®ƒä»¬åšç‚¹ç§¯ä¸åˆç†ã€‚\n",
    "\n",
    "æ‰€ä»¥ï¼ŒFFMå¼•å…¥äº†Field(åŸŸ)çš„æ¦‚å¿µï¼Œå’Œä¸åŒFieldçš„ç‰¹å¾åšäº¤å‰ï¼Œè¦ä½¿ç”¨ä¸åŒçš„éšå‘é‡ã€‚\n",
    "\n",
    "å®è·µè¡¨æ˜ï¼ŒFFMè¿™ä¸ªæ€è·¯æ˜¯æœ‰æ•ˆçš„, FFMçš„ä½œè€…é˜®æ¯“é’¦æ­£æ˜¯å‡­å€Ÿè¿™ä¸ªæ–¹æ¡ˆèµ¢å¾—äº†2015å¹´kaggleä¸¾åŠçš„Criteoæ¯”èµ›çš„å† å†›ã€‚\n",
    "\n",
    "ä½†æ˜¯FFMæœ‰ä¸ªå¾ˆå¤§çš„ç¼ºç‚¹ï¼Œå°±æ˜¯å‚æ•°é‡å¤ªå¤šäº†ã€‚\n",
    "\n",
    "å¯¹äºFMæ¥è¯´ï¼Œæ¯ä¸ªç‰¹å¾åªæœ‰ä¸€ä¸ªéšå‘é‡ï¼Œå‡è®¾æœ‰nä¸ªç‰¹å¾ï¼Œæ¯ä¸ªéšå‘é‡ç»´åº¦ä¸ºkï¼Œå…¨éƒ¨éšå‘é‡å‚æ•°çŸ©é˜µçš„å¤§å° size = n k.\n",
    "\n",
    "ä½†æ˜¯å¯¹äºFFMï¼Œæœ‰è¿‡æœ‰fä¸ªä¸åŒçš„fieldï¼Œæ¯ä¸ªç‰¹å¾éƒ½å°†æœ‰f-1ä¸ªéšå‘é‡ï¼Œå…¨éƒ¨éšå‘é‡çš„å‚æ•°çŸ©é˜µçš„å¤§å°å¢å¤§ä¸º size = (f-1) n k. \n",
    "\n",
    "é€šå¸¸çš„åº”ç”¨åœºæ™¯ä¸­ï¼ŒFieldçš„æ•°é‡æœ‰å‡ åå‡ ç™¾ç»´ï¼Œè€ŒFeatureçš„æ•°é‡æœ‰æ•°ä¸‡æ•°ç™¾ä¸‡ç»´ã€‚\n",
    "\n",
    "å¾ˆæ˜¾ç„¶ï¼ŒFFMå°†éšå‘é‡çš„å‚æ•°è§„æ¨¡æ‰©å¤§äº†å‡ åå‡ ç™¾å€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c8810",
   "metadata": {},
   "source": [
    "FFMçš„æœ¬è´¨æ€æƒ³æ˜¯åœ¨åšç‰¹å¾äº¤å‰çš„æ—¶å€™è¦åŒºåˆ†ä¸åŒçš„Fieldï¼Œå…¶å®ç°æ–¹å¼æ˜¯å’Œä¸åŒçš„Fieldåšäº¤å‰æ—¶ç”¨ä¸åŒçš„éšå‘é‡ã€‚\n",
    "\n",
    "æœ‰æ²¡æœ‰åŠæ³•ä¿ç•™FFMä¸­åŒºåˆ†ä¸åŒFieldçš„ç‰¹æ€§ï¼Œå¹¶é™ä½å‚æ•°è§„æ¨¡å‘¢ï¼Ÿ\n",
    "\n",
    "BilinearFFMè¯´ï¼Œæˆ‘æœ‰åŠæ³•ï¼Œæƒé‡å…±äº«èµ°èµ·æ¥ï¼\n",
    "\n",
    "BilinearFFMä¸ç›´æ¥é’ˆå¯¹ä¸åŒFieldè®¾è®¡ä¸åŒçš„éšå‘é‡ï¼Œè€Œæ˜¯å¼•å…¥äº†Fieldå˜æ¢çŸ©é˜µæ¥åŒºåˆ†ä¸åŒçš„Fieldã€‚\n",
    "\n",
    "æ¯ä¸ªç‰¹å¾è¿˜æ˜¯ä¸€ä¸ªéšå‘é‡ï¼Œä½†æ˜¯å’Œä¸åŒçš„Fieldçš„ç‰¹å¾åšäº¤å‰æ—¶ï¼Œå…ˆä¹˜ä¸Šè¿™ä¸ªç‰¹å¾æ‰€åœ¨Fieldçš„å˜æ¢çŸ©é˜µï¼Œç„¶åå†åšåé¢çš„ç‚¹ç§¯ã€‚\n",
    "\n",
    "å› æ­¤ï¼ŒåŒå±ä¸€ä¸ªFieldçš„ç‰¹å¾å…±äº«ä¸€ä¸ªFieldå˜æ¢çŸ©é˜µã€‚è¿™ç§bilinear_typeå«åš field_each.\n",
    "\n",
    "Fieldå˜æ¢çŸ©é˜µçš„å¤§å°æ˜¯k^2, è¿™ç§æ–¹å¼ä¸‹ï¼Œå…¨éƒ¨éšå‘é‡çš„å‚æ•°å¤§å°åŠ ä¸Šå…±äº«å˜æ¢çŸ©é˜µçš„å‚æ•°å¤§å°ä¸€å…±æ˜¯ size = n k + f k^2 \n",
    "\n",
    "ç”±äºkå’Œfè¿œå°äºnï¼Œè¿™ç§Bilinearæ–¹å¼ç›¸æ¯”FMå¢åŠ çš„å‚æ•°é‡å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚\n",
    "\n",
    "\n",
    "é™¤äº† åŒå±ä¸€ä¸ªFieldçš„ç‰¹å¾å…±äº«ä¸€ä¸ªFieldå˜æ¢çŸ©é˜µå¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æ›´åŠ ç®€å•ç²—æš´ä¸€ç‚¹ï¼Œæ‰€æœ‰ç‰¹å¾å…±äº«ä¸€ä¸ªå˜æ¢çŸ©é˜µ.\n",
    "\n",
    "è¿™ç§bilinear_typeå«åš field_all.è¿™ç§æ–¹å¼ä¸‹ï¼Œsize = n k + k^2 \n",
    "\n",
    "\n",
    "æˆ‘ä»¬ä¹Ÿå¯ä»¥æ›´åŠ ç²¾ç»†ä¸€ç‚¹ï¼Œç›¸åŒçš„Fieldç»„åˆä¹‹é—´çš„äº¤äº’å…±äº«ä¸€ä¸ªå˜æ¢çŸ©é˜µï¼Œè¿™ç§bilinear_typeå«åšfield_interaction. \n",
    "\n",
    "æ€»å…±æœ‰f(f-1)/2ç§ç»„åˆï¼Œè¿™ç§æ–¹å¼ä¸‹ï¼Œ size = n k + k^2 f(f-1)/2\n",
    "\n",
    "ä»¥ä¸Šå°±æ˜¯BilinearFFMçš„åŸºæœ¬æ€æƒ³ã€‚\n",
    "\n",
    "\n",
    "FiBiNETä¸­ç”¨åˆ°çš„Bilinear Interactionç›¸æ¯”BilinearFFM, è¿˜æœ‰ä¸€å¤„å°æ”¹åŠ¨ï¼Œå°†ç‚¹ç§¯æ”¹æˆäº†å“ˆè¾¾ç›ç§¯ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65661157",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2sfj6wh0rj209v08daad.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bac64f",
   "metadata": {},
   "source": [
    "pytorchä»£ç å®ç°å¦‚ä¸‹ï¼Œæ•´ä½“ä¸éš¾ç†è§£ã€‚ä½œ2ç‚¹è¯´æ˜ã€‚\n",
    "\n",
    "1ï¼ŒFieldæ¦‚å¿µè¯´æ˜\n",
    "\n",
    "åœ¨FFMç›¸å…³çš„æ–‡ç« ä¸­ï¼Œå¼•å…¥äº†Fieldçš„æ¦‚å¿µï¼Œä»¥å’ŒFeatureåŒºåˆ†ï¼Œä¸€ä¸ªFieldä¸­å¯ä»¥åŒ…æ‹¬å¤šä¸ªFeature. \n",
    "\n",
    "å®é™…ä¸ŠFieldå°±æ˜¯æˆ‘ä»¬é€šå¸¸ç†è§£çš„ç‰¹å¾ï¼ŒåŒ…æ‹¬æ•°å€¼ç‰¹å¾å’Œç±»åˆ«ç‰¹å¾ï¼Œä½†æ˜¯Featureæ˜¯æ•°å€¼ç‰¹å¾æˆ–è€…ç±»åˆ«ç‰¹å¾onehotåçš„ç‰¹å¾ã€‚ä¸€ä¸ªç±»åˆ«ç‰¹å¾å¯¹åº”ä¸€ä¸ªFieldï¼Œä½†æ˜¯å¯¹åº”å¤šä¸ªFeatureã€‚\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2sh8t8j6pj20gc058mx9.jpg)\n",
    "\n",
    "2ï¼Œcombinationså‡½æ•°è¯´æ˜\n",
    "\n",
    "ç»„åˆå‡½æ•°combinationsä»num_fieldsä¸­ä»»å–2ç§ä½œä¸ºç»„åˆï¼Œå…±æœ‰ num_fields*(num_fields-1)ä¸­ç»„åˆæ–¹å¼ã€‚\n",
    "\n",
    "æ‰€ä»¥è¾“å‡ºçš„Fieldæ•°é‡å˜æˆäº† num_fields*(num_fields-1)/2ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d50922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from itertools import combinations\n",
    "class BilinearInteraction(nn.Module):\n",
    "    \"\"\"\n",
    "    åŒçº¿æ€§FFM\n",
    "    è¾“å…¥shape: [batch_size, num_fields, d_embed] #num_fieldså³num_features\n",
    "    è¾“å‡ºshape: [batch_size, num_fields*(num_fields-1)/2, d_embed]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_fields, d_embed, bilinear_type=\"field_interaction\"):\n",
    "        super().__init__()\n",
    "        self.bilinear_type = bilinear_type\n",
    "        if self.bilinear_type == \"field_all\":\n",
    "            self.bilinear_layer = nn.Linear(d_embed, d_embed, bias=False)\n",
    "        elif self.bilinear_type == \"field_each\":\n",
    "            self.bilinear_layer = nn.ModuleList([nn.Linear(d_embed, d_embed, bias=False)\n",
    "                                                 for i in range(num_fields)])\n",
    "        elif self.bilinear_type == \"field_interaction\":\n",
    "            self.bilinear_layer = nn.ModuleList([nn.Linear(d_embed, d_embed, bias=False)\n",
    "                                                 for i, j in combinations(range(num_fields), 2)])\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def forward(self, feature_emb):\n",
    "        feature_emb_list = torch.split(feature_emb, 1, dim=1)\n",
    "        if self.bilinear_type == \"field_all\":\n",
    "            bilinear_list = [self.bilinear_layer(v_i) * v_j\n",
    "                             for v_i, v_j in combinations(feature_emb_list, 2)]\n",
    "        elif self.bilinear_type == \"field_each\":\n",
    "            bilinear_list = [self.bilinear_layer[i](feature_emb_list[i]) * feature_emb_list[j]\n",
    "                             for i, j in combinations(range(len(feature_emb_list)), 2)]\n",
    "        elif self.bilinear_type == \"field_interaction\":\n",
    "            bilinear_list = [self.bilinear_layer[i](v[0]) * v[1]\n",
    "                             for i, v in enumerate(combinations(feature_emb_list, 2))]\n",
    "        return torch.cat(bilinear_list, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe26681",
   "metadata": {},
   "source": [
    "### äºŒï¼ŒFiBiNETçš„pytorchå®ç°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f340fd",
   "metadata": {},
   "source": [
    "ä¸‹é¢æ˜¯FiBiNETçš„ä¸€ä¸ªpytorchå®ç°ã€‚\n",
    "\n",
    "æ ¸å¿ƒä»£ç æ˜¯SENetAttentionæ¨¡å—å’ŒBilinearInteractionæ¨¡å—çš„å®ç°ã€‚\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2sffi4huoj20g70a4gm4.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93153b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from itertools import combinations\n",
    "\n",
    "class NumEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    è¿ç»­ç‰¹å¾ç”¨linearå±‚ç¼–ç \n",
    "    è¾“å…¥shape: [batch_size,num_features, d_in], # d_in é€šå¸¸æ˜¯1\n",
    "    è¾“å‡ºshape: [batch_size,num_features, d_out]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n: int, d_in: int, d_out: int, bias: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(n, d_in, d_out))\n",
    "        self.bias = nn.Parameter(torch.Tensor(n, d_out)) if bias else None\n",
    "        with torch.no_grad():\n",
    "            for i in range(n):\n",
    "                layer = nn.Linear(d_in, d_out)\n",
    "                self.weight[i] = layer.weight.T\n",
    "                if self.bias is not None:\n",
    "                    self.bias[i] = layer.bias\n",
    "\n",
    "    def forward(self, x_num):\n",
    "        assert x_num.ndim == 3\n",
    "        #x = x_num[..., None] * self.weight[None]\n",
    "        #x = x.sum(-2)\n",
    "        x = torch.einsum(\"bfi,fij->bfj\",x_num,self.weight)\n",
    "        if self.bias is not None:\n",
    "            x = x + self.bias[None]\n",
    "        return x\n",
    "    \n",
    "class CatEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    ç¦»æ•£ç‰¹å¾ç”¨Embeddingå±‚ç¼–ç \n",
    "    è¾“å…¥shape: [batch_size, num_features], \n",
    "    è¾“å‡ºshape: [batch_size, num_features, d_embed]\n",
    "    \"\"\"\n",
    "    def __init__(self, categories, d_embed):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(sum(categories), d_embed)\n",
    "        self.offsets = nn.Parameter(\n",
    "                torch.tensor([0] + categories[:-1]).cumsum(0),requires_grad=False)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, x_cat):\n",
    "        \"\"\"\n",
    "        x_cat: Long tensor of size ``(batch_size, features_num)``\n",
    "        \"\"\"\n",
    "        x = x_cat + self.offsets[None]\n",
    "        return self.embedding(x) \n",
    "    \n",
    "class CatLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    ç¦»æ•£ç‰¹å¾ç”¨Embeddingå®ç°çº¿æ€§å±‚ï¼ˆç­‰ä»·äºå…ˆF.onehotå†nn.Linear()ï¼‰\n",
    "    è¾“å…¥shape: [batch_size, num_features ], \n",
    "    è¾“å‡ºshape: [batch_size, d_out]\n",
    "    \"\"\"\n",
    "    def __init__(self, categories, d_out=1):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Embedding(sum(categories), d_out)\n",
    "        self.bias = nn.Parameter(torch.zeros((d_out,)))\n",
    "        self.offsets = nn.Parameter(\n",
    "                torch.tensor([0] + categories[:-1]).cumsum(0),requires_grad=False)\n",
    "        nn.init.xavier_uniform_(self.fc.weight.data)\n",
    "\n",
    "    def forward(self, x_cat):\n",
    "        \"\"\"\n",
    "        Long tensor of size ``(batch_size, num_features)``\n",
    "        \"\"\"\n",
    "        x = x_cat + self.offsets[None]\n",
    "        return torch.sum(self.fc(x), dim=1) + self.bias \n",
    "    \n",
    "class SENetAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation Attention\n",
    "    è¾“å…¥shape: [batch_size, num_fields, d_embed]   #num_fieldså³num_features\n",
    "    è¾“å‡ºshape: [batch_size, num_fields, d_embed]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_fields, reduction_ratio=3):\n",
    "        super().__init__()\n",
    "        reduced_size = max(1, int(num_fields / reduction_ratio))\n",
    "        self.excitation = nn.Sequential(nn.Linear(num_fields, reduced_size, bias=False),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(reduced_size, num_fields, bias=False),\n",
    "                                        nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        Z = torch.mean(x, dim=-1, out=None) #1,Sequeeze\n",
    "        A = self.excitation(Z) #2,Excitation\n",
    "        V = x * A.unsqueeze(-1) #3,Re-Weight\n",
    "        return V\n",
    "    \n",
    "class BilinearInteraction(nn.Module):\n",
    "    \"\"\"\n",
    "    åŒçº¿æ€§FFM\n",
    "    è¾“å…¥shape: [batch_size, num_fields, d_embed] #num_fieldså³num_features\n",
    "    è¾“å‡ºshape: [batch_size, num_fields*(num_fields-1)/2, d_embed]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_fields, d_embed, bilinear_type=\"field_interaction\"):\n",
    "        super().__init__()\n",
    "        self.bilinear_type = bilinear_type\n",
    "        if self.bilinear_type == \"field_all\":\n",
    "            self.bilinear_layer = nn.Linear(d_embed, d_embed, bias=False)\n",
    "        elif self.bilinear_type == \"field_each\":\n",
    "            self.bilinear_layer = nn.ModuleList([nn.Linear(d_embed, d_embed, bias=False)\n",
    "                                                 for i in range(num_fields)])\n",
    "        elif self.bilinear_type == \"field_interaction\":\n",
    "            self.bilinear_layer = nn.ModuleList([nn.Linear(d_embed, d_embed, bias=False)\n",
    "                                                 for i, j in combinations(range(num_fields), 2)])\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def forward(self, feature_emb):\n",
    "        feature_emb_list = torch.split(feature_emb, 1, dim=1)\n",
    "        if self.bilinear_type == \"field_all\":\n",
    "            bilinear_list = [self.bilinear_layer(v_i) * v_j\n",
    "                             for v_i, v_j in combinations(feature_emb_list, 2)]\n",
    "        elif self.bilinear_type == \"field_each\":\n",
    "            bilinear_list = [self.bilinear_layer[i](feature_emb_list[i]) * feature_emb_list[j]\n",
    "                             for i, j in combinations(range(len(feature_emb_list)), 2)]\n",
    "        elif self.bilinear_type == \"field_interaction\":\n",
    "            bilinear_list = [self.bilinear_layer[i](v[0]) * v[1]\n",
    "                             for i, v in enumerate(combinations(feature_emb_list, 2))]\n",
    "        return torch.cat(bilinear_list, dim=1)\n",
    "    \n",
    "\n",
    "#mlp\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, d_in, d_layers, dropout, \n",
    "                 d_out = 1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for d in d_layers:\n",
    "            layers.append(nn.Linear(d_in, d))\n",
    "            layers.append(nn.BatchNorm1d(d))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            d_in = d\n",
    "        layers.append(nn.Linear(d_layers[-1], d_out))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        float tensor of size ``(batch_size, d_in)``\n",
    "        \"\"\"\n",
    "        return self.mlp(x)\n",
    "    \n",
    "\n",
    "#fibinet \n",
    "class FiBiNET(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 d_numerical, \n",
    "                 categories, \n",
    "                 d_embed,\n",
    "                 mlp_layers, \n",
    "                 mlp_dropout,\n",
    "                 reduction_ratio = 3,\n",
    "                 bilinear_type = \"field_interaction\",\n",
    "                 n_classes = 1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        if d_numerical is None:\n",
    "            d_numerical = 0\n",
    "        if categories is None:\n",
    "            categories = []\n",
    "            \n",
    "        self.categories = categories\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.num_linear = nn.Linear(d_numerical,n_classes) if d_numerical else None\n",
    "        self.cat_linear = CatLinear(categories,n_classes) if categories else None\n",
    "        \n",
    "        self.num_embedding = NumEmbedding(d_numerical,1,d_embed) if d_numerical else None\n",
    "        self.cat_embedding = CatEmbedding(categories, d_embed) if categories else None\n",
    "        \n",
    "        num_fields = d_numerical+len(categories)\n",
    "        \n",
    "        self.se_attention = SENetAttention(num_fields, reduction_ratio)\n",
    "        self.bilinear = BilinearInteraction(num_fields, d_embed, bilinear_type)\n",
    "        \n",
    "        mlp_in = num_fields * (num_fields - 1) * d_embed\n",
    "        self.mlp = MultiLayerPerceptron(\n",
    "            d_in= mlp_in,\n",
    "            d_layers = mlp_layers,\n",
    "            dropout = mlp_dropout,\n",
    "            d_out = n_classes\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x_num: numerical features\n",
    "        x_cat: category features\n",
    "        \"\"\"\n",
    "        x_num,x_cat = x\n",
    "        \n",
    "        #ä¸€ï¼Œwideéƒ¨åˆ†\n",
    "        x_linear = 0.0\n",
    "        if self.num_linear:\n",
    "            x_linear = x_linear + self.num_linear(x_num) \n",
    "        if self.cat_linear:\n",
    "            x_linear = x_linear + self.cat_linear(x_cat)\n",
    "            \n",
    "        #äºŒï¼Œdeepéƒ¨åˆ† \n",
    "        \n",
    "        #1ï¼Œembedding\n",
    "        x_embedding = []\n",
    "        if self.num_embedding:\n",
    "            x_embedding.append(self.num_embedding(x_num[...,None]))\n",
    "        if self.cat_embedding:\n",
    "            x_embedding.append(self.cat_embedding(x_cat))\n",
    "        x_embedding = torch.cat(x_embedding,dim=1)\n",
    "        \n",
    "        #2ï¼Œinteraction\n",
    "        se_embedding = self.se_attention(x_embedding)\n",
    "        ffm_out = self.bilinear(x_embedding)\n",
    "        se_ffm_out = self.bilinear(se_embedding)\n",
    "        x_interaction = torch.flatten(torch.cat([ffm_out, se_ffm_out], dim=1), start_dim=1)\n",
    "        \n",
    "        #3ï¼Œmlp\n",
    "        x_deep = self.mlp(x_interaction)\n",
    "        \n",
    "        #ä¸‰ï¼Œé«˜ä½èåˆ\n",
    "        x_out = x_linear+x_deep\n",
    "        if self.n_classes==1:\n",
    "            x_out = x_out.squeeze(-1)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##æµ‹è¯• FiBiNET\n",
    "\n",
    "model = FiBiNET(d_numerical = 3, categories = [4,3,2],\n",
    "        d_embed = 4, mlp_layers = [20,20], mlp_dropout=0.25,\n",
    "        reduction_ratio = 3,\n",
    "        bilinear_type = \"field_interaction\",\n",
    "        n_classes = 1)\n",
    "\n",
    "x_num = torch.randn(2,3)\n",
    "x_cat = torch.randint(0,2,(2,3))\n",
    "print(model((x_num,x_cat)))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2a960d",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([-0.8621,  0.6743], grad_fn=<SqueezeBackward1>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec37a4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72a05548",
   "metadata": {},
   "source": [
    "## ä¸‰ï¼ŒCriteoæ•°æ®é›†å®Œæ•´èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd5aef",
   "metadata": {},
   "source": [
    "Criteoæ•°æ®é›†æ˜¯ä¸€ä¸ªç»å…¸çš„å¹¿å‘Šç‚¹å‡»ç‡CTRé¢„æµ‹æ•°æ®é›†ã€‚\n",
    "\n",
    "è¿™ä¸ªæ•°æ®é›†çš„ç›®æ ‡æ˜¯é€šè¿‡ç”¨æˆ·ç‰¹å¾å’Œå¹¿å‘Šç‰¹å¾æ¥é¢„æµ‹æŸæ¡å¹¿å‘Šæ˜¯å¦ä¼šä¸ºç”¨æˆ·ç‚¹å‡»ã€‚\n",
    "\n",
    "æ•°æ®é›†æœ‰13ç»´æ•°å€¼ç‰¹å¾(I1-I13)å’Œ26ç»´ç±»åˆ«ç‰¹å¾(C14-C39), å…±39ç»´ç‰¹å¾, ç‰¹å¾ä¸­åŒ…å«ç€è®¸å¤šç¼ºå¤±å€¼ã€‚\n",
    "\n",
    "è®­ç»ƒé›†4000ä¸‡ä¸ªæ ·æœ¬ï¼Œæµ‹è¯•é›†600ä¸‡ä¸ªæ ·æœ¬ã€‚æ•°æ®é›†å¤§å°è¶…è¿‡100G.\n",
    "\n",
    "æ­¤å¤„ä½¿ç”¨çš„æ˜¯é‡‡æ ·100ä¸‡ä¸ªæ ·æœ¬åçš„cretio_smallæ•°æ®é›†ã€‚ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16474d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d99f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import datetime \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import torch \n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset,DataLoader  \n",
    "import torch.nn.functional as F \n",
    "import torchkeras \n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(info+'...\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f720c",
   "metadata": {},
   "source": [
    "### 1ï¼Œå‡†å¤‡æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf49cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,QuantileTransformer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "dfdata = pd.read_csv(\"./eat_pytorch_datasets/criteo_small.zip\",sep=\"\\t\",header=None)\n",
    "dfdata.columns = [\"label\"] + [\"I\"+str(x) for x in range(1,14)] + [\n",
    "    \"C\"+str(x) for x in range(14,40)]\n",
    "\n",
    "cat_cols = [x for x in dfdata.columns if x.startswith('C')]\n",
    "num_cols = [x for x in dfdata.columns if x.startswith('I')]\n",
    "num_pipe = Pipeline(steps = [('impute',SimpleImputer()),('quantile',QuantileTransformer())])\n",
    "\n",
    "for col in cat_cols:\n",
    "    dfdata[col]  = LabelEncoder().fit_transform(dfdata[col])\n",
    "\n",
    "dfdata[num_cols] = num_pipe.fit_transform(dfdata[num_cols])\n",
    "\n",
    "categories = [dfdata[col].max()+1 for col in cat_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e22fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset,DataLoader \n",
    "\n",
    "#DataFrameè½¬æ¢æˆtorchæ•°æ®é›†Dataset, ç‰¹å¾åˆ†å‰²æˆX_num,X_catæ–¹å¼\n",
    "class DfDataset(Dataset):\n",
    "    def __init__(self,df,\n",
    "                 label_col,\n",
    "                 num_features,\n",
    "                 cat_features,\n",
    "                 categories,\n",
    "                 is_training=True):\n",
    "        \n",
    "        self.X_num = torch.tensor(df[num_features].values).float() if num_features else None\n",
    "        self.X_cat = torch.tensor(df[cat_features].values).long() if cat_features else None\n",
    "        self.Y = torch.tensor(df[label_col].values).float() \n",
    "        self.categories = categories\n",
    "        self.is_training = is_training\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        if self.is_training:\n",
    "            return ((self.X_num[index],self.X_cat[index]),self.Y[index])\n",
    "        else:\n",
    "            return (self.X_num[index],self.X_cat[index])\n",
    "    \n",
    "    def get_categories(self):\n",
    "        return self.categories\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fcdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain_val,dftest = train_test_split(dfdata,test_size=0.2)\n",
    "dftrain,dfval = train_test_split(dftrain_val,test_size=0.2)\n",
    "\n",
    "ds_train = DfDataset(dftrain,label_col = \"label\",num_features = num_cols,cat_features = cat_cols,\n",
    "                    categories = categories, is_training=True)\n",
    "\n",
    "ds_val = DfDataset(dfval,label_col = \"label\",num_features = num_cols,cat_features = cat_cols,\n",
    "                    categories = categories, is_training=True)\n",
    "\n",
    "ds_test = DfDataset(dftest,label_col = \"label\",num_features = num_cols,cat_features = cat_cols,\n",
    "                    categories = categories, is_training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train,batch_size = 2048,shuffle=True)\n",
    "dl_val = DataLoader(ds_val,batch_size = 2048,shuffle=False)\n",
    "dl_test = DataLoader(ds_test,batch_size = 2048,shuffle=False)\n",
    "\n",
    "for features,labels in dl_train:\n",
    "    break \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83da026",
   "metadata": {},
   "source": [
    "### 2ï¼Œå®šä¹‰æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net():\n",
    "    net = FiBiNET(\n",
    "        d_numerical= ds_train.X_num.shape[1],\n",
    "        categories= ds_train.get_categories(),\n",
    "        d_embed = 8, mlp_layers = [128,64,32], mlp_dropout=0.25,\n",
    "        reduction_ratio = 3,\n",
    "        bilinear_type = \"field_all\",\n",
    "        n_classes = 1\n",
    "        \n",
    "    )\n",
    "    return net \n",
    "\n",
    "from torchkeras import summary\n",
    "\n",
    "net = create_net()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd54b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e51aff2e",
   "metadata": {},
   "source": [
    "### 3ï¼Œè®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd5a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "from accelerate import Accelerator\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(str(info)+\"\\n\")\n",
    "    \n",
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn,stage = \"train\", metrics_dict = None, \n",
    "                 optimizer = None, lr_scheduler = None,\n",
    "                 accelerator = None\n",
    "                 ):\n",
    "        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n",
    "        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n",
    "        self.accelerator = accelerator\n",
    "    \n",
    "    def __call__(self, features, labels):\n",
    "        #loss\n",
    "        preds = self.net(features)\n",
    "        loss = self.loss_fn(preds,labels)\n",
    "\n",
    "        #backward()\n",
    "        if self.optimizer is not None and self.stage==\"train\":\n",
    "            if self.accelerator is  None:\n",
    "                loss.backward()\n",
    "            else:\n",
    "                self.accelerator.backward(loss)\n",
    "            self.optimizer.step()\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "        #metrics\n",
    "        step_metrics = {self.stage+\"_\"+name:metric_fn(preds, labels).item() \n",
    "                        for name,metric_fn in self.metrics_dict.items()}\n",
    "        return loss.item(),step_metrics\n",
    "    \n",
    "    \n",
    "class EpochRunner:\n",
    "    def __init__(self,steprunner):\n",
    "        self.steprunner = steprunner\n",
    "        self.stage = steprunner.stage\n",
    "        self.steprunner.net.train() if self.stage==\"train\" else self.steprunner.net.eval()\n",
    "        \n",
    "    def __call__(self,dataloader):\n",
    "        total_loss,step = 0,0\n",
    "        loop = tqdm(enumerate(dataloader), total =len(dataloader))\n",
    "        for i, batch in loop:\n",
    "            features,labels = batch\n",
    "            if self.stage==\"train\":\n",
    "                loss, step_metrics = self.steprunner(features,labels)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    loss, step_metrics = self.steprunner(features,labels)\n",
    "\n",
    "            step_log = dict({self.stage+\"_loss\":loss},**step_metrics)\n",
    "\n",
    "            total_loss += loss\n",
    "            step+=1\n",
    "            if i!=len(dataloader)-1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                epoch_loss = total_loss/step\n",
    "                epoch_metrics = {self.stage+\"_\"+name:metric_fn.compute().item() \n",
    "                                 for name,metric_fn in self.steprunner.metrics_dict.items()}\n",
    "                epoch_log = dict({self.stage+\"_loss\":epoch_loss},**epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name,metric_fn in self.steprunner.metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "        return epoch_log\n",
    "\n",
    "class KerasModel(torch.nn.Module):\n",
    "    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None):\n",
    "        super().__init__()\n",
    "        self.accelerator = Accelerator()\n",
    "        self.history = {}\n",
    "        \n",
    "        self.net = net\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metrics_dict = nn.ModuleDict(metrics_dict) \n",
    "        \n",
    "        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(\n",
    "            self.parameters(), lr=1e-2)\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        \n",
    "        self.net,self.loss_fn,self.metrics_dict,self.optimizer = self.accelerator.prepare(\n",
    "            self.net,self.loss_fn,self.metrics_dict,self.optimizer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.net:\n",
    "            return self.net.forward(x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint.pt', \n",
    "            patience=5, monitor=\"val_loss\", mode=\"min\"):\n",
    "        \n",
    "        train_data = self.accelerator.prepare(train_data)\n",
    "        val_data = self.accelerator.prepare(val_data) if val_data else []\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "            printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "            \n",
    "            # 1ï¼Œtrain -------------------------------------------------  \n",
    "            train_step_runner = StepRunner(net = self.net,stage=\"train\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),\n",
    "                    optimizer = self.optimizer, lr_scheduler = self.lr_scheduler,\n",
    "                    accelerator = self.accelerator)\n",
    "            train_epoch_runner = EpochRunner(train_step_runner)\n",
    "            train_metrics = train_epoch_runner(train_data)\n",
    "            \n",
    "            for name, metric in train_metrics.items():\n",
    "                self.history[name] = self.history.get(name, []) + [metric]\n",
    "\n",
    "            # 2ï¼Œvalidate -------------------------------------------------\n",
    "            if val_data:\n",
    "                val_step_runner = StepRunner(net = self.net,stage=\"val\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),\n",
    "                    accelerator = self.accelerator)\n",
    "                val_epoch_runner = EpochRunner(val_step_runner)\n",
    "                with torch.no_grad():\n",
    "                    val_metrics = val_epoch_runner(val_data)\n",
    "                val_metrics[\"epoch\"] = epoch\n",
    "                for name, metric in val_metrics.items():\n",
    "                    self.history[name] = self.history.get(name, []) + [metric]\n",
    "            \n",
    "            # 3ï¼Œearly-stopping -------------------------------------------------\n",
    "            arr_scores = self.history[monitor]\n",
    "            best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "            if best_score_idx==len(arr_scores)-1:\n",
    "                torch.save(self.net.state_dict(),ckpt_path)\n",
    "                print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "                     arr_scores[best_score_idx]),file=sys.stderr)\n",
    "            if len(arr_scores)-best_score_idx>patience:\n",
    "                print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "                    monitor,patience),file=sys.stderr)\n",
    "                self.net.load_state_dict(torch.load(ckpt_path))\n",
    "                break \n",
    "            \n",
    "        return pd.DataFrame(self.history)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, val_data):\n",
    "        val_data = self.accelerator.prepare(val_data)\n",
    "        val_step_runner = StepRunner(net = self.net,stage=\"val\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),\n",
    "                    accelerator = self.accelerator)\n",
    "        val_epoch_runner = EpochRunner(val_step_runner)\n",
    "        val_metrics = val_epoch_runner(val_data)\n",
    "        return val_metrics\n",
    "        \n",
    "       \n",
    "    @torch.no_grad()\n",
    "    def predict(self, dataloader):\n",
    "        dataloader = self.accelerator.prepare(dataloader)\n",
    "        result = torch.cat([self.forward(t[0]) for t in dataloader])\n",
    "        return result.data\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81598c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras.metrics import AUC\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "metrics_dict = {\"auc\":AUC()}\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.002, weight_decay=0.001) \n",
    "\n",
    "model = KerasModel(net,\n",
    "                   loss_fn = loss_fn,\n",
    "                   metrics_dict= metrics_dict,\n",
    "                   optimizer = optimizer\n",
    "                  )         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd242b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhistory = model.fit(train_data=dl_train,val_data=dl_val,epochs=100, patience=5,\n",
    "                      monitor = \"val_auc\",mode=\"max\",ckpt_path='checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e82e1a5",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2t3twovonj20my0axq4j.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994bf3e",
   "metadata": {},
   "source": [
    "### 4ï¼Œè¯„ä¼°æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b68fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(dfhistory, metric):\n",
    "    train_metrics = dfhistory[\"train_\"+metric]\n",
    "    val_metrics = dfhistory['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b334a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c19734",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2t3tup3hxj20gc0af74n.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"auc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4169cb05",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2t3tuemikj20f70ait90.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b04a53e",
   "metadata": {},
   "source": [
    "### 5ï¼Œä½¿ç”¨æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b356206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "preds = torch.sigmoid(model.predict(dl_val))\n",
    "labels = torch.cat([x[-1] for x in dl_val])\n",
    "\n",
    "val_auc = roc_auc_score(labels.cpu().numpy(),preds.cpu().numpy())\n",
    "print(val_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56ee74b",
   "metadata": {},
   "source": [
    "0.7806176567186112"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48965f11",
   "metadata": {},
   "source": [
    "### 6ï¼Œä¿å­˜æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bda74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.net.state_dict(),\"best_fibinet.pt\")\n",
    "net_clone = create_net()\n",
    "net_clone.load_state_dict(torch.load(\"best_fibinet.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c343ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "net_clone.eval()\n",
    "preds = torch.cat([torch.sigmoid(net_clone(x[0])).data for x in dl_val]) \n",
    "labels = torch.cat([x[-1] for x in dl_val])\n",
    "\n",
    "val_auc = roc_auc_score(labels.cpu().numpy(),preds.cpu().numpy())\n",
    "print(val_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922378d",
   "metadata": {},
   "source": [
    "0.7806176567186112"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22370240",
   "metadata": {},
   "source": [
    "å¯ä»¥çœ‹åˆ°FiBiNETåœ¨éªŒè¯é›†çš„AUCå¾—åˆ†ä¸º0.7806,ç›¸æ¯”ä¹‹ä¸‹DeepFMçš„éªŒè¯é›†AUCä¸º0.7803ã€‚\n",
    "\n",
    "ä¸èƒ½è¯´çº¹ä¸ä¸åŠ¨, åªèƒ½è¯´äº†æ¶¨äº†ä¸ªèšŠå­è…¿å¤§å°è‚‰çš„ç‚¹ã€‚\n",
    "\n",
    "å¹¶ä¸”è¿™æ˜¯ä»¥è¾ƒå¤§åœ°ç‰ºç‰²æ¨¡å‹è®­ç»ƒé¢„æµ‹æ•ˆç‡ä¸ºä»£ä»·çš„ã€‚\n",
    "\n",
    "DeepFMè®­ç»ƒä¸€ä¸ªEpochå¤§çº¦éœ€è¦20s, è€ŒFiBiNETè®­ç»ƒä¸€ä¸ªEpochéœ€è¦å¤§çº¦2min.\n",
    "\n",
    "å°½ç®¡å¦‚æ­¤, FiBiNETçš„ç»“æ„è®¾è®¡ä¾ç„¶æ˜¯å€¼å¾—æˆ‘ä»¬å­¦ä¹ å’Œå€Ÿé‰´çš„, é›†ç¥ç»ç½‘ç»œç»“æ„è®¾è®¡ä¸‰å¤§ä¸»æµé«˜çº§æŠ€å·§äºä¸€ä½“, é—ªçƒç€ç©¿è¶Šæ—¶ç©ºçš„æ‰åä¸æ™ºæ…§å…‰èŠ’ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f14a3",
   "metadata": {},
   "source": [
    "**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** \n",
    "\n",
    "å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·\"ç®—æ³•ç¾é£Ÿå±‹\"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚\n",
    "\n",
    "![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
