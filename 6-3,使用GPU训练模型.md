
# 6-3,ä½¿ç”¨GPUè®­ç»ƒæ¨¡å‹


æ·±åº¦å­¦ä¹ çš„è®­ç»ƒè¿‡ç¨‹å¸¸å¸¸éå¸¸è€—æ—¶ï¼Œä¸€ä¸ªæ¨¡å‹è®­ç»ƒå‡ ä¸ªå°æ—¶æ˜¯å®¶å¸¸ä¾¿é¥­ï¼Œè®­ç»ƒå‡ å¤©ä¹Ÿæ˜¯å¸¸æœ‰çš„äº‹æƒ…ï¼Œæœ‰æ—¶å€™ç”šè‡³è¦è®­ç»ƒå‡ åå¤©ã€‚

è®­ç»ƒè¿‡ç¨‹çš„è€—æ—¶ä¸»è¦æ¥è‡ªäºä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†æ¥è‡ªæ•°æ®å‡†å¤‡ï¼Œå¦ä¸€éƒ¨åˆ†æ¥è‡ªå‚æ•°è¿­ä»£ã€‚

å½“æ•°æ®å‡†å¤‡è¿‡ç¨‹è¿˜æ˜¯æ¨¡å‹è®­ç»ƒæ—¶é—´çš„ä¸»è¦ç“¶é¢ˆæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ›´å¤šè¿›ç¨‹æ¥å‡†å¤‡æ•°æ®ã€‚

å½“å‚æ•°è¿­ä»£è¿‡ç¨‹æˆä¸ºè®­ç»ƒæ—¶é—´çš„ä¸»è¦ç“¶é¢ˆæ—¶ï¼Œæˆ‘ä»¬é€šå¸¸çš„æ–¹æ³•æ˜¯åº”ç”¨GPUæ¥è¿›è¡ŒåŠ é€Ÿã€‚

```python
import torch 
import torchkeras 

print("torch.__version__ = ",torch.__version__)
print("torchkeras.__version__ = ",torchkeras.__version__)

```

<!-- #region -->
æ³¨ï¼šæœ¬èŠ‚ä»£ç åªèƒ½åœ¨æœ‰GPUçš„æœºå™¨ç¯å¢ƒä¸Šæ‰èƒ½æ­£ç¡®æ‰§è¡Œã€‚

å¯¹äºæ²¡æœ‰GPUçš„åŒå­¦ï¼Œæ¨èä½¿ç”¨kaggleå¹³å°ä¸Šçš„GPUã€‚


å¯ç‚¹å‡»å¦‚ä¸‹é“¾æ¥ï¼Œç›´æ¥åœ¨kaggleä¸­è¿è¡ŒèŒƒä¾‹ä»£ç ã€‚

https://www.kaggle.com/lyhue1991/pytorch-gpu-examples


<!-- #endregion -->

<!-- #region -->
Pytorchä¸­ä½¿ç”¨GPUåŠ é€Ÿæ¨¡å‹éå¸¸ç®€å•ï¼Œåªè¦å°†æ¨¡å‹å’Œæ•°æ®ç§»åŠ¨åˆ°GPUä¸Šã€‚æ ¸å¿ƒä»£ç åªæœ‰ä»¥ä¸‹å‡ è¡Œã€‚

```python
# å®šä¹‰æ¨¡å‹
... 

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device) # ç§»åŠ¨æ¨¡å‹åˆ°cuda

# è®­ç»ƒæ¨¡å‹
...

features = features.to(device) # ç§»åŠ¨æ•°æ®åˆ°cuda
labels = labels.to(device) # æˆ–è€…  labels = labels.cuda() if torch.cuda.is_available() else labels
...
```

å¦‚æœè¦ä½¿ç”¨å¤šä¸ªGPUè®­ç»ƒæ¨¡å‹ï¼Œä¹Ÿéå¸¸ç®€å•ã€‚åªéœ€è¦åœ¨å°†æ¨¡å‹è®¾ç½®ä¸ºæ•°æ®å¹¶è¡Œé£æ ¼æ¨¡å‹ã€‚
åˆ™æ¨¡å‹ç§»åŠ¨åˆ°GPUä¸Šä¹‹åï¼Œä¼šåœ¨æ¯ä¸€ä¸ªGPUä¸Šæ‹·è´ä¸€ä¸ªå‰¯æœ¬ï¼Œå¹¶æŠŠæ•°æ®å¹³åˆ†åˆ°å„ä¸ªGPUä¸Šè¿›è¡Œè®­ç»ƒã€‚æ ¸å¿ƒä»£ç å¦‚ä¸‹ã€‚

```python
# å®šä¹‰æ¨¡å‹
... 

if torch.cuda.device_count() > 1:
    model = nn.DataParallel(model) # åŒ…è£…ä¸ºå¹¶è¡Œé£æ ¼æ¨¡å‹

# è®­ç»ƒæ¨¡å‹
...
features = features.to(device) # ç§»åŠ¨æ•°æ®åˆ°cuda
labels = labels.to(device) # æˆ–è€… labels = labels.cuda() if torch.cuda.is_available() else labels
...
```
<!-- #endregion -->

## ã€‡ï¼ŒGPUç›¸å…³æ“ä½œæ±‡æ€»

```python
import torch 
from torch import nn 

# 1ï¼ŒæŸ¥çœ‹gpuä¿¡æ¯
if_cuda = torch.cuda.is_available()
print("if_cuda=",if_cuda)

gpu_count = torch.cuda.device_count()
print("gpu_count=",gpu_count)

```

```python
# 2ï¼Œå°†å¼ é‡åœ¨gpuå’Œcpué—´ç§»åŠ¨
tensor = torch.rand((100,100))
tensor_gpu = tensor.to("cuda:0") # æˆ–è€… tensor_gpu = tensor.cuda()
print(tensor_gpu.device)
print(tensor_gpu.is_cuda)

tensor_cpu = tensor_gpu.to("cpu") # æˆ–è€… tensor_cpu = tensor_gpu.cpu() 
print(tensor_cpu.device)

```

```python
# 3ï¼Œå°†æ¨¡å‹ä¸­çš„å…¨éƒ¨å¼ é‡ç§»åŠ¨åˆ°gpuä¸Š
net = nn.Linear(2,1)
print(next(net.parameters()).is_cuda)
net.to("cuda:0") # å°†æ¨¡å‹ä¸­çš„å…¨éƒ¨å‚æ•°å¼ é‡ä¾æ¬¡åˆ°GPUä¸Šï¼Œæ³¨æ„ï¼Œæ— éœ€é‡æ–°èµ‹å€¼ä¸º net = net.to("cuda:0")
print(next(net.parameters()).is_cuda)
print(next(net.parameters()).device)

```

```python
# 4ï¼Œåˆ›å»ºæ”¯æŒå¤šä¸ªgpuæ•°æ®å¹¶è¡Œçš„æ¨¡å‹
linear = nn.Linear(2,1)
print(next(linear.parameters()).device)

model = nn.DataParallel(linear)
print(model.device_ids)
print(next(model.module.parameters()).device) 

#æ³¨æ„ä¿å­˜å‚æ•°æ—¶è¦æŒ‡å®šä¿å­˜model.moduleçš„å‚æ•°
torch.save(model.module.state_dict(), "model_parameter.pt") 

linear = nn.Linear(2,1)
linear.load_state_dict(torch.load("model_parameter.pt")) 

```

## ä¸€ï¼ŒçŸ©é˜µä¹˜æ³•èŒƒä¾‹


ä¸‹é¢åˆ†åˆ«ä½¿ç”¨CPUå’ŒGPUä½œä¸€ä¸ªçŸ©é˜µä¹˜æ³•ï¼Œå¹¶æ¯”è¾ƒå…¶è®¡ç®—æ•ˆç‡ã€‚

```python
import time
import torch 
from torch import nn
```

```python
# ä½¿ç”¨cpu
a = torch.rand((10000,200))
b = torch.rand((200,10000))
tic = time.time()
c = torch.matmul(a,b)
toc = time.time()

print(toc-tic)
print(a.device)
print(b.device)
```

```python
# ä½¿ç”¨gpu
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
a = torch.rand((10000,200),device = device) #å¯ä»¥æŒ‡å®šåœ¨GPUä¸Šåˆ›å»ºå¼ é‡
b = torch.rand((200,10000)) #ä¹Ÿå¯ä»¥åœ¨CPUä¸Šåˆ›å»ºå¼ é‡åç§»åŠ¨åˆ°GPUä¸Š
b = b.to(device) #æˆ–è€… b = b.cuda() if torch.cuda.is_available() else b 
tic = time.time()
c = torch.matmul(a,b)
toc = time.time()
print(toc-tic)
print(a.device)
print(b.device)

```

```python

```

## äºŒï¼Œçº¿æ€§å›å½’èŒƒä¾‹


ä¸‹é¢å¯¹æ¯”ä½¿ç”¨CPUå’ŒGPUè®­ç»ƒä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹çš„æ•ˆç‡


### 1ï¼Œä½¿ç”¨CPU

```python
# å‡†å¤‡æ•°æ®
n = 1000000 #æ ·æœ¬æ•°é‡

X = 10*torch.rand([n,2])-5.0  #torch.randæ˜¯å‡åŒ€åˆ†å¸ƒ 
w0 = torch.tensor([[2.0,-3.0]])
b0 = torch.tensor([[10.0]])
Y = X@w0.t() + b0 + torch.normal( 0.0,2.0,size = [n,1])  # @è¡¨ç¤ºçŸ©é˜µä¹˜æ³•,å¢åŠ æ­£æ€æ‰°åŠ¨
```

```python
# å®šä¹‰æ¨¡å‹
class LinearRegression(nn.Module): 
    def __init__(self):
        super().__init__()
        self.w = nn.Parameter(torch.randn_like(w0))
        self.b = nn.Parameter(torch.zeros_like(b0))
    #æ­£å‘ä¼ æ’­
    def forward(self,x): 
        return x@self.w.t() + self.b
        
linear = LinearRegression() 

```

```python
# è®­ç»ƒæ¨¡å‹
optimizer = torch.optim.Adam(linear.parameters(),lr = 0.1)
loss_fn = nn.MSELoss()

def train(epoches):
    tic = time.time()
    for epoch in range(epoches):
        optimizer.zero_grad()
        Y_pred = linear(X) 
        loss = loss_fn(Y_pred,Y)
        loss.backward() 
        optimizer.step()
        if epoch%50==0:
            print({"epoch":epoch,"loss":loss.item()})
    toc = time.time()
    print("time used:",toc-tic)

train(500)
```

### 2ï¼Œä½¿ç”¨GPU

```python
# å‡†å¤‡æ•°æ®
n = 1000000 #æ ·æœ¬æ•°é‡

X = 10*torch.rand([n,2])-5.0  #torch.randæ˜¯å‡åŒ€åˆ†å¸ƒ 
w0 = torch.tensor([[2.0,-3.0]])
b0 = torch.tensor([[10.0]])
Y = X@w0.t() + b0 + torch.normal( 0.0,2.0,size = [n,1])  # @è¡¨ç¤ºçŸ©é˜µä¹˜æ³•,å¢åŠ æ­£æ€æ‰°åŠ¨

# æ•°æ®ç§»åŠ¨åˆ°GPUä¸Š
print("torch.cuda.is_available() = ",torch.cuda.is_available())
X = X.cuda()
Y = Y.cuda()
print("X.device:",X.device)
print("Y.device:",Y.device)
```

```python
# å®šä¹‰æ¨¡å‹
class LinearRegression(nn.Module): 
    def __init__(self):
        super().__init__()
        self.w = nn.Parameter(torch.randn_like(w0))
        self.b = nn.Parameter(torch.zeros_like(b0))
    #æ­£å‘ä¼ æ’­
    def forward(self,x): 
        return x@self.w.t() + self.b
        
linear = LinearRegression() 

# ç§»åŠ¨æ¨¡å‹åˆ°GPUä¸Š
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
linear.to(device)

#æŸ¥çœ‹æ¨¡å‹æ˜¯å¦å·²ç»ç§»åŠ¨åˆ°GPUä¸Š
print("if on cuda:",next(linear.parameters()).is_cuda)

```

```python
# è®­ç»ƒæ¨¡å‹
optimizer = torch.optim.Adam(linear.parameters(),lr = 0.1)
loss_fn = nn.MSELoss()

def train(epoches):
    tic = time.time()
    for epoch in range(epoches):
        optimizer.zero_grad()
        Y_pred = linear(X) 
        loss = loss_fn(Y_pred,Y)
        loss.backward() 
        optimizer.step()
        if epoch%50==0:
            print({"epoch":epoch,"loss":loss.item()})
    toc = time.time()
    print("time used:",toc-tic)
    
train(500)
```

```python

```

## ä¸‰ï¼Œå›¾ç‰‡åˆ†ç±»èŒƒä¾‹

```python
import torch 
from torch import nn 

import torchvision 
from torchvision import transforms
```

```python
transform = transforms.Compose([transforms.ToTensor()])

ds_train = torchvision.datasets.MNIST(root="minist/",train=True,download=True,transform=transform)
ds_val = torchvision.datasets.MNIST(root="minist/",train=False,download=True,transform=transform)

dl_train =  torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=4)
dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=128, shuffle=False, num_workers=4)

print(len(ds_train))
print(len(ds_val))

```

```python
def create_net():
    net = nn.Sequential()
    net.add_module("conv1",nn.Conv2d(in_channels=1,out_channels=32,kernel_size = 3))
    net.add_module("pool1",nn.MaxPool2d(kernel_size = 2,stride = 2))
    net.add_module("conv2",nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5))
    net.add_module("pool2",nn.MaxPool2d(kernel_size = 2,stride = 2))
    net.add_module("dropout",nn.Dropout2d(p = 0.1))
    net.add_module("adaptive_pool",nn.AdaptiveMaxPool2d((1,1)))
    net.add_module("flatten",nn.Flatten())
    net.add_module("linear1",nn.Linear(64,32))
    net.add_module("relu",nn.ReLU())
    net.add_module("linear2",nn.Linear(32,10))
    return net

net = create_net()
print(net)
```

### 1ï¼Œä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ

```python
import os,sys,time
import numpy as np
import pandas as pd
import datetime 
from tqdm import tqdm 

import torch
from torch import nn 
from copy import deepcopy
from torchmetrics import Accuracy
#æ³¨ï¼šå¤šåˆ†ç±»ä½¿ç”¨torchmetricsä¸­çš„è¯„ä¼°æŒ‡æ ‡ï¼ŒäºŒåˆ†ç±»ä½¿ç”¨torchkeras.metricsä¸­çš„è¯„ä¼°æŒ‡æ ‡

def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(str(info)+"\n")
    

net = create_net() 

loss_fn = nn.CrossEntropyLoss()
optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   
metrics_dict = {"acc":Accuracy()}

epochs = 20 
ckpt_path='checkpoint.pt'

#early_stoppingç›¸å…³è®¾ç½®
monitor="val_acc"
patience=5
mode="max"

history = {}

for epoch in range(1, epochs+1):
    printlog("Epoch {0} / {1}".format(epoch, epochs))

    # 1ï¼Œtrain -------------------------------------------------  
    net.train()
    
    total_loss,step = 0,0
    
    loop = tqdm(enumerate(dl_train), total =len(dl_train))
    train_metrics_dict = deepcopy(metrics_dict) 
    
    for i, batch in loop: 
        
        features,labels = batch
        #forward
        preds = net(features)
        loss = loss_fn(preds,labels)
        
        #backward
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
            
        #metrics
        step_metrics = {"train_"+name:metric_fn(preds, labels).item() 
                        for name,metric_fn in train_metrics_dict.items()}
        
        step_log = dict({"train_loss":loss.item()},**step_metrics)

        total_loss += loss.item()
        
        step+=1
        if i!=len(dl_train)-1:
            loop.set_postfix(**step_log)
        else:
            epoch_loss = total_loss/step
            epoch_metrics = {"train_"+name:metric_fn.compute().item() 
                             for name,metric_fn in train_metrics_dict.items()}
            epoch_log = dict({"train_loss":epoch_loss},**epoch_metrics)
            loop.set_postfix(**epoch_log)

            for name,metric_fn in train_metrics_dict.items():
                metric_fn.reset()
                
    for name, metric in epoch_log.items():
        history[name] = history.get(name, []) + [metric]
        

    # 2ï¼Œvalidate -------------------------------------------------
    net.eval()
    
    total_loss,step = 0,0
    loop = tqdm(enumerate(dl_val), total =len(dl_val))
    
    val_metrics_dict = deepcopy(metrics_dict) 
    
    with torch.no_grad():
        for i, batch in loop: 

            features,labels = batch
            
            #forward
            preds = net(features)
            loss = loss_fn(preds,labels)

            #metrics
            step_metrics = {"val_"+name:metric_fn(preds, labels).item() 
                            for name,metric_fn in val_metrics_dict.items()}

            step_log = dict({"val_loss":loss.item()},**step_metrics)

            total_loss += loss.item()
            step+=1
            if i!=len(dl_val)-1:
                loop.set_postfix(**step_log)
            else:
                epoch_loss = (total_loss/step)
                epoch_metrics = {"val_"+name:metric_fn.compute().item() 
                                 for name,metric_fn in val_metrics_dict.items()}
                epoch_log = dict({"val_loss":epoch_loss},**epoch_metrics)
                loop.set_postfix(**epoch_log)

                for name,metric_fn in val_metrics_dict.items():
                    metric_fn.reset()
                    
    epoch_log["epoch"] = epoch           
    for name, metric in epoch_log.items():
        history[name] = history.get(name, []) + [metric]

    # 3ï¼Œearly-stopping -------------------------------------------------
    arr_scores = history[monitor]
    best_score_idx = np.argmax(arr_scores) if mode=="max" else np.argmin(arr_scores)
    if best_score_idx==len(arr_scores)-1:
        torch.save(net.state_dict(),ckpt_path)
        print("<<<<<< reach best {0} : {1} >>>>>>".format(monitor,
             arr_scores[best_score_idx]),file=sys.stderr)
    if len(arr_scores)-best_score_idx>patience:
        print("<<<<<< {} without improvement in {} epoch, early stopping >>>>>>".format(
            monitor,patience),file=sys.stderr)
        break 
    net.load_state_dict(torch.load(ckpt_path))
    
dfhistory = pd.DataFrame(history)

```

<!-- #region -->
================================================================================2022-07-17 15:07:03
Epoch 1 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:57<00:00,  8.15it/s, train_acc=0.909, train_loss=0.279] 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 16.80it/s, val_acc=0.956, val_loss=0.147] 

================================================================================2022-07-17 15:08:06
Epoch 2 / 20


<<<<<< reach best val_acc : 0.9556000232696533 >>>>>>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:58<00:00,  8.03it/s, train_acc=0.968, train_loss=0.105] 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 18.59it/s, val_acc=0.977, val_loss=0.0849]

================================================================================2022-07-17 15:09:09
Epoch 3 / 20


<<<<<< reach best val_acc : 0.9765999913215637 >>>>>>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:58<00:00,  8.07it/s, train_acc=0.974, train_loss=0.0882]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 17.13it/s, val_acc=0.984, val_loss=0.0554] 
<<<<<< reach best val_acc : 0.9843000173568726 >>>>>>

================================================================================2022-07-17 15:10:12
Epoch 4 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [01:01<00:00,  7.63it/s, train_acc=0.976, train_loss=0.0814] 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 16.34it/s, val_acc=0.979, val_loss=0.0708]

================================================================================2022-07-17 15:11:18
Epoch 5 / 20


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [01:03<00:00,  7.42it/s, train_acc=0.974, train_loss=0.0896]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:05<00:00, 14.06it/s, val_acc=0.979, val_loss=0.076] 

================================================================================2022-07-17 15:12:28
Epoch 6 / 20


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [01:00<00:00,  7.77it/s, train_acc=0.972, train_loss=0.0937]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 17.45it/s, val_acc=0.976, val_loss=0.0787] 

================================================================================2022-07-17 15:13:33
Epoch 7 / 20


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [01:01<00:00,  7.63it/s, train_acc=0.974, train_loss=0.0858]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:05<00:00, 14.50it/s, val_acc=0.976, val_loss=0.082] 

================================================================================2022-07-17 15:14:40
Epoch 8 / 20


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:59<00:00,  7.85it/s, train_acc=0.972, train_loss=0.0944]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 17.21it/s, val_acc=0.982, val_loss=0.062] 
<<<<<< val_acc without improvement in 5 epoch, early stopping >>>>>>

<!-- #endregion -->

CPUæ¯ä¸ªEpochå¤§æ¦‚1åˆ†é’Ÿ


### 2ï¼Œä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒ

```python
import os,sys,time
import numpy as np
import pandas as pd
import datetime 
from tqdm import tqdm 

import torch
from torch import nn 
from copy import deepcopy
from torchmetrics import Accuracy
#æ³¨ï¼šå¤šåˆ†ç±»ä½¿ç”¨torchmetricsä¸­çš„è¯„ä¼°æŒ‡æ ‡ï¼ŒäºŒåˆ†ç±»ä½¿ç”¨torchkeras.metricsä¸­çš„è¯„ä¼°æŒ‡æ ‡

def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(str(info)+"\n")
    
net = create_net() 


loss_fn = nn.CrossEntropyLoss()
optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   
metrics_dict = {"acc":Accuracy()}


# =========================ç§»åŠ¨æ¨¡å‹åˆ°GPUä¸Š==============================
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
net.to(device)
loss_fn.to(device)
for name,fn in metrics_dict.items():
    fn.to(device)
# ====================================================================


epochs = 20 
ckpt_path='checkpoint.pt'

#early_stoppingç›¸å…³è®¾ç½®
monitor="val_acc"
patience=5
mode="max"

history = {}

for epoch in range(1, epochs+1):
    printlog("Epoch {0} / {1}".format(epoch, epochs))

    # 1ï¼Œtrain -------------------------------------------------  
    net.train()
    
    total_loss,step = 0,0
    
    loop = tqdm(enumerate(dl_train), total =len(dl_train))
    train_metrics_dict = deepcopy(metrics_dict) 
    
    for i, batch in loop: 
        
        features,labels = batch
        
        # =========================ç§»åŠ¨æ•°æ®åˆ°GPUä¸Š==============================
        features = features.to(device)
        labels = labels.to(device)
        # ====================================================================
        
        #forward
        preds = net(features)
        loss = loss_fn(preds,labels)
        
        #backward
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
            
        #metrics
        step_metrics = {"train_"+name:metric_fn(preds, labels).item() 
                        for name,metric_fn in train_metrics_dict.items()}
        
        step_log = dict({"train_loss":loss.item()},**step_metrics)

        total_loss += loss.item()
        
        step+=1
        if i!=len(dl_train)-1:
            loop.set_postfix(**step_log)
        else:
            epoch_loss = total_loss/step
            epoch_metrics = {"train_"+name:metric_fn.compute().item() 
                             for name,metric_fn in train_metrics_dict.items()}
            epoch_log = dict({"train_loss":epoch_loss},**epoch_metrics)
            loop.set_postfix(**epoch_log)

            for name,metric_fn in train_metrics_dict.items():
                metric_fn.reset()
                
    for name, metric in epoch_log.items():
        history[name] = history.get(name, []) + [metric]
        

    # 2ï¼Œvalidate -------------------------------------------------
    net.eval()
    
    total_loss,step = 0,0
    loop = tqdm(enumerate(dl_val), total =len(dl_val))
    
    val_metrics_dict = deepcopy(metrics_dict) 
    
    with torch.no_grad():
        for i, batch in loop: 

            features,labels = batch
            
            # =========================ç§»åŠ¨æ•°æ®åˆ°GPUä¸Š==============================
            features = features.to(device)
            labels = labels.to(device)
            # ====================================================================
            
            #forward
            preds = net(features)
            loss = loss_fn(preds,labels)

            #metrics
            step_metrics = {"val_"+name:metric_fn(preds, labels).item() 
                            for name,metric_fn in val_metrics_dict.items()}

            step_log = dict({"val_loss":loss.item()},**step_metrics)

            total_loss += loss.item()
            step+=1
            if i!=len(dl_val)-1:
                loop.set_postfix(**step_log)
            else:
                epoch_loss = (total_loss/step)
                epoch_metrics = {"val_"+name:metric_fn.compute().item() 
                                 for name,metric_fn in val_metrics_dict.items()}
                epoch_log = dict({"val_loss":epoch_loss},**epoch_metrics)
                loop.set_postfix(**epoch_log)

                for name,metric_fn in val_metrics_dict.items():
                    metric_fn.reset()
                    
    epoch_log["epoch"] = epoch           
    for name, metric in epoch_log.items():
        history[name] = history.get(name, []) + [metric]

    # 3ï¼Œearly-stopping -------------------------------------------------
    arr_scores = history[monitor]
    best_score_idx = np.argmax(arr_scores) if mode=="max" else np.argmin(arr_scores)
    if best_score_idx==len(arr_scores)-1:
        torch.save(net.state_dict(),ckpt_path)
        print("<<<<<< reach best {0} : {1} >>>>>>".format(monitor,
             arr_scores[best_score_idx]),file=sys.stderr)
    if len(arr_scores)-best_score_idx>patience:
        print("<<<<<< {} without improvement in {} epoch, early stopping >>>>>>".format(
            monitor,patience),file=sys.stderr)
        break 
    net.load_state_dict(torch.load(ckpt_path))
    
dfhistory = pd.DataFrame(history)

```

```
================================================================================2022-07-17 15:20:40
Epoch 1 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 37.07it/s, train_acc=0.89, train_loss=0.336]  
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:02<00:00, 37.31it/s, val_acc=0.95, val_loss=0.16]   

================================================================================2022-07-17 15:20:55
Epoch 2 / 20


<<<<<< reach best val_acc : 0.9498000144958496 >>>>>>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 37.04it/s, train_acc=0.964, train_loss=0.115] 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 43.36it/s, val_acc=0.972, val_loss=0.0909]

================================================================================2022-07-17 15:21:10
Epoch 3 / 20


<<<<<< reach best val_acc : 0.9721999764442444 >>>>>>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 38.05it/s, train_acc=0.971, train_loss=0.0968]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.10it/s, val_acc=0.974, val_loss=0.0878] 

================================================================================2022-07-17 15:21:24
Epoch 4 / 20

<<<<<< reach best val_acc : 0.974399983882904 >>>>>>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:13<00:00, 35.56it/s, train_acc=0.973, train_loss=0.089] 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:02<00:00, 38.16it/s, val_acc=0.982, val_loss=0.0585]

================================================================================2022-07-17 15:21:40
Epoch 5 / 20


<<<<<< reach best val_acc : 0.9822999835014343 >>>>>>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 36.80it/s, train_acc=0.977, train_loss=0.0803]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.38it/s, val_acc=0.976, val_loss=0.0791]

================================================================================2022-07-17 15:21:55
Epoch 6 / 20


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:13<00:00, 34.63it/s, train_acc=0.977, train_loss=0.0787]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:02<00:00, 39.01it/s, val_acc=0.97, val_loss=0.105]   

================================================================================2022-07-17 15:22:11
Epoch 7 / 20


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 37.39it/s, train_acc=0.975, train_loss=0.0871]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:02<00:00, 39.16it/s, val_acc=0.984, val_loss=0.0611]

================================================================================2022-07-17 15:22:26
Epoch 8 / 20


<<<<<< reach best val_acc : 0.9835000038146973 >>>>>>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:13<00:00, 35.63it/s, train_acc=0.976, train_loss=0.0774] 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.92it/s, val_acc=0.982, val_loss=0.0778] 

================================================================================2022-07-17 15:22:41
Epoch 9 / 20


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 37.96it/s, train_acc=0.976, train_loss=0.0819]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.99it/s, val_acc=0.981, val_loss=0.0652] 

================================================================================2022-07-17 15:22:56
Epoch 10 / 20


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:13<00:00, 35.29it/s, train_acc=0.975, train_loss=0.0852]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 41.38it/s, val_acc=0.978, val_loss=0.0808]

================================================================================2022-07-17 15:23:12
Epoch 11 / 20


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 38.77it/s, train_acc=0.975, train_loss=0.0863] 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.71it/s, val_acc=0.983, val_loss=0.0665] 

================================================================================2022-07-17 15:23:26
Epoch 12 / 20


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 36.55it/s, train_acc=0.976, train_loss=0.0818]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:02<00:00, 37.44it/s, val_acc=0.979, val_loss=0.0819]
<<<<<< val_acc without improvement in 5 epoch, early stopping >>>>>>
```


ä½¿ç”¨GPUåæ¯ä¸ªEpochåªéœ€è¦10ç§’é’Ÿå·¦å³ï¼Œæå‡äº†6å€ã€‚



## å››ï¼Œtorchkeras.KerasModelä¸­ä½¿ç”¨GPU

```python
ä»ä¸Šé¢çš„ä¾‹å­å¯ä»¥çœ‹åˆ°ï¼Œåœ¨pytorchä¸­ä½¿ç”¨GPUå¹¶ä¸å¤æ‚ï¼Œä½†å¯¹äºç»å¸¸ç‚¼ä¸¹çš„åŒå­¦æ¥è¯´ï¼Œæ¨¡å‹å’Œæ•°æ®è€æ˜¯ç§»æ¥ç§»å»è¿˜æ˜¯è›®éº»çƒ¦çš„ã€‚

ä¸€ä¸å°å¿ƒå°±ä¼šå¿˜äº†ç§»åŠ¨æŸäº›æ•°æ®æˆ–è€…æŸäº›moduleï¼Œå¯¼è‡´æŠ¥é”™ã€‚

torchkeras.KerasModel åœ¨è®¾è®¡çš„æ—¶å€™è€ƒè™‘åˆ°äº†è¿™ä¸€ç‚¹ï¼Œå¦‚æœç¯å¢ƒå½“ä¸­å­˜åœ¨å¯ç”¨çš„GPUï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨GPUï¼Œåä¹‹åˆ™ä½¿ç”¨CPUã€‚

é€šè¿‡å¼•å…¥accelerateçš„ä¸€äº›åŸºç¡€åŠŸèƒ½ï¼Œtorchkeras.KerasModelä»¥éå¸¸ä¼˜é›…çš„æ–¹å¼åœ¨GPUå’ŒCPUä¹‹é—´åˆ‡æ¢ã€‚

è¯¦ç»†å®ç°å¯ä»¥å‚è€ƒtorchkeras.KerasModelçš„æºç ã€‚
```

```python
!pip install torchkeras==3.2.3
```

```python
import  accelerate 
accelerator = accelerate.Accelerator()
print(accelerator.device)  
```

```python
from torchkeras import KerasModel 
from torchmetrics import Accuracy

net = create_net() 
model = KerasModel(net,
                   loss_fn=nn.CrossEntropyLoss(),
                   metrics_dict = {"acc":Accuracy()},
                   optimizer = torch.optim.Adam(net.parameters(),lr = 0.01)  )

model.fit(
    train_data = dl_train,
    val_data= dl_val,
    epochs=10,
    patience=3,
    monitor="val_acc", 
    mode="max")
```

```python

```

## äº”ï¼Œtorchkeras.LightModelä¸­ä½¿ç”¨GPU


é€šè¿‡å¼•ç”¨pytorch_lightningçš„åŠŸèƒ½ï¼Œ

torchkeras.LightModelä»¥æ›´åŠ æ˜¾å¼çš„æ–¹å¼æ”¯æŒGPUè®­ç»ƒï¼Œ

ä¸ä»…å¦‚æ­¤ï¼Œè¿˜èƒ½æ”¯æŒå¤šGPUå’ŒTPUè®­ç»ƒã€‚


```python
from torchmetrics import Accuracy 
from torchkeras import LightModel 

net = create_net() 
model = LightModel(net,
                   loss_fn=nn.CrossEntropyLoss(),
                   metrics_dict = {"acc":Accuracy()},
                   optimizer = torch.optim.Adam(net.parameters(),lr = 0.01) )

```

```python
import pytorch_lightning as pl     

#1ï¼Œè®¾ç½®å›è°ƒå‡½æ•°
model_ckpt = pl.callbacks.ModelCheckpoint(
    monitor='val_acc',
    save_top_k=1,
    mode='max'
)

early_stopping = pl.callbacks.EarlyStopping(monitor = 'val_acc',
                           patience=3,
                           mode = 'max'
                          )

#2ï¼Œè®¾ç½®è®­ç»ƒå‚æ•°

# gpus=0 åˆ™ä½¿ç”¨cpuè®­ç»ƒï¼Œgpus=1åˆ™ä½¿ç”¨1ä¸ªgpuè®­ç»ƒï¼Œgpus=2åˆ™ä½¿ç”¨2ä¸ªgpuè®­ç»ƒï¼Œgpus=-1åˆ™ä½¿ç”¨æ‰€æœ‰gpuè®­ç»ƒï¼Œ
# gpus=[0,1]åˆ™æŒ‡å®šä½¿ç”¨0å·å’Œ1å·gpuè®­ç»ƒï¼Œ gpus="0,1,2,3"åˆ™ä½¿ç”¨0,1,2,3å·gpuè®­ç»ƒ
# tpus=1 åˆ™ä½¿ç”¨1ä¸ªtpuè®­ç»ƒ
trainer = pl.Trainer(logger=True,
                     min_epochs=3,max_epochs=20,
                     gpus=1,
                     callbacks = [model_ckpt,early_stopping],
                     enable_progress_bar = True) 


##4ï¼Œå¯åŠ¨è®­ç»ƒå¾ªç¯
trainer.fit(model,dl_train,dl_val)


```

```
================================================================================2022-07-18 00:18:14
{'epoch': 0, 'val_loss': 2.31911301612854, 'val_acc': 0.0546875}
<<<<<< reach best val_acc : 0.0546875 >>>>>>

================================================================================2022-07-18 00:18:29
{'epoch': 0, 'val_loss': 0.10364170372486115, 'val_acc': 0.9693999886512756}
{'epoch': 0, 'train_loss': 0.31413567066192627, 'train_acc': 0.8975499868392944}
<<<<<< reach best val_acc : 0.9693999886512756 >>>>>>

================================================================================2022-07-18 00:18:43
{'epoch': 1, 'val_loss': 0.0983758345246315, 'val_acc': 0.9710999727249146}
{'epoch': 1, 'train_loss': 0.10680060088634491, 'train_acc': 0.9673333168029785}
<<<<<< reach best val_acc : 0.9710999727249146 >>>>>>

================================================================================2022-07-18 00:18:58
{'epoch': 2, 'val_loss': 0.08315123617649078, 'val_acc': 0.9764999747276306}
{'epoch': 2, 'train_loss': 0.09339822083711624, 'train_acc': 0.9722166657447815}
<<<<<< reach best val_acc : 0.9764999747276306 >>>>>>

================================================================================2022-07-18 00:19:13
{'epoch': 3, 'val_loss': 0.06529796123504639, 'val_acc': 0.9799000024795532}
{'epoch': 3, 'train_loss': 0.08487282693386078, 'train_acc': 0.9746000170707703}
<<<<<< reach best val_acc : 0.9799000024795532 >>>>>>

================================================================================2022-07-18 00:19:27
{'epoch': 4, 'val_loss': 0.10162600129842758, 'val_acc': 0.9735000133514404}
{'epoch': 4, 'train_loss': 0.08439336717128754, 'train_acc': 0.9746666550636292}

================================================================================2022-07-18 00:19:42
{'epoch': 5, 'val_loss': 0.0818500965833664, 'val_acc': 0.9789000153541565}
{'epoch': 5, 'train_loss': 0.08107426762580872, 'train_acc': 0.9763166904449463}

================================================================================2022-07-18 00:19:56
{'epoch': 6, 'val_loss': 0.08046088367700577, 'val_acc': 0.979200005531311}
{'epoch': 6, 'train_loss': 0.08173364400863647, 'train_acc': 0.9772833585739136}
```


**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)
