{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea02e6fd",
   "metadata": {},
   "source": [
    "# Mac M1 èŠ¯ç‰‡åŠ é€ŸpytorchæŒ‡å—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86314b9",
   "metadata": {},
   "source": [
    "å‚è€ƒæ–‡ç« :\n",
    "\n",
    "ã€ŠPyTorchå®£å¸ƒæ”¯æŒè‹¹æœM1èŠ¯ç‰‡GPUåŠ é€Ÿï¼šè®­ç»ƒå¿«6å€ï¼Œæ¨ç†æå‡21å€ã€‹ https://zhuanlan.zhihu.com/p/516920793\n",
    "\n",
    "ã€ŠMacbookM1èŠ¯ç‰‡æ·±åº¦å­¦ä¹ ç¯å¢ƒé…ç½®æœ€å…¨æ•™ç¨‹ï¼šç®€æ˜å®‰è£…å¼€å‘TensorFlowä¸PyTorchã€‹https://zhuanlan.zhihu.com/p/483551833\n",
    "\n",
    "ã€Šä¸€æ–‡è§£é‡Šconda,pip,anaconda,miniconda,miniforgeã€‹ https://zhuanlan.zhihu.com/p/518926990\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec75498",
   "metadata": {},
   "source": [
    "## ä¸€ï¼ŒåŠ é€ŸåŸç†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edfe53",
   "metadata": {},
   "source": [
    "* Question1ï¼ŒMac M1èŠ¯ç‰‡ ä¸ºä»€ä¹ˆå¯ä»¥ç”¨æ¥åŠ é€Ÿ pytorchï¼Ÿ\n",
    "\n",
    "å› ä¸º Mac M1èŠ¯ç‰‡ä¸æ˜¯ä¸€ä¸ªå•çº¯çš„ä¸€ä¸ªCPUèŠ¯ç‰‡ï¼Œè€Œæ˜¯åŒ…æ‹¬äº†CPU(ä¸­å¤®å¤„ç†å™¨)ï¼ŒGPU(å›¾å½¢å¤„ç†å™¨)ï¼ŒNPU(ç¥ç»ç½‘ç»œå¼•æ“)ï¼Œä»¥åŠç»Ÿä¸€å†…å­˜å•å…ƒç­‰ä¼—å¤šç»„ä»¶çš„ä¸€å—é›†æˆèŠ¯ç‰‡ã€‚ç”±äºMac M1èŠ¯ç‰‡é›†æˆäº†GPUç»„ä»¶ï¼Œæ‰€ä»¥å¯ä»¥ç”¨æ¥åŠ é€Ÿpytorch.\n",
    "\n",
    "* Question2ï¼ŒMac M1èŠ¯ç‰‡ ä¸ŠGPUçš„çš„æ˜¾å­˜æœ‰å¤šå¤§ï¼Ÿ\n",
    "\n",
    "Mac M1èŠ¯ç‰‡çš„CPUå’ŒGPUä½¿ç”¨ç»Ÿä¸€çš„å†…å­˜å•å…ƒã€‚æ‰€ä»¥Mac M1èŠ¯ç‰‡çš„èƒ½ä½¿ç”¨çš„æ˜¾å­˜å¤§å°å°±æ˜¯ Mac ç”µè„‘çš„å†…å­˜å¤§å°ã€‚\n",
    "\n",
    "* Question3ï¼Œä½¿ç”¨Mac M1èŠ¯ç‰‡åŠ é€Ÿ pytorch éœ€è¦å®‰è£… cudaåç«¯å—ï¼Ÿ\n",
    "\n",
    "ä¸éœ€è¦ï¼Œcudaæ˜¯é€‚é…nvidiaçš„GPUçš„ï¼ŒMac M1èŠ¯ç‰‡ä¸­çš„GPUé€‚é…çš„åŠ é€Ÿåç«¯æ˜¯mpsï¼Œåœ¨Macå¯¹åº”æ“ä½œç³»ç»Ÿä¸­å·²ç»å…·å¤‡ï¼Œæ— éœ€å•ç‹¬å®‰è£…ã€‚åªéœ€è¦å®‰è£…é€‚é…çš„pytorchå³å¯ã€‚\n",
    "\n",
    "* Question4ï¼Œä¸ºä»€ä¹ˆæœ‰äº›å¯ä»¥åœ¨Mac IntelèŠ¯ç‰‡ç”µè„‘å®‰è£…çš„è½¯ä»¶ä¸èƒ½åœ¨Mac M1èŠ¯ç‰‡ç”µè„‘ä¸Šå®‰è£…ï¼Ÿ\n",
    "\n",
    "Mac M1èŠ¯ç‰‡ä¸ºäº†è¿½æ±‚é«˜æ€§èƒ½å’ŒèŠ‚èƒ½ï¼Œåœ¨åº•å±‚è®¾è®¡ä¸Šä½¿ç”¨çš„æ˜¯ä¸€ç§å«åšarmæ¶æ„çš„ç²¾ç®€æŒ‡ä»¤é›†ï¼Œä¸åŒäºIntelç­‰å¸¸ç”¨CPUèŠ¯ç‰‡é‡‡ç”¨çš„x86æ¶æ„å®Œæ•´æŒ‡ä»¤é›†ã€‚æ‰€ä»¥æœ‰äº›åŸºäºx86æŒ‡ä»¤é›†å¼€å‘çš„è½¯ä»¶ä¸èƒ½ç›´æ¥åœ¨Mac M1èŠ¯ç‰‡ç”µè„‘ä¸Šä½¿ç”¨ã€‚\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8k14eaodhj30vf0u0juj.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a39248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c17aa29",
   "metadata": {},
   "source": [
    "## äºŒï¼Œç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639e6db",
   "metadata": {},
   "source": [
    "\n",
    "0ï¼Œæ£€æŸ¥macå‹å·\n",
    "\n",
    "ç‚¹å‡»æ¡Œé¢å·¦ä¸Šè§’macå›¾æ ‡â€”â€”>å…³äºæœ¬æœºâ€”â€”>æ¦‚è§ˆï¼Œç¡®å®šæ˜¯m1èŠ¯ç‰‡ï¼Œäº†è§£å†…å­˜å¤§å°(æœ€å¥½æœ‰16Gä»¥ä¸Šï¼Œ8Gå¯èƒ½ä¸å¤ªå¤Ÿç”¨)ã€‚\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8k27lhkrhj30vo0fgmye.jpg) \n",
    "\n",
    "\n",
    "\n",
    "1ï¼Œä¸‹è½½ miniforge3 (miniforge3å¯ä»¥ç†è§£æˆ miniconda/annoconda çš„ç¤¾åŒºç‰ˆï¼Œæä¾›äº†æ›´ç¨³å®šçš„å¯¹M1èŠ¯ç‰‡çš„æ”¯æŒ)\n",
    "\n",
    "https://github.com/conda-forge/miniforge/#download\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8k24engoxj311a0ki780.jpg)\n",
    "\n",
    "å¤‡æ³¨: annoconda åœ¨ 2022å¹´5æœˆå¼€å§‹ä¹Ÿå‘å¸ƒäº†å¯¹ mac m1èŠ¯ç‰‡çš„å®˜æ–¹æ”¯æŒï¼Œä½†è¿˜æ˜¯æ¨èç¤¾åŒºå‘å¸ƒçš„miniforge3ï¼Œå¼€æºä¸”æ›´åŠ ç¨³å®šã€‚\n",
    "\n",
    "\n",
    "2ï¼Œå®‰è£… miniforge3\n",
    "\n",
    "```bash\n",
    "chmod +x ~/Downloads/Miniforge3-MacOSX-arm64.sh\n",
    "sh ~/Downloads/Miniforge3-MacOSX-arm64.sh\n",
    "source ~/miniforge3/bin/activate\n",
    "```\n",
    "\n",
    "\n",
    "3ï¼Œå®‰è£… pytorch (v1.12ç‰ˆæœ¬å·²ç»æ­£å¼æ”¯æŒäº†ç”¨äºmac m1èŠ¯ç‰‡gpuåŠ é€Ÿçš„mpsåç«¯ã€‚)\n",
    "\n",
    "```\n",
    "pip install torch>=1.12 -i https://pypi.tuna.tsinghua.edu.cn/simple \n",
    "\n",
    "```\n",
    "\n",
    "4ï¼Œæµ‹è¯•ç¯å¢ƒ\n",
    "\n",
    "```python\n",
    "import torch \n",
    "\n",
    "print(torch.backends.mps.is_available()) \n",
    "print(torch.backends.mps.is_built())\n",
    "```\n",
    "å¦‚æœè¾“å‡ºéƒ½æ˜¯Trueçš„è¯ï¼Œé‚£ä¹ˆæ­å–œä½ é…ç½®æˆåŠŸäº†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab870fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d45bae58",
   "metadata": {},
   "source": [
    "## ä¸‰ï¼ŒèŒƒä¾‹ä»£ç "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c8fa6",
   "metadata": {},
   "source": [
    "ä¸‹é¢ä»¥mnistæ‰‹å†™æ•°å­—è¯†åˆ«ä¸ºä¾‹ï¼Œæ¼”ç¤ºä½¿ç”¨mac M1èŠ¯ç‰‡GPUçš„mpsåç«¯æ¥åŠ é€Ÿpytorchçš„å®Œæ•´æµç¨‹ã€‚\n",
    "\n",
    "æ ¸å¿ƒæ“ä½œéå¸¸ç®€å•ï¼Œå’Œä½¿ç”¨cudaç±»ä¼¼ï¼Œè®­ç»ƒå‰æŠŠæ¨¡å‹å’Œæ•°æ®éƒ½ç§»åŠ¨åˆ°torch.device(\"mps\")å°±å¯ä»¥äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c32f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "================================================================================2022-12-02 21:27:39\n",
      "Epoch 1 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:36<00:00, 13.00it/s, train_acc=0.766, train_loss=0.81]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.58it/s, val_acc=0.956, val_loss=0.144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:28:17\n",
      "Epoch 2 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "<<<<<< reach best val_acc : 0.9558000564575195 >>>>>>\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 13.93it/s, train_acc=0.959, train_loss=0.138]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.61it/s, val_acc=0.968, val_loss=0.108]\n",
      "<<<<<< reach best val_acc : 0.968000054359436 >>>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:28:52\n",
      "Epoch 3 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 13.98it/s, train_acc=0.964, train_loss=0.123]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.79it/s, val_acc=0.978, val_loss=0.0732]\n",
      "<<<<<< reach best val_acc : 0.9783000349998474 >>>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:29:28\n",
      "Epoch 4 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 13.96it/s, train_acc=0.968, train_loss=0.11]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.51it/s, val_acc=0.977, val_loss=0.0863]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:30:03\n",
      "Epoch 5 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 13.98it/s, train_acc=0.966, train_loss=0.118]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.28it/s, val_acc=0.971, val_loss=0.103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:30:38\n",
      "Epoch 6 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 13.98it/s, train_acc=0.958, train_loss=0.15]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.15it/s, val_acc=0.972, val_loss=0.0903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:31:14\n",
      "Epoch 7 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 13.99it/s, train_acc=0.245, train_loss=inf]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.49it/s, val_acc=0.114, val_loss=2.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:31:49\n",
      "Epoch 8 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 14.18it/s, train_acc=0.982, train_loss=0.0575]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 46.04it/s, val_acc=0.981, val_loss=0.065]\n",
      "<<<<<< reach best val_acc : 0.9807000756263733 >>>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:32:24\n",
      "Epoch 9 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 14.20it/s, train_acc=0.985, train_loss=0.0474]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.78it/s, val_acc=0.979, val_loss=0.0678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:32:59\n",
      "Epoch 10 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 14.18it/s, train_acc=0.981, train_loss=0.06]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 43.97it/s, val_acc=0.98, val_loss=0.0664]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:33:34\n",
      "Epoch 11 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 14.12it/s, train_acc=0.98, train_loss=0.0642]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 45.20it/s, val_acc=0.975, val_loss=0.0896]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:34:09\n",
      "Epoch 12 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 14.18it/s, train_acc=0.975, train_loss=0.0832]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 45.62it/s, val_acc=0.978, val_loss=0.0702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2022-12-02 21:34:44\n",
      "Epoch 13 / 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 14.20it/s, train_acc=0.969, train_loss=0.101]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.81it/s, val_acc=0.979, val_loss=0.0701]\n",
      "<<<<<< val_acc without improvement in 5 epoch, early stopping >>>>>>\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "import torchvision \n",
    "from torchvision import transforms \n",
    "import torch.nn.functional as F \n",
    "\n",
    "\n",
    "import os,sys,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "from copy import deepcopy\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(str(info)+\"\\n\")\n",
    "    \n",
    "    \n",
    "#================================================================================\n",
    "# ä¸€ï¼Œå‡†å¤‡æ•°æ®\n",
    "#================================================================================\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "ds_train = torchvision.datasets.MNIST(root=\"mnist/\",train=True,download=True,transform=transform)\n",
    "ds_val = torchvision.datasets.MNIST(root=\"mnist/\",train=False,download=True,transform=transform)\n",
    "\n",
    "dl_train =  torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=2)\n",
    "dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# äºŒï¼Œå®šä¹‰æ¨¡å‹\n",
    "#================================================================================\n",
    "\n",
    "\n",
    "def create_net():\n",
    "    net = nn.Sequential()\n",
    "    net.add_module(\"conv1\",nn.Conv2d(in_channels=1,out_channels=64,kernel_size = 3))\n",
    "    net.add_module(\"pool1\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"conv2\",nn.Conv2d(in_channels=64,out_channels=512,kernel_size = 3))\n",
    "    net.add_module(\"pool2\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"dropout\",nn.Dropout2d(p = 0.1))\n",
    "    net.add_module(\"adaptive_pool\",nn.AdaptiveMaxPool2d((1,1)))\n",
    "    net.add_module(\"flatten\",nn.Flatten())\n",
    "    net.add_module(\"linear1\",nn.Linear(512,1024))\n",
    "    net.add_module(\"relu\",nn.ReLU())\n",
    "    net.add_module(\"linear2\",nn.Linear(1024,10))\n",
    "    return net\n",
    "\n",
    "net = create_net()\n",
    "print(net)\n",
    "\n",
    "# è¯„ä¼°æŒ‡æ ‡\n",
    "class Accuracy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.correct = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "        self.total = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        preds = preds.argmax(dim=-1)\n",
    "        m = (preds == targets).sum()\n",
    "        n = targets.shape[0] \n",
    "        self.correct += m \n",
    "        self.total += n\n",
    "        \n",
    "        return m/n\n",
    "\n",
    "    def compute(self):\n",
    "        return self.correct.float() / self.total \n",
    "    \n",
    "    def reset(self):\n",
    "        self.correct -= self.correct\n",
    "        self.total -= self.total\n",
    "        \n",
    "#================================================================================\n",
    "# ä¸‰ï¼Œè®­ç»ƒæ¨¡å‹\n",
    "#================================================================================     \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   \n",
    "metrics_dict = nn.ModuleDict({\"acc\":Accuracy()})\n",
    "\n",
    "\n",
    "# =========================ç§»åŠ¨æ¨¡å‹åˆ°mpsä¸Š==============================\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "loss_fn.to(device)\n",
    "metrics_dict.to(device)\n",
    "# ====================================================================\n",
    "\n",
    "\n",
    "epochs = 20 \n",
    "ckpt_path='checkpoint.pt'\n",
    "\n",
    "#early_stoppingç›¸å…³è®¾ç½®\n",
    "monitor=\"val_acc\"\n",
    "patience=5\n",
    "mode=\"max\"\n",
    "\n",
    "history = {}\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "\n",
    "    # 1ï¼Œtrain -------------------------------------------------  \n",
    "    net.train()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    \n",
    "    loop = tqdm(enumerate(dl_train), total =len(dl_train),ncols=100)\n",
    "    train_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    for i, batch in loop: \n",
    "        \n",
    "        features,labels = batch\n",
    "        \n",
    "        # =========================ç§»åŠ¨æ•°æ®åˆ°mpsä¸Š==============================\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # ====================================================================\n",
    "        \n",
    "        #forward\n",
    "        preds = net(features)\n",
    "        loss = loss_fn(preds,labels)\n",
    "        \n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        #metrics\n",
    "        step_metrics = {\"train_\"+name:metric_fn(preds, labels).item() \n",
    "                        for name,metric_fn in train_metrics_dict.items()}\n",
    "        \n",
    "        step_log = dict({\"train_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        step+=1\n",
    "        if i!=len(dl_train)-1:\n",
    "            loop.set_postfix(**step_log)\n",
    "        else:\n",
    "            epoch_loss = total_loss/step\n",
    "            epoch_metrics = {\"train_\"+name:metric_fn.compute().item() \n",
    "                             for name,metric_fn in train_metrics_dict.items()}\n",
    "            epoch_log = dict({\"train_loss\":epoch_loss},**epoch_metrics)\n",
    "            loop.set_postfix(**epoch_log)\n",
    "\n",
    "            for name,metric_fn in train_metrics_dict.items():\n",
    "                metric_fn.reset()\n",
    "                \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "        \n",
    "\n",
    "    # 2ï¼Œvalidate -------------------------------------------------\n",
    "    net.eval()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    loop = tqdm(enumerate(dl_val), total =len(dl_val),ncols=100)\n",
    "    \n",
    "    val_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in loop: \n",
    "\n",
    "            features,labels = batch\n",
    "            \n",
    "            # =========================ç§»åŠ¨æ•°æ®åˆ°mpsä¸Š==============================\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # ====================================================================\n",
    "            \n",
    "            #forward\n",
    "            preds = net(features)\n",
    "            loss = loss_fn(preds,labels)\n",
    "\n",
    "            #metrics\n",
    "            step_metrics = {\"val_\"+name:metric_fn(preds, labels).item() \n",
    "                            for name,metric_fn in val_metrics_dict.items()}\n",
    "\n",
    "            step_log = dict({\"val_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            step+=1\n",
    "            if i!=len(dl_val)-1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                epoch_loss = (total_loss/step)\n",
    "                epoch_metrics = {\"val_\"+name:metric_fn.compute().item() \n",
    "                                 for name,metric_fn in val_metrics_dict.items()}\n",
    "                epoch_log = dict({\"val_loss\":epoch_loss},**epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name,metric_fn in val_metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "                    \n",
    "    epoch_log[\"epoch\"] = epoch           \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "    # 3ï¼Œearly-stopping -------------------------------------------------\n",
    "    arr_scores = history[monitor]\n",
    "    best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "    if best_score_idx==len(arr_scores)-1:\n",
    "        torch.save(net.state_dict(),ckpt_path)\n",
    "        print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "             arr_scores[best_score_idx]),file=sys.stderr)\n",
    "    if len(arr_scores)-best_score_idx>patience:\n",
    "        print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "            monitor,patience),file=sys.stderr)\n",
    "        break \n",
    "    net.load_state_dict(torch.load(ckpt_path))\n",
    "    \n",
    "dfhistory = pd.DataFrame(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7fdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "817c0ca1-dfdc-42f3-a660-b34b096ac2d4",
   "metadata": {},
   "source": [
    "## å››ï¼Œä½¿ç”¨torchkerasæ”¯æŒMac M1èŠ¯ç‰‡åŠ é€Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527a167-02c8-4980-ac1d-ecece961616b",
   "metadata": {},
   "source": [
    "æˆ‘åœ¨æœ€æ–°çš„3.3.0çš„torchkerasç‰ˆæœ¬ä¸­å¼•å…¥äº†å¯¹ mac m1èŠ¯ç‰‡çš„æ”¯æŒï¼Œå½“å­˜åœ¨å¯ç”¨çš„ mac m1èŠ¯ç‰‡/ GPU æ—¶ï¼Œä¼šé»˜è®¤ä½¿ç”¨å®ƒä»¬è¿›è¡ŒåŠ é€Ÿï¼Œæ— éœ€åšä»»ä½•é…ç½®ã€‚\n",
    "\n",
    "ä½¿ç”¨èŒƒä¾‹å¦‚ä¸‹ã€‚ğŸ˜‹ğŸ˜‹ğŸ˜‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb81b0e-5a0a-42cb-831d-b701f2b768af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchkeras\n",
      "  Downloading torchkeras-3.3.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: torchkeras\n",
      "Successfully installed torchkeras-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchkeras>=3.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfa97081-8940-41c3-9283-ea0c5444efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "--------------------------------------------------------------------------\n",
      "Layer (type)                            Output Shape              Param #\n",
      "==========================================================================\n",
      "Conv2d-1                            [-1, 64, 26, 26]                  640\n",
      "MaxPool2d-2                         [-1, 64, 13, 13]                    0\n",
      "Conv2d-3                           [-1, 512, 11, 11]              295,424\n",
      "MaxPool2d-4                          [-1, 512, 5, 5]                    0\n",
      "Dropout2d-5                          [-1, 512, 5, 5]                    0\n",
      "AdaptiveMaxPool2d-6                  [-1, 512, 1, 1]                    0\n",
      "Flatten-7                                  [-1, 512]                    0\n",
      "Linear-8                                  [-1, 1024]              525,312\n",
      "ReLU-9                                    [-1, 1024]                    0\n",
      "Linear-10                                   [-1, 10]               10,250\n",
      "==========================================================================\n",
      "Total params: 831,626\n",
      "Trainable params: 831,626\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "Input size (MB): 0.000069\n",
      "Forward/backward pass size (MB): 1.104080\n",
      "Params size (MB): 3.172401\n",
      "Estimated Total Size (MB): 4.276550\n",
      "--------------------------------------------------------------------------\n",
      "\u001b[0;31m<<<<<< âš¡ï¸ mps is used >>>>>>\u001b[0m\n",
      "\n",
      "================================================================================2022-12-02 22:17:29\n",
      "Epoch 1 / 15\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 13.89it/s, train_acc=0.903, train_loss=0.304]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.44it/s, val_acc=0.973, val_loss=0.0884]\n",
      "\u001b[0;31m<<<<<< reach best val_acc : 0.9730000495910645 >>>>>>\u001b[0m\n",
      "\n",
      "================================================================================2022-12-02 22:18:05\n",
      "Epoch 2 / 15\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:33<00:00, 14.09it/s, train_acc=0.974, train_loss=0.0823]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 45.71it/s, val_acc=0.979, val_loss=0.0662]\n",
      "\u001b[0;31m<<<<<< reach best val_acc : 0.9794000387191772 >>>>>>\u001b[0m\n",
      "\n",
      "================================================================================2022-12-02 22:18:40\n",
      "Epoch 3 / 15\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:32<00:00, 14.22it/s, train_acc=0.982, train_loss=0.0553]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.59it/s, val_acc=0.981, val_loss=0.0699]\n",
      "\u001b[0;31m<<<<<< reach best val_acc : 0.9808000326156616 >>>>>>\u001b[0m\n",
      "\n",
      "================================================================================2022-12-02 22:19:15\n",
      "Epoch 4 / 15\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:32<00:00, 14.21it/s, train_acc=0.986, train_loss=0.0434]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.89it/s, val_acc=0.988, val_loss=0.0382]\n",
      "\u001b[0;31m<<<<<< reach best val_acc : 0.9883000254631042 >>>>>>\u001b[0m\n",
      "\n",
      "================================================================================2022-12-02 22:19:49\n",
      "Epoch 5 / 15\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:32<00:00, 14.22it/s, train_acc=0.989, train_loss=0.0326]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 44.56it/s, val_acc=0.987, val_loss=0.0429]\n",
      "\n",
      "================================================================================2022-12-02 22:20:24\n",
      "Epoch 6 / 15\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:35<00:00, 13.13it/s, train_acc=0.99, train_loss=0.0313]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 43.52it/s, val_acc=0.987, val_loss=0.0486]\n",
      "\n",
      "================================================================================2022-12-02 22:21:02\n",
      "Epoch 7 / 15\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:32<00:00, 14.32it/s, train_acc=0.991, train_loss=0.0255]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 43.23it/s, val_acc=0.986, val_loss=0.0591]\n",
      "\n",
      "================================================================================2022-12-02 22:21:36\n",
      "Epoch 8 / 15\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:32<00:00, 14.27it/s, train_acc=0.994, train_loss=0.0199]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 45.32it/s, val_acc=0.985, val_loss=0.0542]\n",
      "\n",
      "================================================================================2022-12-02 22:22:11\n",
      "Epoch 9 / 15\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:32<00:00, 14.28it/s, train_acc=0.993, train_loss=0.0228]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 43.70it/s, val_acc=0.987, val_loss=0.0471]\n",
      "\u001b[0;31m<<<<<< val_acc without improvement in 5 epoch, early stopping >>>>>>\u001b[0m\n",
      "   train_loss  train_acc  val_loss  val_acc  epoch\n",
      "0    0.303751   0.903283  0.088422   0.9730      1\n",
      "1    0.082336   0.973917  0.066228   0.9794      2\n",
      "2    0.055266   0.982233  0.069914   0.9808      3\n",
      "3    0.043367   0.985983  0.038230   0.9883      4\n",
      "4    0.032618   0.989317  0.042920   0.9869      5\n",
      "5    0.031270   0.989533  0.048605   0.9871      6\n",
      "6    0.025532   0.991283  0.059145   0.9862      7\n",
      "7    0.019919   0.993550  0.054234   0.9853      8\n",
      "8    0.022779   0.992517  0.047057   0.9874      9\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.95it/s, val_acc=0.988, val_loss=0.0382]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchkeras #Attention this line \n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# ä¸€ï¼Œå‡†å¤‡æ•°æ®\n",
    "#================================================================================\n",
    "\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "ds_train = torchvision.datasets.MNIST(root=\"mnist/\",train=True,download=True,transform=transform)\n",
    "ds_val = torchvision.datasets.MNIST(root=\"mnist/\",train=False,download=True,transform=transform)\n",
    "dl_train =  torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=2)\n",
    "dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "for features,labels in dl_train:\n",
    "    break \n",
    "\n",
    "#================================================================================\n",
    "# äºŒï¼Œå®šä¹‰æ¨¡å‹\n",
    "#================================================================================\n",
    "\n",
    "\n",
    "def create_net():\n",
    "    net = nn.Sequential()\n",
    "    net.add_module(\"conv1\",nn.Conv2d(in_channels=1,out_channels=64,kernel_size = 3))\n",
    "    net.add_module(\"pool1\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"conv2\",nn.Conv2d(in_channels=64,out_channels=512,kernel_size = 3))\n",
    "    net.add_module(\"pool2\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"dropout\",nn.Dropout2d(p = 0.1))\n",
    "    net.add_module(\"adaptive_pool\",nn.AdaptiveMaxPool2d((1,1)))\n",
    "    net.add_module(\"flatten\",nn.Flatten())\n",
    "    net.add_module(\"linear1\",nn.Linear(512,1024))\n",
    "    net.add_module(\"relu\",nn.ReLU())\n",
    "    net.add_module(\"linear2\",nn.Linear(1024,10))\n",
    "    return net\n",
    "\n",
    "net = create_net()\n",
    "print(net)\n",
    "\n",
    "# è¯„ä¼°æŒ‡æ ‡\n",
    "class Accuracy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.correct = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "        self.total = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        preds = preds.argmax(dim=-1)\n",
    "        m = (preds == targets).sum()\n",
    "        n = targets.shape[0] \n",
    "        self.correct += m \n",
    "        self.total += n\n",
    "        \n",
    "        return m/n\n",
    "\n",
    "    def compute(self):\n",
    "        return self.correct.float() / self.total \n",
    "    \n",
    "    def reset(self):\n",
    "        self.correct -= self.correct\n",
    "        self.total -= self.total\n",
    "        \n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# ä¸‰ï¼Œè®­ç»ƒæ¨¡å‹\n",
    "#================================================================================\n",
    "\n",
    "model = torchkeras.KerasModel(net,\n",
    "      loss_fn = nn.CrossEntropyLoss(),\n",
    "      optimizer= torch.optim.Adam(net.parameters(),lr=0.001),\n",
    "      metrics_dict = {\"acc\":Accuracy()}\n",
    "    )\n",
    "\n",
    "from torchkeras import summary\n",
    "summary(model,input_data=features);\n",
    "\n",
    "\n",
    "# if gpu/mps is available, will auto use it, otherwise cpu will be used.\n",
    "\n",
    "dfhistory=model.fit(train_data=dl_train, \n",
    "                    val_data=dl_val, \n",
    "                    epochs=15, \n",
    "                    patience=5, \n",
    "                    monitor=\"val_acc\",mode=\"max\",\n",
    "                    ckpt_path='checkpoint.pt')\n",
    "\n",
    "#================================================================================\n",
    "# å››ï¼Œè¯„ä¼°æ¨¡å‹\n",
    "#================================================================================\n",
    "\n",
    "model.evaluate(dl_val)\n",
    "\n",
    "\n",
    "#================================================================================\n",
    "# äº”ï¼Œä½¿ç”¨æ¨¡å‹\n",
    "#================================================================================\n",
    "\n",
    "model.predict(dl_val)[0:10]\n",
    "\n",
    "#================================================================================\n",
    "# å…­ï¼Œä¿å­˜æ¨¡å‹\n",
    "#================================================================================\n",
    "# The best net parameters  has been saved at ckpt_path='checkpoint.pt' during training.\n",
    "net_clone = create_net() \n",
    "net_clone.load_state_dict(torch.load(\"checkpoint.pt\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c94a1-8df1-4c2e-a131-578588792967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f63aa-2dc8-4004-bbbf-062b42aab800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddbfb751",
   "metadata": {},
   "source": [
    "## äº”ï¼ŒM1èŠ¯ç‰‡ä¸CPUå’ŒNvidia GPUé€Ÿåº¦å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f25cd-53a2-44a3-b308-9cafa045ee60",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ä»¥ä¸Šä»£ç ä½œä¸ºèŒƒä¾‹ï¼Œåˆ†åˆ«åœ¨CPU, mac m1èŠ¯ç‰‡ï¼Œä»¥åŠNvidia GPUä¸Š è¿è¡Œã€‚\n",
    "\n",
    "å¾—åˆ°çš„è¿è¡Œé€Ÿåº¦æˆªå›¾å¦‚ä¸‹ï¼š\n",
    "\n",
    "çº¯CPUè·‘æ•ˆæœ\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8pu8qudibj318i0d0n06.jpg)\n",
    "\n",
    "Mac M1 èŠ¯ç‰‡åŠ é€Ÿæ•ˆæœ\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8pubdxbrkj318u0eywhq.jpg)\n",
    "\n",
    "\n",
    "Tesla P100 GPUåŠ é€Ÿæ•ˆæœ\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8pu9epg15j319i0dcn0c.jpg)\n",
    "\n",
    "\n",
    "çº¯CPUè·‘ä¸€ä¸ªepochå¤§çº¦æ˜¯3min 18sã€‚\n",
    "\n",
    "ä½¿ç”¨mac m1èŠ¯ç‰‡åŠ é€Ÿï¼Œä¸€ä¸ªepochå¤§çº¦æ˜¯33 sï¼Œç›¸æ¯”CPUè·‘ï¼ŒåŠ é€Ÿçº¦6å€ã€‚\n",
    "\n",
    "ä½¿ç”¨Nvidia Tesla P100 GPUåŠ é€Ÿï¼Œä¸€ä¸ªepochå¤§çº¦æ˜¯ 8sï¼Œç›¸æ¯”CPUè·‘ï¼ŒåŠ é€Ÿçº¦25å€ã€‚\n",
    "\n",
    "è¿™å’Œpytorchå®˜ç½‘æ˜¾ç¤ºçš„è®­ç»ƒè¿‡ç¨‹å¹³å‡åŠ é€Ÿ7å€ç›¸å½“ã€‚\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8putb28ivj30zk0lwq4j.jpg)\n",
    "\n",
    "æ•´ä½“æ¥è¯´Mac M1èŠ¯ç‰‡å¯¹ æ·±åº¦å­¦ä¹ è®­ç»ƒè¿‡ç¨‹çš„åŠ é€Ÿè¿˜æ˜¯éå¸¸æ˜¾è‘—çš„ï¼Œé€šå¸¸è¾¾åˆ°5åˆ°7å€å·¦å³ã€‚\n",
    "\n",
    "ä¸è¿‡ç›®å‰çœ‹å’Œä¼ä¸šä¸­æœ€å¸¸ä½¿ç”¨çš„é«˜ç«¯çš„Tesla P100 GPUç›¸æ¯”ï¼Œè¿˜æ˜¯æœ‰2åˆ°4å€çš„è®­ç»ƒé€Ÿåº¦å·®å¼‚ï¼Œå¯ä»¥è§†åšä¸€ä¸ªminiç‰ˆçš„GPUå§ã€‚\n",
    "\n",
    "å› æ­¤Mac M1èŠ¯ç‰‡æ¯”è¾ƒé€‚åˆæœ¬åœ°è®­ç»ƒä¸€äº›ä¸­å°è§„æ¨¡çš„æ¨¡å‹ï¼Œå¿«é€Ÿè¿­ä»£ideaï¼Œä½¿ç”¨èµ·æ¥è¿˜æ˜¯è›®é¦™çš„ã€‚\n",
    "\n",
    "å°¤å…¶æ˜¯æœ¬æ¥å°±æ‰“ç®—æƒ³æ¢ä¸ªç”µè„‘çš„ï¼Œç”¨macåšå¼€å‘æœ¬æ¥æ¯”windowså¥½ä½¿å¤šäº†ã€‚\n",
    "\n",
    "æœ‰éœ€è¦çš„å°ä¼™ä¼´æ¨èä¹°è¿™ä¸ªï¼Œäº¬ä¸œè‡ªè¥çš„æ¸ é“ï¼ŒMac Book Pro M1èŠ¯ç‰‡ï¼Œ16Gç»Ÿä¸€å†…å­˜ï¼Œå°å‹ç‚¼ä¸¹åŸºæœ¬å¤Ÿç”¨ã€‚\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/008vxvgGgy1h8pw5ijnfuj30qi0z30uf.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
