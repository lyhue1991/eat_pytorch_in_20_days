{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ce156f",
   "metadata": {},
   "source": [
    "# 5-2,æ¨¡å‹å±‚layers\n",
    "\n",
    "æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸€èˆ¬ç”±å„ç§æ¨¡å‹å±‚ç»„åˆè€Œæˆã€‚\n",
    "\n",
    "torch.nnä¸­å†…ç½®äº†éå¸¸ä¸°å¯Œçš„å„ç§æ¨¡å‹å±‚ã€‚å®ƒä»¬éƒ½å±äºnn.Moduleçš„å­ç±»ï¼Œå…·å¤‡å‚æ•°ç®¡ç†åŠŸèƒ½ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "\n",
    "* nn.Linear, nn.Flatten, nn.Dropout, nn.BatchNorm2d, nn.Embedding\n",
    "\n",
    "* nn.Conv2d,nn.AvgPool2d,nn.Conv1d,nn.ConvTranspose2d\n",
    "\n",
    "* nn.GRU,nn.LSTM\n",
    "\n",
    "* nn.Transformer\n",
    "\n",
    "å¦‚æœè¿™äº›å†…ç½®æ¨¡å‹å±‚ä¸èƒ½å¤Ÿæ»¡è¶³éœ€æ±‚ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºè‡ªå®šä¹‰çš„æ¨¡å‹å±‚ã€‚\n",
    "\n",
    "å®é™…ä¸Šï¼Œpytorchä¸åŒºåˆ†æ¨¡å‹å’Œæ¨¡å‹å±‚ï¼Œéƒ½æ˜¯é€šè¿‡ç»§æ‰¿nn.Moduleè¿›è¡Œæ„å»ºã€‚\n",
    "\n",
    "å› æ­¤ï¼Œæˆ‘ä»¬åªè¦ç»§æ‰¿nn.ModuleåŸºç±»å¹¶å®ç°forwardæ–¹æ³•å³å¯è‡ªå®šä¹‰æ¨¡å‹å±‚ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175636b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bf8eb30",
   "metadata": {},
   "source": [
    "## ä¸€ï¼ŒåŸºç¡€å±‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89b697",
   "metadata": {},
   "source": [
    "ä¸€äº›åŸºç¡€çš„å†…ç½®æ¨¡å‹å±‚ç®€å•ä»‹ç»å¦‚ä¸‹ã€‚\n",
    "\n",
    "* nn.Linearï¼šå…¨è¿æ¥å±‚ã€‚å‚æ•°ä¸ªæ•° = è¾“å…¥å±‚ç‰¹å¾æ•°Ã— è¾“å‡ºå±‚ç‰¹å¾æ•°(weight)ï¼‹ è¾“å‡ºå±‚ç‰¹å¾æ•°(bias)\n",
    "\n",
    "* nn.Embeddingï¼šåµŒå…¥å±‚ã€‚ä¸€ç§æ¯”Onehotæ›´åŠ æœ‰æ•ˆçš„å¯¹ç¦»æ•£ç‰¹å¾è¿›è¡Œç¼–ç çš„æ–¹æ³•ã€‚ä¸€èˆ¬ç”¨äºå°†è¾“å…¥ä¸­çš„å•è¯æ˜ å°„ä¸ºç¨ å¯†å‘é‡ã€‚åµŒå…¥å±‚çš„å‚æ•°éœ€è¦å­¦ä¹ ã€‚\n",
    "\n",
    "* nn.Flattenï¼šå‹å¹³å±‚ï¼Œç”¨äºå°†å¤šç»´å¼ é‡æ ·æœ¬å‹æˆä¸€ç»´å¼ é‡æ ·æœ¬ã€‚\n",
    "\n",
    "* nn.BatchNorm1dï¼šä¸€ç»´æ‰¹æ ‡å‡†åŒ–å±‚ã€‚é€šè¿‡çº¿æ€§å˜æ¢å°†è¾“å…¥æ‰¹æ¬¡ç¼©æ”¾å¹³ç§»åˆ°ç¨³å®šçš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚å¯ä»¥å¢å¼ºæ¨¡å‹å¯¹è¾“å…¥ä¸åŒåˆ†å¸ƒçš„é€‚åº”æ€§ï¼ŒåŠ å¿«æ¨¡å‹è®­ç»ƒé€Ÿåº¦ï¼Œæœ‰è½»å¾®æ­£åˆ™åŒ–æ•ˆæœã€‚ä¸€èˆ¬åœ¨æ¿€æ´»å‡½æ•°ä¹‹å‰ä½¿ç”¨ã€‚å¯ä»¥ç”¨afineå‚æ•°è®¾ç½®è¯¥å±‚æ˜¯å¦å«æœ‰å¯ä»¥è®­ç»ƒçš„å‚æ•°ã€‚\n",
    "\n",
    "* nn.BatchNorm2dï¼šäºŒç»´æ‰¹æ ‡å‡†åŒ–å±‚ã€‚ å¸¸ç”¨äºCVé¢†åŸŸã€‚\n",
    "\n",
    "* nn.BatchNorm3dï¼šä¸‰ç»´æ‰¹æ ‡å‡†åŒ–å±‚ã€‚\n",
    "\n",
    "* nn.Dropoutï¼šä¸€ç»´éšæœºä¸¢å¼ƒå±‚ã€‚ä¸€ç§æ­£åˆ™åŒ–æ‰‹æ®µã€‚\n",
    "\n",
    "* nn.Dropout2dï¼šäºŒç»´éšæœºä¸¢å¼ƒå±‚ã€‚\n",
    "\n",
    "* nn.Dropout3dï¼šä¸‰ç»´éšæœºä¸¢å¼ƒå±‚ã€‚\n",
    "\n",
    "* nn.Thresholdï¼šé™å¹…å±‚ã€‚å½“è¾“å…¥å¤§äºæˆ–å°äºé˜ˆå€¼èŒƒå›´æ—¶ï¼Œæˆªæ–­ä¹‹ã€‚\n",
    "\n",
    "* nn.ConstantPad2dï¼š äºŒç»´å¸¸æ•°å¡«å……å±‚ã€‚å¯¹äºŒç»´å¼ é‡æ ·æœ¬å¡«å……å¸¸æ•°æ‰©å±•é•¿åº¦ã€‚\n",
    "\n",
    "* nn.ReplicationPad1dï¼š ä¸€ç»´å¤åˆ¶å¡«å……å±‚ã€‚å¯¹ä¸€ç»´å¼ é‡æ ·æœ¬é€šè¿‡å¤åˆ¶è¾¹ç¼˜å€¼å¡«å……æ‰©å±•é•¿åº¦ã€‚\n",
    "\n",
    "* nn.ZeroPad2dï¼šäºŒç»´é›¶å€¼å¡«å……å±‚ã€‚å¯¹äºŒç»´å¼ é‡æ ·æœ¬åœ¨è¾¹ç¼˜å¡«å……0å€¼.\n",
    "\n",
    "* nn.GroupNormï¼šç»„å½’ä¸€åŒ–ã€‚ä¸€ç§æ›¿ä»£æ‰¹å½’ä¸€åŒ–çš„æ–¹æ³•ï¼Œå°†é€šé“åˆ†æˆè‹¥å¹²ç»„è¿›è¡Œå½’ä¸€ã€‚ä¸å—batchå¤§å°é™åˆ¶ã€‚\n",
    "\n",
    "* nn.LayerNormï¼šå±‚å½’ä¸€åŒ–ã€‚å¸¸ç”¨äºNLPé¢†åŸŸï¼Œä¸å—åºåˆ—é•¿åº¦ä¸ä¸€è‡´å½±å“ã€‚\n",
    "\n",
    "* nn.InstanceNorm2d: æ ·æœ¬å½’ä¸€åŒ–ã€‚ä¸€èˆ¬åœ¨å›¾åƒé£æ ¼è¿ç§»ä»»åŠ¡ä¸­æ•ˆæœè¾ƒå¥½ã€‚\n",
    "\n",
    "\n",
    "\n",
    "é‡ç‚¹è¯´è¯´å„ç§å½’ä¸€åŒ–å±‚ï¼š\n",
    "\n",
    "$$y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta$$\n",
    "\n",
    "\n",
    "\n",
    "* ç»“æ„åŒ–æ•°æ®çš„BatchNorm1Då½’ä¸€åŒ– ã€ç»“æ„åŒ–æ•°æ®çš„ä¸»è¦åŒºåˆ†åº¦æ¥è‡ªæ¯ä¸ªæ ·æœ¬ç‰¹å¾åœ¨å…¨ä½“æ ·æœ¬ä¸­çš„æ’åºï¼Œå°†å…¨éƒ¨æ ·æœ¬çš„æŸä¸ªç‰¹å¾éƒ½è¿›è¡Œç›¸åŒçš„æ”¾å¤§ç¼©å°å¹³ç§»æ“ä½œï¼Œæ ·æœ¬é—´çš„åŒºåˆ†åº¦åŸºæœ¬ä¿æŒä¸å˜ï¼Œæ‰€ä»¥ç»“æ„åŒ–æ•°æ®å¯ä»¥åšBatchNormï¼Œä½†LayerNormä¼šæ‰“ä¹±å…¨ä½“æ ·æœ¬æ ¹æ®æŸä¸ªç‰¹å¾çš„æ’åºå…³ç³»ï¼Œå¼•èµ·åŒºåˆ†åº¦ä¸‹é™ã€‘\n",
    "\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h5mbd2ill5j20a808z0ta.jpg)\n",
    "\n",
    "\n",
    "* å›¾ç‰‡æ•°æ®çš„å„ç§å½’ä¸€åŒ–(ä¸€èˆ¬å¸¸ç”¨BatchNorm2D)ã€å›¾ç‰‡æ•°æ®çš„ä¸»è¦åŒºåˆ†åº¦æ¥è‡ªå›¾ç‰‡ä¸­çš„çº¹ç†ç»“æ„ï¼Œæ‰€ä»¥å›¾ç‰‡æ•°æ®çš„å½’ä¸€åŒ–ä¸€å®šè¦åœ¨å›¾ç‰‡çš„å®½é«˜æ–¹å‘ä¸Šæ“ä½œä»¥ä¿æŒçº¹ç†ç»“æ„ï¼Œæ­¤å¤–åœ¨Batchç»´åº¦ä¸Šæ“ä½œè¿˜èƒ½å¤Ÿå¼•å…¥å°‘è®¸çš„æ­£åˆ™åŒ–ï¼Œå¯¹æå‡ç²¾åº¦æœ‰è¿›ä¸€æ­¥çš„å¸®åŠ©ã€‚ã€‘\n",
    "\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h5m92dtnd0j20tn07ztab.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* æ–‡æœ¬æ•°æ®çš„LayerNormå½’ä¸€åŒ– ã€æ–‡æœ¬æ•°æ®çš„ä¸»è¦åŒºåˆ†åº¦æ¥è‡ªäºè¯å‘é‡(Embeddingå‘é‡)çš„æ–¹å‘ï¼Œæ‰€ä»¥æ–‡æœ¬æ•°æ®çš„å½’ä¸€åŒ–ä¸€å®šè¦åœ¨ ç‰¹å¾(é€šé“)ç»´åº¦ä¸Šæ“ä½œ ä»¥ä¿æŒ è¯å‘é‡æ–¹å‘ä¸å˜ã€‚æ­¤å¤–æ–‡æœ¬æ•°æ®è¿˜æœ‰ä¸€ä¸ªé‡è¦çš„ç‰¹ç‚¹æ˜¯ä¸åŒæ ·æœ¬çš„åºåˆ—é•¿åº¦å¾€å¾€ä¸ä¸€æ ·ï¼Œæ‰€ä»¥ä¸å¯ä»¥åœ¨Sequenceå’ŒBatchç»´åº¦ä¸Šåšå½’ä¸€åŒ–ï¼Œå¦åˆ™å°†ä¸å¯é¿å…åœ°è®©paddingä½ç½®å¯¹åº”çš„å‘é‡å˜æˆéé›¶å‘é‡ã€‘\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h5m903lv0nj20jc0iawfx.jpg)\n",
    "\n",
    "\n",
    "\n",
    "* æ­¤å¤–ï¼Œæœ‰è®ºæ–‡æå‡ºäº†ä¸€ç§å¯è‡ªé€‚åº”å­¦ä¹ çš„å½’ä¸€åŒ–ï¼šSwitchableNormï¼Œå¯åº”ç”¨äºå„ç§åœºæ™¯ä¸”æœ‰ä¸€å®šçš„æ•ˆæœæå‡ã€‚ã€SwitchableNormæ˜¯å°†BNã€LNã€INç»“åˆï¼Œèµ‹äºˆæƒé‡ï¼Œè®©ç½‘ç»œè‡ªå·±å»å­¦ä¹ å½’ä¸€åŒ–å±‚åº”è¯¥ä½¿ç”¨ä»€ä¹ˆæ–¹æ³•ã€‚ã€‘\n",
    "\n",
    "å‚è€ƒè®ºæ–‡ï¼šhttps://arxiv.org/pdf/1806.10779.pdf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "å¯¹BatchNorméœ€è¦æ³¨æ„çš„å‡ ç‚¹ï¼š\n",
    "\n",
    "(1)BatchNormæ”¾åœ¨æ¿€æ´»å‡½æ•°å‰è¿˜æ˜¯æ¿€æ´»å‡½æ•°åï¼Ÿ\n",
    "\n",
    "åŸå§‹è®ºæ–‡è®¤ä¸ºå°†BatchNormæ”¾åœ¨æ¿€æ´»å‡½æ•°å‰æ•ˆæœè¾ƒå¥½ï¼Œåé¢çš„ç ”ç©¶ä¸€èˆ¬è®¤ä¸ºå°†BatchNormæ”¾åœ¨æ¿€æ´»å‡½æ•°ä¹‹åæ›´å¥½ã€‚\n",
    "\n",
    "(2)BatchNormåœ¨è®­ç»ƒè¿‡ç¨‹å’Œæ¨ç†è¿‡ç¨‹çš„é€»è¾‘æ˜¯å¦ä¸€æ ·ï¼Ÿ\n",
    "\n",
    "ä¸ä¸€æ ·ï¼è®­ç»ƒè¿‡ç¨‹BatchNormçš„å‡å€¼å’Œæ–¹å·®å’Œæ ¹æ®mini-batchä¸­çš„æ•°æ®ä¼°è®¡çš„ï¼Œè€Œæ¨ç†è¿‡ç¨‹ä¸­BatchNormçš„å‡å€¼å’Œæ–¹å·®æ˜¯ç”¨çš„è®­ç»ƒè¿‡ç¨‹ä¸­çš„å…¨ä½“æ ·æœ¬ä¼°è®¡çš„ã€‚å› æ­¤é¢„æµ‹è¿‡ç¨‹æ˜¯ç¨³å®šçš„ï¼Œç›¸åŒçš„æ ·æœ¬ä¸ä¼šå› ä¸ºæ‰€åœ¨æ‰¹æ¬¡çš„å·®å¼‚å¾—åˆ°ä¸åŒçš„ç»“æœï¼Œä½†è®­ç»ƒè¿‡ç¨‹ä¸­åˆ™ä¼šå—åˆ°æ‰¹æ¬¡ä¸­å…¶ä»–æ ·æœ¬çš„å½±å“æ‰€ä»¥æœ‰æ­£åˆ™åŒ–æ•ˆæœã€‚\n",
    "\n",
    "(3)BatchNormçš„ç²¾åº¦æ•ˆæœä¸batch_sizeå¤§å°æœ‰ä½•å…³ç³»? \n",
    "\n",
    "å¦‚æœå—åˆ°GPUå†…å­˜é™åˆ¶ï¼Œä¸å¾—ä¸ä½¿ç”¨å¾ˆå°çš„batch_sizeï¼Œè®­ç»ƒé˜¶æ®µæ—¶ä½¿ç”¨çš„mini-batchä¸Šçš„å‡å€¼å’Œæ–¹å·®çš„ä¼°è®¡å’Œé¢„æµ‹é˜¶æ®µæ—¶ä½¿ç”¨çš„å…¨ä½“æ ·æœ¬ä¸Šçš„å‡å€¼å’Œæ–¹å·®çš„ä¼°è®¡å·®å¼‚å¯èƒ½ä¼šè¾ƒå¤§ï¼Œæ•ˆæœä¼šå˜å·®ã€‚è¿™æ—¶å€™ï¼Œå¯ä»¥å°è¯•LayerNormæˆ–è€…GroupNormç­‰å½’ä¸€åŒ–æ–¹æ³•ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf76da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel mean: 1.043081283569336e-07\n",
      "channel std: 1.0000009536743164\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "batch_size, channel, height, width = 32, 16, 128, 128\n",
    "\n",
    "tensor = torch.arange(0,32*16*128*128).view(32,16,128,128).float() \n",
    "\n",
    "bn = nn.BatchNorm2d(num_features=channel,affine=False)\n",
    "bn_out = bn(tensor)\n",
    "\n",
    "\n",
    "channel_mean = torch.mean(bn_out[:,0,:,:]) \n",
    "channel_std = torch.std(bn_out[:,0,:,:])\n",
    "print(\"channel mean:\",channel_mean.item())\n",
    "print(\"channel std:\",channel_std.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f406b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_mean: -5.8673322200775146e-08\n",
      "token_mean: 1.0002442598342896\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "batch_size, sequence, features = 32, 100, 2048\n",
    "tensor = torch.arange(0,32*100*2048).view(32,100,2048).float() \n",
    "\n",
    "ln = nn.LayerNorm(normalized_shape=[features],\n",
    "                  elementwise_affine = False)\n",
    "\n",
    "ln_out = ln(tensor)\n",
    "\n",
    "token_mean = torch.mean(ln_out[0,0,:]) \n",
    "token_std = torch.std(ln_out[0,0,:])\n",
    "print(\"token_mean:\",token_mean.item())\n",
    "print(\"token_mean:\",token_std.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1b19de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d05ae41",
   "metadata": {},
   "source": [
    "## äºŒï¼Œå·ç§¯ç½‘ç»œç›¸å…³å±‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45681a",
   "metadata": {},
   "source": [
    "ä¸€äº›ä¸å·ç§¯ç›¸å…³çš„å†…ç½®å±‚ä»‹ç»å¦‚ä¸‹\n",
    "\n",
    "* nn.Conv1dï¼šæ™®é€šä¸€ç»´å·ç§¯ï¼Œå¸¸ç”¨äºæ–‡æœ¬ã€‚å‚æ•°ä¸ªæ•° = è¾“å…¥é€šé“æ•°Ã—å·ç§¯æ ¸å°ºå¯¸(å¦‚3)Ã—å·ç§¯æ ¸ä¸ªæ•° + å·ç§¯æ ¸å°ºå¯¸(å¦‚3ï¼‰\n",
    "  \n",
    "* nn.Conv2dï¼šæ™®é€šäºŒç»´å·ç§¯ï¼Œå¸¸ç”¨äºå›¾åƒã€‚å‚æ•°ä¸ªæ•° = è¾“å…¥é€šé“æ•°Ã—å·ç§¯æ ¸å°ºå¯¸(å¦‚3ä¹˜3)Ã—å·ç§¯æ ¸ä¸ªæ•° + å·ç§¯æ ¸å°ºå¯¸(å¦‚3ä¹˜3)ã€‚) é€šè¿‡è°ƒæ•´dilationå‚æ•°å¤§äº1ï¼Œå¯ä»¥å˜æˆç©ºæ´å·ç§¯ï¼Œå¢åŠ æ„Ÿå—é‡ã€‚ é€šè¿‡è°ƒæ•´groupså‚æ•°ä¸ä¸º1ï¼Œå¯ä»¥å˜æˆåˆ†ç»„å·ç§¯ã€‚åˆ†ç»„å·ç§¯ä¸­æ¯ä¸ªå·ç§¯æ ¸ä»…å¯¹å…¶å¯¹åº”çš„ä¸€ä¸ªåˆ†ç»„è¿›è¡Œæ“ä½œã€‚ å½“groupså‚æ•°æ•°é‡ç­‰äºè¾“å…¥é€šé“æ•°æ—¶ï¼Œç›¸å½“äºtensorflowä¸­çš„äºŒç»´æ·±åº¦å·ç§¯å±‚tf.keras.layers.DepthwiseConv2Dã€‚ åˆ©ç”¨åˆ†ç»„å·ç§¯å’Œ1ä¹˜1å·ç§¯çš„ç»„åˆæ“ä½œï¼Œå¯ä»¥æ„é€ ç›¸å½“äºKerasä¸­çš„äºŒç»´æ·±åº¦å¯åˆ†ç¦»å·ç§¯å±‚tf.keras.layers.SeparableConv2Dã€‚\n",
    "\n",
    "* nn.Conv3dï¼šæ™®é€šä¸‰ç»´å·ç§¯ï¼Œå¸¸ç”¨äºè§†é¢‘ã€‚å‚æ•°ä¸ªæ•° = è¾“å…¥é€šé“æ•°Ã—å·ç§¯æ ¸å°ºå¯¸(å¦‚3ä¹˜3ä¹˜3)Ã—å·ç§¯æ ¸ä¸ªæ•° + å·ç§¯æ ¸å°ºå¯¸(å¦‚3ä¹˜3ä¹˜3) ã€‚\n",
    "\n",
    "* nn.MaxPool1d: ä¸€ç»´æœ€å¤§æ± åŒ–ã€‚\n",
    "\n",
    "* nn.MaxPool2dï¼šäºŒç»´æœ€å¤§æ± åŒ–ã€‚ä¸€ç§ä¸‹é‡‡æ ·æ–¹å¼ã€‚æ²¡æœ‰éœ€è¦è®­ç»ƒçš„å‚æ•°ã€‚\n",
    "\n",
    "* nn.MaxPool3dï¼šä¸‰ç»´æœ€å¤§æ± åŒ–ã€‚\n",
    "\n",
    "* nn.AdaptiveMaxPool2dï¼šäºŒç»´è‡ªé€‚åº”æœ€å¤§æ± åŒ–ã€‚æ— è®ºè¾“å…¥å›¾åƒçš„å°ºå¯¸å¦‚ä½•å˜åŒ–ï¼Œè¾“å‡ºçš„å›¾åƒå°ºå¯¸æ˜¯å›ºå®šçš„ã€‚\n",
    "  è¯¥å‡½æ•°çš„å®ç°åŸç†ï¼Œå¤§æ¦‚æ˜¯é€šè¿‡è¾“å…¥å›¾åƒçš„å°ºå¯¸å’Œè¦å¾—åˆ°çš„è¾“å‡ºå›¾åƒçš„å°ºå¯¸æ¥åå‘æ¨ç®—æ± åŒ–ç®—å­çš„padding,strideç­‰å‚æ•°ã€‚\n",
    "  \n",
    "* nn.FractionalMaxPool2dï¼šäºŒç»´åˆ†æ•°æœ€å¤§æ± åŒ–ã€‚æ™®é€šæœ€å¤§æ± åŒ–é€šå¸¸è¾“å…¥å°ºå¯¸æ˜¯è¾“å‡ºçš„æ•´æ•°å€ã€‚è€Œåˆ†æ•°æœ€å¤§æ± åŒ–åˆ™å¯ä»¥ä¸å¿…æ˜¯æ•´æ•°ã€‚åˆ†æ•°æœ€å¤§æ± åŒ–ä½¿ç”¨äº†ä¸€äº›éšæœºé‡‡æ ·ç­–ç•¥ï¼Œæœ‰ä¸€å®šçš„æ­£åˆ™æ•ˆæœï¼Œå¯ä»¥ç”¨å®ƒæ¥ä»£æ›¿æ™®é€šæœ€å¤§æ± åŒ–å’ŒDropoutå±‚ã€‚\n",
    "\n",
    "* nn.AvgPool2dï¼šäºŒç»´å¹³å‡æ± åŒ–ã€‚\n",
    "\n",
    "* nn.AdaptiveAvgPool2dï¼šäºŒç»´è‡ªé€‚åº”å¹³å‡æ± åŒ–ã€‚æ— è®ºè¾“å…¥çš„ç»´åº¦å¦‚ä½•å˜åŒ–ï¼Œè¾“å‡ºçš„ç»´åº¦æ˜¯å›ºå®šçš„ã€‚\n",
    "\n",
    "* nn.ConvTranspose2dï¼šäºŒç»´å·ç§¯è½¬ç½®å±‚ï¼Œä¿—ç§°åå·ç§¯å±‚ã€‚å¹¶éå·ç§¯çš„é€†æ“ä½œï¼Œä½†åœ¨å·ç§¯æ ¸ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œå½“å…¶è¾“å…¥å°ºå¯¸æ˜¯å·ç§¯æ“ä½œè¾“å‡ºå°ºå¯¸çš„æƒ…å†µä¸‹ï¼Œå·ç§¯è½¬ç½®çš„è¾“å‡ºå°ºå¯¸æ°å¥½æ˜¯å·ç§¯æ“ä½œçš„è¾“å…¥å°ºå¯¸ã€‚åœ¨è¯­ä¹‰åˆ†å‰²ä¸­å¯ç”¨äºä¸Šé‡‡æ ·ã€‚\n",
    "\n",
    "* nn.Upsampleï¼šä¸Šé‡‡æ ·å±‚ï¼Œæ“ä½œæ•ˆæœå’Œæ± åŒ–ç›¸åã€‚å¯ä»¥é€šè¿‡modeå‚æ•°æ§åˆ¶ä¸Šé‡‡æ ·ç­–ç•¥ä¸º\"nearest\"æœ€é‚»è¿‘ç­–ç•¥æˆ–\"linear\"çº¿æ€§æ’å€¼ç­–ç•¥ã€‚\n",
    "\n",
    "* nn.Unfoldï¼šæ»‘åŠ¨çª—å£æå–å±‚ã€‚å…¶å‚æ•°å’Œå·ç§¯æ“ä½œnn.Conv2dç›¸åŒã€‚å®é™…ä¸Šï¼Œå·ç§¯æ“ä½œå¯ä»¥ç­‰ä»·äºnn.Unfoldå’Œnn.Linearä»¥åŠnn.Foldçš„ä¸€ä¸ªç»„åˆã€‚\n",
    "  å…¶ä¸­nn.Unfoldæ“ä½œå¯ä»¥ä»è¾“å…¥ä¸­æå–å„ä¸ªæ»‘åŠ¨çª—å£çš„æ•°å€¼çŸ©é˜µï¼Œå¹¶å°†å…¶å‹å¹³æˆä¸€ç»´ã€‚åˆ©ç”¨nn.Linearå°†nn.Unfoldçš„è¾“å‡ºå’Œå·ç§¯æ ¸åšä¹˜æ³•åï¼Œå†ä½¿ç”¨\n",
    "  nn.Foldæ“ä½œå°†ç»“æœè½¬æ¢æˆè¾“å‡ºå›¾ç‰‡å½¢çŠ¶ã€‚\n",
    "\n",
    "* nn.Foldï¼šé€†æ»‘åŠ¨çª—å£æå–å±‚ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb129af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "065c1f9b",
   "metadata": {},
   "source": [
    "é‡ç‚¹è¯´è¯´å„ç§å¸¸ç”¨çš„å·ç§¯å±‚å’Œä¸Šé‡‡æ ·å±‚ï¼š\n",
    "\n",
    "* æ™®é€šå·ç§¯ã€æ™®é€šå·ç§¯çš„æ“ä½œåˆ†æˆ3ä¸ªç»´åº¦ï¼Œåœ¨ç©ºé—´ç»´åº¦(Hå’ŒWç»´åº¦)æ˜¯å…±äº«å·ç§¯æ ¸æƒé‡æ»‘çª—ç›¸ä¹˜æ±‚å’Œ(èåˆç©ºé—´ä¿¡æ¯)ï¼Œåœ¨è¾“å…¥é€šé“ç»´åº¦æ˜¯æ¯ä¸€ä¸ªé€šé“ä½¿ç”¨ä¸åŒçš„å·ç§¯æ ¸å‚æ•°å¹¶å¯¹è¾“å…¥é€šé“ç»´åº¦æ±‚å’Œ(èåˆé€šé“ä¿¡æ¯)ï¼Œåœ¨è¾“å‡ºé€šé“ç»´åº¦æ“ä½œæ–¹å¼æ˜¯å¹¶è¡Œå †å (å¤šç§)ï¼Œæœ‰å¤šå°‘ä¸ªå·ç§¯æ ¸å°±æœ‰å¤šå°‘ä¸ªè¾“å‡ºé€šé“ã€‘\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h5nhe0lsutg20az0aln03.gif)\n",
    "\n",
    "\n",
    "\n",
    "* ç©ºæ´å·ç§¯ã€å’Œæ™®é€šå·ç§¯ç›¸æ¯”ï¼Œç©ºæ´å·ç§¯å¯ä»¥åœ¨ä¿æŒè¾ƒå°å‚æ•°è§„æ¨¡çš„æ¡ä»¶ä¸‹å¢å¤§æ„Ÿå—é‡ï¼Œå¸¸ç”¨äºå›¾åƒåˆ†å‰²é¢†åŸŸã€‚å…¶ç¼ºç‚¹æ˜¯å¯èƒ½äº§ç”Ÿç½‘æ ¼æ•ˆåº”ï¼Œå³æœ‰äº›åƒç´ è¢«ç©ºæ´æ¼è¿‡æ— æ³•åˆ©ç”¨åˆ°ï¼Œå¯ä»¥é€šè¿‡ä½¿ç”¨ä¸åŒè†¨èƒ€å› å­çš„ç©ºæ´å·ç§¯çš„ç»„åˆæ¥å…‹æœè¯¥é—®é¢˜ï¼Œå‚è€ƒæ–‡ç« ï¼šhttps://developer.orbbec.com.cn/v/blog_detail/892 ã€‘ \n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h5nhe0y7x1g20az0al0vu.gif)\n",
    "\n",
    "\n",
    "* åˆ†ç»„å·ç§¯ ã€å’Œæ™®é€šå·ç§¯ç›¸æ¯”ï¼Œåˆ†ç»„å·ç§¯å°†è¾“å…¥é€šé“åˆ†æˆgç»„ï¼Œå·ç§¯æ ¸ä¹Ÿåˆ†æˆå¯¹åº”çš„gç»„ï¼Œæ¯ä¸ªå·ç§¯æ ¸åªåœ¨å…¶å¯¹åº”çš„é‚£ç»„è¾“å…¥é€šé“ä¸Šåšå·ç§¯ï¼Œæœ€åå°†gç»„ç»“æœå †å æ‹¼æ¥ã€‚ç”±äºæ¯ä¸ªå·ç§¯æ ¸åªéœ€è¦åœ¨å…¨éƒ¨è¾“å…¥é€šé“çš„1/gä¸ªé€šé“ä¸Šåšå·ç§¯ï¼Œå‚æ•°é‡é™ä½ä¸ºæ™®é€šå·ç§¯çš„1/gã€‚åˆ†ç»„å·ç§¯è¦æ±‚è¾“å…¥é€šé“å’Œè¾“å‡ºé€šé“æ•°éƒ½æ˜¯gçš„æ•´æ•°å€ã€‚å‚è€ƒæ–‡ç« ï¼šhttps://zhuanlan.zhihu.com/p/65377955 ã€‘\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h5npy1zyalj20ie0erwf8.jpg)\n",
    "\n",
    "\n",
    "\n",
    "* æ·±åº¦å¯åˆ†ç¦»å·ç§¯ã€æ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„æ€æƒ³æ˜¯å…ˆç”¨g=m(è¾“å…¥é€šé“æ•°)çš„åˆ†ç»„å·ç§¯é€é€šé“ä½œç”¨èåˆç©ºé—´ä¿¡æ¯ï¼Œå†ç”¨n(è¾“å‡ºé€šé“æ•°)ä¸ª1ä¹˜1å·ç§¯èåˆé€šé“ä¿¡æ¯ã€‚ å…¶å‚æ•°é‡ä¸º (mÃ—kÃ—k)+ nÃ—m, ç›¸æ¯”æ™®é€šå·ç§¯çš„å‚æ•°é‡ mÃ—nÃ—kÃ—k æ˜¾è‘—å‡å° ã€‘\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h5npbiuvzvj20uq0e7dge.jpg)\n",
    "\n",
    "\n",
    "* è½¬ç½®å·ç§¯ ã€ä¸€èˆ¬çš„å·ç§¯æ“ä½œåä¼šè®©ç‰¹å¾å›¾å°ºå¯¸å˜å°ï¼Œä½†è½¬ç½®å·ç§¯(ä¹Ÿè¢«ç§°ä¸ºåå·ç§¯)å¯ä»¥å®ç°ç›¸åçš„æ•ˆæœï¼Œå³æ”¾å¤§ç‰¹å¾å›¾å°ºå¯¸ã€‚å¯¹ä¸¤ç§æ–¹å¼ç†è§£è½¬ç½®å·ç§¯ï¼Œç¬¬ä¸€ç§æ–¹å¼æ˜¯è½¬ç½®å·ç§¯æ˜¯ä¸€ç§ç‰¹æ®Šçš„å·ç§¯ï¼Œé€šè¿‡è®¾ç½®åˆé€‚çš„paddingçš„å¤§å°æ¥æ¢å¤ç‰¹å¾å›¾å°ºå¯¸ã€‚ç¬¬äºŒç§ç†è§£åŸºäºå·ç§¯è¿ç®—çš„çŸ©é˜µä¹˜æ³•è¡¨ç¤ºæ–¹æ³•ï¼Œè½¬ç½®å·ç§¯ç›¸å½“äºå°†å·ç§¯æ ¸å¯¹åº”çš„è¡¨ç¤ºçŸ©é˜µåšè½¬ç½®ï¼Œç„¶åä¹˜ä¸Šè¾“å‡ºç‰¹å¾å›¾å‹å¹³çš„ä¸€ç»´å‘é‡ï¼Œå³å¯æ¢å¤åŸå§‹è¾“å…¥ç‰¹å¾å›¾çš„å¤§å°ã€‚\n",
    "å‚è€ƒæ–‡ç« ï¼šhttps://zhuanlan.zhihu.com/p/115070523ã€‘\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h5ns98iiamj20v70u075e.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* ä¸Šé‡‡æ ·å±‚ ã€é™¤äº†ä½¿ç”¨è½¬ç½®å·ç§¯è¿›è¡Œä¸Šé‡‡æ ·å¤–ï¼Œåœ¨å›¾åƒåˆ†å‰²é¢†åŸŸæ›´å¤šçš„æ—¶å€™ä¸€èˆ¬æ˜¯ä½¿ç”¨åŒçº¿æ€§æ’å€¼çš„æ–¹å¼è¿›è¡Œä¸Šé‡‡æ ·ï¼Œè¯¥æ–¹æ³•æ²¡æœ‰éœ€è¦å­¦ä¹ çš„å‚æ•°ï¼Œé€šå¸¸æ•ˆæœä¹Ÿæ›´å¥½ï¼Œé™¤äº†åŒçº¿æ€§æ’å€¼ä¹‹å¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨æœ€é‚»è¿‘æ’å€¼çš„æ–¹å¼è¿›è¡Œä¸Šé‡‡æ ·ï¼Œä½†ä½¿ç”¨è¾ƒå°‘ã€‚ã€‘\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h5nsi5pt4eg20na0co74k.gif)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ea2f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--inputs--\n",
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.],\n",
      "          [ 5.,  6.,  7.,  8.,  9.],\n",
      "          [10., 11., 12., 13., 14.],\n",
      "          [15., 16., 17., 18., 19.],\n",
      "          [20., 21., 22., 23., 24.]]]])\n",
      "--filters--\n",
      "tensor([[[[1., 1.],\n",
      "          [1., 1.]]]])\n",
      "--outputs--\n",
      "tensor([[[[12., 16., 20., 24.],\n",
      "          [32., 36., 40., 44.],\n",
      "          [52., 56., 60., 64.],\n",
      "          [72., 76., 80., 84.]]]]) \n",
      "\n",
      "--outputs(stride=2)--\n",
      "tensor([[[[12., 20.],\n",
      "          [52., 60.]]]]) \n",
      "\n",
      "--outputs(padding=1)--\n",
      "tensor([[[[ 0.,  1.,  3.,  5.,  7.,  4.],\n",
      "          [ 5., 12., 16., 20., 24., 13.],\n",
      "          [15., 32., 36., 40., 44., 23.],\n",
      "          [25., 52., 56., 60., 64., 33.],\n",
      "          [35., 72., 76., 80., 84., 43.],\n",
      "          [20., 41., 43., 45., 47., 24.]]]]) \n",
      "\n",
      "--outputs(dilation=2)--\n",
      "tensor([[[[24., 28., 32.],\n",
      "          [44., 48., 52.],\n",
      "          [64., 68., 72.]]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# å·ç§¯è¾“å‡ºå°ºå¯¸è®¡ç®—å…¬å¼ o = (i + 2*p -k')//s  + 1 \n",
    "# å¯¹ç©ºæ´å·ç§¯ k' = d(k-1) + 1\n",
    "# oæ˜¯è¾“å‡ºå°ºå¯¸ï¼Œi æ˜¯è¾“å…¥å°ºå¯¸ï¼Œpæ˜¯ paddingå¤§å°ï¼Œ k æ˜¯å·ç§¯æ ¸å°ºå¯¸ï¼Œ sæ˜¯strideæ­¥é•¿, dæ˜¯dilationç©ºæ´å‚æ•°\n",
    "\n",
    "inputs = torch.arange(0,25).view(1,1,5,5).float() # i= 5\n",
    "filters = torch.tensor([[[[1.0,1],[1,1]]]]) # k = 2\n",
    "\n",
    "outputs = F.conv2d(inputs, filters) # o = (5+2*0-2)//1+1 = 4\n",
    "outputs_s2 = F.conv2d(inputs, filters, stride=2)  #o = (5+2*0-2)//2+1 = 2\n",
    "outputs_p1 = F.conv2d(inputs, filters, padding=1) #o = (5+2*1-2)//1+1 = 6\n",
    "outputs_d2 = F.conv2d(inputs,filters, dilation=2) #o = (5+2*0-(2(2-1)+1))//1+1 = 3\n",
    "\n",
    "print(\"--inputs--\")\n",
    "print(inputs)\n",
    "print(\"--filters--\")\n",
    "print(filters)\n",
    "\n",
    "print(\"--outputs--\")\n",
    "print(outputs,\"\\n\")\n",
    "\n",
    "print(\"--outputs(stride=2)--\")\n",
    "print(outputs_s2,\"\\n\")\n",
    "\n",
    "print(\"--outputs(padding=1)--\")\n",
    "print(outputs_p1,\"\\n\")\n",
    "\n",
    "print(\"--outputs(dilation=2)--\")\n",
    "print(outputs_d2,\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27bdd558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: torch.Size([8, 64, 128, 128])\n",
      "\n",
      "\n",
      "--conv--\n",
      "conv_out.shape: torch.Size([8, 32, 126, 126])\n",
      "conv.weight.shape: torch.Size([32, 64, 3, 3])\n",
      "\n",
      "\n",
      "--group conv--\n",
      "group_out.shape: torch.Size([8, 32, 126, 126])\n",
      "conv_group.weight.shape: torch.Size([32, 8, 3, 3])\n",
      "\n",
      "\n",
      "--separable conv--\n",
      "separable_out.shape: torch.Size([8, 32, 126, 126])\n",
      "depth_conv.weight.shape: torch.Size([64, 1, 3, 3])\n",
      "oneone_conv.weight.shape: torch.Size([32, 64, 1, 1])\n",
      "\n",
      "\n",
      "--conv transpose--\n",
      "features_like.shape: torch.Size([8, 64, 128, 128])\n",
      "conv_t.weight.shape: torch.Size([32, 64, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "features = torch.randn(8,64,128,128)\n",
    "print(\"features.shape:\",features.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "#æ™®é€šå·ç§¯\n",
    "print(\"--conv--\")\n",
    "conv = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3)\n",
    "conv_out = conv(features)\n",
    "print(\"conv_out.shape:\",conv_out.shape) \n",
    "print(\"conv.weight.shape:\",conv.weight.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "#åˆ†ç»„å·ç§¯\n",
    "print(\"--group conv--\")\n",
    "conv_group = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,groups=8)\n",
    "group_out = conv_group(features)\n",
    "print(\"group_out.shape:\",group_out.shape) \n",
    "print(\"conv_group.weight.shape:\",conv_group.weight.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "#æ·±åº¦å¯åˆ†ç¦»å·ç§¯\n",
    "print(\"--separable conv--\")\n",
    "depth_conv = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,groups=64)\n",
    "oneone_conv = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=1)\n",
    "separable_conv = nn.Sequential(depth_conv,oneone_conv)\n",
    "separable_out = separable_conv(features)\n",
    "print(\"separable_out.shape:\",separable_out.shape) \n",
    "print(\"depth_conv.weight.shape:\",depth_conv.weight.shape)\n",
    "print(\"oneone_conv.weight.shape:\",oneone_conv.weight.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "#è½¬ç½®å·ç§¯\n",
    "print(\"--conv transpose--\")\n",
    "conv_t = nn.ConvTranspose2d(in_channels=32,out_channels=64,kernel_size=3)\n",
    "features_like = conv_t(conv_out)\n",
    "print(\"features_like.shape:\",features_like.shape)\n",
    "print(\"conv_t.weight.shape:\",conv_t.weight.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d22c1c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[[[1., 2.],\n",
      "          [3., 4.]]]])\n",
      "\n",
      "\n",
      "nearest(inputs)ï¼š\n",
      "tensor([[[[1., 1., 2., 2.],\n",
      "          [1., 1., 2., 2.],\n",
      "          [3., 3., 4., 4.],\n",
      "          [3., 3., 4., 4.]]]])\n",
      "\n",
      "\n",
      "bilinear(inputs)ï¼š\n",
      "tensor([[[[1.0000, 1.3333, 1.6667, 2.0000],\n",
      "          [1.6667, 2.0000, 2.3333, 2.6667],\n",
      "          [2.3333, 2.6667, 3.0000, 3.3333],\n",
      "          [3.0000, 3.3333, 3.6667, 4.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "inputs = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)\n",
    "print(\"inputs:\")\n",
    "print(inputs)\n",
    "print(\"\\n\")\n",
    "\n",
    "nearest = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "bilinear = nn.Upsample(scale_factor=2,mode=\"bilinear\",align_corners=True)\n",
    "\n",
    "print(\"nearest(inputs)ï¼š\")\n",
    "print(nearest(inputs))\n",
    "print(\"\\n\")\n",
    "print(\"bilinear(inputs)ï¼š\")\n",
    "print(bilinear(inputs)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8b35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "094132b2",
   "metadata": {},
   "source": [
    "## ä¸‰ï¼Œå¾ªç¯ç½‘ç»œç›¸å…³å±‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab158895",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* nn.LSTMï¼šé•¿çŸ­è®°å¿†å¾ªç¯ç½‘ç»œå±‚ã€æ”¯æŒå¤šå±‚ã€‘ã€‚æœ€æ™®éä½¿ç”¨çš„å¾ªç¯ç½‘ç»œå±‚ã€‚å…·æœ‰æºå¸¦è½¨é“ï¼Œé—å¿˜é—¨ï¼Œæ›´æ–°é—¨ï¼Œè¾“å‡ºé—¨ã€‚å¯ä»¥è¾ƒä¸ºæœ‰æ•ˆåœ°ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä»è€Œèƒ½å¤Ÿé€‚ç”¨é•¿æœŸä¾èµ–é—®é¢˜ã€‚è®¾ç½®bidirectional = Trueæ—¶å¯ä»¥å¾—åˆ°åŒå‘LSTMã€‚éœ€è¦æ³¨æ„çš„æ—¶ï¼Œé»˜è®¤çš„è¾“å…¥å’Œè¾“å‡ºå½¢çŠ¶æ˜¯(seq,batch,feature), å¦‚æœéœ€è¦å°†batchç»´åº¦æ”¾åœ¨ç¬¬0ç»´ï¼Œåˆ™è¦è®¾ç½®batch_firstå‚æ•°è®¾ç½®ä¸ºTrueã€‚\n",
    "\n",
    "* nn.GRUï¼šé—¨æ§å¾ªç¯ç½‘ç»œå±‚ã€æ”¯æŒå¤šå±‚ã€‘ã€‚LSTMçš„ä½é…ç‰ˆï¼Œä¸å…·æœ‰æºå¸¦è½¨é“ï¼Œå‚æ•°æ•°é‡å°‘äºLSTMï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ã€‚\n",
    "\n",
    "* nn.RNNï¼šç®€å•å¾ªç¯ç½‘ç»œå±‚ã€æ”¯æŒå¤šå±‚ã€‘ã€‚å®¹æ˜“å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±ï¼Œä¸èƒ½å¤Ÿé€‚ç”¨é•¿æœŸä¾èµ–é—®é¢˜ã€‚ä¸€èˆ¬è¾ƒå°‘ä½¿ç”¨ã€‚\n",
    "\n",
    "* nn.LSTMCellï¼šé•¿çŸ­è®°å¿†å¾ªç¯ç½‘ç»œå•å…ƒã€‚å’Œnn.LSTMåœ¨æ•´ä¸ªåºåˆ—ä¸Šè¿­ä»£ç›¸æ¯”ï¼Œå®ƒä»…åœ¨åºåˆ—ä¸Šè¿­ä»£ä¸€æ­¥ã€‚ä¸€èˆ¬è¾ƒå°‘ä½¿ç”¨ã€‚\n",
    "\n",
    "* nn.GRUCellï¼šé—¨æ§å¾ªç¯ç½‘ç»œå•å…ƒã€‚å’Œnn.GRUåœ¨æ•´ä¸ªåºåˆ—ä¸Šè¿­ä»£ç›¸æ¯”ï¼Œå®ƒä»…åœ¨åºåˆ—ä¸Šè¿­ä»£ä¸€æ­¥ã€‚ä¸€èˆ¬è¾ƒå°‘ä½¿ç”¨ã€‚\n",
    "\n",
    "* nn.RNNCellï¼šç®€å•å¾ªç¯ç½‘ç»œå•å…ƒã€‚å’Œnn.RNNåœ¨æ•´ä¸ªåºåˆ—ä¸Šè¿­ä»£ç›¸æ¯”ï¼Œå®ƒä»…åœ¨åºåˆ—ä¸Šè¿­ä»£ä¸€æ­¥ã€‚ä¸€èˆ¬è¾ƒå°‘ä½¿ç”¨ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ce392",
   "metadata": {},
   "source": [
    "é‡ç‚¹ä»‹ç»ä¸€ä¸‹LSTMå’ŒGRU \n",
    "\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h5rzqa54z6j20u00j30u3.jpg)\n",
    "\n",
    "ä¸€èˆ¬åœ°ï¼Œå„ç§RNNåºåˆ—æ¨¡å‹å±‚(RNN,GRU,LSTMç­‰)å¯ä»¥ç”¨å‡½æ•°è¡¨ç¤ºå¦‚ä¸‹:\n",
    "\n",
    "$$h_t = f(h_{t-1},x_t)$$\n",
    "\n",
    "è¿™ä¸ªå…¬å¼çš„å«ä¹‰æ˜¯ï¼štæ—¶åˆ»å¾ªç¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºå‘é‡$h_t$ç”±t-1æ—¶åˆ»çš„è¾“å‡ºå‘é‡$h_{t-1}$å’Œtæ—¶åˆ»çš„è¾“å…¥$i_t$å˜æ¢è€Œæ¥ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed59b95",
   "metadata": {},
   "source": [
    "* LSTM ç»“æ„è§£æ \n",
    "\n",
    "å‚è€ƒæ–‡ç« ï¼šã€Šäººäººéƒ½èƒ½çœ‹æ‡‚çš„LSTMã€‹https://zhuanlan.zhihu.com/p/32085405\n",
    "\n",
    "LSTMé€šè¿‡å¼•å…¥äº†ä¸‰ä¸ªé—¨æ¥æ§åˆ¶ä¿¡æ¯çš„ä¼ é€’ï¼Œåˆ†åˆ«æ˜¯é—å¿˜é—¨ï¼Œè¾“å…¥é—¨ å’Œè¾“å‡ºé—¨ ã€‚ä¸‰ä¸ªé—¨çš„ä½œç”¨ä¸ºï¼š\n",
    "\n",
    "ï¼ˆ1ï¼‰é—å¿˜é—¨: é—å¿˜é—¨$f_t$æ§åˆ¶ä¸Šä¸€æ—¶åˆ»çš„å†…éƒ¨çŠ¶æ€  éœ€è¦é—å¿˜å¤šå°‘ä¿¡æ¯ï¼›\n",
    "\n",
    "ï¼ˆ2ï¼‰è¾“å…¥é—¨: è¾“å…¥é—¨$i_t$æ§åˆ¶å½“å‰æ—¶åˆ»çš„å€™é€‰çŠ¶æ€  æœ‰å¤šå°‘ä¿¡æ¯éœ€è¦ä¿å­˜ï¼›\n",
    "\n",
    "ï¼ˆ3ï¼‰è¾“å‡ºé—¨: è¾“å‡ºé—¨$o_t$æ§åˆ¶å½“å‰æ—¶åˆ»çš„å†…éƒ¨çŠ¶æ€  æœ‰å¤šå°‘ä¿¡æ¯éœ€è¦è¾“å‡ºç»™å¤–éƒ¨çŠ¶æ€  ï¼›\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "i_{t}=\\sigma\\left(W_{i} x_{t}+U_{i} h_{t-1}+b_{i}\\right) \\tag{1} \\\\\n",
    "f_{t}=\\sigma\\left(W_{f} x_{t}+U_{f} h_{t-1}+b_{f}\\right) \\tag{2} \\\\\n",
    "o_{t}=\\sigma\\left(W_{o} x_{t}+U_{o} h_{t-1}+b_{o}\\right) \\tag{3} \\\\\n",
    "\\tilde{c}_{t}=\\tanh \\left(W_{c} x_{t}+U_{c} h_{t-1}+b_{c}\\right) \\tag{4} \\\\\n",
    "c_{t}=f_{t} \\odot c_{t-1}+i_{t} \\odot \\tilde{c}_{t} \\tag{5} \\\\\n",
    "h_{t}=o_{t} \\odot \\tanh \\left(c_{t}\\right) \\tag{6}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52277c4",
   "metadata": {},
   "source": [
    "* GRU ç»“æ„è§£æ\n",
    "\n",
    "å‚è€ƒæ–‡ç« ï¼šã€Šäººäººéƒ½èƒ½çœ‹æ‡‚çš„GRUã€‹https://zhuanlan.zhihu.com/p/32481747\n",
    "\n",
    "GRUçš„ç»“æ„æ¯”LSTMæ›´ä¸ºç®€å•ä¸€äº›ï¼ŒGRUåªæœ‰ä¸¤ä¸ªé—¨ï¼Œæ›´æ–°é—¨å’Œé‡ç½®é—¨  ã€‚\n",
    "\n",
    "ï¼ˆ1ï¼‰æ›´æ–°é—¨ï¼šæ›´æ–°é—¨ç”¨äºæ§åˆ¶æ¯ä¸€æ­¥$h_t$è¢«æ›´æ–°çš„æ¯”ä¾‹ï¼Œæ›´æ–°é—¨è¶Šå¤§ï¼Œ$h_t$æ›´æ–°å¹…åº¦è¶Šå¤§ã€‚\n",
    "\n",
    "ï¼ˆ2ï¼‰é‡ç½®é—¨ï¼šé‡ç½®é—¨ç”¨äºæ§åˆ¶æ›´æ–°å€™é€‰å‘é‡$\\tilde{h}_{t}$ä¸­å‰ä¸€æ­¥çš„çŠ¶æ€$h_{t-1}$è¢«é‡æ–°æ”¾å…¥çš„æ¯”ä¾‹ï¼Œé‡ç½®é—¨è¶Šå¤§ï¼Œæ›´æ–°å€™é€‰å‘é‡ä¸­$h_{t-1}$è¢«é‡æ–°æ”¾è¿›æ¥çš„æ¯”ä¾‹è¶Šå¤§ã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "å…¬å¼ä¸­çš„å°åœˆè¡¨ç¤ºå“ˆè¾¾ç›ç§¯ï¼Œä¹Ÿå°±æ˜¯ä¸¤ä¸ªå‘é‡é€ä½ç›¸ä¹˜ã€‚\n",
    "\n",
    "å…¶ä¸­(1)å¼å’Œ(2)å¼è®¡ç®—çš„æ˜¯æ›´æ–°é—¨$u_t$å’Œé‡ç½®é—¨$r_t$ï¼Œæ˜¯ä¸¤ä¸ªé•¿åº¦å’Œ$h_t$ç›¸åŒçš„å‘é‡ã€‚\n",
    "\n",
    "\n",
    "æ³¨æ„åˆ°(4)å¼ å®é™…ä¸Šå’ŒResNetçš„æ®‹å·®ç»“æ„æ˜¯ç›¸ä¼¼çš„ï¼Œéƒ½æ˜¯ f(x) = x + g(x) çš„å½¢å¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°é˜²æ­¢é•¿åºåˆ—å­¦ä¹ åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "z_{t}=\\sigma\\left(W_{z} x_{t}+U_{z} h_{t-1}+b_{z}\\right)\\tag{1} \\\\\n",
    "r_{t}=\\sigma\\left(W_{r} x_{t}+U_{r} h_{t-1}+b_{r}\\right) \\tag{2}\\\\\n",
    "\\tilde{h}_{t}=\\tanh \\left(W_{h} x_{t}+U_{h}\\left(r_{t} \\odot h_{t-1}\\right)+b_{h}\\right) \\tag{3}\\\\\n",
    "h_{t}= h_{t-1} - z_{t}\\odot h_{t-1}  + z_{t} \\odot  \\tilde{h}_{t} \\tag{4}\n",
    "\\end{align}\n",
    "$$\n",
    "GRUçš„å‚æ•°æ•°é‡ä¸ºLSTMçš„3/4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce71a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--GRU--\n",
      "gru_output.shape: torch.Size([8, 200, 32])\n",
      "gru_hn.shape: torch.Size([1, 8, 32])\n",
      "\n",
      "\n",
      "--LSTM--\n",
      "lstm_output.shape: torch.Size([8, 200, 32])\n",
      "lstm_hn.shape: torch.Size([1, 8, 32])\n",
      "lstm_cn.shape: torch.Size([1, 8, 32])\n",
      "--------------------------------------------------------------------------\n",
      "Layer (type)                            Output Shape              Param #\n",
      "==========================================================================\n",
      "GRU-1                                  [-1, 200, 32]                9,408\n",
      "==========================================================================\n",
      "Total params: 9,408\n",
      "Trainable params: 9,408\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "Input size (MB): 0.000069\n",
      "Forward/backward pass size (MB): 0.048828\n",
      "Params size (MB): 0.035889\n",
      "Estimated Total Size (MB): 0.084785\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Layer (type)                            Output Shape              Param #\n",
      "==========================================================================\n",
      "LSTM-1                                 [-1, 200, 32]               12,544\n",
      "==========================================================================\n",
      "Total params: 12,544\n",
      "Trainable params: 12,544\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "Input size (MB): 0.000069\n",
      "Forward/backward pass size (MB): 0.048828\n",
      "Params size (MB): 0.047852\n",
      "Estimated Total Size (MB): 0.096748\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "inputs = torch.randn(8,200,64) #batch_size, seq_length, features\n",
    "\n",
    "gru = nn.GRU(input_size=64,hidden_size=32,num_layers=1,batch_first=True)\n",
    "gru_output,gru_hn = gru(inputs)\n",
    "print(\"--GRU--\")\n",
    "print(\"gru_output.shape:\",gru_output.shape)\n",
    "print(\"gru_hn.shape:\",gru_hn.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"--LSTM--\")\n",
    "lstm = nn.LSTM(input_size=64,hidden_size=32,num_layers=1,batch_first=True)\n",
    "lstm_output,(lstm_hn,lstm_cn) = lstm(inputs)\n",
    "print(\"lstm_output.shape:\",lstm_output.shape)\n",
    "print(\"lstm_hn.shape:\",lstm_hn.shape)\n",
    "print(\"lstm_cn.shape:\",lstm_cn.shape)\n",
    "\n",
    "\n",
    "from torchkeras import summary\n",
    "summary(gru,input_data=inputs);\n",
    "summary(lstm,input_data=inputs);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea31566a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9408/12544 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a3282c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c1253cc",
   "metadata": {},
   "source": [
    "## å››ï¼ŒTransformerç›¸å…³å±‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cae9f0",
   "metadata": {},
   "source": [
    "* nn.Transformerï¼šTransformerç½‘ç»œç»“æ„ã€‚Transformerç½‘ç»œç»“æ„æ˜¯æ›¿ä»£å¾ªç¯ç½‘ç»œçš„ä¸€ç§ç»“æ„ï¼Œè§£å†³äº†å¾ªç¯ç½‘ç»œéš¾ä»¥å¹¶è¡Œï¼Œéš¾ä»¥æ•æ‰é•¿æœŸä¾èµ–çš„ç¼ºé™·ã€‚å®ƒæ˜¯ç›®å‰NLPä»»åŠ¡çš„ä¸»æµæ¨¡å‹çš„ä¸»è¦æ„æˆéƒ¨åˆ†ã€‚\n",
    "\n",
    "* nn.TransformerEncoderï¼šTransformerç¼–ç å™¨ç»“æ„ã€‚ç”±å¤šä¸ª nn.TransformerEncoderLayerç¼–ç å™¨å±‚ç»„æˆã€‚\n",
    "\n",
    "* nn.TransformerDecoderï¼šTransformerè§£ç å™¨ç»“æ„ã€‚ç”±å¤šä¸ª nn.TransformerDecoderLayerè§£ç å™¨å±‚ç»„æˆã€‚\n",
    "\n",
    "* nn.TransformerEncoderLayerï¼šTransformerçš„ç¼–ç å™¨å±‚ã€‚ä¸»è¦ç”±Multi-Head self-Attention, Feed-Forwardå‰é¦ˆç½‘ç»œ, LayerNormå½’ä¸€åŒ–å±‚, ä»¥åŠæ®‹å·®è¿æ¥å±‚ç»„æˆã€‚\n",
    "\n",
    "* nn.TransformerDecoderLayerï¼šTransformerçš„è§£ç å™¨å±‚ã€‚ä¸»è¦ç”±Masked Multi-Head self-Attention, Multi-Head cross-Attention, Feed-Forwardå‰é¦ˆç½‘ç»œ, LayerNormå½’ä¸€åŒ–å±‚, ä»¥åŠæ®‹å·®è¿æ¥å±‚ç»„æˆã€‚\n",
    "\n",
    "* nn.MultiheadAttentionï¼šå¤šå¤´æ³¨æ„åŠ›å±‚ã€‚ç”¨äºåœ¨åºåˆ—æ–¹å‘ä¸Šèåˆç‰¹å¾ã€‚ä½¿ç”¨çš„æ˜¯Scaled Dot Production Attentionï¼Œå¹¶å¼•å…¥äº†å¤šä¸ªæ³¨æ„åŠ›å¤´ã€‚\n",
    "\n",
    "\n",
    "$$\\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}\\right) V$$ \n",
    "\\begin{aligned}\n",
    "\\operatorname{MultiHead}(Q, K, V) &=\\operatorname{Concat}\\left(\\operatorname{head}_{1}, \\ldots, \\text { head }_{\\mathrm{h}}\\right) W^{O} \\\\\n",
    "\\text { where }\\, head_{i} &=\\operatorname{Attention}\\left(Q W_{i}^{Q}, K W_{i}^{K}, V W_{i}^{V}\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "![](./data/5-2-Transformerç»“æ„.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f81dc5",
   "metadata": {},
   "source": [
    "å‚è€ƒé˜…è¯»ææ–™ï¼š \n",
    "\n",
    "TransformerçŸ¥ä¹åŸç†è®²è§£ï¼šhttps://zhuanlan.zhihu.com/p/48508221\n",
    "\n",
    "Transformerå“ˆä½›åšå®¢ä»£ç è®²è§£ï¼šhttp://nlp.seas.harvard.edu/annotated-transformer/ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0f30d",
   "metadata": {},
   "source": [
    "ä¸»è¦å¯¹Transformerçš„è¦ç‚¹é—®é¢˜åšä¸€äº›æ¢³ç†ï¼š\n",
    "\n",
    "\n",
    "1ï¼ŒTransformeræ˜¯å¦‚ä½•è§£å†³é•¿è·ç¦»ä¾èµ–çš„é—®é¢˜çš„ï¼Ÿ\n",
    "\n",
    "Transformeræ˜¯é€šè¿‡å¼•å…¥Scale-Dot-Productæ³¨æ„åŠ›æœºåˆ¶æ¥èåˆåºåˆ—ä¸Šä¸åŒä½ç½®çš„ä¿¡æ¯ï¼Œä»è€Œè§£å†³é•¿è·ç¦»ä¾èµ–é—®é¢˜ã€‚ä»¥æ–‡æœ¬æ•°æ®ä¸ºä¾‹ï¼Œåœ¨å¾ªç¯ç¥ç»ç½‘ç»œLSTMç»“æ„ä¸­ï¼Œè¾“å…¥åºåˆ—ä¸Šç›¸è·å¾ˆè¿œçš„ä¸¤ä¸ªå•è¯æ— æ³•ç›´æ¥å‘ç”Ÿäº¤äº’ï¼Œåªèƒ½é€šè¿‡éšè—å±‚è¾“å‡ºæˆ–è€…ç»†èƒçŠ¶æ€æŒ‰ç…§æ—¶é—´æ­¥éª¤ä¸€ä¸ªä¸€ä¸ªå‘åè¿›è¡Œä¼ é€’ã€‚å¯¹äºä¸¤ä¸ªåœ¨åºåˆ—ä¸Šç›¸è·éå¸¸è¿œçš„å•è¯ï¼Œä¸­é—´ç»è¿‡çš„å…¶å®ƒå•è¯è®©éšè—å±‚è¾“å‡ºå’Œç»†èƒçŠ¶æ€æ··å…¥äº†å¤ªå¤šçš„ä¿¡æ¯ï¼Œå¾ˆéš¾æœ‰æ•ˆåœ°æ•æ‰è¿™ç§é•¿è·ç¦»ä¾èµ–ç‰¹å¾ã€‚ä½†æ˜¯åœ¨Scale-Dot-Productæ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œåºåˆ—ä¸Šçš„æ¯ä¸ªå•è¯éƒ½ä¼šå’Œå…¶å®ƒæ‰€æœ‰å•è¯åšä¸€æ¬¡ç‚¹ç§¯è®¡ç®—æ³¨æ„åŠ›å¾—åˆ†ï¼Œè¿™ç§æ³¨æ„åŠ›æœºåˆ¶ä¸­å•è¯ä¹‹é—´çš„äº¤äº’æ˜¯å¼ºåˆ¶çš„ä¸å—è·ç¦»å½±å“çš„ï¼Œæ‰€ä»¥å¯ä»¥è§£å†³é•¿è·ç¦»ä¾èµ–é—®é¢˜ã€‚\n",
    "\n",
    "\n",
    "2ï¼ŒTransformeråœ¨è®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µå¯ä»¥åœ¨æ—¶é—´(åºåˆ—)ç»´åº¦ä¸Šè¿›è¡Œå¹¶è¡Œå—ï¼Ÿ\n",
    "\n",
    "åœ¨è®­ç»ƒé˜¶æ®µï¼ŒEncoderå’ŒDecoderåœ¨æ—¶é—´(åºåˆ—)ç»´åº¦éƒ½æ˜¯å¹¶è¡Œçš„ï¼Œåœ¨æµ‹è¯•é˜¶æ®µï¼ŒEncoderåœ¨åºåˆ—ç»´åº¦æ˜¯å¹¶è¡Œçš„ï¼ŒDecoderæ˜¯ä¸²è¡Œçš„ã€‚\n",
    "\n",
    "é¦–å…ˆï¼ŒEncoderéƒ¨åˆ†åœ¨è®­ç»ƒé˜¶æ®µå’Œé¢„æµ‹é˜¶æ®µéƒ½å¯ä»¥å¹¶è¡Œæ¯”è¾ƒå¥½ç†è§£ï¼Œæ— è®ºåœ¨è®­ç»ƒè¿˜æ˜¯é¢„æµ‹é˜¶æ®µï¼Œå®ƒå¹²çš„äº‹æƒ…éƒ½æ˜¯æŠŠå·²çŸ¥çš„å®Œæ•´è¾“å…¥ç¼–ç æˆmemoryï¼Œåœ¨åºåˆ—ç»´åº¦å¯ä»¥å¹¶è¡Œã€‚\n",
    "\n",
    "å¯¹äºDecoderéƒ¨åˆ†æœ‰äº›å¾®å¦™ã€‚åœ¨é¢„æµ‹é˜¶æ®µDecoderè‚¯å®šæ˜¯ä¸èƒ½å¹¶è¡Œçš„ï¼Œå› ä¸ºDecoderå®é™…ä¸Šæ˜¯ä¸€ä¸ªè‡ªå›å½’ï¼Œå®ƒå‰é¢k-1ä½ç½®çš„è¾“å‡ºä¼šå˜æˆç¬¬kä½çš„è¾“å…¥çš„ã€‚å‰é¢æ²¡æœ‰è®¡ç®—å®Œï¼Œåé¢æ˜¯æ‹¿ä¸åˆ°è¾“å…¥çš„ï¼Œè‚¯å®šä¸å¯ä»¥å¹¶è¡Œã€‚é‚£ä¹ˆè®­ç»ƒé˜¶æ®µèƒ½å¦å¹¶è¡Œå‘¢ï¼Ÿè™½ç„¶è®­ç»ƒé˜¶æ®µçŸ¥é“äº†å…¨éƒ¨çš„è§£ç ç»“æœï¼Œä½†æ˜¯è®­ç»ƒé˜¶æ®µè¦å’Œé¢„æµ‹é˜¶æ®µä¸€è‡´å•Šï¼Œå‰é¢çš„è§£ç è¾“å‡ºä¸èƒ½å—åˆ°åé¢è§£ç ç»“æœçš„å½±å“å•Šã€‚ä½†Transformeré€šè¿‡åœ¨Decoderä¸­å·§å¦™åœ°å¼•å…¥MaskæŠ€å·§ï¼Œä½¿å¾—åœ¨ç”¨Attentionæœºåˆ¶åšåºåˆ—ç‰¹å¾èåˆçš„æ—¶å€™ï¼Œæ¯ä¸ªå•è¯å¯¹ä½äºå®ƒä¹‹åçš„å•è¯çš„æ³¨æ„åŠ›å¾—åˆ†éƒ½ä¸º0ï¼Œè¿™æ ·å°±ä¿è¯äº†å‰é¢çš„è§£ç è¾“å‡ºä¸ä¼šå—åˆ°åé¢è§£ç ç»“æœçš„å½±å“ï¼Œå› æ­¤Decoderåœ¨è®­ç»ƒé˜¶æ®µå¯ä»¥åœ¨åºåˆ—ç»´åº¦åšå¹¶è¡Œã€‚\n",
    "\n",
    "\n",
    "3ï¼ŒScaled-Dot Product Attentionä¸ºä»€ä¹ˆè¦é™¤ä»¥$\\sqrt{d_k}$?\n",
    "\n",
    "ä¸ºäº†é¿å…$d_k$å˜å¾—å¾ˆå¤§æ—¶softmaxå‡½æ•°çš„æ¢¯åº¦è¶‹äº0ã€‚å‡è®¾Qå’ŒKä¸­çš„å–å‡ºçš„ä¸¤ä¸ªå‘é‡$q$å’Œ$k$çš„æ¯ä¸ªå…ƒç´ å€¼éƒ½æ˜¯æ­£æ€éšæœºåˆ†å¸ƒï¼Œæ•°å­¦ä¸Šå¯ä»¥è¯æ˜ä¸¤ä¸ªç‹¬ç«‹çš„æ­£æ€éšæœºå˜é‡çš„ç§¯ä¾ç„¶æ˜¯ä¸€ä¸ªæ­£æ€éšæœºå˜é‡ï¼Œé‚£ä¹ˆä¸¤ä¸ªå‘é‡åšç‚¹ç§¯ï¼Œä¼šå¾—åˆ°$d_k$ä¸ªæ­£æ€éšæœºå˜é‡çš„å’Œï¼Œæ•°å­¦ä¸Š$d_k$ä¸ªæ­£æ€éšæœºå˜é‡çš„å’Œä¾ç„¶æ˜¯ä¸€ä¸ªæ­£æ€éšæœºå˜é‡ï¼Œå…¶æ–¹å·®æ˜¯åŸæ¥çš„$d_k$å€ï¼Œæ ‡å‡†å·®æ˜¯åŸæ¥çš„$\\sqrt{d_k}$å€ã€‚å¦‚æœä¸åšscale, å½“$d_k$å¾ˆå¤§æ—¶ï¼Œæ±‚å¾—çš„$QK^T$å…ƒç´ çš„ç»å¯¹å€¼å®¹æ˜“å¾ˆå¤§ï¼Œå¯¼è‡´è½åœ¨softmaxçš„æç«¯åŒºåŸŸ(è¶‹äº0æˆ–è€…1)ï¼Œæç«¯åŒºåŸŸsoftmaxå‡½æ•°çš„æ¢¯åº¦å€¼è¶‹äº0ï¼Œä¸åˆ©äºæ¨¡å‹å­¦ä¹ ã€‚é™¤ä»¥$\\sqrt{d_k}$ï¼Œæ°å¥½åšäº†å½’ä¸€ï¼Œä¸å—$d_k$å˜åŒ–å½±å“ã€‚\n",
    "\n",
    "\n",
    "4ï¼ŒMultiHeadAttentionçš„å‚æ•°æ•°é‡å’Œheadæ•°é‡æœ‰ä½•å…³ç³»?\n",
    "\n",
    "MultiHeadAttentionçš„å‚æ•°æ•°é‡å’Œheadæ•°é‡æ— å…³ã€‚å¤šå¤´æ³¨æ„åŠ›çš„å‚æ•°æ¥è‡ªå¯¹QKVçš„ä¸‰ä¸ªå˜æ¢çŸ©é˜µä»¥åŠå¤šå¤´ç»“æœconcatåçš„è¾“å‡ºå˜æ¢çŸ©é˜µã€‚å‡è®¾åµŒå…¥å‘é‡çš„é•¿åº¦æ˜¯d_model, ä¸€å…±æœ‰hä¸ªhead. å¯¹æ¯ä¸ªheadï¼Œ$W_{i}^{Q},W_{i}^{K},W_{i}^{V}$ è¿™ä¸‰ä¸ªå˜æ¢çŸ©é˜µçš„å°ºå¯¸éƒ½æ˜¯ d_modelÃ—(d_model/h)ï¼Œæ‰€ä»¥hä¸ªheadæ€»çš„å‚æ•°æ•°é‡å°±æ˜¯3Ã—d_modelÃ—(d_model/h)Ã—h = 3Ã—d_modelÃ—d_modelã€‚å®ƒä»¬çš„è¾“å‡ºå‘é‡é•¿åº¦éƒ½å˜æˆ d_model/hï¼Œç»è¿‡attentionä½œç”¨åå‘é‡é•¿åº¦ä¿æŒï¼Œhä¸ªheadçš„è¾“å‡ºæ‹¼æ¥åˆ°ä¸€èµ·åå‘é‡é•¿åº¦è¿˜æ˜¯d_modelï¼Œæ‰€ä»¥æœ€åè¾“å‡ºå˜æ¢çŸ©é˜µçš„å°ºå¯¸æ˜¯d_modelÃ—d_modelã€‚å› æ­¤ï¼ŒMultiHeadAttentionçš„å‚æ•°æ•°é‡ä¸º 4Ã—d_modelÃ—d_modelï¼Œå’Œheadæ•°é‡æ— å…³ã€‚\n",
    "\n",
    "\n",
    "5ï¼ŒTransformeræœ‰ä»€ä¹ˆç¼ºç‚¹ï¼Ÿ\n",
    "\n",
    "Transformerä¸»è¦çš„ç¼ºç‚¹æœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯æ³¨æ„åŠ›æœºåˆ¶ç›¸å¯¹åºåˆ—é•¿åº¦çš„å¤æ‚åº¦æ˜¯O(n^2)ï¼Œç¬¬äºŒä¸ªæ˜¯å¯¹ä½ç½®ä¿¡æ¯çš„ã€‚\n",
    "ç¬¬ä¸€ï¼ŒTransformeråœ¨ç”¨Attentionæœºåˆ¶åšåºåˆ—ç‰¹å¾èåˆçš„æ—¶å€™ï¼Œæ¯ä¸¤ä¸ªå•è¯ä¹‹é—´éƒ½è¦è®¡ç®—ç‚¹ç§¯è·å¾—æ³¨æ„åŠ›å¾—åˆ†ï¼Œè¿™ä¸ªè®¡ç®—å¤æ‚åº¦å’Œåºåˆ—çš„é•¿åº¦å¹³æ–¹æˆæ­£æ¯”ï¼Œå¯¹äºä¸€äº›ç‰¹åˆ«é•¿çš„åºåˆ—ï¼Œå¯èƒ½å­˜åœ¨ç€æ€§èƒ½ç“¶é¢ˆï¼Œæœ‰ä¸€äº›é’ˆå¯¹è¿™ä¸ªé—®é¢˜çš„æ”¹è¿›æ–¹æ¡ˆå¦‚Linformerã€‚\n",
    "ç¬¬äºŒä¸ªæ˜¯Transformeré€šè¿‡å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ä¸¤ä¸¤ä½ç½®åšç‚¹ä¹˜æ¥èåˆåºåˆ—ç‰¹å¾ï¼Œè€Œä¸æ˜¯åƒå¾ªç¯ç¥ç»ç½‘ç»œé‚£æ ·ç”±å…ˆåˆ°ååœ°å¤„ç†åºåˆ—ä¸­çš„æ•°æ®ï¼Œå¯¼è‡´ä¸¢å¤±äº†å•è¯ä¹‹é—´çš„ä½ç½®ä¿¡æ¯å…³ç³»ï¼Œé€šè¿‡åœ¨è¾“å…¥ä¸­å¼•å…¥æ­£ä½™å¼¦å‡½æ•°æ„é€ çš„ä½ç½®ç¼–ç PositionEncodingä¸€å®šç¨‹åº¦ä¸Šè¡¥å……äº†ä½ç½®ä¿¡æ¯ï¼Œä½†è¿˜æ˜¯ä¸å¦‚å¾ªç¯ç¥ç»ç½‘ç»œé‚£æ ·è‡ªç„¶å’Œé«˜æ•ˆã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f468519a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Layer (type)                            Output Shape              Param #\n",
      "==========================================================================\n",
      "MultiheadAttention-1                   [-1, 200, 64]               16,640\n",
      "==========================================================================\n",
      "Total params: 16,640\n",
      "Trainable params: 16,640\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "Input size (MB): 0.000000\n",
      "Forward/backward pass size (MB): 0.097656\n",
      "Params size (MB): 0.063477\n",
      "Estimated Total Size (MB): 0.161133\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Layer (type)                            Output Shape              Param #\n",
      "==========================================================================\n",
      "MultiheadAttention-1                   [-1, 200, 64]               16,640\n",
      "==========================================================================\n",
      "Total params: 16,640\n",
      "Trainable params: 16,640\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "Input size (MB): 0.000000\n",
      "Forward/backward pass size (MB): 0.097656\n",
      "Params size (MB): 0.063477\n",
      "Estimated Total Size (MB): 0.161133\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "#éªŒè¯MultiheadAttentionå’Œheadæ•°é‡æ— å…³\n",
    "inputs = torch.randn(8,200,64) #batch_size, seq_length, features\n",
    "\n",
    "attention_h8 = nn.MultiheadAttention(\n",
    "    embed_dim = 64,\n",
    "    num_heads = 8,\n",
    "    bias=True,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "attention_h16 = nn.MultiheadAttention(\n",
    "    embed_dim = 64,\n",
    "    num_heads = 16,\n",
    "    bias=True,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "\n",
    "out_h8 = attention_h8(inputs,inputs,inputs)\n",
    "out_h16 = attention_h16(inputs,inputs,inputs)\n",
    "\n",
    "from torchkeras import summary \n",
    "summary(attention_h8,input_data_args=(inputs,inputs,inputs));\n",
    "\n",
    "summary(attention_h16,input_data_args=(inputs,inputs,inputs));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df6ad71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from copy import deepcopy\n",
    "\n",
    "#å¤šå¤´æ³¨æ„åŠ›çš„ä¸€ç§ç®€æ´å®ç°\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self,query, key, value, mask=None, dropout=None):\n",
    "        d_k = query.size(-1)\n",
    "        scores = query@key.transpose(-2,-1) / d_k**0.5     \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e20)\n",
    "        p_attn = F.softmax(scores, dim = -1)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        return p_attn@value, p_attn\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = nn.ModuleList([deepcopy(nn.Linear(d_model, d_model)) for _ in range(4)])\n",
    "        \n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.attention = ScaledDotProductAttention()\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = self.attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da2d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373a7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58c8c14c",
   "metadata": {},
   "source": [
    "## äº”ï¼Œè‡ªå®šä¹‰æ¨¡å‹å±‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9f9b1",
   "metadata": {},
   "source": [
    "å¦‚æœPytorchçš„å†…ç½®æ¨¡å‹å±‚ä¸èƒ½å¤Ÿæ»¡è¶³éœ€æ±‚ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºè‡ªå®šä¹‰çš„æ¨¡å‹å±‚ã€‚\n",
    "\n",
    "å®é™…ä¸Šï¼Œpytorchä¸åŒºåˆ†æ¨¡å‹å’Œæ¨¡å‹å±‚ï¼Œéƒ½æ˜¯é€šè¿‡ç»§æ‰¿nn.Moduleè¿›è¡Œæ„å»ºã€‚\n",
    "\n",
    "å› æ­¤ï¼Œæˆ‘ä»¬åªè¦ç»§æ‰¿nn.ModuleåŸºç±»å¹¶å®ç°forwardæ–¹æ³•å³å¯è‡ªå®šä¹‰æ¨¡å‹å±‚ã€‚\n",
    "\n",
    "ä¸‹é¢æ˜¯Pytorchçš„nn.Linearå±‚çš„æºç ï¼Œæˆ‘ä»¬å¯ä»¥ä»¿ç…§å®ƒæ¥è‡ªå®šä¹‰æ¨¡å‹å±‚ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "664b53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e12a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5ff24cd",
   "metadata": {},
   "source": [
    "**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** \n",
    "\n",
    "å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·\"ç®—æ³•ç¾é£Ÿå±‹\"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚\n",
    "\n",
    "![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
