
# 7-5ï¼ŒFiBiNETæ¨¡å‹


ç¥ç»ç½‘ç»œçš„ç»“æ„è®¾è®¡æœ‰3ä¸ªä¸»æµçš„é«˜çº§æŠ€å·§ï¼š

* 1ï¼Œé«˜ä½èåˆ (å°†é«˜å±‚æ¬¡ç‰¹å¾ä¸ä½å±‚æ¬¡ç‰¹å¾èåˆï¼Œæå‡ç‰¹å¾ç»´åº¦çš„ä¸°å¯Œæ€§å’Œå¤šæ ·æ€§ï¼Œåƒäººä¸€æ ·åŒæ—¶è€ƒè™‘æ•´ä½“å’Œç»†èŠ‚)
* 2ï¼Œæƒå€¼å…±äº« (ä¸€ä¸ªæƒå€¼çŸ©é˜µå‚ä¸å¤šä¸ªä¸åŒçš„è®¡ç®—ï¼Œé™ä½å‚æ•°è§„æ¨¡å¹¶åŒæ—¶ç¼“è§£æ ·æœ¬ç¨€ç–æ€§ï¼Œåƒäººä¸€æ ·ä¸€æ¡çŸ¥è¯†å¤šå¤„è¿ç”¨)
* 3ï¼ŒåŠ¨æ€é€‚åº” (ä¸åŒçš„è¾“å…¥æ ·æœ¬ä½¿ç”¨ä¸åŒçš„æƒå€¼çŸ©é˜µï¼ŒåŠ¨æ€åœ°è¿›è¡Œç‰¹å¾é€‰æ‹©å¹¶èµ‹äºˆç‰¹å¾é‡è¦åº¦è§£é‡Šæ€§ï¼Œåƒäººä¸€æ ·èšç„¦é‡è¦ä¿¡æ¯æ’é™¤å¹²æ‰°ä¿¡æ¯)

æŠ€å·§åº”ç”¨èŒƒä¾‹ï¼š

* 1ï¼Œé«˜ä½èåˆ (DeepWide,UNet,ç‰¹å¾é‡‘å­—å¡”FPN...)
* 2ï¼Œæƒå€¼å…±äº« (CNN,RNN,FM,DeepFM,BlinearFFM...)
* 3ï¼ŒåŠ¨æ€é€‚åº” (å„ç§Attentionæœºåˆ¶...)

æ–°æµªå¾®åšå¹¿å‘Šæ¨èæŠ€æœ¯å›¢é˜Ÿ2019å¹´å‘å¸ƒçš„CTRé¢„ä¼°æ¨¡å‹FiBiNETåŒæ—¶å·§å¦™åœ°è¿ç”¨äº†ä»¥ä¸Š3ç§æŠ€å·§ï¼Œæ˜¯ç¥ç»ç½‘ç»œç»“æ„è®¾è®¡çš„æ•™ç§‘ä¹¦çº§çš„èŒƒä¾‹ã€‚

åœ¨æ­¤ä»‹ç»ç»™å¤§å®¶ã€‚


å‚è€ƒèµ„æ–™ï¼š
* FiBiNETè®ºæ–‡ï¼šhttps://arxiv.org/pdf/1905.09433.pdf
* FiBiNET-ç»“åˆç‰¹å¾é‡è¦æ€§å’ŒåŒçº¿æ€§ç‰¹å¾äº¤äº’è¿›è¡ŒCTRé¢„ä¼°ï¼šhttps://zhuanlan.zhihu.com/p/72931811
* ä»£ç å®ç°ï¼šhttps://github.com/xue-pai/FuxiCTR/blob/main/fuxictr/pytorch/models/FiBiNET.py 
* SENetåŸç†ï¼šhttps://zhuanlan.zhihu.com/p/65459972


<br>

<font color="red">
 
å…¬ä¼—å· **ç®—æ³•ç¾é£Ÿå±‹** å›å¤å…³é”®è¯ï¼š**pytorch**ï¼Œ è·å–æœ¬é¡¹ç›®æºç å’Œæ‰€ç”¨æ•°æ®é›†ç™¾åº¦äº‘ç›˜ä¸‹è½½é“¾æ¥ã€‚
    
</font> 



## ä¸€ï¼ŒFiBiNETåŸç†è§£æ


FiBiNETå…¨ç§°ä¸ºFeature Importance and Bilinear Interaction Network.

é¡¾åæ€ä¹‰ï¼Œå…¶ä¸»è¦çš„åˆ›æ„æœ‰2ä¸ªã€‚

ç¬¬ä¸€ä¸ªæ˜¯Feature Importanceï¼Œé€šè¿‡å€Ÿé‰´SENetï¼ˆSqueeze-and-Excitationï¼‰Attentionæœºåˆ¶å®ç°ç‰¹å¾é€‰æ‹©å’Œé‡è¦åº¦è§£é‡Šã€‚

ç¬¬äºŒä¸ªæ˜¯Bilinear Interaction Networkï¼Œè¿™æ˜¯åº”ç”¨æƒå€¼å…±äº«æŠ€å·§å¯¹ FFM(Field-Aware FM)ç»“æ„è¿›è¡Œæ”¹è¿›çš„ä¸€ç§ç»“æ„ã€‚

åŒæ—¶ï¼ŒFiBiNETä¿ç•™äº†DeepWideçš„é«˜ä½èåˆçš„ç½‘ç»œæ¶æ„ã€‚

æ‰€ä»¥å®ƒç»¼åˆä½¿ç”¨äº† é«˜ä½èåˆã€æƒå€¼å…±äº«ã€åŠ¨æ€é€‚åº” è¿™3ç§ç¥ç»ç½‘ç»œç»“æ„è®¾è®¡çš„é«˜çº§æŠ€å·§ã€‚ä¸€ä¸ªä¸è½ï¼ŒTriple kill!

æˆ‘ä»¬é‡ç‚¹ä»‹ç»ä¸€ä¸‹ SENet Attention å’Œ Bilinear Interaction.


### 1, SENet Attention 


SENet å…¨ç§°ä¸º Squeeze-and-Excitation Networkï¼Œæ˜¯ä¸€ç§é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—ç‰¹å¾é‡è¦åº¦çš„ç½‘ç»œæ¨¡å—ã€‚

æœ€æ—©æ˜¯åœ¨CVé¢†åŸŸå¼•å…¥ï¼Œé€šè¿‡åœ¨ResNetç»“æ„ä¸Šæ·»åŠ SENet Attentionæ¨¡å—ï¼Œèµ¢å¾—äº†ImageNet 2017ç«èµ›åˆ†ç±»ä»»åŠ¡çš„å† å†›ã€‚

å¦‚ä½•è®¡ç®—å„ä¸ªFeature Map(é€šé“)çš„ç‰¹å¾é‡è¦åº¦(æ³¨æ„åŠ›æƒé‡)å‘¢ï¼Ÿ

SENetçš„æ€æƒ³éå¸¸ç®€æ´ã€‚

step1: é€šè¿‡å…¨å±€æ± åŒ–å°†å„ä¸ªFeature Mapç”±ä¸€ä¸ªä¸€ä¸ªçš„çŸ©é˜µæ±‡æ€»æˆä¸€ä¸ªä¸€ä¸ªçš„æ ‡é‡ã€‚æ­¤å³Squeezeæ“ä½œã€‚

step2ï¼šé€šè¿‡ä¸€ä¸ª2å±‚MLPå°†æ±‡æ€»æˆå¾—åˆ°çš„ä¸€ä¸ªä¸€ä¸ªçš„æ ‡é‡æ‰€æ„æˆçš„å‘é‡è¿›è¡Œå˜æ¢ï¼Œå¾—åˆ°æ³¨æ„åŠ›æƒé‡ã€‚æ­¤å³Excitationæ“ä½œã€‚ 
ç»†èŠ‚ä¸€ç‚¹åœ°è¯´ï¼Œè¿™ä¸ª2å±‚çš„MLPçš„ç¬¬1å±‚å°†é€šé“æ•°é‡ç¼©å‡æˆåŸæ¥çš„1/3, ç¬¬2å±‚å†å°†é€šé“æ•°æ¢å¤ã€‚å¹¶ä¸”æ¯å±‚åé¢éƒ½æ¥å…¥äº†æ¿€æ´»å‡½æ•°ã€‚

step3ï¼šç”¨æ³¨æ„åŠ›æƒé‡ä¹˜ä»¥åŸå§‹çš„Feature Mapã€‚è¿™ä¸ªæ˜¯Re-Weightæ“ä½œã€‚


å›¾ç‰‡ç¤ºæ„å¦‚ä¸‹ã€‚

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2sfkkfcy3j208w06fgll.jpg)



pytorchä»£ç å®ç°å¦‚ä¸‹ï¼Œå¯èƒ½æ¯”å›¾ç‰‡æ›´åŠ å¥½æ‡‚ã€‚

```python
import torch 
from torch import nn 
class SENetAttention(nn.Module):
    """
    Squeeze-and-Excitation Attention
    è¾“å…¥shape: [batch_size, num_fields, d_embed]   #num_fieldså³num_features
    è¾“å‡ºshape: [batch_size, num_fields, d_embed]
    """
    def __init__(self, num_fields, reduction_ratio=3):
        super().__init__()
        reduced_size = max(1, int(num_fields / reduction_ratio))
        self.excitation = nn.Sequential(nn.Linear(num_fields, reduced_size, bias=False),
                                        nn.ReLU(),
                                        nn.Linear(reduced_size, num_fields, bias=False),
                                        nn.ReLU())

    def forward(self, x):
        Z = torch.mean(x, dim=-1, out=None) #1,Sequeeze
        A = self.excitation(Z) #2,Excitation
        V = x * A.unsqueeze(-1) #3,Re-Weight
        return V
```

```python

```

### 2, Bilinear Interaction 


Bilinear Interactionå®é™…ä¸Šæ˜¯FFMåœ¨æƒå€¼å…±äº«æ€æƒ³ä¸‹çš„ä¸€ç§æ”¹è¿›ï¼Œä¹Ÿå¯ä»¥ç§°ä¹‹ä¸ºBilinear FFMã€‚

æˆ‘ä»¬å…ˆè¯´è¯´FFM(Field-Aware FM)ï¼Œå†çœ‹çœ‹è¿™ä¸ªBilinear FFM æ€ä¹ˆæ”¹è¿›çš„ã€‚


FMç”¨éšå‘é‡ä¹‹é—´çš„ç‚¹ç§¯æ¥è®¡ç®—ç‰¹å¾ä¹‹é—´çš„äº¤å‰ï¼Œå¹¶ä¸”ä¸€ä¸ªç‰¹å¾ç”¨ä¸€ä¸ªéšå‘é‡æ¥è¡¨ç¤ºã€‚

FFMè®¤ä¸ºä¸€ä¸ªç‰¹å¾ç”¨ä¸€ä¸ªéšå‘é‡æ¥è¡¨è¾¾å¤ªç²—ç³™äº†ï¼Œå¦‚æœè¿™ä¸ªç‰¹å¾å’Œä¸åŒåˆ†ç»„(Field)çš„ç‰¹å¾æ¥åšäº¤å‰ï¼Œåº”è¯¥ç”¨ä¸åŒçš„éšå‘é‡ã€‚

ä¸¾ä¾‹æ¥è¯´ï¼Œè€ƒè™‘ä¸€ä¸ªå¹¿å‘Šç‚¹å‡»é¢„æµ‹çš„åœºæ™¯ï¼Œå¹¿å‘Šç±»åˆ« å’Œ ç”¨æˆ·æ‰€åœ¨åŸå¸‚ã€ç”¨æˆ·èŒä¸šä¹‹é—´çš„äº¤å‰ã€‚

åœ¨FMä¸­ ä¸€ä¸ªç¡®å®šçš„å¹¿å‘Šç±»åˆ« æ¯”å¦‚æ¸¸æˆå¹¿å‘Š ä¸è®ºæ˜¯å’Œç”¨æˆ·æ‰€åœ¨åŸå¸‚ï¼Œè¿˜æ˜¯ç”¨æˆ·èŒä¸šäº¤å‰ï¼Œéƒ½ç”¨åŒä¸€ä¸ªéšå‘é‡ã€‚

ä½†æ˜¯FFMè®¤ä¸ºï¼Œç”¨æˆ·æ‰€åœ¨åŸå¸‚å’Œç”¨æˆ·èŒä¸šæ˜¯ä¸¤ç±»å®Œå…¨ä¸åŒçš„ç‰¹å¾(ä¸åŒField)ï¼Œæè¿°å®ƒä»¬çš„å‘é‡ç©ºé—´åº”è¯¥æ˜¯å®Œå…¨ä¸ç›¸å…³çš„ï¼ŒFMç”¨ä¸€ä¸ªç›¸åŒçš„éšå‘é‡æ¥å’Œå®ƒä»¬åšç‚¹ç§¯ä¸åˆç†ã€‚

æ‰€ä»¥ï¼ŒFFMå¼•å…¥äº†Field(åŸŸ)çš„æ¦‚å¿µï¼Œå’Œä¸åŒFieldçš„ç‰¹å¾åšäº¤å‰ï¼Œè¦ä½¿ç”¨ä¸åŒçš„éšå‘é‡ã€‚

å®è·µè¡¨æ˜ï¼ŒFFMè¿™ä¸ªæ€è·¯æ˜¯æœ‰æ•ˆçš„, FFMçš„ä½œè€…é˜®æ¯“é’¦æ­£æ˜¯å‡­å€Ÿè¿™ä¸ªæ–¹æ¡ˆèµ¢å¾—äº†2015å¹´kaggleä¸¾åŠçš„Criteoæ¯”èµ›çš„å† å†›ã€‚

ä½†æ˜¯FFMæœ‰ä¸ªå¾ˆå¤§çš„ç¼ºç‚¹ï¼Œå°±æ˜¯å‚æ•°é‡å¤ªå¤šäº†ã€‚

å¯¹äºFMæ¥è¯´ï¼Œæ¯ä¸ªç‰¹å¾åªæœ‰ä¸€ä¸ªéšå‘é‡ï¼Œå‡è®¾æœ‰nä¸ªç‰¹å¾ï¼Œæ¯ä¸ªéšå‘é‡ç»´åº¦ä¸ºkï¼Œå…¨éƒ¨éšå‘é‡å‚æ•°çŸ©é˜µçš„å¤§å° size = n k.

ä½†æ˜¯å¯¹äºFFMï¼Œæœ‰è¿‡æœ‰fä¸ªä¸åŒçš„fieldï¼Œæ¯ä¸ªç‰¹å¾éƒ½å°†æœ‰f-1ä¸ªéšå‘é‡ï¼Œå…¨éƒ¨éšå‘é‡çš„å‚æ•°çŸ©é˜µçš„å¤§å°å¢å¤§ä¸º size = (f-1) n k. 

é€šå¸¸çš„åº”ç”¨åœºæ™¯ä¸­ï¼ŒFieldçš„æ•°é‡æœ‰å‡ åå‡ ç™¾ç»´ï¼Œè€ŒFeatureçš„æ•°é‡æœ‰æ•°ä¸‡æ•°ç™¾ä¸‡ç»´ã€‚

å¾ˆæ˜¾ç„¶ï¼ŒFFMå°†éšå‘é‡çš„å‚æ•°è§„æ¨¡æ‰©å¤§äº†å‡ åå‡ ç™¾å€ã€‚

<!-- #region -->
FFMçš„æœ¬è´¨æ€æƒ³æ˜¯åœ¨åšç‰¹å¾äº¤å‰çš„æ—¶å€™è¦åŒºåˆ†ä¸åŒçš„Fieldï¼Œå…¶å®ç°æ–¹å¼æ˜¯å’Œä¸åŒçš„Fieldåšäº¤å‰æ—¶ç”¨ä¸åŒçš„éšå‘é‡ã€‚

æœ‰æ²¡æœ‰åŠæ³•ä¿ç•™FFMä¸­åŒºåˆ†ä¸åŒFieldçš„ç‰¹æ€§ï¼Œå¹¶é™ä½å‚æ•°è§„æ¨¡å‘¢ï¼Ÿ

BilinearFFMè¯´ï¼Œæˆ‘æœ‰åŠæ³•ï¼Œæƒé‡å…±äº«èµ°èµ·æ¥ï¼

BilinearFFMä¸ç›´æ¥é’ˆå¯¹ä¸åŒFieldè®¾è®¡ä¸åŒçš„éšå‘é‡ï¼Œè€Œæ˜¯å¼•å…¥äº†Fieldå˜æ¢çŸ©é˜µæ¥åŒºåˆ†ä¸åŒçš„Fieldã€‚

æ¯ä¸ªç‰¹å¾è¿˜æ˜¯ä¸€ä¸ªéšå‘é‡ï¼Œä½†æ˜¯å’Œä¸åŒçš„Fieldçš„ç‰¹å¾åšäº¤å‰æ—¶ï¼Œå…ˆä¹˜ä¸Šè¿™ä¸ªç‰¹å¾æ‰€åœ¨Fieldçš„å˜æ¢çŸ©é˜µï¼Œç„¶åå†åšåé¢çš„ç‚¹ç§¯ã€‚

å› æ­¤ï¼ŒåŒå±ä¸€ä¸ªFieldçš„ç‰¹å¾å…±äº«ä¸€ä¸ªFieldå˜æ¢çŸ©é˜µã€‚è¿™ç§bilinear_typeå«åš field_each.

Fieldå˜æ¢çŸ©é˜µçš„å¤§å°æ˜¯k^2, è¿™ç§æ–¹å¼ä¸‹ï¼Œå…¨éƒ¨éšå‘é‡çš„å‚æ•°å¤§å°åŠ ä¸Šå…±äº«å˜æ¢çŸ©é˜µçš„å‚æ•°å¤§å°ä¸€å…±æ˜¯ size = n k + f k^2 

ç”±äºkå’Œfè¿œå°äºnï¼Œè¿™ç§Bilinearæ–¹å¼ç›¸æ¯”FMå¢åŠ çš„å‚æ•°é‡å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚


é™¤äº† åŒå±ä¸€ä¸ªFieldçš„ç‰¹å¾å…±äº«ä¸€ä¸ªFieldå˜æ¢çŸ©é˜µå¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æ›´åŠ ç®€å•ç²—æš´ä¸€ç‚¹ï¼Œæ‰€æœ‰ç‰¹å¾å…±äº«ä¸€ä¸ªå˜æ¢çŸ©é˜µ.

è¿™ç§bilinear_typeå«åš field_all.è¿™ç§æ–¹å¼ä¸‹ï¼Œsize = n k + k^2 


æˆ‘ä»¬ä¹Ÿå¯ä»¥æ›´åŠ ç²¾ç»†ä¸€ç‚¹ï¼Œç›¸åŒçš„Fieldç»„åˆä¹‹é—´çš„äº¤äº’å…±äº«ä¸€ä¸ªå˜æ¢çŸ©é˜µï¼Œè¿™ç§bilinear_typeå«åšfield_interaction. 

æ€»å…±æœ‰f(f-1)/2ç§ç»„åˆï¼Œè¿™ç§æ–¹å¼ä¸‹ï¼Œ size = n k + k^2 f(f-1)/2

ä»¥ä¸Šå°±æ˜¯BilinearFFMçš„åŸºæœ¬æ€æƒ³ã€‚


FiBiNETä¸­ç”¨åˆ°çš„Bilinear Interactionç›¸æ¯”BilinearFFM, è¿˜æœ‰ä¸€å¤„å°æ”¹åŠ¨ï¼Œå°†ç‚¹ç§¯æ”¹æˆäº†å“ˆè¾¾ç›ç§¯ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

<!-- #endregion -->

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2sfj6wh0rj209v08daad.jpg)


pytorchä»£ç å®ç°å¦‚ä¸‹ï¼Œæ•´ä½“ä¸éš¾ç†è§£ã€‚ä½œ2ç‚¹è¯´æ˜ã€‚

1ï¼ŒFieldæ¦‚å¿µè¯´æ˜

åœ¨FFMç›¸å…³çš„æ–‡ç« ä¸­ï¼Œå¼•å…¥äº†Fieldçš„æ¦‚å¿µï¼Œä»¥å’ŒFeatureåŒºåˆ†ï¼Œä¸€ä¸ªFieldä¸­å¯ä»¥åŒ…æ‹¬å¤šä¸ªFeature. 

å®é™…ä¸ŠFieldå°±æ˜¯æˆ‘ä»¬é€šå¸¸ç†è§£çš„ç‰¹å¾ï¼ŒåŒ…æ‹¬æ•°å€¼ç‰¹å¾å’Œç±»åˆ«ç‰¹å¾ï¼Œä½†æ˜¯Featureæ˜¯æ•°å€¼ç‰¹å¾æˆ–è€…ç±»åˆ«ç‰¹å¾onehotåçš„ç‰¹å¾ã€‚ä¸€ä¸ªç±»åˆ«ç‰¹å¾å¯¹åº”ä¸€ä¸ªFieldï¼Œä½†æ˜¯å¯¹åº”å¤šä¸ªFeatureã€‚

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2sh8t8j6pj20gc058mx9.jpg)

2ï¼Œcombinationså‡½æ•°è¯´æ˜

ç»„åˆå‡½æ•°combinationsä»num_fieldsä¸­ä»»å–2ç§ä½œä¸ºç»„åˆï¼Œå…±æœ‰ num_fields*(num_fields-1)ä¸­ç»„åˆæ–¹å¼ã€‚

æ‰€ä»¥è¾“å‡ºçš„Fieldæ•°é‡å˜æˆäº† num_fields*(num_fields-1)/2ã€‚

```python
import torch 
from torch import nn 
from itertools import combinations
class BilinearInteraction(nn.Module):
    """
    åŒçº¿æ€§FFM
    è¾“å…¥shape: [batch_size, num_fields, d_embed] #num_fieldså³num_features
    è¾“å‡ºshape: [batch_size, num_fields*(num_fields-1)/2, d_embed]
    """
    def __init__(self, num_fields, d_embed, bilinear_type="field_interaction"):
        super().__init__()
        self.bilinear_type = bilinear_type
        if self.bilinear_type == "field_all":
            self.bilinear_layer = nn.Linear(d_embed, d_embed, bias=False)
        elif self.bilinear_type == "field_each":
            self.bilinear_layer = nn.ModuleList([nn.Linear(d_embed, d_embed, bias=False)
                                                 for i in range(num_fields)])
        elif self.bilinear_type == "field_interaction":
            self.bilinear_layer = nn.ModuleList([nn.Linear(d_embed, d_embed, bias=False)
                                                 for i, j in combinations(range(num_fields), 2)])
        else:
            raise NotImplementedError()

    def forward(self, feature_emb):
        feature_emb_list = torch.split(feature_emb, 1, dim=1)
        if self.bilinear_type == "field_all":
            bilinear_list = [self.bilinear_layer(v_i) * v_j
                             for v_i, v_j in combinations(feature_emb_list, 2)]
        elif self.bilinear_type == "field_each":
            bilinear_list = [self.bilinear_layer[i](feature_emb_list[i]) * feature_emb_list[j]
                             for i, j in combinations(range(len(feature_emb_list)), 2)]
        elif self.bilinear_type == "field_interaction":
            bilinear_list = [self.bilinear_layer[i](v[0]) * v[1]
                             for i, v in enumerate(combinations(feature_emb_list, 2))]
        return torch.cat(bilinear_list, dim=1)
```

### äºŒï¼ŒFiBiNETçš„pytorchå®ç°


ä¸‹é¢æ˜¯FiBiNETçš„ä¸€ä¸ªpytorchå®ç°ã€‚

æ ¸å¿ƒä»£ç æ˜¯SENetAttentionæ¨¡å—å’ŒBilinearInteractionæ¨¡å—çš„å®ç°ã€‚

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2sffi4huoj20g70a4gm4.jpg)

```python
import torch 
from torch import nn 
from itertools import combinations

class NumEmbedding(nn.Module):
    """
    è¿ç»­ç‰¹å¾ç”¨linearå±‚ç¼–ç 
    è¾“å…¥shape: [batch_size,num_features, d_in], # d_in é€šå¸¸æ˜¯1
    è¾“å‡ºshape: [batch_size,num_features, d_out]
    """
    
    def __init__(self, n: int, d_in: int, d_out: int, bias: bool = False) -> None:
        super().__init__()
        self.weight = nn.Parameter(torch.Tensor(n, d_in, d_out))
        self.bias = nn.Parameter(torch.Tensor(n, d_out)) if bias else None
        with torch.no_grad():
            for i in range(n):
                layer = nn.Linear(d_in, d_out)
                self.weight[i] = layer.weight.T
                if self.bias is not None:
                    self.bias[i] = layer.bias

    def forward(self, x_num):
        assert x_num.ndim == 3
        #x = x_num[..., None] * self.weight[None]
        #x = x.sum(-2)
        x = torch.einsum("bfi,fij->bfj",x_num,self.weight)
        if self.bias is not None:
            x = x + self.bias[None]
        return x
    
class CatEmbedding(nn.Module):
    """
    ç¦»æ•£ç‰¹å¾ç”¨Embeddingå±‚ç¼–ç 
    è¾“å…¥shape: [batch_size, num_features], 
    è¾“å‡ºshape: [batch_size, num_features, d_embed]
    """
    def __init__(self, categories, d_embed):
        super().__init__()
        self.embedding = nn.Embedding(sum(categories), d_embed)
        self.offsets = nn.Parameter(
                torch.tensor([0] + categories[:-1]).cumsum(0),requires_grad=False)
        
        nn.init.xavier_uniform_(self.embedding.weight.data)

    def forward(self, x_cat):
        """
        x_cat: Long tensor of size ``(batch_size, features_num)``
        """
        x = x_cat + self.offsets[None]
        return self.embedding(x) 
    
class CatLinear(nn.Module):
    """
    ç¦»æ•£ç‰¹å¾ç”¨Embeddingå®ç°çº¿æ€§å±‚ï¼ˆç­‰ä»·äºå…ˆF.onehotå†nn.Linear()ï¼‰
    è¾“å…¥shape: [batch_size, num_features ], 
    è¾“å‡ºshape: [batch_size, d_out]
    """
    def __init__(self, categories, d_out=1):
        super().__init__()
        self.fc = nn.Embedding(sum(categories), d_out)
        self.bias = nn.Parameter(torch.zeros((d_out,)))
        self.offsets = nn.Parameter(
                torch.tensor([0] + categories[:-1]).cumsum(0),requires_grad=False)
        nn.init.xavier_uniform_(self.fc.weight.data)

    def forward(self, x_cat):
        """
        Long tensor of size ``(batch_size, num_features)``
        """
        x = x_cat + self.offsets[None]
        return torch.sum(self.fc(x), dim=1) + self.bias 
    
class SENetAttention(nn.Module):
    """
    Squeeze-and-Excitation Attention
    è¾“å…¥shape: [batch_size, num_fields, d_embed]   #num_fieldså³num_features
    è¾“å‡ºshape: [batch_size, num_fields, d_embed]
    """
    def __init__(self, num_fields, reduction_ratio=3):
        super().__init__()
        reduced_size = max(1, int(num_fields / reduction_ratio))
        self.excitation = nn.Sequential(nn.Linear(num_fields, reduced_size, bias=False),
                                        nn.ReLU(),
                                        nn.Linear(reduced_size, num_fields, bias=False),
                                        nn.ReLU())

    def forward(self, x):
        Z = torch.mean(x, dim=-1, out=None) #1,Sequeeze
        A = self.excitation(Z) #2,Excitation
        V = x * A.unsqueeze(-1) #3,Re-Weight
        return V
    
class BilinearInteraction(nn.Module):
    """
    åŒçº¿æ€§FFM
    è¾“å…¥shape: [batch_size, num_fields, d_embed] #num_fieldså³num_features
    è¾“å‡ºshape: [batch_size, num_fields*(num_fields-1)/2, d_embed]
    """
    def __init__(self, num_fields, d_embed, bilinear_type="field_interaction"):
        super().__init__()
        self.bilinear_type = bilinear_type
        if self.bilinear_type == "field_all":
            self.bilinear_layer = nn.Linear(d_embed, d_embed, bias=False)
        elif self.bilinear_type == "field_each":
            self.bilinear_layer = nn.ModuleList([nn.Linear(d_embed, d_embed, bias=False)
                                                 for i in range(num_fields)])
        elif self.bilinear_type == "field_interaction":
            self.bilinear_layer = nn.ModuleList([nn.Linear(d_embed, d_embed, bias=False)
                                                 for i, j in combinations(range(num_fields), 2)])
        else:
            raise NotImplementedError()

    def forward(self, feature_emb):
        feature_emb_list = torch.split(feature_emb, 1, dim=1)
        if self.bilinear_type == "field_all":
            bilinear_list = [self.bilinear_layer(v_i) * v_j
                             for v_i, v_j in combinations(feature_emb_list, 2)]
        elif self.bilinear_type == "field_each":
            bilinear_list = [self.bilinear_layer[i](feature_emb_list[i]) * feature_emb_list[j]
                             for i, j in combinations(range(len(feature_emb_list)), 2)]
        elif self.bilinear_type == "field_interaction":
            bilinear_list = [self.bilinear_layer[i](v[0]) * v[1]
                             for i, v in enumerate(combinations(feature_emb_list, 2))]
        return torch.cat(bilinear_list, dim=1)
    

#mlp
class MultiLayerPerceptron(nn.Module):
    def __init__(self, d_in, d_layers, dropout, 
                 d_out = 1):
        super().__init__()
        layers = []
        for d in d_layers:
            layers.append(nn.Linear(d_in, d))
            layers.append(nn.BatchNorm1d(d))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(p=dropout))
            d_in = d
        layers.append(nn.Linear(d_layers[-1], d_out))
        self.mlp = nn.Sequential(*layers)

    def forward(self, x):
        """
        float tensor of size ``(batch_size, d_in)``
        """
        return self.mlp(x)
    

#fibinet 
class FiBiNET(nn.Module):
    
    def __init__(self,
                 d_numerical, 
                 categories, 
                 d_embed,
                 mlp_layers, 
                 mlp_dropout,
                 reduction_ratio = 3,
                 bilinear_type = "field_interaction",
                 n_classes = 1):
        
        super().__init__()
        
        if d_numerical is None:
            d_numerical = 0
        if categories is None:
            categories = []
            
        self.categories = categories
        self.n_classes = n_classes
        
        self.num_linear = nn.Linear(d_numerical,n_classes) if d_numerical else None
        self.cat_linear = CatLinear(categories,n_classes) if categories else None
        
        self.num_embedding = NumEmbedding(d_numerical,1,d_embed) if d_numerical else None
        self.cat_embedding = CatEmbedding(categories, d_embed) if categories else None
        
        num_fields = d_numerical+len(categories)
        
        self.se_attention = SENetAttention(num_fields, reduction_ratio)
        self.bilinear = BilinearInteraction(num_fields, d_embed, bilinear_type)
        
        mlp_in = num_fields * (num_fields - 1) * d_embed
        self.mlp = MultiLayerPerceptron(
            d_in= mlp_in,
            d_layers = mlp_layers,
            dropout = mlp_dropout,
            d_out = n_classes
        )
        
        
    def forward(self, x):
        """
        x_num: numerical features
        x_cat: category features
        """
        x_num,x_cat = x
        
        #ä¸€ï¼Œwideéƒ¨åˆ†
        x_linear = 0.0
        if self.num_linear:
            x_linear = x_linear + self.num_linear(x_num) 
        if self.cat_linear:
            x_linear = x_linear + self.cat_linear(x_cat)
            
        #äºŒï¼Œdeepéƒ¨åˆ† 
        
        #1ï¼Œembedding
        x_embedding = []
        if self.num_embedding:
            x_embedding.append(self.num_embedding(x_num[...,None]))
        if self.cat_embedding:
            x_embedding.append(self.cat_embedding(x_cat))
        x_embedding = torch.cat(x_embedding,dim=1)
        
        #2ï¼Œinteraction
        se_embedding = self.se_attention(x_embedding)
        ffm_out = self.bilinear(x_embedding)
        se_ffm_out = self.bilinear(se_embedding)
        x_interaction = torch.flatten(torch.cat([ffm_out, se_ffm_out], dim=1), start_dim=1)
        
        #3ï¼Œmlp
        x_deep = self.mlp(x_interaction)
        
        #ä¸‰ï¼Œé«˜ä½èåˆ
        x_out = x_linear+x_deep
        if self.n_classes==1:
            x_out = x_out.squeeze(-1)
        return x_out
```

```python
##æµ‹è¯• FiBiNET

model = FiBiNET(d_numerical = 3, categories = [4,3,2],
        d_embed = 4, mlp_layers = [20,20], mlp_dropout=0.25,
        reduction_ratio = 3,
        bilinear_type = "field_interaction",
        n_classes = 1)

x_num = torch.randn(2,3)
x_cat = torch.randint(0,2,(2,3))
print(model((x_num,x_cat)))  

```

```
tensor([-0.8621,  0.6743], grad_fn=<SqueezeBackward1>)
```

```python

```

## ä¸‰ï¼ŒCriteoæ•°æ®é›†å®Œæ•´èŒƒä¾‹


Criteoæ•°æ®é›†æ˜¯ä¸€ä¸ªç»å…¸çš„å¹¿å‘Šç‚¹å‡»ç‡CTRé¢„æµ‹æ•°æ®é›†ã€‚

è¿™ä¸ªæ•°æ®é›†çš„ç›®æ ‡æ˜¯é€šè¿‡ç”¨æˆ·ç‰¹å¾å’Œå¹¿å‘Šç‰¹å¾æ¥é¢„æµ‹æŸæ¡å¹¿å‘Šæ˜¯å¦ä¼šä¸ºç”¨æˆ·ç‚¹å‡»ã€‚

æ•°æ®é›†æœ‰13ç»´æ•°å€¼ç‰¹å¾(I1-I13)å’Œ26ç»´ç±»åˆ«ç‰¹å¾(C14-C39), å…±39ç»´ç‰¹å¾, ç‰¹å¾ä¸­åŒ…å«ç€è®¸å¤šç¼ºå¤±å€¼ã€‚

è®­ç»ƒé›†4000ä¸‡ä¸ªæ ·æœ¬ï¼Œæµ‹è¯•é›†600ä¸‡ä¸ªæ ·æœ¬ã€‚æ•°æ®é›†å¤§å°è¶…è¿‡100G.

æ­¤å¤„ä½¿ç”¨çš„æ˜¯é‡‡æ ·100ä¸‡ä¸ªæ ·æœ¬åçš„cretio_smallæ•°æ®é›†ã€‚ 


```python

```

```python
import numpy as np 
import pandas as pd 
import datetime 

from sklearn.model_selection import train_test_split 

import torch 
from torch import nn 
from torch.utils.data import Dataset,DataLoader  
import torch.nn.functional as F 
import torchkeras 

def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(info+'...\n\n')

```

### 1ï¼Œå‡†å¤‡æ•°æ®

```python
from sklearn.preprocessing import LabelEncoder,QuantileTransformer
from sklearn.pipeline import Pipeline 
from sklearn.impute import SimpleImputer 

dfdata = pd.read_csv("./eat_pytorch_datasets/criteo_small.zip",sep="\t",header=None)
dfdata.columns = ["label"] + ["I"+str(x) for x in range(1,14)] + [
    "C"+str(x) for x in range(14,40)]

cat_cols = [x for x in dfdata.columns if x.startswith('C')]
num_cols = [x for x in dfdata.columns if x.startswith('I')]
num_pipe = Pipeline(steps = [('impute',SimpleImputer()),('quantile',QuantileTransformer())])

for col in cat_cols:
    dfdata[col]  = LabelEncoder().fit_transform(dfdata[col])

dfdata[num_cols] = num_pipe.fit_transform(dfdata[num_cols])

categories = [dfdata[col].max()+1 for col in cat_cols]

```

```python
import torch 
from torch.utils.data import Dataset,DataLoader 

#DataFrameè½¬æ¢æˆtorchæ•°æ®é›†Dataset, ç‰¹å¾åˆ†å‰²æˆX_num,X_catæ–¹å¼
class DfDataset(Dataset):
    def __init__(self,df,
                 label_col,
                 num_features,
                 cat_features,
                 categories,
                 is_training=True):
        
        self.X_num = torch.tensor(df[num_features].values).float() if num_features else None
        self.X_cat = torch.tensor(df[cat_features].values).long() if cat_features else None
        self.Y = torch.tensor(df[label_col].values).float() 
        self.categories = categories
        self.is_training = is_training
    
    def __len__(self):
        return len(self.Y)
    
    def __getitem__(self,index):
        if self.is_training:
            return ((self.X_num[index],self.X_cat[index]),self.Y[index])
        else:
            return (self.X_num[index],self.X_cat[index])
    
    def get_categories(self):
        return self.categories
    
```

```python
dftrain_val,dftest = train_test_split(dfdata,test_size=0.2)
dftrain,dfval = train_test_split(dftrain_val,test_size=0.2)

ds_train = DfDataset(dftrain,label_col = "label",num_features = num_cols,cat_features = cat_cols,
                    categories = categories, is_training=True)

ds_val = DfDataset(dfval,label_col = "label",num_features = num_cols,cat_features = cat_cols,
                    categories = categories, is_training=True)

ds_test = DfDataset(dftest,label_col = "label",num_features = num_cols,cat_features = cat_cols,
                    categories = categories, is_training=True)

```

```python
dl_train = DataLoader(ds_train,batch_size = 2048,shuffle=True)
dl_val = DataLoader(ds_val,batch_size = 2048,shuffle=False)
dl_test = DataLoader(ds_test,batch_size = 2048,shuffle=False)

for features,labels in dl_train:
    break 
    
```

### 2ï¼Œå®šä¹‰æ¨¡å‹

```python
def create_net():
    net = FiBiNET(
        d_numerical= ds_train.X_num.shape[1],
        categories= ds_train.get_categories(),
        d_embed = 8, mlp_layers = [128,64,32], mlp_dropout=0.25,
        reduction_ratio = 3,
        bilinear_type = "field_all",
        n_classes = 1
        
    )
    return net 

from torchkeras import summary

net = create_net()


```

```python

```

### 3ï¼Œè®­ç»ƒæ¨¡å‹

```python
import os,sys,time
import numpy as np
import pandas as pd
import datetime 
from tqdm import tqdm 

import torch
from torch import nn 
from accelerate import Accelerator
from copy import deepcopy


def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(str(info)+"\n")
    
class StepRunner:
    def __init__(self, net, loss_fn,stage = "train", metrics_dict = None, 
                 optimizer = None, lr_scheduler = None,
                 accelerator = None
                 ):
        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage
        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler
        self.accelerator = accelerator
    
    def __call__(self, features, labels):
        #loss
        preds = self.net(features)
        loss = self.loss_fn(preds,labels)

        #backward()
        if self.optimizer is not None and self.stage=="train":
            if self.accelerator is  None:
                loss.backward()
            else:
                self.accelerator.backward(loss)
            self.optimizer.step()
            if self.lr_scheduler is not None:
                self.lr_scheduler.step()
            self.optimizer.zero_grad()
            
        #metrics
        step_metrics = {self.stage+"_"+name:metric_fn(preds, labels).item() 
                        for name,metric_fn in self.metrics_dict.items()}
        return loss.item(),step_metrics
    
    
class EpochRunner:
    def __init__(self,steprunner):
        self.steprunner = steprunner
        self.stage = steprunner.stage
        self.steprunner.net.train() if self.stage=="train" else self.steprunner.net.eval()
        
    def __call__(self,dataloader):
        total_loss,step = 0,0
        loop = tqdm(enumerate(dataloader), total =len(dataloader))
        for i, batch in loop:
            features,labels = batch
            if self.stage=="train":
                loss, step_metrics = self.steprunner(features,labels)
            else:
                with torch.no_grad():
                    loss, step_metrics = self.steprunner(features,labels)

            step_log = dict({self.stage+"_loss":loss},**step_metrics)

            total_loss += loss
            step+=1
            if i!=len(dataloader)-1:
                loop.set_postfix(**step_log)
            else:
                epoch_loss = total_loss/step
                epoch_metrics = {self.stage+"_"+name:metric_fn.compute().item() 
                                 for name,metric_fn in self.steprunner.metrics_dict.items()}
                epoch_log = dict({self.stage+"_loss":epoch_loss},**epoch_metrics)
                loop.set_postfix(**epoch_log)

                for name,metric_fn in self.steprunner.metrics_dict.items():
                    metric_fn.reset()
        return epoch_log

class KerasModel(torch.nn.Module):
    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None):
        super().__init__()
        self.accelerator = Accelerator()
        self.history = {}
        
        self.net = net
        self.loss_fn = loss_fn
        self.metrics_dict = nn.ModuleDict(metrics_dict) 
        
        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(
            self.parameters(), lr=1e-2)
        self.lr_scheduler = lr_scheduler
        
        self.net,self.loss_fn,self.metrics_dict,self.optimizer = self.accelerator.prepare(
            self.net,self.loss_fn,self.metrics_dict,self.optimizer)

    def forward(self, x):
        if self.net:
            return self.net.forward(x)
        else:
            raise NotImplementedError


    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint.pt', 
            patience=5, monitor="val_loss", mode="min"):
        
        train_data = self.accelerator.prepare(train_data)
        val_data = self.accelerator.prepare(val_data) if val_data else []

        for epoch in range(1, epochs+1):
            printlog("Epoch {0} / {1}".format(epoch, epochs))
            
            # 1ï¼Œtrain -------------------------------------------------  
            train_step_runner = StepRunner(net = self.net,stage="train",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    optimizer = self.optimizer, lr_scheduler = self.lr_scheduler,
                    accelerator = self.accelerator)
            train_epoch_runner = EpochRunner(train_step_runner)
            train_metrics = train_epoch_runner(train_data)
            
            for name, metric in train_metrics.items():
                self.history[name] = self.history.get(name, []) + [metric]

            # 2ï¼Œvalidate -------------------------------------------------
            if val_data:
                val_step_runner = StepRunner(net = self.net,stage="val",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    accelerator = self.accelerator)
                val_epoch_runner = EpochRunner(val_step_runner)
                with torch.no_grad():
                    val_metrics = val_epoch_runner(val_data)
                val_metrics["epoch"] = epoch
                for name, metric in val_metrics.items():
                    self.history[name] = self.history.get(name, []) + [metric]
            
            # 3ï¼Œearly-stopping -------------------------------------------------
            arr_scores = self.history[monitor]
            best_score_idx = np.argmax(arr_scores) if mode=="max" else np.argmin(arr_scores)
            if best_score_idx==len(arr_scores)-1:
                torch.save(self.net.state_dict(),ckpt_path)
                print("<<<<<< reach best {0} : {1} >>>>>>".format(monitor,
                     arr_scores[best_score_idx]),file=sys.stderr)
            if len(arr_scores)-best_score_idx>patience:
                print("<<<<<< {} without improvement in {} epoch, early stopping >>>>>>".format(
                    monitor,patience),file=sys.stderr)
                self.net.load_state_dict(torch.load(ckpt_path))
                break 
            
        return pd.DataFrame(self.history)

    @torch.no_grad()
    def evaluate(self, val_data):
        val_data = self.accelerator.prepare(val_data)
        val_step_runner = StepRunner(net = self.net,stage="val",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    accelerator = self.accelerator)
        val_epoch_runner = EpochRunner(val_step_runner)
        val_metrics = val_epoch_runner(val_data)
        return val_metrics
        
       
    @torch.no_grad()
    def predict(self, dataloader):
        dataloader = self.accelerator.prepare(dataloader)
        result = torch.cat([self.forward(t[0]) for t in dataloader])
        return result.data
              
```

```python
from torchkeras.metrics import AUC

loss_fn = nn.BCEWithLogitsLoss()

metrics_dict = {"auc":AUC()}

optimizer = torch.optim.Adam(net.parameters(), lr=0.002, weight_decay=0.001) 

model = KerasModel(net,
                   loss_fn = loss_fn,
                   metrics_dict= metrics_dict,
                   optimizer = optimizer
                  )         
```

```python
dfhistory = model.fit(train_data=dl_train,val_data=dl_val,epochs=100, patience=5,
                      monitor = "val_auc",mode="max",ckpt_path='checkpoint.pt')
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2t3twovonj20my0axq4j.jpg)



### 4ï¼Œè¯„ä¼°æ¨¡å‹

```python
%matplotlib inline
%config InlineBackend.figure_format = 'svg'

import matplotlib.pyplot as plt

def plot_metric(dfhistory, metric):
    train_metrics = dfhistory["train_"+metric]
    val_metrics = dfhistory['val_'+metric]
    epochs = range(1, len(train_metrics) + 1)
    plt.plot(epochs, train_metrics, 'bo--')
    plt.plot(epochs, val_metrics, 'ro-')
    plt.title('Training and validation '+ metric)
    plt.xlabel("Epochs")
    plt.ylabel(metric)
    plt.legend(["train_"+metric, 'val_'+metric])
    plt.show()
```

```python
plot_metric(dfhistory,"loss")
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2t3tup3hxj20gc0af74n.jpg)

```python
plot_metric(dfhistory,"auc")
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2t3tuemikj20f70ait90.jpg)


### 5ï¼Œä½¿ç”¨æ¨¡å‹

```python
from sklearn.metrics import roc_auc_score
preds = torch.sigmoid(model.predict(dl_val))
labels = torch.cat([x[-1] for x in dl_val])

val_auc = roc_auc_score(labels.cpu().numpy(),preds.cpu().numpy())
print(val_auc)
```

0.7806176567186112


### 6ï¼Œä¿å­˜æ¨¡å‹

```python
torch.save(model.net.state_dict(),"best_fibinet.pt")
net_clone = create_net()
net_clone.load_state_dict(torch.load("best_fibinet.pt"))
```

```python
from sklearn.metrics import roc_auc_score
net_clone.eval()
preds = torch.cat([torch.sigmoid(net_clone(x[0])).data for x in dl_val]) 
labels = torch.cat([x[-1] for x in dl_val])

val_auc = roc_auc_score(labels.cpu().numpy(),preds.cpu().numpy())
print(val_auc)
```

0.7806176567186112


å¯ä»¥çœ‹åˆ°FiBiNETåœ¨éªŒè¯é›†çš„AUCå¾—åˆ†ä¸º0.7806,ç›¸æ¯”ä¹‹ä¸‹DeepFMçš„éªŒè¯é›†AUCä¸º0.7803ã€‚

ä¸èƒ½è¯´çº¹ä¸ä¸åŠ¨, åªèƒ½è¯´äº†æ¶¨äº†ä¸ªèšŠå­è…¿å¤§å°è‚‰çš„ç‚¹ã€‚

å¹¶ä¸”è¿™æ˜¯ä»¥è¾ƒå¤§åœ°ç‰ºç‰²æ¨¡å‹è®­ç»ƒé¢„æµ‹æ•ˆç‡ä¸ºä»£ä»·çš„ã€‚

DeepFMè®­ç»ƒä¸€ä¸ªEpochå¤§çº¦éœ€è¦20s, è€ŒFiBiNETè®­ç»ƒä¸€ä¸ªEpochéœ€è¦å¤§çº¦2min.

å°½ç®¡å¦‚æ­¤, FiBiNETçš„ç»“æ„è®¾è®¡ä¾ç„¶æ˜¯å€¼å¾—æˆ‘ä»¬å­¦ä¹ å’Œå€Ÿé‰´çš„, é›†ç¥ç»ç½‘ç»œç»“æ„è®¾è®¡ä¸‰å¤§ä¸»æµé«˜çº§æŠ€å·§äºä¸€ä½“, é—ªçƒç€ç©¿è¶Šæ—¶ç©ºçš„æ‰åä¸æ™ºæ…§å…‰èŠ’ã€‚




**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)
