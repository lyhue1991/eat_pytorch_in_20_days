# 1-3,æ–‡æœ¬æ•°æ®å»ºæ¨¡æµç¨‹èŒƒä¾‹


### ä¸€ï¼Œå‡†å¤‡æ•°æ®


imdbæ•°æ®é›†çš„ç›®æ ‡æ˜¯æ ¹æ®ç”µå½±è¯„è®ºçš„æ–‡æœ¬å†…å®¹é¢„æµ‹è¯„è®ºçš„æƒ…æ„Ÿæ ‡ç­¾ã€‚

è®­ç»ƒé›†æœ‰20000æ¡ç”µå½±è¯„è®ºæ–‡æœ¬ï¼Œæµ‹è¯•é›†æœ‰5000æ¡ç”µå½±è¯„è®ºæ–‡æœ¬ï¼Œå…¶ä¸­æ­£é¢è¯„è®ºå’Œè´Ÿé¢è¯„è®ºéƒ½å„å ä¸€åŠã€‚

æ–‡æœ¬æ•°æ®é¢„å¤„ç†è¾ƒä¸ºç¹çï¼ŒåŒ…æ‹¬ä¸­æ–‡åˆ‡è¯ï¼ˆæœ¬ç¤ºä¾‹ä¸æ¶‰åŠï¼‰ï¼Œæ„å»ºè¯å…¸ï¼Œç¼–ç è½¬æ¢ï¼Œåºåˆ—å¡«å……ï¼Œæ„å»ºæ•°æ®ç®¡é“ç­‰ç­‰ã€‚



åœ¨torchä¸­é¢„å¤„ç†æ–‡æœ¬æ•°æ®ä¸€èˆ¬ä½¿ç”¨torchtextæˆ–è€…è‡ªå®šä¹‰Datasetï¼ŒtorchtextåŠŸèƒ½éå¸¸å¼ºå¤§ï¼Œå¯ä»¥æ„å»ºæ–‡æœ¬åˆ†ç±»ï¼Œåºåˆ—æ ‡æ³¨ï¼Œé—®ç­”æ¨¡å‹ï¼Œæœºå™¨ç¿»è¯‘ç­‰NLPä»»åŠ¡çš„æ•°æ®é›†ã€‚

ä¸‹é¢ä»…æ¼”ç¤ºä½¿ç”¨å®ƒæ¥æ„å»ºæ–‡æœ¬åˆ†ç±»æ•°æ®é›†çš„æ–¹æ³•ã€‚

è¾ƒå®Œæ•´çš„æ•™ç¨‹å¯ä»¥å‚è€ƒä»¥ä¸‹çŸ¥ä¹æ–‡ç« ï¼šã€Špytorchå­¦ä¹ ç¬”è®°â€”Torchtextã€‹

https://zhuanlan.zhihu.com/p/65833208


![](./data/ç”µå½±è¯„è®º.jpg)


torchtextå¸¸è§APIä¸€è§ˆ

* torchtext.data.Example : ç”¨æ¥è¡¨ç¤ºä¸€ä¸ªæ ·æœ¬ï¼Œæ•°æ®å’Œæ ‡ç­¾
* torchtext.vocab.Vocab: è¯æ±‡è¡¨ï¼Œå¯ä»¥å¯¼å…¥ä¸€äº›é¢„è®­ç»ƒè¯å‘é‡
* torchtext.data.Datasets: æ•°æ®é›†ç±»ï¼Œ`__getitem__`è¿”å› Exampleå®ä¾‹, torchtext.data.TabularDatasetæ˜¯å…¶å­ç±»ã€‚
* torchtext.data.Field : ç”¨æ¥å®šä¹‰å­—æ®µçš„å¤„ç†æ–¹æ³•ï¼ˆæ–‡æœ¬å­—æ®µï¼Œæ ‡ç­¾å­—æ®µï¼‰åˆ›å»º Exampleæ—¶çš„ é¢„å¤„ç†ï¼Œbatch æ—¶çš„ä¸€äº›å¤„ç†æ“ä½œã€‚
* torchtext.data.Iterator: è¿­ä»£å™¨ï¼Œç”¨æ¥ç”Ÿæˆ batch
* torchtext.datasets: åŒ…å«äº†å¸¸è§çš„æ•°æ®é›†.


```python
import torch
import string,re
import torchtext

MAX_WORDS = 10000  # ä»…è€ƒè™‘æœ€é«˜é¢‘çš„10000ä¸ªè¯
MAX_LEN = 200  # æ¯ä¸ªæ ·æœ¬ä¿ç•™200ä¸ªè¯çš„é•¿åº¦
BATCH_SIZE = 20 

#åˆ†è¯æ–¹æ³•
tokenizer = lambda x:re.sub('[%s]'%string.punctuation,"",x).split(" ")

#è¿‡æ»¤æ‰ä½é¢‘è¯
def filterLowFreqWords(arr,vocab):
    arr = [[x if x<MAX_WORDS else 0 for x in example] 
           for example in arr]
    return arr

#1,å®šä¹‰å„ä¸ªå­—æ®µçš„é¢„å¤„ç†æ–¹æ³•
TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer, lower=True, 
                  fix_length=MAX_LEN,postprocessing = filterLowFreqWords)

LABEL = torchtext.data.Field(sequential=False, use_vocab=False)

#2,æ„å»ºè¡¨æ ¼å‹dataset
#torchtext.data.TabularDatasetå¯è¯»å–csv,tsv,jsonç­‰æ ¼å¼
ds_train, ds_valid = torchtext.data.TabularDataset.splits(
        path='./data/imdb', train='train.tsv',test='test.tsv', format='tsv',
        fields=[('label', LABEL), ('text', TEXT)],skip_header = False)

#3,æ„å»ºè¯å…¸
TEXT.build_vocab(ds_train)

#4,æ„å»ºæ•°æ®ç®¡é“è¿­ä»£å™¨
train_iter, valid_iter = torchtext.data.Iterator.splits(
        (ds_train, ds_valid),  sort_within_batch=True,sort_key=lambda x: len(x.text),
        batch_sizes=(BATCH_SIZE,BATCH_SIZE))

```

```python
#æŸ¥çœ‹exampleä¿¡æ¯
print(ds_train[0].text)
print(ds_train[0].label)

```

```
['it', 'really', 'boggles', 'my', 'mind', 'when', 'someone', 'comes', 'across', 'a', 'movie', 'like', 'this', 'and', 'claims', 'it', 'to', 'be', 'one', 'of', 'the', 'worst', 'slasher', 'films', 'out', 'there', 'this', 'is', 'by', 'far', 'not', 'one', 'of', 'the', 'worst', 'out', 'there', 'still', 'not', 'a', 'good', 'movie', 'but', 'not', 'the', 'worst', 'nonetheless', 'go', 'see', 'something', 'like', 'death', 'nurse', 'or', 'blood', 'lake', 'and', 'then', 'come', 'back', 'to', 'me', 'and', 'tell', 'me', 'if', 'you', 'think', 'the', 'night', 'brings', 'charlie', 'is', 'the', 'worst', 'the', 'film', 'has', 'decent', 'camera', 'work', 'and', 'editing', 'which', 'is', 'way', 'more', 'than', 'i', 'can', 'say', 'for', 'many', 'more', 'extremely', 'obscure', 'slasher', 'filmsbr', 'br', 'the', 'film', 'doesnt', 'deliver', 'on', 'the', 'onscreen', 'deaths', 'theres', 'one', 'death', 'where', 'you', 'see', 'his', 'pruning', 'saw', 'rip', 'into', 'a', 'neck', 'but', 'all', 'other', 'deaths', 'are', 'hardly', 'interesting', 'but', 'the', 'lack', 'of', 'onscreen', 'graphic', 'violence', 'doesnt', 'mean', 'this', 'isnt', 'a', 'slasher', 'film', 'just', 'a', 'bad', 'onebr', 'br', 'the', 'film', 'was', 'obviously', 'intended', 'not', 'to', 'be', 'taken', 'too', 'seriously', 'the', 'film', 'came', 'in', 'at', 'the', 'end', 'of', 'the', 'second', 'slasher', 'cycle', 'so', 'it', 'certainly', 'was', 'a', 'reflection', 'on', 'traditional', 'slasher', 'elements', 'done', 'in', 'a', 'tongue', 'in', 'cheek', 'way', 'for', 'example', 'after', 'a', 'kill', 'charlie', 'goes', 'to', 'the', 'towns', 'welcome', 'sign', 'and', 'marks', 'the', 'population', 'down', 'one', 'less', 'this', 'is', 'something', 'that', 'can', 'only', 'get', 'a', 'laughbr', 'br', 'if', 'youre', 'into', 'slasher', 'films', 'definitely', 'give', 'this', 'film', 'a', 'watch', 'it', 'is', 'slightly', 'different', 'than', 'your', 'usual', 'slasher', 'film', 'with', 'possibility', 'of', 'two', 'killers', 'but', 'not', 'by', 'much', 'the', 'comedy', 'of', 'the', 'movie', 'is', 'pretty', 'much', 'telling', 'the', 'audience', 'to', 'relax', 'and', 'not', 'take', 'the', 'movie', 'so', 'god', 'darn', 'serious', 'you', 'may', 'forget', 'the', 'movie', 'you', 'may', 'remember', 'it', 'ill', 'remember', 'it', 'because', 'i', 'love', 'the', 'name']
0
```

```python
# æŸ¥çœ‹è¯å…¸ä¿¡æ¯
print(len(TEXT.vocab))

#itos: index to string
print(TEXT.vocab.itos[0]) 
print(TEXT.vocab.itos[1]) 

#stoi: string to index
print(TEXT.vocab.stoi['<unk>']) #unknown æœªçŸ¥è¯
print(TEXT.vocab.stoi['<pad>']) #padding  å¡«å……


#freqs: è¯é¢‘
print(TEXT.vocab.freqs['<unk>']) 
print(TEXT.vocab.freqs['a']) 
print(TEXT.vocab.freqs['good']) 

```

```
108197
<unk>
<pad>
0
1
0
129453
11457
```

```python
# æŸ¥çœ‹æ•°æ®ç®¡é“ä¿¡æ¯
# æ³¨æ„æœ‰å‘ï¼štextç¬¬0ç»´æ˜¯å¥å­é•¿åº¦
for batch in train_iter:
    features = batch.text
    labels = batch.label
    print(features)
    print(features.shape)
    print(labels)
    break
```

```
tensor([[  17,   31,  148,  ...,   54,   11,  201],
        [   2,    2,  904,  ...,  335,    7,  109],
        [1371, 1737,   44,  ...,  806,    2,   11],
        ...,
        [   6,    5,   62,  ...,    1,    1,    1],
        [ 170,    0,   27,  ...,    1,    1,    1],
        [  15,    0,   45,  ...,    1,    1,    1]])
torch.Size([200, 20])
tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0])

```

```python
# å°†æ•°æ®ç®¡é“ç»„ç»‡æˆtorch.utils.data.DataLoaderç›¸ä¼¼çš„features,labelè¾“å‡ºå½¢å¼
class DataLoader:
    def __init__(self,data_iter):
        self.data_iter = data_iter
        self.length = len(data_iter)
    
    def __len__(self):
        return self.length
    
    def __iter__(self):
        # æ³¨æ„ï¼šæ­¤å¤„è°ƒæ•´featuresä¸º batch firstï¼Œå¹¶è°ƒæ•´labelçš„shapeå’Œdtype
        for batch in self.data_iter:
            yield(torch.transpose(batch.text,0,1),
                  torch.unsqueeze(batch.label.float(),dim = 1))
    
dl_train = DataLoader(train_iter)
dl_valid = DataLoader(valid_iter)

```

### äºŒï¼Œå®šä¹‰æ¨¡å‹


ä½¿ç”¨Pytorché€šå¸¸æœ‰ä¸‰ç§æ–¹å¼æ„å»ºæ¨¡å‹ï¼šä½¿ç”¨nn.SequentialæŒ‰å±‚é¡ºåºæ„å»ºæ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºè‡ªå®šä¹‰æ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºæ¨¡å‹å¹¶è¾…åŠ©åº”ç”¨æ¨¡å‹å®¹å™¨(nn.Sequential,nn.ModuleList,nn.ModuleDict)è¿›è¡Œå°è£…ã€‚

æ­¤å¤„é€‰æ‹©ä½¿ç”¨ç¬¬ä¸‰ç§æ–¹å¼è¿›è¡Œæ„å»ºã€‚


```python
import torch
from torch import nn 
from torchkeras import LightModel,summary 

```

```python
torch.random.seed()
import torch
from torch import nn 

class Net(nn.Module):
    
    def __init__(self):
        super(Net, self).__init__()
        
        #è®¾ç½®padding_idxå‚æ•°åå°†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°†å¡«å……çš„tokenå§‹ç»ˆèµ‹å€¼ä¸º0å‘é‡
        self.embedding = nn.Embedding(num_embeddings = MAX_WORDS,embedding_dim = 3,padding_idx = 1)
        self.conv = nn.Sequential()
        self.conv.add_module("conv_1",nn.Conv1d(in_channels = 3,out_channels = 16,kernel_size = 5))
        self.conv.add_module("pool_1",nn.MaxPool1d(kernel_size = 2))
        self.conv.add_module("relu_1",nn.ReLU())
        self.conv.add_module("conv_2",nn.Conv1d(in_channels = 16,out_channels = 128,kernel_size = 2))
        self.conv.add_module("pool_2",nn.MaxPool1d(kernel_size = 2))
        self.conv.add_module("relu_2",nn.ReLU())
        
        self.dense = nn.Sequential()
        self.dense.add_module("flatten",nn.Flatten())
        self.dense.add_module("linear",nn.Linear(6144,1))
        self.dense.add_module("sigmoid",nn.Sigmoid())
        
    def forward(self,x):
        x = self.embedding(x).transpose(1,2)
        x = self.conv(x)
        y = self.dense(x)
        return y
        

net = Net()
print(net)

summary(net, input_shape = (200,),input_dtype = torch.LongTensor)

```

```
Net(
  (embedding): Embedding(10000, 3, padding_idx=1)
  (conv): Sequential(
    (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (relu_1): ReLU()
    (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
    (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (relu_2): ReLU()
  )
  (dense): Sequential(
    (flatten): Flatten()
    (linear): Linear(in_features=6144, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
         Embedding-1               [-1, 200, 3]          30,000
            Conv1d-2              [-1, 16, 196]             256
         MaxPool1d-3               [-1, 16, 98]               0
              ReLU-4               [-1, 16, 98]               0
            Conv1d-5              [-1, 128, 97]           4,224
         MaxPool1d-6              [-1, 128, 48]               0
              ReLU-7              [-1, 128, 48]               0
           Flatten-8                 [-1, 6144]               0
            Linear-9                    [-1, 1]           6,145
          Sigmoid-10                    [-1, 1]               0
================================================================
Total params: 40,625
Trainable params: 40,625
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.000763
Forward/backward pass size (MB): 0.287796
Params size (MB): 0.154972
Estimated Total Size (MB): 0.443531
----------------------------------------------------------------
```


### ä¸‰ï¼Œè®­ç»ƒæ¨¡å‹


è®­ç»ƒPytorché€šå¸¸éœ€è¦ç”¨æˆ·ç¼–å†™è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼Œè®­ç»ƒå¾ªç¯çš„ä»£ç é£æ ¼å› äººè€Œå¼‚ã€‚

æœ‰3ç±»å…¸å‹çš„è®­ç»ƒå¾ªç¯ä»£ç é£æ ¼ï¼šè„šæœ¬å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œå‡½æ•°å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œç±»å½¢å¼è®­ç»ƒå¾ªç¯ã€‚

æ­¤å¤„ä»‹ç»ä¸€ç§ç±»å½¢å¼çš„è®­ç»ƒå¾ªç¯ã€‚

æˆ‘ä»¬åˆ©ç”¨Pytorch-Lightningå®šä¹‰äº†ä¸€ä¸ªé«˜é˜¶çš„æ¨¡å‹æ¥å£LightModel, å°è£…åœ¨torchkerasä¸­, å¯ä»¥éå¸¸æ–¹ä¾¿åœ°è®­ç»ƒæ¨¡å‹ã€‚


```python
import pytorch_lightning as pl 
from torchkeras import LightModel 

class Model(LightModel):
    
    #loss,and optional metrics
    def shared_step(self,batch)->dict:
        x, y = batch
        prediction = self(x)
        loss = nn.BCELoss()(prediction,y)
        preds = torch.where(prediction>0.5,torch.ones_like(prediction),torch.zeros_like(prediction))
        acc = pl.metrics.functional.accuracy(preds, y)
        dic = {"loss":loss,"accuracy":acc} 
        return dic
    
    #optimizer,and optional lr_scheduler
    def configure_optimizers(self):
        optimizer= torch.optim.Adagrad(self.parameters(),lr = 0.02)
        return optimizer

```

```python
pl.seed_everything(1234)
net = Net()
model = Model(net)

ckpt_cb = pl.callbacks.ModelCheckpoint(monitor='val_loss')

# set gpus=0 will use cpuï¼Œ
# set gpus=1 will use 1 gpu
# set gpus=2 will use 2gpus 
# set gpus = -1 will use all gpus 
# you can also set gpus = [0,1] to use the  given gpus
# you can even set tpu_cores=2 to use two tpus 

trainer = pl.Trainer(max_epochs=20,gpus = 0, callbacks=[ckpt_cb]) 
trainer.fit(model,dl_train,dl_valid)


```

```
================================================================================2021-01-16 21:47:29
epoch =  0
{'val_loss': 0.6834630966186523, 'val_accuracy': 0.5546000003814697}
{'accuracy': 0.5224003791809082, 'loss': 0.7246873378753662}

================================================================================2021-01-16 21:48:07
epoch =  1
{'val_loss': 0.6371415257453918, 'val_accuracy': 0.63319993019104}
{'accuracy': 0.6110503673553467, 'loss': 0.6552867889404297}

================================================================================2021-01-16 21:48:50
epoch =  2
{'val_loss': 0.5896139740943909, 'val_accuracy': 0.6798002123832703}
{'accuracy': 0.6910000443458557, 'loss': 0.5874115824699402}

================================================================================2021-01-16 21:49:32
epoch =  3
{'val_loss': 0.5726749300956726, 'val_accuracy': 0.6971999406814575}
{'accuracy': 0.7391000390052795, 'loss': 0.5251786112785339}

================================================================================2021-01-16 21:50:13
epoch =  4
{'val_loss': 0.5328916311264038, 'val_accuracy': 0.7326000332832336}
{'accuracy': 0.7705488801002502, 'loss': 0.4773417115211487}

================================================================================2021-01-16 21:50:54
epoch =  5
{'val_loss': 0.5194208025932312, 'val_accuracy': 0.7413997650146484}
{'accuracy': 0.7968998551368713, 'loss': 0.43944093585014343}

================================================================================2021-01-16 21:51:35
epoch =  6
{'val_loss': 0.5199333429336548, 'val_accuracy': 0.7429998517036438}
{'accuracy': 0.8130489587783813, 'loss': 0.4102325737476349}

================================================================================2021-01-16 21:52:16
epoch =  7
{'val_loss': 0.5124538540840149, 'val_accuracy': 0.7517998814582825}
{'accuracy': 0.8314500451087952, 'loss': 0.3849221169948578}

================================================================================2021-01-16 21:52:58
epoch =  8
{'val_loss': 0.510671079158783, 'val_accuracy': 0.7554002404212952}
{'accuracy': 0.8438503742218018, 'loss': 0.3616768419742584}

================================================================================2021-01-16 21:53:39
epoch =  9
{'val_loss': 0.5184627771377563, 'val_accuracy': 0.7530001997947693}
{'accuracy': 0.8568001985549927, 'loss': 0.34138554334640503}

================================================================================2021-01-16 21:54:20
epoch =  10
{'val_loss': 0.5105863809585571, 'val_accuracy': 0.7580001354217529}
{'accuracy': 0.865899920463562, 'loss': 0.32265418767929077}

================================================================================2021-01-16 21:55:02
epoch =  11
{'val_loss': 0.5222727656364441, 'val_accuracy': 0.7586002349853516}
{'accuracy': 0.8747013211250305, 'loss': 0.306064248085022}

================================================================================2021-01-16 21:55:43
epoch =  12
{'val_loss': 0.5208917856216431, 'val_accuracy': 0.7597998976707458}
{'accuracy': 0.8820013403892517, 'loss': 0.29068493843078613}

================================================================================2021-01-16 21:56:24
epoch =  13
{'val_loss': 0.5236031413078308, 'val_accuracy': 0.7603999376296997}
{'accuracy': 0.889351487159729, 'loss': 0.2765159606933594}

================================================================================2021-01-16 21:57:04
epoch =  14
{'val_loss': 0.5428195595741272, 'val_accuracy': 0.7572000622749329}
{'accuracy': 0.8975020051002502, 'loss': 0.26261812448501587}

================================================================================2021-01-16 21:57:45
epoch =  15
{'val_loss': 0.5340956449508667, 'val_accuracy': 0.7602002024650574}
{'accuracy': 0.9049026966094971, 'loss': 0.25028231739997864}

================================================================================2021-01-16 21:58:25
epoch =  16
{'val_loss': 0.5380828380584717, 'val_accuracy': 0.7612000107765198}
{'accuracy': 0.9085531234741211, 'loss': 0.23980091512203217}

================================================================================2021-01-16 21:59:05
epoch =  17
{'val_loss': 0.5447139739990234, 'val_accuracy': 0.7638000249862671}
{'accuracy': 0.9168024659156799, 'loss': 0.22760336101055145}

================================================================================2021-01-16 21:59:45
epoch =  18
{'val_loss': 0.5505074858665466, 'val_accuracy': 0.7636001110076904}
{'accuracy': 0.921653687953949, 'loss': 0.21746191382408142}

================================================================================2021-01-16 22:00:26
epoch =  19
{'val_loss': 0.5615255236625671, 'val_accuracy': 0.7634001970291138}
{'accuracy': 0.9263033270835876, 'loss': 0.2077799290418625}
```

```python

```

### å››ï¼Œè¯„ä¼°æ¨¡å‹

```python
import pandas as pd 

history = model.history
dfhistory = pd.DataFrame(history) 
dfhistory 
```

```python
%matplotlib inline
%config InlineBackend.figure_format = 'svg'

import matplotlib.pyplot as plt

def plot_metric(dfhistory, metric):
    train_metrics = dfhistory[metric]
    val_metrics = dfhistory['val_'+metric]
    epochs = range(1, len(train_metrics) + 1)
    plt.plot(epochs, train_metrics, 'bo--')
    plt.plot(epochs, val_metrics, 'ro-')
    plt.title('Training and validation '+ metric)
    plt.xlabel("Epochs")
    plt.ylabel(metric)
    plt.legend(["train_"+metric, 'val_'+metric])
    plt.show()
```

```python
plot_metric(dfhistory,"loss")
```

![](./data/1-3-lossæ›²çº¿.png)

```python
plot_metric(dfhistory,"accuracy")
```

![](./data/1-3-accuracyæ›²çº¿.png)

```python
# è¯„ä¼°
results = trainer.test(model, test_dataloaders=dl_valid, verbose = False)
print(results[0])

```

```
{'val_loss': 0.5056138457655907, 'val_accuracy': 0.7948000040054322}
```


### äº”ï¼Œä½¿ç”¨æ¨¡å‹

```python
def predict(model,dl):
    model.eval()
    result = torch.cat([model.forward(t[0].to(model.device)) for t in dl])
    return(result.data)

result = predict(model,dl_valid)
result 
```

```
tensor([[0.0357],
        [0.8699],
        [0.3303],
        ...,
        [0.9962],
        [0.5566],
        [0.0491]])
```

```python

```

### å…­ï¼Œä¿å­˜æ¨¡å‹

```python
print(ckpt_cb.best_model_score)
model.load_from_checkpoint(ckpt_cb.best_model_path)

best_net  = model.net
torch.save(best_net.state_dict(),"./data/net.pt")

```

```python
net_clone = Net()
net_clone.load_state_dict(torch.load("./data/net.pt"))
model_clone = Model(net_clone)
trainer = pl.Trainer()
result = trainer.test(model_clone,test_dataloaders=dl_valid, verbose = False) 

print(result)
```

```
[{'test_loss': 0.4958915710449219, 'test_accuracy': 0.75}]
```


**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](./data/ç®—æ³•ç¾é£Ÿå±‹äºŒç»´ç .jpg)
