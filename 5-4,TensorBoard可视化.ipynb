{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf3407b",
   "metadata": {},
   "source": [
    "# 5-4,TensorBoardå¯è§†åŒ–\n",
    "\n",
    "åœ¨æˆ‘ä»¬çš„ç‚¼ä¸¹è¿‡ç¨‹ä¸­ï¼Œå¦‚æœèƒ½å¤Ÿä½¿ç”¨ä¸°å¯Œçš„å›¾åƒæ¥å±•ç¤ºæ¨¡å‹çš„ç»“æ„ï¼ŒæŒ‡æ ‡çš„å˜åŒ–ï¼Œå‚æ•°çš„åˆ†å¸ƒï¼Œè¾“å…¥çš„å½¢æ€ç­‰ä¿¡æ¯ï¼Œæ— ç–‘ä¼šæå‡æˆ‘ä»¬å¯¹é—®é¢˜çš„æ´å¯ŸåŠ›ï¼Œå¹¶å¢åŠ è®¸å¤šç‚¼ä¸¹çš„ä¹è¶£ã€‚\n",
    "\n",
    "TensorBoardæ­£æ˜¯è¿™æ ·ä¸€ä¸ªç¥å¥‡çš„ç‚¼ä¸¹å¯è§†åŒ–è¾…åŠ©å·¥å…·ã€‚å®ƒåŸæ˜¯TensorFlowçš„å°å¼Ÿï¼Œä½†å®ƒä¹Ÿèƒ½å¤Ÿå¾ˆå¥½åœ°å’ŒPytorchè¿›è¡Œé…åˆã€‚ç”šè‡³åœ¨Pytorchä¸­ä½¿ç”¨TensorBoardæ¯”TensorFlowä¸­ä½¿ç”¨TensorBoardè¿˜è¦æ¥çš„æ›´åŠ ç®€å•å’Œè‡ªç„¶ã€‚\n",
    "\n",
    "Pytorchä¸­åˆ©ç”¨TensorBoardå¯è§†åŒ–çš„å¤§æ¦‚è¿‡ç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "é¦–å…ˆåœ¨Pytorchä¸­æŒ‡å®šä¸€ä¸ªç›®å½•åˆ›å»ºä¸€ä¸ªtorch.utils.tensorboard.SummaryWriteræ—¥å¿—å†™å…¥å™¨ã€‚\n",
    "\n",
    "ç„¶åæ ¹æ®éœ€è¦å¯è§†åŒ–çš„ä¿¡æ¯ï¼Œåˆ©ç”¨æ—¥å¿—å†™å…¥å™¨å°†ç›¸åº”ä¿¡æ¯æ—¥å¿—å†™å…¥æˆ‘ä»¬æŒ‡å®šçš„ç›®å½•ã€‚\n",
    "\n",
    "æœ€åå°±å¯ä»¥ä¼ å…¥æ—¥å¿—ç›®å½•ä½œä¸ºå‚æ•°å¯åŠ¨TensorBoardï¼Œç„¶åå°±å¯ä»¥åœ¨TensorBoardä¸­æ„‰å¿«åœ°çœ‹ç‰‡äº†ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä¸»è¦ä»‹ç»Pytorchä¸­åˆ©ç”¨TensorBoardè¿›è¡Œå¦‚ä¸‹æ–¹é¢ä¿¡æ¯çš„å¯è§†åŒ–çš„æ–¹æ³•ã€‚\n",
    "\n",
    "* å¯è§†åŒ–æ¨¡å‹ç»“æ„ï¼š writer.add_graph\n",
    "\n",
    "* å¯è§†åŒ–æŒ‡æ ‡å˜åŒ–ï¼š writer.add_scalar\n",
    "\n",
    "* å¯è§†åŒ–å‚æ•°åˆ†å¸ƒï¼š writer.add_histogram\n",
    "\n",
    "* å¯è§†åŒ–åŸå§‹å›¾åƒï¼š writer.add_image æˆ– writer.add_images\n",
    "\n",
    "* å¯è§†åŒ–äººå·¥ç»˜å›¾ï¼š writer.add_figure\n",
    "\n",
    "\n",
    "è¿™äº›æ–¹æ³•å°½ç®¡éå¸¸ç®€å•ï¼Œä½†æ¯æ¬¡è®­ç»ƒçš„æ—¶å€™éƒ½è¦è°ƒå–è°ƒè¯•è¿˜æ˜¯éå¸¸éº»çƒ¦çš„ã€‚\n",
    "\n",
    "ä½œè€…åœ¨torchkerasåº“ä¸­é›†æˆäº†ä¸€ä¸ªtorchkeras.callback.TensorBoardå›è°ƒå‡½æ•°å·¥å…·ï¼Œ\n",
    "\n",
    "åˆ©ç”¨è¯¥å·¥å…·é…åˆtorchkeras.LightModelå¯ä»¥ç”¨æå°‘çš„ä»£ç åœ¨TensorBoardä¸­å®ç°ç»å¤§éƒ¨åˆ†å¸¸ç”¨çš„å¯è§†åŒ–åŠŸèƒ½ã€‚\n",
    "\n",
    "\n",
    "åŒ…æ‹¬ï¼š\n",
    "\n",
    "* å¯è§†åŒ–æ¨¡å‹ç»“æ„\n",
    "\n",
    "* å¯è§†åŒ–æŒ‡æ ‡å˜åŒ–\n",
    "\n",
    "* å¯è§†åŒ–å‚æ•°åˆ†å¸ƒ\n",
    "\n",
    "* å¯è§†åŒ–è¶…å‚è°ƒæ•´\n",
    "\n",
    "å¯ä»¥è¯´éå¸¸æ–¹ä¾¿å“¦ã€‚ğŸ˜‹ğŸ˜‹ \n",
    "\n",
    "\n",
    "\n",
    "æœ¬ç¯‡ç»“æ„ï¼š\n",
    "\n",
    "ä¸€ï¼Œå¯è§†åŒ–æ¨¡å‹ç»“æ„\n",
    "\n",
    "äºŒï¼Œå¯è§†åŒ–æŒ‡æ ‡å˜åŒ–\n",
    "\n",
    "ä¸‰ï¼Œå¯è§†åŒ–å‚æ•°åˆ†å¸ƒ\n",
    "\n",
    "å››ï¼Œå¯è§†åŒ–åŸå§‹å›¾åƒ\n",
    "\n",
    "äº”ï¼Œå¯è§†åŒ–äººå·¥ç»˜å›¾\n",
    "\n",
    "å…­ï¼Œtorchkerasä¸­çš„TensorBoardå›è°ƒå‡½æ•°\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a386b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchkeras==3.2.3 -i https://pypi.python.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd99c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchkeras\n",
    "\n",
    "print(\"torch.__version__=\"+torch.__version__) \n",
    "print(\"torchkeras.__version__=\"+torchkeras.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257008a6",
   "metadata": {},
   "source": [
    "```\n",
    "torch.__version__=1.10.0\n",
    "torchkeras.__version__=3.2.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e97d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24716404",
   "metadata": {},
   "source": [
    "## ä¸€ï¼Œå¯è§†åŒ–æ¨¡å‹ç»“æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b02805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchkeras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size = 3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2,stride = 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5)\n",
    "        self.dropout = nn.Dropout2d(p = 0.1)\n",
    "        self.adaptive_pool = nn.AdaptiveMaxPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(64,32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        y = self.linear2(x)\n",
    "        return y\n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b3e32",
   "metadata": {},
   "source": [
    "```\n",
    "Net(\n",
    "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
    "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
    "  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
    "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
    "  (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
    "  (relu): ReLU()\n",
    "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc54dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import summary \n",
    "summary(net,input_shape= (3,32,32));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbee62",
   "metadata": {},
   "source": [
    "```\n",
    "--------------------------------------------------------------------------\n",
    "Layer (type)                            Output Shape              Param #\n",
    "==========================================================================\n",
    "Conv2d-1                            [-1, 32, 30, 30]                  896\n",
    "MaxPool2d-2                         [-1, 32, 15, 15]                    0\n",
    "Conv2d-3                            [-1, 64, 11, 11]               51,264\n",
    "MaxPool2d-4                           [-1, 64, 5, 5]                    0\n",
    "Dropout2d-5                           [-1, 64, 5, 5]                    0\n",
    "AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0\n",
    "Flatten-7                                   [-1, 64]                    0\n",
    "Linear-8                                    [-1, 32]                2,080\n",
    "ReLU-9                                      [-1, 32]                    0\n",
    "Linear-10                                    [-1, 1]                   33\n",
    "==========================================================================\n",
    "Total params: 54,273\n",
    "Trainable params: 54,273\n",
    "Non-trainable params: 0\n",
    "--------------------------------------------------------------------------\n",
    "Input size (MB): 0.011719\n",
    "Forward/backward pass size (MB): 0.359627\n",
    "Params size (MB): 0.207035\n",
    "Estimated Total Size (MB): 0.578381\n",
    "--------------------------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./data/tensorboard')\n",
    "writer.add_graph(net,input_to_model = torch.rand(1,3,32,32))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "#%tensorboard --logdir ./data/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453aacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "#æŸ¥çœ‹å¯åŠ¨çš„tensorboardç¨‹åº\n",
    "notebook.list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef2d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#å¯åŠ¨tensorboardç¨‹åº\n",
    "notebook.start(\"--logdir ./data/tensorboard\")\n",
    "#ç­‰ä»·äºåœ¨å‘½ä»¤è¡Œä¸­æ‰§è¡Œ tensorboard --logdir ./data/tensorboard\n",
    "#å¯ä»¥åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ http://localhost:6006/ æŸ¥çœ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9bb350",
   "metadata": {},
   "source": [
    "![](./data/5-4-graphç»“æ„.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bcaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7702fc2e",
   "metadata": {},
   "source": [
    "## äºŒï¼Œå¯è§†åŒ–æŒ‡æ ‡å˜åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f996cb",
   "metadata": {},
   "source": [
    "æœ‰æ—¶å€™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¦‚æœèƒ½å¤Ÿå®æ—¶åŠ¨æ€åœ°æŸ¥çœ‹losså’Œå„ç§metricçš„å˜åŒ–æ›²çº¿ï¼Œé‚£ä¹ˆæ— ç–‘å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´åŠ ç›´è§‚åœ°äº†è§£æ¨¡å‹çš„è®­ç»ƒæƒ…å†µã€‚\n",
    "\n",
    "æ³¨æ„ï¼Œwriter.add_scalarä»…èƒ½å¯¹æ ‡é‡çš„å€¼çš„å˜åŒ–è¿›è¡Œå¯è§†åŒ–ã€‚å› æ­¤å®ƒä¸€èˆ¬ç”¨äºå¯¹losså’Œmetricçš„å˜åŒ–è¿›è¡Œå¯è§†åŒ–åˆ†æã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3df8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# f(x) = a*x**2 + b*x + cçš„æœ€å°å€¼\n",
    "x = torch.tensor(0.0,requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼\n",
    "a = torch.tensor(1.0)\n",
    "b = torch.tensor(-2.0)\n",
    "c = torch.tensor(1.0)\n",
    "\n",
    "optimizer = torch.optim.SGD(params=[x],lr = 0.01)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    result = a*torch.pow(x,2) + b*x + c \n",
    "    return(result)\n",
    "\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "for i in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    optimizer.step()\n",
    "    writer.add_scalar(\"x\",x.item(),i) #æ—¥å¿—ä¸­è®°å½•xåœ¨ç¬¬step i çš„å€¼\n",
    "    writer.add_scalar(\"y\",y.item(),i) #æ—¥å¿—ä¸­è®°å½•yåœ¨ç¬¬step i çš„å€¼\n",
    "\n",
    "writer.close()\n",
    "    \n",
    "print(\"y=\",f(x).data,\";\",\"x=\",x.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03458d74",
   "metadata": {},
   "source": [
    "```\n",
    "y= tensor(0.) ; x= tensor(1.0000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d967087",
   "metadata": {},
   "source": [
    "![](./data/5-4-æŒ‡æ ‡å˜åŒ–.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c1615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9404e49d",
   "metadata": {},
   "source": [
    "## ä¸‰ï¼Œå¯è§†åŒ–å‚æ•°åˆ†å¸ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce4704",
   "metadata": {},
   "source": [
    "å¦‚æœéœ€è¦å¯¹æ¨¡å‹çš„å‚æ•°(ä¸€èˆ¬éæ ‡é‡)åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„å˜åŒ–è¿›è¡Œå¯è§†åŒ–ï¼Œå¯ä»¥ä½¿ç”¨ writer.add_histogramã€‚\n",
    "\n",
    "å®ƒèƒ½å¤Ÿè§‚æµ‹å¼ é‡å€¼åˆ†å¸ƒçš„ç›´æ–¹å›¾éšè®­ç»ƒæ­¥éª¤çš„å˜åŒ–è¶‹åŠ¿ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f175bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# åˆ›å»ºæ­£æ€åˆ†å¸ƒçš„å¼ é‡æ¨¡æ‹Ÿå‚æ•°çŸ©é˜µ\n",
    "def norm(mean,std):\n",
    "    t = std*torch.randn((100,20))+mean\n",
    "    return t\n",
    "\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "for step,mean in enumerate(range(-10,10,1)):\n",
    "    w = norm(mean,1)\n",
    "    writer.add_histogram(\"w\",w, step)\n",
    "    writer.flush()\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b37ac",
   "metadata": {},
   "source": [
    "![](./data/5-4-å¼ é‡åˆ†å¸ƒ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2310df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1468da",
   "metadata": {},
   "source": [
    "## å››ï¼Œå¯è§†åŒ–åŸå§‹å›¾åƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895df3a8",
   "metadata": {},
   "source": [
    "å¦‚æœæˆ‘ä»¬åšå›¾åƒç›¸å…³çš„ä»»åŠ¡ï¼Œä¹Ÿå¯ä»¥å°†åŸå§‹çš„å›¾ç‰‡åœ¨tensorboardä¸­è¿›è¡Œå¯è§†åŒ–å±•ç¤ºã€‚\n",
    "\n",
    "å¦‚æœåªå†™å…¥ä¸€å¼ å›¾ç‰‡ä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨writer.add_imageã€‚\n",
    "\n",
    "å¦‚æœè¦å†™å…¥å¤šå¼ å›¾ç‰‡ä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨writer.add_imagesã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥ç”¨ torchvision.utils.make_gridå°†å¤šå¼ å›¾ç‰‡æ‹¼æˆä¸€å¼ å›¾ç‰‡ï¼Œç„¶åç”¨writer.add_imageå†™å…¥ã€‚\n",
    "\n",
    "æ³¨æ„ï¼Œä¼ å…¥çš„æ˜¯ä»£è¡¨å›¾ç‰‡ä¿¡æ¯çš„Pytorchä¸­çš„å¼ é‡æ•°æ®ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b981de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms as T,datasets \n",
    "\n",
    "\n",
    "transform_img = T.Compose(\n",
    "    [T.ToTensor()])\n",
    "\n",
    "def transform_label(x):\n",
    "    return torch.tensor([x]).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.ImageFolder(\"./data/cifar2/train/\",\n",
    "            transform = transform_img,target_transform= transform_label)\n",
    "ds_val = datasets.ImageFolder(\"./data/cifar2/test/\",\n",
    "            transform = transform_img,target_transform= transform_label)\n",
    "\n",
    "print(ds_train.class_to_idx)\n",
    "\n",
    "dl_train = DataLoader(ds_train,batch_size = 50,shuffle = True)\n",
    "dl_val = DataLoader(ds_val,batch_size = 50,shuffle = True)\n",
    "\n",
    "images,labels = next(iter(dl_train))\n",
    "\n",
    "# ä»…æŸ¥çœ‹ä¸€å¼ å›¾ç‰‡\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "writer.add_image('images[0]', images[0])\n",
    "writer.close()\n",
    "\n",
    "# å°†å¤šå¼ å›¾ç‰‡æ‹¼æ¥æˆä¸€å¼ å›¾ç‰‡ï¼Œä¸­é—´ç”¨é»‘è‰²ç½‘æ ¼åˆ†å‰²\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('image_grid', img_grid)\n",
    "writer.close()\n",
    "\n",
    "# å°†å¤šå¼ å›¾ç‰‡ç›´æ¥å†™å…¥\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "writer.add_images(\"images\",images,global_step = 0)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1459c87d",
   "metadata": {},
   "source": [
    "```\n",
    "{'0_airplane': 0, '1_automobile': 1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001c5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "445ded04",
   "metadata": {},
   "source": [
    "![](./data/5-4-åŸå§‹å›¾åƒå¯è§†åŒ–.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e3cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18582555",
   "metadata": {},
   "source": [
    "## äº”ï¼Œå¯è§†åŒ–äººå·¥ç»˜å›¾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea92bfa0",
   "metadata": {},
   "source": [
    "å¦‚æœæˆ‘ä»¬å°†matplotlibç»˜å›¾çš„ç»“æœå† tensorboardä¸­å±•ç¤ºï¼Œå¯ä»¥ä½¿ç”¨ add_figure.\n",
    "\n",
    "æ³¨æ„ï¼Œå’Œwriter.add_imageä¸åŒçš„æ˜¯ï¼Œwriter.add_figureéœ€è¦ä¼ å…¥matplotlibçš„figureå¯¹è±¡ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e152a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms as T,datasets \n",
    "\n",
    "transform_img = T.Compose(\n",
    "    [T.ToTensor()])\n",
    "\n",
    "def transform_label(x):\n",
    "    return torch.tensor([x]).float()\n",
    "\n",
    "\n",
    "ds_train = datasets.ImageFolder(\"./data/cifar2/train/\",\n",
    "            transform = transform_img,target_transform= transform_label)\n",
    "ds_val = datasets.ImageFolder(\"./data/cifar2/test/\",\n",
    "            transform = transform_img,target_transform= transform_label)\n",
    "\n",
    "print(ds_train.class_to_idx)\n",
    "\n",
    "dl_train = DataLoader(ds_train,batch_size = 50,shuffle = True)\n",
    "dl_val = DataLoader(ds_val,batch_size = 50,shuffle = True)\n",
    "\n",
    "images,labels = next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a52a7",
   "metadata": {},
   "source": [
    "```\n",
    "{'0_airplane': 0, '1_automobile': 1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "figure = plt.figure(figsize=(8,8)) \n",
    "for i in range(9):\n",
    "    img,label = ds_train[i]\n",
    "    img = img.permute(1,2,0)\n",
    "    ax=plt.subplot(3,3,i+1)\n",
    "    ax.imshow(img.numpy())\n",
    "    ax.set_title(\"label = %d\"%label.item())\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd7f2b",
   "metadata": {},
   "source": [
    "![](./data/5-4-ä¹å®«æ ¼.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223dbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./data/tensorboard')\n",
    "writer.add_figure('figure',figure,global_step=0)\n",
    "writer.close()                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79149475",
   "metadata": {},
   "source": [
    "![](./data/5-4-å¯è§†åŒ–äººå·¥ç»˜å›¾.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc56f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "776fbda0",
   "metadata": {},
   "source": [
    "## å…­ï¼Œtorchkerasä¸­çš„TensorBoardå›è°ƒå‡½æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72d113a",
   "metadata": {},
   "source": [
    "ä¸‹é¢æ˜¯ä¸€ä¸ªåœ¨torchkerasä¸­è°ƒç”¨TensorBoardå›è°ƒå‡½æ•°å®ç°\n",
    "å¸¸ç”¨å¯è§†åŒ–åŠŸèƒ½çš„å®Œæ•´èŒƒä¾‹ã€‚\n",
    "\n",
    "éå¸¸ç®€å•ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e5463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "\n",
    "import torchkeras #Attention this line \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbb3ee",
   "metadata": {},
   "source": [
    "### 1ï¼Œå‡†å¤‡æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "#number of samples\n",
    "n_positive,n_negative = 2000,2000\n",
    "\n",
    "#positive samples\n",
    "r_p = 5.0 + torch.normal(0.0,1.0,size = [n_positive,1]) \n",
    "theta_p = 2*np.pi*torch.rand([n_positive,1])\n",
    "Xp = torch.cat([r_p*torch.cos(theta_p),r_p*torch.sin(theta_p)],axis = 1)\n",
    "Yp = torch.ones_like(r_p)\n",
    "\n",
    "#negative samples\n",
    "r_n = 8.0 + torch.normal(0.0,1.0,size = [n_negative,1]) \n",
    "theta_n = 2*np.pi*torch.rand([n_negative,1])\n",
    "Xn = torch.cat([r_n*torch.cos(theta_n),r_n*torch.sin(theta_n)],axis = 1)\n",
    "Yn = torch.zeros_like(r_n)\n",
    "\n",
    "#concat positive and negative samples\n",
    "X = torch.cat([Xp,Xn],axis = 0)\n",
    "Y = torch.cat([Yp,Yn],axis = 0)\n",
    "\n",
    "\n",
    "#visual samples\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.scatter(Xp[:,0],Xp[:,1],c = \"r\")\n",
    "plt.scatter(Xn[:,0],Xn[:,1],c = \"g\")\n",
    "plt.legend([\"positive\",\"negative\"]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23218dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TensorDataset(X,Y)\n",
    "ds_train,ds_val = torch.utils.data.random_split(ds,[int(len(ds)*0.7),len(ds)-int(len(ds)*0.7)])\n",
    "dl_train = DataLoader(ds_train,batch_size = 200,shuffle=True,num_workers=2)\n",
    "dl_val = DataLoader(ds_val,batch_size = 200,num_workers=2)\n",
    "\n",
    "\n",
    "for features,labels in dl_train:\n",
    "    break\n",
    "print(features.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f56a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b3c90dc",
   "metadata": {},
   "source": [
    "### 2ï¼Œå®šä¹‰æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2,4)\n",
    "        self.fc2 = nn.Linear(4,8) \n",
    "        self.fc3 = nn.Linear(8,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        y = self.fc3(x) #don't need nn.Sigmoid()\n",
    "        return y\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras.metrics import Accuracy \n",
    "\n",
    "net = Net() \n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "metric_dict = {\"acc\":Accuracy()}\n",
    "\n",
    "lr = 0.03\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.0001)\n",
    "\n",
    "model = torchkeras.LightModel(net,\n",
    "                   loss_fn = loss_fn,\n",
    "                   metrics_dict= metric_dict,\n",
    "                   optimizer = optimizer,\n",
    "                   lr_scheduler = lr_scheduler,\n",
    "                  )       \n",
    "\n",
    "from torchkeras import summary\n",
    "summary(model,input_data=features);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9351f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1986375",
   "metadata": {},
   "source": [
    "### 3ï¼Œè®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef27156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl  \n",
    "from torchkeras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5a9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1ï¼Œè®¾ç½®å›è°ƒå‡½æ•°\n",
    "model_ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = pl.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                           patience=3,\n",
    "                           mode = 'min'\n",
    "                          )\n",
    "\n",
    "tensorboard = TensorBoard(\n",
    "    save_dir='tb_logs',\n",
    "    model_name='cnn',\n",
    "    log_weight=True,\n",
    "    log_weight_freq=2, #æ²¡ä¸¤ä¸ªepochè®°å½•ä¸€æ¬¡æƒé‡å¯è§†åŒ–\n",
    "    log_graph=True,\n",
    "    example_input_array=features,\n",
    "    log_hparams=True, #è®°å½•è¶…å‚\n",
    "    hparams_dict={\"lr\":lr},\n",
    ")\n",
    "\n",
    "#2ï¼Œè®¾ç½®è®­ç»ƒå‚æ•°\n",
    "\n",
    "# gpus=0 åˆ™ä½¿ç”¨cpuè®­ç»ƒï¼Œgpus=1åˆ™ä½¿ç”¨1ä¸ªgpuè®­ç»ƒï¼Œgpus=2åˆ™ä½¿ç”¨2ä¸ªgpuè®­ç»ƒï¼Œgpus=-1åˆ™ä½¿ç”¨æ‰€æœ‰gpuè®­ç»ƒï¼Œ\n",
    "# gpus=[0,1]åˆ™æŒ‡å®šä½¿ç”¨0å·å’Œ1å·gpuè®­ç»ƒï¼Œ gpus=\"0,1,2,3\"åˆ™ä½¿ç”¨0,1,2,3å·gpuè®­ç»ƒ\n",
    "# tpus=1 åˆ™ä½¿ç”¨1ä¸ªtpuè®­ç»ƒ\n",
    "trainer = pl.Trainer(logger=True,\n",
    "                     min_epochs=3,max_epochs=10,\n",
    "                     gpus=0,\n",
    "                     callbacks = [model_ckpt,early_stopping,tensorboard],\n",
    "                     enable_progress_bar = True) \n",
    "\n",
    "\n",
    "##4ï¼Œå¯åŠ¨è®­ç»ƒå¾ªç¯\n",
    "trainer.fit(model,dl_train,dl_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad295f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c603d258",
   "metadata": {},
   "source": [
    "### 4, TensorBoardå¯è§†åŒ–ç›‘æ§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=\"./tb_logs\" --bind_all --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b648c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() \n",
    "notebook.start(\"--logdir ./tb_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100ded9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d02e4bb",
   "metadata": {},
   "source": [
    "#### metrics\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h412vlgpqdj20n40cmaaf.jpg)\n",
    "\n",
    "#### graphs\n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h4130c9g6lj20d90dd0st.jpg)\n",
    "\n",
    "#### histograms \n",
    "\n",
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h4132au1scj20e709xjri.jpg) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892bc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4c58721",
   "metadata": {},
   "source": [
    "**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** \n",
    "\n",
    "å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·\"ç®—æ³•ç¾é£Ÿå±‹\"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚\n",
    "\n",
    "![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0097993b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75da9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
