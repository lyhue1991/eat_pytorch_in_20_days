# 4-3,nn.functional å’Œ nn.Module

```python
import os
import datetime

#æ‰“å°æ—¶é—´
def printbar():
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)

#macç³»ç»Ÿä¸Špytorchå’Œmatplotlibåœ¨jupyterä¸­åŒæ—¶è·‘éœ€è¦æ›´æ”¹ç¯å¢ƒå˜é‡
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE" 
```

### ä¸€ï¼Œnn.functional å’Œ nn.Module


å‰é¢æˆ‘ä»¬ä»‹ç»äº†Pytorchçš„å¼ é‡çš„ç»“æ„æ“ä½œå’Œæ•°å­¦è¿ç®—ä¸­çš„ä¸€äº›å¸¸ç”¨APIã€‚

åˆ©ç”¨è¿™äº›å¼ é‡çš„APIæˆ‘ä»¬å¯ä»¥æ„å»ºå‡ºç¥ç»ç½‘ç»œç›¸å…³çš„ç»„ä»¶(å¦‚æ¿€æ´»å‡½æ•°ï¼Œæ¨¡å‹å±‚ï¼ŒæŸå¤±å‡½æ•°)ã€‚

Pytorchå’Œç¥ç»ç½‘ç»œç›¸å…³çš„åŠŸèƒ½ç»„ä»¶å¤§å¤šéƒ½å°è£…åœ¨ torch.nnæ¨¡å—ä¸‹ã€‚

è¿™äº›åŠŸèƒ½ç»„ä»¶çš„ç»å¤§éƒ¨åˆ†æ—¢æœ‰å‡½æ•°å½¢å¼å®ç°ï¼Œä¹Ÿæœ‰ç±»å½¢å¼å®ç°ã€‚

å…¶ä¸­nn.functional(ä¸€èˆ¬å¼•å…¥åæ”¹åä¸ºF)æœ‰å„ç§åŠŸèƒ½ç»„ä»¶çš„å‡½æ•°å®ç°ã€‚ä¾‹å¦‚ï¼š

(æ¿€æ´»å‡½æ•°)
* F.relu 
* F.sigmoid
* F.tanh
* F.softmax

(æ¨¡å‹å±‚)
* F.linear
* F.conv2d
* F.max_pool2d
* F.dropout2d
* F.embedding

(æŸå¤±å‡½æ•°)
* F.binary_cross_entropy
* F.mse_loss
* F.cross_entropy

ä¸ºäº†ä¾¿äºå¯¹å‚æ•°è¿›è¡Œç®¡ç†ï¼Œä¸€èˆ¬é€šè¿‡ç»§æ‰¿ nn.Module è½¬æ¢æˆä¸ºç±»çš„å®ç°å½¢å¼ï¼Œå¹¶ç›´æ¥å°è£…åœ¨ nn æ¨¡å—ä¸‹ã€‚ä¾‹å¦‚ï¼š

(æ¿€æ´»å‡½æ•°)
* nn.ReLU
* nn.Sigmoid
* nn.Tanh
* nn.Softmax

(æ¨¡å‹å±‚)
* nn.Linear
* nn.Conv2d
* nn.MaxPool2d
* nn.Dropout2d
* nn.Embedding

(æŸå¤±å‡½æ•°)
* nn.BCELoss
* nn.MSELoss
* nn.CrossEntropyLoss

å®é™…ä¸Šnn.Moduleé™¤äº†å¯ä»¥ç®¡ç†å…¶å¼•ç”¨çš„å„ç§å‚æ•°ï¼Œè¿˜å¯ä»¥ç®¡ç†å…¶å¼•ç”¨çš„å­æ¨¡å—ï¼ŒåŠŸèƒ½ååˆ†å¼ºå¤§ã€‚



```python

```

### äºŒï¼Œä½¿ç”¨nn.Moduleæ¥ç®¡ç†å‚æ•°


åœ¨Pytorchä¸­ï¼Œæ¨¡å‹çš„å‚æ•°æ˜¯éœ€è¦è¢«ä¼˜åŒ–å™¨è®­ç»ƒçš„ï¼Œå› æ­¤ï¼Œé€šå¸¸è¦è®¾ç½®å‚æ•°ä¸º requires_grad = True çš„å¼ é‡ã€‚

åŒæ—¶ï¼Œåœ¨ä¸€ä¸ªæ¨¡å‹ä¸­ï¼Œå¾€å¾€æœ‰è®¸å¤šçš„å‚æ•°ï¼Œè¦æ‰‹åŠ¨ç®¡ç†è¿™äº›å‚æ•°å¹¶ä¸æ˜¯ä¸€ä»¶å®¹æ˜“çš„äº‹æƒ…ã€‚

Pytorchä¸€èˆ¬å°†å‚æ•°ç”¨nn.Parameteræ¥è¡¨ç¤ºï¼Œå¹¶ä¸”ç”¨nn.Moduleæ¥ç®¡ç†å…¶ç»“æ„ä¸‹çš„æ‰€æœ‰å‚æ•°ã€‚


```python
import torch 
from torch import nn 
import torch.nn.functional  as F
from matplotlib import pyplot as plt

```

```python
# nn.Parameter å…·æœ‰ requires_grad = True å±æ€§
w = nn.Parameter(torch.randn(2,2))
print(w)
print(w.requires_grad)
```

```
Parameter containing:
tensor([[ 0.3544, -1.1643],
        [ 1.2302,  1.3952]], requires_grad=True)
True
```

```python
# nn.ParameterList å¯ä»¥å°†å¤šä¸ªnn.Parameterç»„æˆä¸€ä¸ªåˆ—è¡¨
params_list = nn.ParameterList([nn.Parameter(torch.rand(8,i)) for i in range(1,3)])
print(params_list)
print(params_list[0].requires_grad)
```

```
ParameterList(
    (0): Parameter containing: [torch.FloatTensor of size 8x1]
    (1): Parameter containing: [torch.FloatTensor of size 8x2]
)
True
```

```python
# nn.ParameterDict å¯ä»¥å°†å¤šä¸ªnn.Parameterç»„æˆä¸€ä¸ªå­—å…¸

params_dict = nn.ParameterDict({"a":nn.Parameter(torch.rand(2,2)),
                               "b":nn.Parameter(torch.zeros(2))})
print(params_dict)
print(params_dict["a"].requires_grad)
```

```
ParameterDict(
    (a): Parameter containing: [torch.FloatTensor of size 2x2]
    (b): Parameter containing: [torch.FloatTensor of size 2]
)
True
```

```python
# å¯ä»¥ç”¨Moduleå°†å®ƒä»¬ç®¡ç†èµ·æ¥
# module.parameters()è¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼ŒåŒ…æ‹¬å…¶ç»“æ„ä¸‹çš„æ‰€æœ‰parameters

module = nn.Module()
module.w = w
module.params_list = params_list
module.params_dict = params_dict

num_param = 0
for param in module.parameters():
    print(param,"\n")
    num_param = num_param + 1
print("number of Parameters =",num_param)

```

```
Parameter containing:
tensor([[ 0.3544, -1.1643],
        [ 1.2302,  1.3952]], requires_grad=True) 

Parameter containing:
tensor([[0.9391],
        [0.7590],
        [0.6899],
        [0.4786],
        [0.2392],
        [0.9645],
        [0.1968],
        [0.1353]], requires_grad=True) 

Parameter containing:
tensor([[0.8012, 0.9587],
        [0.0276, 0.5995],
        [0.7338, 0.5559],
        [0.1704, 0.5814],
        [0.7626, 0.1179],
        [0.4945, 0.2408],
        [0.7179, 0.0575],
        [0.3418, 0.7291]], requires_grad=True) 

Parameter containing:
tensor([[0.7729, 0.2383],
        [0.7054, 0.9937]], requires_grad=True) 

Parameter containing:
tensor([0., 0.], requires_grad=True) 

number of Parameters = 5
```

```python
#å®è·µå½“ä¸­ï¼Œä¸€èˆ¬é€šè¿‡ç»§æ‰¿nn.Moduleæ¥æ„å»ºæ¨¡å—ç±»ï¼Œå¹¶å°†æ‰€æœ‰å«æœ‰éœ€è¦å­¦ä¹ çš„å‚æ•°çš„éƒ¨åˆ†æ”¾åœ¨æ„é€ å‡½æ•°ä¸­ã€‚

#ä»¥ä¸‹èŒƒä¾‹ä¸ºPytorchä¸­nn.Linearçš„æºç çš„ç®€åŒ–ç‰ˆæœ¬
#å¯ä»¥çœ‹åˆ°å®ƒå°†éœ€è¦å­¦ä¹ çš„å‚æ•°æ”¾åœ¨äº†__init__æ„é€ å‡½æ•°ä¸­ï¼Œå¹¶åœ¨forwardä¸­è°ƒç”¨F.linearå‡½æ•°æ¥å®ç°è®¡ç®—é€»è¾‘ã€‚

class Linear(nn.Module):
    __constants__ = ['in_features', 'out_features']

    def __init__(self, in_features, out_features, bias=True):
        super(Linear, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))
        if bias:
            self.bias = nn.Parameter(torch.Tensor(out_features))
        else:
            self.register_parameter('bias', None)

    def forward(self, input):
        return F.linear(input, self.weight, self.bias)

```

```python

```

### ä¸‰ï¼Œä½¿ç”¨nn.Moduleæ¥ç®¡ç†å­æ¨¡å—


ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éƒ½å¾ˆå°‘ç›´æ¥ä½¿ç”¨ nn.Parameteræ¥å®šä¹‰å‚æ•°æ„å»ºæ¨¡å‹ï¼Œè€Œæ˜¯é€šè¿‡ä¸€äº›æ‹¼è£…ä¸€äº›å¸¸ç”¨çš„æ¨¡å‹å±‚æ¥æ„é€ æ¨¡å‹ã€‚

è¿™äº›æ¨¡å‹å±‚ä¹Ÿæ˜¯ç»§æ‰¿è‡ªnn.Moduleçš„å¯¹è±¡,æœ¬èº«ä¹ŸåŒ…æ‹¬å‚æ•°ï¼Œå±äºæˆ‘ä»¬è¦å®šä¹‰çš„æ¨¡å—çš„å­æ¨¡å—ã€‚

nn.Moduleæä¾›äº†ä¸€äº›æ–¹æ³•å¯ä»¥ç®¡ç†è¿™äº›å­æ¨¡å—ã€‚

* children() æ–¹æ³•: è¿”å›ç”Ÿæˆå™¨ï¼ŒåŒ…æ‹¬æ¨¡å—ä¸‹çš„æ‰€æœ‰å­æ¨¡å—ã€‚

* named_children()æ–¹æ³•ï¼šè¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼ŒåŒ…æ‹¬æ¨¡å—ä¸‹çš„æ‰€æœ‰å­æ¨¡å—ï¼Œä»¥åŠå®ƒä»¬çš„åå­—ã€‚

* modules()æ–¹æ³•ï¼šè¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼ŒåŒ…æ‹¬æ¨¡å—ä¸‹çš„æ‰€æœ‰å„ä¸ªå±‚çº§çš„æ¨¡å—ï¼ŒåŒ…æ‹¬æ¨¡å—æœ¬èº«ã€‚

* named_modules()æ–¹æ³•ï¼šè¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼ŒåŒ…æ‹¬æ¨¡å—ä¸‹çš„æ‰€æœ‰å„ä¸ªå±‚çº§çš„æ¨¡å—ä»¥åŠå®ƒä»¬çš„åå­—ï¼ŒåŒ…æ‹¬æ¨¡å—æœ¬èº«ã€‚

å…¶ä¸­chidren()æ–¹æ³•å’Œnamed_children()æ–¹æ³•è¾ƒå¤šä½¿ç”¨ã€‚

modules()æ–¹æ³•å’Œnamed_modules()æ–¹æ³•è¾ƒå°‘ä½¿ç”¨ï¼Œå…¶åŠŸèƒ½å¯ä»¥é€šè¿‡å¤šä¸ªnamed_children()çš„åµŒå¥—ä½¿ç”¨å®ç°ã€‚


```python
class Net(nn.Module):
    
    def __init__(self):
        super(Net, self).__init__()
        
        self.embedding = nn.Embedding(num_embeddings = 10000,embedding_dim = 3,padding_idx = 1)
        self.conv = nn.Sequential()
        self.conv.add_module("conv_1",nn.Conv1d(in_channels = 3,out_channels = 16,kernel_size = 5))
        self.conv.add_module("pool_1",nn.MaxPool1d(kernel_size = 2))
        self.conv.add_module("relu_1",nn.ReLU())
        self.conv.add_module("conv_2",nn.Conv1d(in_channels = 16,out_channels = 128,kernel_size = 2))
        self.conv.add_module("pool_2",nn.MaxPool1d(kernel_size = 2))
        self.conv.add_module("relu_2",nn.ReLU())
        
        self.dense = nn.Sequential()
        self.dense.add_module("flatten",nn.Flatten())
        self.dense.add_module("linear",nn.Linear(6144,1))
        self.dense.add_module("sigmoid",nn.Sigmoid())
        
    def forward(self,x):
        x = self.embedding(x).transpose(1,2)
        x = self.conv(x)
        y = self.dense(x)
        return y
    
net = Net()

```

```python
i = 0
for child in net.children():
    i+=1
    print(child,"\n")
print("child number",i)

```

```
Embedding(10000, 3, padding_idx=1) 

Sequential(
  (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
  (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_1): ReLU()
  (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
  (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_2): ReLU()
) 

Sequential(
  (flatten): Flatten()
  (linear): Linear(in_features=6144, out_features=1, bias=True)
  (sigmoid): Sigmoid()
) 

child number 3

```

```python
i = 0
for name,child in net.named_children():
    i+=1
    print(name,":",child,"\n")
print("child number",i)
```

```
embedding : Embedding(10000, 3, padding_idx=1) 

conv : Sequential(
  (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
  (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_1): ReLU()
  (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
  (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_2): ReLU()
) 

dense : Sequential(
  (flatten): Flatten()
  (linear): Linear(in_features=6144, out_features=1, bias=True)
  (sigmoid): Sigmoid()
) 

child number 3
```

```python
i = 0
for module in net.modules():
    i+=1
    print(module)
print("module number:",i)
```

```
Net(
  (embedding): Embedding(10000, 3, padding_idx=1)
  (conv): Sequential(
    (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (relu_1): ReLU()
    (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
    (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (relu_2): ReLU()
  )
  (dense): Sequential(
    (flatten): Flatten()
    (linear): Linear(in_features=6144, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
Embedding(10000, 3, padding_idx=1)
Sequential(
  (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
  (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_1): ReLU()
  (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
  (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_2): ReLU()
)
Conv1d(3, 16, kernel_size=(5,), stride=(1,))
MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
ReLU()
Conv1d(16, 128, kernel_size=(2,), stride=(1,))
MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
ReLU()
Sequential(
  (flatten): Flatten()
  (linear): Linear(in_features=6144, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
Flatten()
Linear(in_features=6144, out_features=1, bias=True)
Sigmoid()
module number: 13
```


ä¸‹é¢æˆ‘ä»¬é€šè¿‡named_childrenæ–¹æ³•æ‰¾åˆ°embeddingå±‚ï¼Œå¹¶å°†å…¶å‚æ•°è®¾ç½®ä¸ºä¸å¯è®­ç»ƒ(ç›¸å½“äºå†»ç»“embeddingå±‚)ã€‚

```python
children_dict = {name:module for name,module in net.named_children()}

print(children_dict)
embedding = children_dict["embedding"]
embedding.requires_grad_(False) #å†»ç»“å…¶å‚æ•°
```

```
{'embedding': Embedding(10000, 3, padding_idx=1), 'conv': Sequential(
  (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
  (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_1): ReLU()
  (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
  (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_2): ReLU()
), 'dense': Sequential(
  (flatten): Flatten()
  (linear): Linear(in_features=6144, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)}
```

```python
#å¯ä»¥çœ‹åˆ°å…¶ç¬¬ä¸€å±‚çš„å‚æ•°å·²ç»ä¸å¯ä»¥è¢«è®­ç»ƒäº†ã€‚
for param in embedding.parameters():
    print(param.requires_grad)
    print(param.numel())
```

```
False
30000
```

```python
from torchkeras import summary
summary(net,input_shape = (200,),input_dtype = torch.LongTensor)
# ä¸å¯è®­ç»ƒå‚æ•°æ•°é‡å¢åŠ 
```

```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
         Embedding-1               [-1, 200, 3]          30,000
            Conv1d-2              [-1, 16, 196]             256
         MaxPool1d-3               [-1, 16, 98]               0
              ReLU-4               [-1, 16, 98]               0
            Conv1d-5              [-1, 128, 97]           4,224
         MaxPool1d-6              [-1, 128, 48]               0
              ReLU-7              [-1, 128, 48]               0
           Flatten-8                 [-1, 6144]               0
            Linear-9                    [-1, 1]           6,145
          Sigmoid-10                    [-1, 1]               0
================================================================
Total params: 40,625
Trainable params: 10,625
Non-trainable params: 30,000
----------------------------------------------------------------
Input size (MB): 0.000763
Forward/backward pass size (MB): 0.287796
Params size (MB): 0.154972
Estimated Total Size (MB): 0.443531
----------------------------------------------------------------
```

```python

```

**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](./data/ç®—æ³•ç¾é£Ÿå±‹äºŒç»´ç .jpg)
