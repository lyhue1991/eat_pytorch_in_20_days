# 1-2,å›¾ç‰‡æ•°æ®å»ºæ¨¡æµç¨‹èŒƒä¾‹

```python
import os
import datetime

#æ‰“å°æ—¶é—´
def printbar():
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)

#macç³»ç»Ÿä¸Špytorchå’Œmatplotlibåœ¨jupyterä¸­åŒæ—¶è·‘éœ€è¦æ›´æ”¹ç¯å¢ƒå˜é‡
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE" 

```

```python
!pip install torchvison==0.11.2
!pip install torchkeras==3.2.3
```

```python
import torch 
import torchvision 
import torchkeras 
print("torch.__version__ = ", torch.__version__)
print("torchvision.__version__ = ", torchvision.__version__) 
print("torchkeras.__version__ = ", torchkeras.__version__) 
```


```
torch.__version__ =  1.10.0
torchvision.__version__ =  0.11.2
torchkeras.__version__ =  3.2.3
```


<br>

<font color="red">
 
å…¬ä¼—å· **ç®—æ³•ç¾é£Ÿå±‹** å›å¤å…³é”®è¯ï¼š**pytorch**ï¼Œ è·å–æœ¬é¡¹ç›®æºç å’Œæ‰€ç”¨æ•°æ®é›†ç™¾åº¦äº‘ç›˜ä¸‹è½½é“¾æ¥ã€‚
    
</font> 



### ä¸€ï¼Œå‡†å¤‡æ•°æ®


cifar2æ•°æ®é›†ä¸ºcifar10æ•°æ®é›†çš„å­é›†ï¼ŒåªåŒ…æ‹¬å‰ä¸¤ç§ç±»åˆ«airplaneå’Œautomobileã€‚

è®­ç»ƒé›†æœ‰airplaneå’Œautomobileå›¾ç‰‡å„5000å¼ ï¼Œæµ‹è¯•é›†æœ‰airplaneå’Œautomobileå›¾ç‰‡å„1000å¼ ã€‚

cifar2ä»»åŠ¡çš„ç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªæ¨¡å‹æ¥å¯¹é£æœºairplaneå’ŒæœºåŠ¨è½¦automobileä¸¤ç§å›¾ç‰‡è¿›è¡Œåˆ†ç±»ã€‚

æˆ‘ä»¬å‡†å¤‡çš„Cifar2æ•°æ®é›†çš„æ–‡ä»¶ç»“æ„å¦‚ä¸‹æ‰€ç¤ºã€‚

![](./data/cifar2.jpg)

```python

```

åœ¨Pytorchä¸­æ„å»ºå›¾ç‰‡æ•°æ®ç®¡é“é€šå¸¸æœ‰ä¸¤ç§æ–¹æ³•ã€‚

ç¬¬ä¸€ç§æ˜¯ä½¿ç”¨ torchvisionä¸­çš„datasets.ImageFolderæ¥è¯»å–å›¾ç‰‡ç„¶åç”¨ DataLoaderæ¥å¹¶è¡ŒåŠ è½½ã€‚

ç¬¬äºŒç§æ˜¯é€šè¿‡ç»§æ‰¿ torch.utils.data.Dataset å®ç°ç”¨æˆ·è‡ªå®šä¹‰è¯»å–é€»è¾‘ç„¶åç”¨ DataLoaderæ¥å¹¶è¡ŒåŠ è½½ã€‚

ç¬¬äºŒç§æ–¹æ³•æ˜¯è¯»å–ç”¨æˆ·è‡ªå®šä¹‰æ•°æ®é›†çš„é€šç”¨æ–¹æ³•ï¼Œæ—¢å¯ä»¥è¯»å–å›¾ç‰‡æ•°æ®é›†ï¼Œä¹Ÿå¯ä»¥è¯»å–æ–‡æœ¬æ•°æ®é›†ã€‚

æœ¬ç¯‡æˆ‘ä»¬ä»‹ç»ç¬¬ä¸€ç§æ–¹æ³•ã€‚


```python
import torch 
from torch import nn
from torch.utils.data import Dataset,DataLoader
from torchvision import transforms as T
from torchvision import datasets 
```

```python
transform_img = T.Compose(
    [T.ToTensor()])

def transform_label(x):
    return torch.tensor([x]).float()

```

```python
ds_train = datasets.ImageFolder("./eat_pytorch_datasets/cifar2/train/",
            transform = transform_img,target_transform = transform_label)
ds_val = datasets.ImageFolder("./eat_pytorch_datasets/cifar2/test/",
            transform = transform_img,target_transform = transform_label)
print(ds_train.class_to_idx)

```

```
{'0_airplane': 0, '1_automobile': 1}
```

```python
dl_train = DataLoader(ds_train,batch_size = 50,shuffle = True)
dl_val = DataLoader(ds_val,batch_size = 50,shuffle = False)

```

```python
%matplotlib inline
%config InlineBackend.figure_format = 'svg'

#æŸ¥çœ‹éƒ¨åˆ†æ ·æœ¬
from matplotlib import pyplot as plt 

plt.figure(figsize=(8,8)) 
for i in range(9):
    img,label = ds_train[i]
    img = img.permute(1,2,0)
    ax=plt.subplot(3,3,i+1)
    ax.imshow(img.numpy())
    ax.set_title("label = %d"%label.item())
    ax.set_xticks([])
    ax.set_yticks([]) 
plt.show()

```

![](./data/1-2-æŸ¥çœ‹æ ·æœ¬.png)

```python
# Pytorchçš„å›¾ç‰‡é»˜è®¤é¡ºåºæ˜¯ Batch,Channel,Width,Height
for features,labels in dl_train:
    print(features.shape,labels.shape) 
    break
    
```

```
torch.Size([50, 3, 32, 32]) torch.Size([50, 1])
```


### äºŒï¼Œå®šä¹‰æ¨¡å‹


ä½¿ç”¨Pytorché€šå¸¸æœ‰ä¸‰ç§æ–¹å¼æ„å»ºæ¨¡å‹ï¼šä½¿ç”¨nn.SequentialæŒ‰å±‚é¡ºåºæ„å»ºæ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºè‡ªå®šä¹‰æ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºæ¨¡å‹å¹¶è¾…åŠ©åº”ç”¨æ¨¡å‹å®¹å™¨(nn.Sequential,nn.ModuleList,nn.ModuleDict)è¿›è¡Œå°è£…ã€‚

æ­¤å¤„é€‰æ‹©é€šè¿‡ç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºè‡ªå®šä¹‰æ¨¡å‹ã€‚

```python
#æµ‹è¯•AdaptiveMaxPool2dçš„æ•ˆæœ
pool = nn.AdaptiveMaxPool2d((1,1))
t = torch.randn(10,8,32,32)
pool(t).shape 
```

```
torch.Size([10, 8, 1, 1])
```

```python
class Net(nn.Module):
    
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size = 3)
        self.pool = nn.MaxPool2d(kernel_size = 2,stride = 2)
        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5)
        self.dropout = nn.Dropout2d(p = 0.1)
        self.adaptive_pool = nn.AdaptiveMaxPool2d((1,1))
        self.flatten = nn.Flatten()
        self.linear1 = nn.Linear(64,32)
        self.relu = nn.ReLU()
        self.linear2 = nn.Linear(32,1)
        
    def forward(self,x):
        x = self.conv1(x)
        x = self.pool(x)
        x = self.conv2(x)
        x = self.pool(x)
        x = self.dropout(x)
        x = self.adaptive_pool(x)
        x = self.flatten(x)
        x = self.linear1(x)
        x = self.relu(x)
        x = self.linear2(x)
        return x 
        
net = Net()
print(net)

```

```
Net(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=1, bias=True)
)
```

```python
import torchkeras
torchkeras.summary(net,input_data = features);
```

```
--------------------------------------------------------------------------
Layer (type)                            Output Shape              Param #
==========================================================================
Conv2d-1                            [-1, 32, 30, 30]                  896
MaxPool2d-2                         [-1, 32, 15, 15]                    0
Conv2d-3                            [-1, 64, 11, 11]               51,264
MaxPool2d-4                           [-1, 64, 5, 5]                    0
Dropout2d-5                           [-1, 64, 5, 5]                    0
AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0
Flatten-7                                   [-1, 64]                    0
Linear-8                                    [-1, 32]                2,080
ReLU-9                                      [-1, 32]                    0
Linear-10                                    [-1, 1]                   33
Net-11                                       [-1, 1]               54,273
==========================================================================
Total params: 108,546
Trainable params: 108,546
Non-trainable params: 0
--------------------------------------------------------------------------
Input size (MB): 0.000069
Forward/backward pass size (MB): 0.359634
Params size (MB): 0.414070
Estimated Total Size (MB): 0.773773
--------------------------------------------------------------------------
```


### ä¸‰ï¼Œè®­ç»ƒæ¨¡å‹


Pytorché€šå¸¸éœ€è¦ç”¨æˆ·ç¼–å†™è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼Œè®­ç»ƒå¾ªç¯çš„ä»£ç é£æ ¼å› äººè€Œå¼‚ã€‚

æœ‰3ç±»å…¸å‹çš„è®­ç»ƒå¾ªç¯ä»£ç é£æ ¼ï¼šè„šæœ¬å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œå‡½æ•°å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œç±»å½¢å¼è®­ç»ƒå¾ªç¯ã€‚

æ­¤å¤„ä»‹ç»ä¸€ç§è¾ƒé€šç”¨çš„ä»¿ç…§Kerasé£æ ¼çš„å‡½æ•°å½¢å¼çš„è®­ç»ƒå¾ªç¯ã€‚

è¯¥è®­ç»ƒå¾ªç¯çš„ä»£ç ä¹Ÿæ˜¯torchkerasåº“çš„æ ¸å¿ƒä»£ç ã€‚

torchkerasè¯¦æƒ…:  https://github.com/lyhue1991/torchkeras 


```python
import os,sys,time
import numpy as np
import pandas as pd
import datetime 
from tqdm import tqdm 

import torch
from torch import nn 
from copy import deepcopy

def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(str(info)+"\n")

class StepRunner:
    def __init__(self, net, loss_fn,
                 stage = "train", metrics_dict = None, 
                 optimizer = None
                 ):
        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage
        self.optimizer = optimizer
            
    def step(self, features, labels):
        #loss
        preds = self.net(features)
        loss = self.loss_fn(preds,labels)
        
        #backward()
        if self.optimizer is not None and self.stage=="train": 
            loss.backward()
            self.optimizer.step()
            self.optimizer.zero_grad()
            
        #metrics
        step_metrics = {self.stage+"_"+name:metric_fn(preds, labels).item() 
                        for name,metric_fn in self.metrics_dict.items()}
        return loss.item(),step_metrics
    
    def train_step(self,features,labels):
        self.net.train() #è®­ç»ƒæ¨¡å¼, dropoutå±‚å‘ç”Ÿä½œç”¨
        return self.step(features,labels)
    
    @torch.no_grad()
    def eval_step(self,features,labels):
        self.net.eval() #é¢„æµ‹æ¨¡å¼, dropoutå±‚ä¸å‘ç”Ÿä½œç”¨
        return self.step(features,labels)
    
    def __call__(self,features,labels):
        if self.stage=="train":
            return self.train_step(features,labels) 
        else:
            return self.eval_step(features,labels)
        
class EpochRunner:
    def __init__(self,steprunner):
        self.steprunner = steprunner
        self.stage = steprunner.stage
        
    def __call__(self,dataloader):
        total_loss,step = 0,0
        loop = tqdm(enumerate(dataloader), total =len(dataloader))
        for i, batch in loop: 
            loss, step_metrics = self.steprunner(*batch)
            step_log = dict({self.stage+"_loss":loss},**step_metrics)
            total_loss += loss
            step+=1
            if i!=len(dataloader)-1:
                loop.set_postfix(**step_log)
            else:
                epoch_loss = total_loss/step
                epoch_metrics = {self.stage+"_"+name:metric_fn.compute().item() 
                                 for name,metric_fn in self.steprunner.metrics_dict.items()}
                epoch_log = dict({self.stage+"_loss":epoch_loss},**epoch_metrics)
                loop.set_postfix(**epoch_log)

                for name,metric_fn in self.steprunner.metrics_dict.items():
                    metric_fn.reset()
        return epoch_log


def train_model(net, optimizer, loss_fn, metrics_dict, 
                train_data, val_data=None, 
                epochs=10, ckpt_path='checkpoint.pt',
                patience=5, monitor="val_loss", mode="min"):
    
    history = {}

    for epoch in range(1, epochs+1):
        printlog("Epoch {0} / {1}".format(epoch, epochs))

        # 1ï¼Œtrain -------------------------------------------------  
        train_step_runner = StepRunner(net = net,stage="train",
                loss_fn = loss_fn,metrics_dict=deepcopy(metrics_dict),
                optimizer = optimizer)
        train_epoch_runner = EpochRunner(train_step_runner)
        train_metrics = train_epoch_runner(train_data)

        for name, metric in train_metrics.items():
            history[name] = history.get(name, []) + [metric]

        # 2ï¼Œvalidate -------------------------------------------------
        if val_data:
            val_step_runner = StepRunner(net = net,stage="val",
                loss_fn = loss_fn,metrics_dict=deepcopy(metrics_dict))
            val_epoch_runner = EpochRunner(val_step_runner)
            with torch.no_grad():
                val_metrics = val_epoch_runner(val_data)
            val_metrics["epoch"] = epoch
            for name, metric in val_metrics.items():
                history[name] = history.get(name, []) + [metric]

        # 3ï¼Œearly-stopping -------------------------------------------------
        arr_scores = history[monitor]
        best_score_idx = np.argmax(arr_scores) if mode=="max" else np.argmin(arr_scores)
        if best_score_idx==len(arr_scores)-1:
            torch.save(net.state_dict(),ckpt_path)
            print("<<<<<< reach best {0} : {1} >>>>>>".format(monitor,
                 arr_scores[best_score_idx]),file=sys.stderr)
        if len(arr_scores)-best_score_idx>patience:
            print("<<<<<< {} without improvement in {} epoch, early stopping >>>>>>".format(
                monitor,patience),file=sys.stderr)
            break 
        net.load_state_dict(torch.load(ckpt_path))

    return pd.DataFrame(history)

```

```python

```

```python
import torchmetrics 

class Accuracy(torchmetrics.Accuracy):
    def __init__(self, dist_sync_on_step=False):
        super().__init__(dist_sync_on_step=dist_sync_on_step)
        
    def update(self, preds: torch.Tensor, targets: torch.Tensor):
        super().update(torch.sigmoid(preds),targets.long())
            
    def compute(self):
        return super().compute()
    
    
loss_fn = nn.BCEWithLogitsLoss()
optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   
metrics_dict = {"acc":Accuracy()}

dfhistory = train_model(net,
    optimizer,
    loss_fn,
    metrics_dict,
    train_data = dl_train,
    val_data= dl_val,
    epochs=10,
    patience=5,
    monitor="val_acc", 
    mode="max")

```

```
================================================================================2022-07-10 20:06:16
Epoch 1 / 10

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.74it/s, train_acc=0.735, train_loss=0.53]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 20.07it/s, val_acc=0.827, val_loss=0.383]
<<<<<< reach best val_acc : 0.8274999856948853 >>>>>>

================================================================================2022-07-10 20:06:35
Epoch 2 / 10

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:16<00:00, 11.96it/s, train_acc=0.832, train_loss=0.391]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:02<00:00, 18.13it/s, val_acc=0.854, val_loss=0.317]
<<<<<< reach best val_acc : 0.8544999957084656 >>>>>>

================================================================================2022-07-10 20:06:54
Epoch 3 / 10

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.71it/s, train_acc=0.87, train_loss=0.313]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:02<00:00, 19.96it/s, val_acc=0.902, val_loss=0.239]
<<<<<< reach best val_acc : 0.9024999737739563 >>>>>>

================================================================================2022-07-10 20:07:13
Epoch 4 / 10

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:16<00:00, 11.88it/s, train_acc=0.889, train_loss=0.265]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:02<00:00, 18.46it/s, val_acc=0.91, val_loss=0.216]
<<<<<< reach best val_acc : 0.9100000262260437 >>>>>>

================================================================================2022-07-10 20:07:32
Epoch 5 / 10

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.71it/s, train_acc=0.902, train_loss=0.239]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:02<00:00, 19.68it/s, val_acc=0.891, val_loss=0.279]

================================================================================2022-07-10 20:07:51
Epoch 6 / 10

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.75it/s, train_acc=0.915, train_loss=0.212]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:02<00:00, 19.52it/s, val_acc=0.908, val_loss=0.222]

================================================================================2022-07-10 20:08:10
Epoch 7 / 10

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:16<00:00, 11.79it/s, train_acc=0.921, train_loss=0.196]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:02<00:00, 19.26it/s, val_acc=0.929, val_loss=0.187]
<<<<<< reach best val_acc : 0.9294999837875366 >>>>>>

================================================================================2022-07-10 20:08:29
Epoch 8 / 10

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.59it/s, train_acc=0.931, train_loss=0.175]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:02<00:00, 19.91it/s, val_acc=0.938, val_loss=0.187]
<<<<<< reach best val_acc : 0.9375 >>>>>>

================================================================================2022-07-10 20:08:49
Epoch 9 / 10

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.68it/s, train_acc=0.929, train_loss=0.178]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:02<00:00, 19.90it/s, val_acc=0.937, val_loss=0.181]

================================================================================2022-07-10 20:09:08
Epoch 10 / 10

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:16<00:00, 11.84it/s, train_acc=0.937, train_loss=0.16] 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:02<00:00, 19.91it/s, val_acc=0.937, val_loss=0.167]
```

```python

```

### å››ï¼Œè¯„ä¼°æ¨¡å‹

```python
dfhistory 
```

```
train_loss	train_acc	val_loss	val_acc	epoch
0	0.761911	0.6896	0.503468	0.765	1
1	0.500893	0.7627	0.403210	0.830	2
2	0.417750	0.8128	0.328020	0.870	3
3	0.366155	0.8444	0.370906	0.814	4
4	0.364717	0.8428	0.290701	0.876	5
5	0.610342	0.6406	0.693153	0.500	6
6	0.693610	0.4976	0.693386	0.500	7
7	0.693578	0.5046	0.693815	0.500	8
8	0.693735	0.4988	0.693718	0.500	9
9	0.693681	0.4960	0.694350	0.500	10
```

```python

```

```python
%matplotlib inline
%config InlineBackend.figure_format = 'svg'

import matplotlib.pyplot as plt

def plot_metric(dfhistory, metric):
    train_metrics = dfhistory["train_"+metric]
    val_metrics = dfhistory['val_'+metric]
    epochs = range(1, len(train_metrics) + 1)
    plt.plot(epochs, train_metrics, 'bo--')
    plt.plot(epochs, val_metrics, 'ro-')
    plt.title('Training and validation '+ metric)
    plt.xlabel("Epochs")
    plt.ylabel(metric)
    plt.legend(["train_"+metric, 'val_'+metric])
    plt.show()
```

```python
plot_metric(dfhistory,"loss")
```

![](./data/1-2-lossæ›²çº¿.png)

```python
plot_metric(dfhistory,"acc")
```

![](./data/1-2-aucæ›²çº¿.png)

```python

```

### äº”ï¼Œä½¿ç”¨æ¨¡å‹

```python
def predict(net,dl):
    net.eval()
    with torch.no_grad():
        result = nn.Sigmoid()(torch.cat([net.forward(t[0]) for t in dl]))
    return(result.data)
```

```python
#é¢„æµ‹æ¦‚ç‡
y_pred_probs = predict(net,dl_val)
y_pred_probs
```

```
tensor([[3.6409e-03],
        [3.1401e-05],
        [1.4732e-02],
        ...,
        [9.6308e-01],
        [9.9835e-01],
        [7.8825e-01]])
```

```python
#é¢„æµ‹ç±»åˆ«
y_pred = torch.where(y_pred_probs>0.5,
        torch.ones_like(y_pred_probs),torch.zeros_like(y_pred_probs))
y_pred
```

```
tensor([[0.],
        [0.],
        [0.],
        ...,
        [1.],
        [1.],
        [1.]])
```

```python

```

### å…­ï¼Œä¿å­˜æ¨¡å‹


æ¨èä½¿ç”¨ä¿å­˜å‚æ•°æ–¹å¼ä¿å­˜Pytorchæ¨¡å‹ã€‚

```python
print(net.state_dict().keys())
```

```
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias'])
```

```python
# ä¿å­˜æ¨¡å‹å‚æ•°

torch.save(net.state_dict(), "./data/net_parameter.pt")

net_clone = Net()
net_clone.load_state_dict(torch.load("./data/net_parameter.pt"))

predict(net_clone,dl_val)
```

```
tensor([[3.6409e-03],
        [3.1401e-05],
        [1.4732e-02],
        ...,
        [9.6308e-01],
        [9.9835e-01],
        [7.8825e-01]])
```

```python

```

**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)

