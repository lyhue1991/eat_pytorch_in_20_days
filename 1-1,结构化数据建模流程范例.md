# 1-1,ç»“æ„åŒ–æ•°æ®å»ºæ¨¡æµç¨‹èŒƒä¾‹

```python
import os
import datetime

#æ‰“å°æ—¶é—´
def printbar():
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)

#macç³»ç»Ÿä¸Špytorchå’Œmatplotlibåœ¨jupyterä¸­åŒæ—¶è·‘éœ€è¦æ›´æ”¹ç¯å¢ƒå˜é‡
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE" 

```

```python
!pip install torch==1.10.0
!pip install torchkeras==3.2.3
```


```python
import torch 
import torchkeras 
print("torch.__version__ = ", torch.__version__)
print("torchkeras.__version__ = ", torchkeras.__version__) 
```

```
torch.__version__ =  1.10.0
torchkeras.__version__ =  3.2.3
```


<br>

<font color="red">
 
å…¬ä¼—å· **ç®—æ³•ç¾é£Ÿå±‹** å›å¤å…³é”®è¯ï¼š**pytorch**ï¼Œ è·å–æœ¬é¡¹ç›®æºç å’Œæ‰€ç”¨æ•°æ®é›†ç™¾åº¦äº‘ç›˜ä¸‹è½½é“¾æ¥ã€‚
    
</font> 



### ä¸€ï¼Œå‡†å¤‡æ•°æ®


titanicæ•°æ®é›†çš„ç›®æ ‡æ˜¯æ ¹æ®ä¹˜å®¢ä¿¡æ¯é¢„æµ‹ä»–ä»¬åœ¨Titanicå·æ’å‡»å†°å±±æ²‰æ²¡åèƒ½å¦ç”Ÿå­˜ã€‚

ç»“æ„åŒ–æ•°æ®ä¸€èˆ¬ä¼šä½¿ç”¨Pandasä¸­çš„DataFrameè¿›è¡Œé¢„å¤„ç†ã€‚


```python
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import torch 
from torch import nn 
from torch.utils.data import Dataset,DataLoader,TensorDataset

dftrain_raw = pd.read_csv('./eat_pytorch_datasets/titanic/train.csv')
dftest_raw = pd.read_csv('./eat_pytorch_datasets/titanic/test.csv')
dftrain_raw.head(10)

```

![](./data/1-1-æ•°æ®é›†å±•ç¤º.jpg)


å­—æ®µè¯´æ˜ï¼š

* Survived:0ä»£è¡¨æ­»äº¡ï¼Œ1ä»£è¡¨å­˜æ´»ã€yæ ‡ç­¾ã€‘
* Pclass:ä¹˜å®¢æ‰€æŒç¥¨ç±»ï¼Œæœ‰ä¸‰ç§å€¼(1,2,3) ã€è½¬æ¢æˆonehotç¼–ç ã€‘
* Name:ä¹˜å®¢å§“å ã€èˆå»ã€‘
* Sex:ä¹˜å®¢æ€§åˆ« ã€è½¬æ¢æˆboolç‰¹å¾ã€‘
* Age:ä¹˜å®¢å¹´é¾„(æœ‰ç¼ºå¤±) ã€æ•°å€¼ç‰¹å¾ï¼Œæ·»åŠ â€œå¹´é¾„æ˜¯å¦ç¼ºå¤±â€ä½œä¸ºè¾…åŠ©ç‰¹å¾ã€‘
* SibSp:ä¹˜å®¢å…„å¼Ÿå§å¦¹/é…å¶çš„ä¸ªæ•°(æ•´æ•°å€¼) ã€æ•°å€¼ç‰¹å¾ã€‘
* Parch:ä¹˜å®¢çˆ¶æ¯/å­©å­çš„ä¸ªæ•°(æ•´æ•°å€¼)ã€æ•°å€¼ç‰¹å¾ã€‘
* Ticket:ç¥¨å·(å­—ç¬¦ä¸²)ã€èˆå»ã€‘
* Fare:ä¹˜å®¢æ‰€æŒç¥¨çš„ä»·æ ¼(æµ®ç‚¹æ•°ï¼Œ0-500ä¸ç­‰) ã€æ•°å€¼ç‰¹å¾ã€‘
* Cabin:ä¹˜å®¢æ‰€åœ¨èˆ¹èˆ±(æœ‰ç¼ºå¤±) ã€æ·»åŠ â€œæ‰€åœ¨èˆ¹èˆ±æ˜¯å¦ç¼ºå¤±â€ä½œä¸ºè¾…åŠ©ç‰¹å¾ã€‘
* Embarked:ä¹˜å®¢ç™»èˆ¹æ¸¯å£:Sã€Cã€Q(æœ‰ç¼ºå¤±)ã€è½¬æ¢æˆonehotç¼–ç ï¼Œå››ç»´åº¦ S,C,Q,nanã€‘



åˆ©ç”¨Pandasçš„æ•°æ®å¯è§†åŒ–åŠŸèƒ½æˆ‘ä»¬å¯ä»¥ç®€å•åœ°è¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æEDAï¼ˆExploratory Data Analysisï¼‰ã€‚

labelåˆ†å¸ƒæƒ…å†µ

```python
%matplotlib inline
%config InlineBackend.figure_format = 'png'
ax = dftrain_raw['Survived'].value_counts().plot(kind = 'bar',
     figsize = (12,8),fontsize=15,rot = 0)
ax.set_ylabel('Counts',fontsize = 15)
ax.set_xlabel('Survived',fontsize = 15)
plt.show()

```

![](./data/1-1-Labelåˆ†å¸ƒ.jpg)


å¹´é¾„åˆ†å¸ƒæƒ…å†µ

```python
%matplotlib inline
%config InlineBackend.figure_format = 'png'
ax = dftrain_raw['Age'].plot(kind = 'hist',bins = 20,color= 'purple',
                    figsize = (12,8),fontsize=15)

ax.set_ylabel('Frequency',fontsize = 15)
ax.set_xlabel('Age',fontsize = 15)
plt.show()

```

![](./data/1-1-å¹´é¾„åˆ†å¸ƒ.jpg)


å¹´é¾„å’Œlabelçš„ç›¸å…³æ€§

```python
%matplotlib inline
%config InlineBackend.figure_format = 'png'
ax = dftrain_raw.query('Survived == 0')['Age'].plot(kind = 'density',
                      figsize = (12,8),fontsize=15)
dftrain_raw.query('Survived == 1')['Age'].plot(kind = 'density',
                      figsize = (12,8),fontsize=15)
ax.legend(['Survived==0','Survived==1'],fontsize = 12)
ax.set_ylabel('Density',fontsize = 15)
ax.set_xlabel('Age',fontsize = 15)
plt.show()
```

![](./data/1-1-å¹´é¾„ç›¸å…³æ€§.jpg)


ä¸‹é¢ä¸ºæ­£å¼çš„æ•°æ®é¢„å¤„ç†

```python
def preprocessing(dfdata):

    dfresult= pd.DataFrame()

    #Pclass
    dfPclass = pd.get_dummies(dfdata['Pclass'])
    dfPclass.columns = ['Pclass_' +str(x) for x in dfPclass.columns ]
    dfresult = pd.concat([dfresult,dfPclass],axis = 1)

    #Sex
    dfSex = pd.get_dummies(dfdata['Sex'])
    dfresult = pd.concat([dfresult,dfSex],axis = 1)

    #Age
    dfresult['Age'] = dfdata['Age'].fillna(0)
    dfresult['Age_null'] = pd.isna(dfdata['Age']).astype('int32')

    #SibSp,Parch,Fare
    dfresult['SibSp'] = dfdata['SibSp']
    dfresult['Parch'] = dfdata['Parch']
    dfresult['Fare'] = dfdata['Fare']

    #Carbin
    dfresult['Cabin_null'] =  pd.isna(dfdata['Cabin']).astype('int32')

    #Embarked
    dfEmbarked = pd.get_dummies(dfdata['Embarked'],dummy_na=True)
    dfEmbarked.columns = ['Embarked_' + str(x) for x in dfEmbarked.columns]
    dfresult = pd.concat([dfresult,dfEmbarked],axis = 1)

    return(dfresult)

x_train = preprocessing(dftrain_raw).values
y_train = dftrain_raw[['Survived']].values

x_test = preprocessing(dftest_raw).values
y_test = dftest_raw[['Survived']].values

print("x_train.shape =", x_train.shape )
print("x_test.shape =", x_test.shape )

print("y_train.shape =", y_train.shape )
print("y_test.shape =", y_test.shape )

```

```
x_train.shape = (712, 15)
x_test.shape = (179, 15)
y_train.shape = (712, 1)
y_test.shape = (179, 1)
```


è¿›ä¸€æ­¥ä½¿ç”¨DataLoaderå’ŒTensorDatasetå°è£…æˆå¯ä»¥è¿­ä»£çš„æ•°æ®ç®¡é“ã€‚

```python
dl_train = DataLoader(TensorDataset(torch.tensor(x_train).float(),torch.tensor(y_train).float()),
                     shuffle = True, batch_size = 8)
dl_val = DataLoader(TensorDataset(torch.tensor(x_test).float(),torch.tensor(y_test).float()),
                     shuffle = False, batch_size = 8)

```

```python
# æµ‹è¯•æ•°æ®ç®¡é“
for features,labels in dl_train:
    print(features,labels)
    break
```

```
tensor([[  0.0000,   0.0000,   1.0000,   0.0000,   1.0000,   0.0000,   1.0000,
           0.0000,   0.0000,   7.8958,   1.0000,   0.0000,   0.0000,   1.0000,
           0.0000],
        [  1.0000,   0.0000,   0.0000,   0.0000,   1.0000,   0.0000,   1.0000,
           0.0000,   0.0000,  30.5000,   0.0000,   0.0000,   0.0000,   1.0000,
           0.0000],
        [  1.0000,   0.0000,   0.0000,   1.0000,   0.0000,  31.0000,   0.0000,
           1.0000,   0.0000, 113.2750,   0.0000,   1.0000,   0.0000,   0.0000,
           0.0000],
        [  1.0000,   0.0000,   0.0000,   0.0000,   1.0000,  60.0000,   0.0000,
           0.0000,   0.0000,  26.5500,   1.0000,   0.0000,   0.0000,   1.0000,
           0.0000],
        [  0.0000,   0.0000,   1.0000,   0.0000,   1.0000,  28.0000,   0.0000,
           0.0000,   0.0000,  22.5250,   1.0000,   0.0000,   0.0000,   1.0000,
           0.0000],
        [  0.0000,   0.0000,   1.0000,   0.0000,   1.0000,  32.0000,   0.0000,
           0.0000,   0.0000,   8.3625,   1.0000,   0.0000,   0.0000,   1.0000,
           0.0000],
        [  0.0000,   1.0000,   0.0000,   1.0000,   0.0000,  28.0000,   0.0000,
           0.0000,   0.0000,  13.0000,   1.0000,   0.0000,   0.0000,   1.0000,
           0.0000],
        [  1.0000,   0.0000,   0.0000,   0.0000,   1.0000,  36.0000,   0.0000,
           0.0000,   1.0000, 512.3292,   0.0000,   1.0000,   0.0000,   0.0000,
           0.0000]]) tensor([[0.],
        [1.],
        [1.],
        [0.],
        [0.],
        [0.],
        [1.],
        [1.]])
```

```python

```

### äºŒï¼Œå®šä¹‰æ¨¡å‹


ä½¿ç”¨Pytorché€šå¸¸æœ‰ä¸‰ç§æ–¹å¼æ„å»ºæ¨¡å‹ï¼šä½¿ç”¨nn.SequentialæŒ‰å±‚é¡ºåºæ„å»ºæ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºè‡ªå®šä¹‰æ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºæ¨¡å‹å¹¶è¾…åŠ©åº”ç”¨æ¨¡å‹å®¹å™¨è¿›è¡Œå°è£…ã€‚

æ­¤å¤„é€‰æ‹©ä½¿ç”¨æœ€ç®€å•çš„nn.Sequentialï¼ŒæŒ‰å±‚é¡ºåºæ¨¡å‹ã€‚

```python
def create_net():
    net = nn.Sequential()
    net.add_module("linear1",nn.Linear(15,20))
    net.add_module("relu1",nn.ReLU())
    net.add_module("linear2",nn.Linear(20,15))
    net.add_module("relu2",nn.ReLU())
    net.add_module("linear3",nn.Linear(15,1))
    return net
    
net = create_net()
print(net)
```

```python

```

### ä¸‰ï¼Œè®­ç»ƒæ¨¡å‹


Pytorché€šå¸¸éœ€è¦ç”¨æˆ·ç¼–å†™è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼Œè®­ç»ƒå¾ªç¯çš„ä»£ç é£æ ¼å› äººè€Œå¼‚ã€‚

æœ‰3ç±»å…¸å‹çš„è®­ç»ƒå¾ªç¯ä»£ç é£æ ¼ï¼šè„šæœ¬å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œå‡½æ•°å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œç±»å½¢å¼è®­ç»ƒå¾ªç¯ã€‚

æ­¤å¤„ä»‹ç»ä¸€ç§è¾ƒé€šç”¨çš„ä»¿ç…§Kerasé£æ ¼çš„è„šæœ¬å½¢å¼çš„è®­ç»ƒå¾ªç¯ã€‚

è¯¥è„šæœ¬å½¢å¼çš„è®­ç»ƒä»£ç ä¸ torchkeras åº“çš„æ ¸å¿ƒä»£ç åŸºæœ¬ä¸€è‡´ã€‚

torchkerasè¯¦æƒ…:  https://github.com/lyhue1991/torchkeras 


```python
import os,sys,time
import numpy as np
import pandas as pd
import datetime 
from tqdm import tqdm 

import torch
from torch import nn 
from copy import deepcopy
from torchkeras.metrics import Accuracy


def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(str(info)+"\n")
    

loss_fn = nn.BCEWithLogitsLoss()
optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   
metrics_dict = {"acc":Accuracy()}

epochs = 20 
ckpt_path='checkpoint.pt'

#early_stoppingç›¸å…³è®¾ç½®
monitor="val_acc"
patience=5
mode="max"

history = {}

for epoch in range(1, epochs+1):
    printlog("Epoch {0} / {1}".format(epoch, epochs))

    # 1ï¼Œtrain -------------------------------------------------  
    net.train()
    
    total_loss,step = 0,0
    
    loop = tqdm(enumerate(dl_train), total =len(dl_train))
    train_metrics_dict = deepcopy(metrics_dict) 
    
    for i, batch in loop: 
        
        features,labels = batch
        #forward
        preds = net(features)
        loss = loss_fn(preds,labels)
        
        #backward
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
            
        #metrics
        step_metrics = {"train_"+name:metric_fn(preds, labels).item() 
                        for name,metric_fn in train_metrics_dict.items()}
        
        step_log = dict({"train_loss":loss.item()},**step_metrics)

        total_loss += loss.item()
        
        step+=1
        if i!=len(dl_train)-1:
            loop.set_postfix(**step_log)
        else:
            epoch_loss = total_loss/step
            epoch_metrics = {"train_"+name:metric_fn.compute().item() 
                             for name,metric_fn in train_metrics_dict.items()}
            epoch_log = dict({"train_loss":epoch_loss},**epoch_metrics)
            loop.set_postfix(**epoch_log)

            for name,metric_fn in train_metrics_dict.items():
                metric_fn.reset()
                
    for name, metric in epoch_log.items():
        history[name] = history.get(name, []) + [metric]
        

    # 2ï¼Œvalidate -------------------------------------------------
    net.eval()
    
    total_loss,step = 0,0
    loop = tqdm(enumerate(dl_val), total =len(dl_val))
    
    val_metrics_dict = deepcopy(metrics_dict) 
    
    with torch.no_grad():
        for i, batch in loop: 

            features,labels = batch
            
            #forward
            preds = net(features)
            loss = loss_fn(preds,labels)

            #metrics
            step_metrics = {"val_"+name:metric_fn(preds, labels).item() 
                            for name,metric_fn in val_metrics_dict.items()}

            step_log = dict({"val_loss":loss.item()},**step_metrics)

            total_loss += loss.item()
            step+=1
            if i!=len(dl_val)-1:
                loop.set_postfix(**step_log)
            else:
                epoch_loss = (total_loss/step)
                epoch_metrics = {"val_"+name:metric_fn.compute().item() 
                                 for name,metric_fn in val_metrics_dict.items()}
                epoch_log = dict({"val_loss":epoch_loss},**epoch_metrics)
                loop.set_postfix(**epoch_log)

                for name,metric_fn in val_metrics_dict.items():
                    metric_fn.reset()
                    
    epoch_log["epoch"] = epoch           
    for name, metric in epoch_log.items():
        history[name] = history.get(name, []) + [metric]

    # 3ï¼Œearly-stopping -------------------------------------------------
    arr_scores = history[monitor]
    best_score_idx = np.argmax(arr_scores) if mode=="max" else np.argmin(arr_scores)
    if best_score_idx==len(arr_scores)-1:
        torch.save(net.state_dict(),ckpt_path)
        print("<<<<<< reach best {0} : {1} >>>>>>".format(monitor,
             arr_scores[best_score_idx]),file=sys.stderr)
    if len(arr_scores)-best_score_idx>patience:
        print("<<<<<< {} without improvement in {} epoch, early stopping >>>>>>".format(
            monitor,patience),file=sys.stderr)
        break 
    net.load_state_dict(torch.load(ckpt_path))
    
dfhistory = pd.DataFrame(history)

```

```
================================================================================2022-07-10 21:55:18
Epoch 1 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 192.16it/s, train_acc=0.664, train_loss=0.646]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 252.37it/s, val_acc=0.721, val_loss=0.571]
<<<<<< reach best val_acc : 0.7206704020500183 >>>>>>

================================================================================2022-07-10 21:55:19
Epoch 2 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 212.44it/s, train_acc=0.725, train_loss=0.576]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 183.68it/s, val_acc=0.726, val_loss=0.503]
<<<<<< reach best val_acc : 0.7262569665908813 >>>>>>

================================================================================2022-07-10 21:55:19
Epoch 3 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 128.57it/s, train_acc=0.772, train_loss=0.517]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 195.21it/s, val_acc=0.782, val_loss=0.445]
<<<<<< reach best val_acc : 0.7821229100227356 >>>>>>

================================================================================2022-07-10 21:55:20
Epoch 4 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 139.91it/s, train_acc=0.784, train_loss=0.495]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 281.71it/s, val_acc=0.793, val_loss=0.435]
<<<<<< reach best val_acc : 0.7932960987091064 >>>>>>

================================================================================2022-07-10 21:55:21
Epoch 5 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 216.33it/s, train_acc=0.788, train_loss=0.493]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 246.54it/s, val_acc=0.81, val_loss=0.409]
<<<<<< reach best val_acc : 0.8100558519363403 >>>>>>

================================================================================2022-07-10 21:55:21
Epoch 6 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 191.69it/s, train_acc=0.765, train_loss=0.481]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 251.35it/s, val_acc=0.777, val_loss=0.436]

================================================================================2022-07-10 21:55:22
Epoch 7 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 192.42it/s, train_acc=0.781, train_loss=0.493]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 241.61it/s, val_acc=0.771, val_loss=0.462]

================================================================================2022-07-10 21:55:22
Epoch 8 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 211.52it/s, train_acc=0.801, train_loss=0.475]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 263.07it/s, val_acc=0.793, val_loss=0.406]

================================================================================2022-07-10 21:55:23
Epoch 9 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 199.20it/s, train_acc=0.798, train_loss=0.444]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 265.92it/s, val_acc=0.782, val_loss=0.43]

================================================================================2022-07-10 21:55:23
Epoch 10 / 20

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<00:00, 193.12it/s, train_acc=0.81, train_loss=0.445] 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 259.94it/s, val_acc=0.771, val_loss=0.506]
<<<<<< val_acc without improvement in 5 epoch, early stopping >>>>>>

```

```python

```

```python

```

### å››ï¼Œè¯„ä¼°æ¨¡å‹


æˆ‘ä»¬é¦–å…ˆè¯„ä¼°ä¸€ä¸‹æ¨¡å‹åœ¨è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸Šçš„æ•ˆæœã€‚

```python
dfhistory 
```

![](./data/1-1-dfhistory.png)

```python
%matplotlib inline
%config InlineBackend.figure_format = 'svg'

import matplotlib.pyplot as plt

def plot_metric(dfhistory, metric):
    train_metrics = dfhistory["train_"+metric]
    val_metrics = dfhistory['val_'+metric]
    epochs = range(1, len(train_metrics) + 1)
    plt.plot(epochs, train_metrics, 'bo--')
    plt.plot(epochs, val_metrics, 'ro-')
    plt.title('Training and validation '+ metric)
    plt.xlabel("Epochs")
    plt.ylabel(metric)
    plt.legend(["train_"+metric, 'val_'+metric])
    plt.show()
```

```python
plot_metric(dfhistory,"loss")
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h426f4kjqfj20fy0a9q3a.jpg)


```python
plot_metric(dfhistory,"acc")
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h426dvo2upj20fy0a9t92.jpg)

```python

```

```python

```

### äº”ï¼Œä½¿ç”¨æ¨¡å‹

```python
#é¢„æµ‹æ¦‚ç‡

y_pred_probs = torch.sigmoid(net(torch.tensor(x_test[0:10]).float())).data
y_pred_probs
```

```
tensor([[0.1146],
        [0.6517],
        [0.4307],
        [0.8692],
        [0.5542],
        [0.7894],
        [0.1096],
        [0.7125],
        [0.6027],
        [0.1139]])
```

```python
#é¢„æµ‹ç±»åˆ«
y_pred = torch.where(y_pred_probs>0.5,
        torch.ones_like(y_pred_probs),torch.zeros_like(y_pred_probs))
y_pred
```

```
tensor([[0.],
        [1.],
        [0.],
        [1.],
        [1.],
        [1.],
        [0.],
        [1.],
        [1.],
        [0.]])
```

```python

```

### å…­ï¼Œä¿å­˜æ¨¡å‹


Pytorch æœ‰ä¸¤ç§ä¿å­˜æ¨¡å‹çš„æ–¹å¼ï¼Œéƒ½æ˜¯é€šè¿‡è°ƒç”¨pickleåºåˆ—åŒ–æ–¹æ³•å®ç°çš„ã€‚

ç¬¬ä¸€ç§æ–¹æ³•åªä¿å­˜æ¨¡å‹å‚æ•°ã€‚

ç¬¬äºŒç§æ–¹æ³•ä¿å­˜å®Œæ•´æ¨¡å‹ã€‚

æ¨èä½¿ç”¨ç¬¬ä¸€ç§ï¼Œç¬¬äºŒç§æ–¹æ³•å¯èƒ½åœ¨åˆ‡æ¢è®¾å¤‡å’Œç›®å½•çš„æ—¶å€™å‡ºç°å„ç§é—®é¢˜ã€‚



**1ï¼Œä¿å­˜æ¨¡å‹å‚æ•°(æ¨è)**

```python
print(net.state_dict().keys())
```

```
odict_keys(['linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias', 'linear3.weight', 'linear3.bias'])
```

```python
# ä¿å­˜æ¨¡å‹å‚æ•°

torch.save(net.state_dict(), "./data/net_parameter.pt")

net_clone = create_net()
net_clone.load_state_dict(torch.load("./data/net_parameter.pt"))

torch.sigmoid(net_clone.forward(torch.tensor(x_test[0:10]).float())).data

```

```
tensor([[0.1146],
        [0.6517],
        [0.4307],
        [0.8692],
        [0.5542],
        [0.7894],
        [0.1096],
        [0.7125],
        [0.6027],
        [0.1139]])
```

```python

```

**2ï¼Œä¿å­˜å®Œæ•´æ¨¡å‹(ä¸æ¨è)**

```python

torch.save(net, './data/net_model.pt')
net_loaded = torch.load('./data/net_model.pt')
torch.sigmoid(net_loaded(torch.tensor(x_test[0:10]).float())).data

```

```
tensor([[0.1146],
        [0.6517],
        [0.4307],
        [0.8692],
        [0.5542],
        [0.7894],
        [0.1096],
        [0.7125],
        [0.6027],
        [0.1139]])
```

```python

```

**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)

```python

```
