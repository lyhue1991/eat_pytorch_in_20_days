{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca7bf1c",
   "metadata": {},
   "source": [
    "\n",
    "# 6-3,ä½¿ç”¨GPUè®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadcb375",
   "metadata": {},
   "source": [
    "æ·±åº¦å­¦ä¹ çš„è®­ç»ƒè¿‡ç¨‹å¸¸å¸¸éå¸¸è€—æ—¶ï¼Œä¸€ä¸ªæ¨¡å‹è®­ç»ƒå‡ ä¸ªå°æ—¶æ˜¯å®¶å¸¸ä¾¿é¥­ï¼Œè®­ç»ƒå‡ å¤©ä¹Ÿæ˜¯å¸¸æœ‰çš„äº‹æƒ…ï¼Œæœ‰æ—¶å€™ç”šè‡³è¦è®­ç»ƒå‡ åå¤©ã€‚\n",
    "\n",
    "è®­ç»ƒè¿‡ç¨‹çš„è€—æ—¶ä¸»è¦æ¥è‡ªäºä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†æ¥è‡ªæ•°æ®å‡†å¤‡ï¼Œå¦ä¸€éƒ¨åˆ†æ¥è‡ªå‚æ•°è¿­ä»£ã€‚\n",
    "\n",
    "å½“æ•°æ®å‡†å¤‡è¿‡ç¨‹è¿˜æ˜¯æ¨¡å‹è®­ç»ƒæ—¶é—´çš„ä¸»è¦ç“¶é¢ˆæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ›´å¤šè¿›ç¨‹æ¥å‡†å¤‡æ•°æ®ã€‚\n",
    "\n",
    "å½“å‚æ•°è¿­ä»£è¿‡ç¨‹æˆä¸ºè®­ç»ƒæ—¶é—´çš„ä¸»è¦ç“¶é¢ˆæ—¶ï¼Œæˆ‘ä»¬é€šå¸¸çš„æ–¹æ³•æ˜¯åº”ç”¨GPUæ¥è¿›è¡ŒåŠ é€Ÿã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14993aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchkeras \n",
    "\n",
    "print(\"torch.__version__ = \",torch.__version__)\n",
    "print(\"torchkeras.__version__ = \",torchkeras.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67c1c4c",
   "metadata": {},
   "source": [
    "æ³¨ï¼šæœ¬èŠ‚ä»£ç åªèƒ½åœ¨æœ‰GPUçš„æœºå™¨ç¯å¢ƒä¸Šæ‰èƒ½æ­£ç¡®æ‰§è¡Œã€‚\n",
    "\n",
    "å¯¹äºæ²¡æœ‰GPUçš„åŒå­¦ï¼Œæ¨èä½¿ç”¨kaggleå¹³å°ä¸Šçš„GPUã€‚\n",
    "\n",
    "\n",
    "å¯ç‚¹å‡»å¦‚ä¸‹é“¾æ¥ï¼Œç›´æ¥åœ¨kaggleä¸­è¿è¡ŒèŒƒä¾‹ä»£ç ã€‚\n",
    "\n",
    "https://www.kaggle.com/lyhue1991/pytorch-gpu-examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed179b3",
   "metadata": {},
   "source": [
    "Pytorchä¸­ä½¿ç”¨GPUåŠ é€Ÿæ¨¡å‹éå¸¸ç®€å•ï¼Œåªè¦å°†æ¨¡å‹å’Œæ•°æ®ç§»åŠ¨åˆ°GPUä¸Šã€‚æ ¸å¿ƒä»£ç åªæœ‰ä»¥ä¸‹å‡ è¡Œã€‚\n",
    "\n",
    "```python\n",
    "# å®šä¹‰æ¨¡å‹\n",
    "... \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # ç§»åŠ¨æ¨¡å‹åˆ°cuda\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "...\n",
    "\n",
    "features = features.to(device) # ç§»åŠ¨æ•°æ®åˆ°cuda\n",
    "labels = labels.to(device) # æˆ–è€…  labels = labels.cuda() if torch.cuda.is_available() else labels\n",
    "...\n",
    "```\n",
    "\n",
    "å¦‚æœè¦ä½¿ç”¨å¤šä¸ªGPUè®­ç»ƒæ¨¡å‹ï¼Œä¹Ÿéå¸¸ç®€å•ã€‚åªéœ€è¦åœ¨å°†æ¨¡å‹è®¾ç½®ä¸ºæ•°æ®å¹¶è¡Œé£æ ¼æ¨¡å‹ã€‚\n",
    "åˆ™æ¨¡å‹ç§»åŠ¨åˆ°GPUä¸Šä¹‹åï¼Œä¼šåœ¨æ¯ä¸€ä¸ªGPUä¸Šæ‹·è´ä¸€ä¸ªå‰¯æœ¬ï¼Œå¹¶æŠŠæ•°æ®å¹³åˆ†åˆ°å„ä¸ªGPUä¸Šè¿›è¡Œè®­ç»ƒã€‚æ ¸å¿ƒä»£ç å¦‚ä¸‹ã€‚\n",
    "\n",
    "```python\n",
    "# å®šä¹‰æ¨¡å‹\n",
    "... \n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model) # åŒ…è£…ä¸ºå¹¶è¡Œé£æ ¼æ¨¡å‹\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "...\n",
    "features = features.to(device) # ç§»åŠ¨æ•°æ®åˆ°cuda\n",
    "labels = labels.to(device) # æˆ–è€… labels = labels.cuda() if torch.cuda.is_available() else labels\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa2354a",
   "metadata": {},
   "source": [
    "## ã€‡ï¼ŒGPUç›¸å…³æ“ä½œæ±‡æ€»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f0023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "# 1ï¼ŒæŸ¥çœ‹gpuä¿¡æ¯\n",
    "if_cuda = torch.cuda.is_available()\n",
    "print(\"if_cuda=\",if_cuda)\n",
    "\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(\"gpu_count=\",gpu_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ï¼Œå°†å¼ é‡åœ¨gpuå’Œcpué—´ç§»åŠ¨\n",
    "tensor = torch.rand((100,100))\n",
    "tensor_gpu = tensor.to(\"cuda:0\") # æˆ–è€… tensor_gpu = tensor.cuda()\n",
    "print(tensor_gpu.device)\n",
    "print(tensor_gpu.is_cuda)\n",
    "\n",
    "tensor_cpu = tensor_gpu.to(\"cpu\") # æˆ–è€… tensor_cpu = tensor_gpu.cpu() \n",
    "print(tensor_cpu.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa73c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ï¼Œå°†æ¨¡å‹ä¸­çš„å…¨éƒ¨å¼ é‡ç§»åŠ¨åˆ°gpuä¸Š\n",
    "net = nn.Linear(2,1)\n",
    "print(next(net.parameters()).is_cuda)\n",
    "net.to(\"cuda:0\") # å°†æ¨¡å‹ä¸­çš„å…¨éƒ¨å‚æ•°å¼ é‡ä¾æ¬¡åˆ°GPUä¸Šï¼Œæ³¨æ„ï¼Œæ— éœ€é‡æ–°èµ‹å€¼ä¸º net = net.to(\"cuda:0\")\n",
    "print(next(net.parameters()).is_cuda)\n",
    "print(next(net.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029cd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ï¼Œåˆ›å»ºæ”¯æŒå¤šä¸ªgpuæ•°æ®å¹¶è¡Œçš„æ¨¡å‹\n",
    "linear = nn.Linear(2,1)\n",
    "print(next(linear.parameters()).device)\n",
    "\n",
    "model = nn.DataParallel(linear)\n",
    "print(model.device_ids)\n",
    "print(next(model.module.parameters()).device) \n",
    "\n",
    "#æ³¨æ„ä¿å­˜å‚æ•°æ—¶è¦æŒ‡å®šä¿å­˜model.moduleçš„å‚æ•°\n",
    "torch.save(model.module.state_dict(), \"model_parameter.pt\") \n",
    "\n",
    "linear = nn.Linear(2,1)\n",
    "linear.load_state_dict(torch.load(\"model_parameter.pt\")) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dde858",
   "metadata": {},
   "source": [
    "## ä¸€ï¼ŒçŸ©é˜µä¹˜æ³•èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f750b06",
   "metadata": {},
   "source": [
    "ä¸‹é¢åˆ†åˆ«ä½¿ç”¨CPUå’ŒGPUä½œä¸€ä¸ªçŸ©é˜µä¹˜æ³•ï¼Œå¹¶æ¯”è¾ƒå…¶è®¡ç®—æ•ˆç‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a729766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨cpu\n",
    "a = torch.rand((10000,200))\n",
    "b = torch.rand((200,10000))\n",
    "tic = time.time()\n",
    "c = torch.matmul(a,b)\n",
    "toc = time.time()\n",
    "\n",
    "print(toc-tic)\n",
    "print(a.device)\n",
    "print(b.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "a = torch.rand((10000,200),device = device) #å¯ä»¥æŒ‡å®šåœ¨GPUä¸Šåˆ›å»ºå¼ é‡\n",
    "b = torch.rand((200,10000)) #ä¹Ÿå¯ä»¥åœ¨CPUä¸Šåˆ›å»ºå¼ é‡åç§»åŠ¨åˆ°GPUä¸Š\n",
    "b = b.to(device) #æˆ–è€… b = b.cuda() if torch.cuda.is_available() else b \n",
    "tic = time.time()\n",
    "c = torch.matmul(a,b)\n",
    "toc = time.time()\n",
    "print(toc-tic)\n",
    "print(a.device)\n",
    "print(b.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa7654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1babcdf5",
   "metadata": {},
   "source": [
    "## äºŒï¼Œçº¿æ€§å›å½’èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7b1e8",
   "metadata": {},
   "source": [
    "ä¸‹é¢å¯¹æ¯”ä½¿ç”¨CPUå’ŒGPUè®­ç»ƒä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹çš„æ•ˆç‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77c320",
   "metadata": {},
   "source": [
    "### 1ï¼Œä½¿ç”¨CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfecdb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡†å¤‡æ•°æ®\n",
    "n = 1000000 #æ ·æœ¬æ•°é‡\n",
    "\n",
    "X = 10*torch.rand([n,2])-5.0  #torch.randæ˜¯å‡åŒ€åˆ†å¸ƒ \n",
    "w0 = torch.tensor([[2.0,-3.0]])\n",
    "b0 = torch.tensor([[10.0]])\n",
    "Y = X@w0.t() + b0 + torch.normal( 0.0,2.0,size = [n,1])  # @è¡¨ç¤ºçŸ©é˜µä¹˜æ³•,å¢åŠ æ­£æ€æ‰°åŠ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add72b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æ¨¡å‹\n",
    "class LinearRegression(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.randn_like(w0))\n",
    "        self.b = nn.Parameter(torch.zeros_like(b0))\n",
    "    #æ­£å‘ä¼ æ’­\n",
    "    def forward(self,x): \n",
    "        return x@self.w.t() + self.b\n",
    "        \n",
    "linear = LinearRegression() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091eef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒæ¨¡å‹\n",
    "optimizer = torch.optim.Adam(linear.parameters(),lr = 0.1)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def train(epoches):\n",
    "    tic = time.time()\n",
    "    for epoch in range(epoches):\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = linear(X) \n",
    "        loss = loss_fn(Y_pred,Y)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        if epoch%50==0:\n",
    "            print({\"epoch\":epoch,\"loss\":loss.item()})\n",
    "    toc = time.time()\n",
    "    print(\"time used:\",toc-tic)\n",
    "\n",
    "train(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0099bc25",
   "metadata": {},
   "source": [
    "### 2ï¼Œä½¿ç”¨GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡†å¤‡æ•°æ®\n",
    "n = 1000000 #æ ·æœ¬æ•°é‡\n",
    "\n",
    "X = 10*torch.rand([n,2])-5.0  #torch.randæ˜¯å‡åŒ€åˆ†å¸ƒ \n",
    "w0 = torch.tensor([[2.0,-3.0]])\n",
    "b0 = torch.tensor([[10.0]])\n",
    "Y = X@w0.t() + b0 + torch.normal( 0.0,2.0,size = [n,1])  # @è¡¨ç¤ºçŸ©é˜µä¹˜æ³•,å¢åŠ æ­£æ€æ‰°åŠ¨\n",
    "\n",
    "# æ•°æ®ç§»åŠ¨åˆ°GPUä¸Š\n",
    "print(\"torch.cuda.is_available() = \",torch.cuda.is_available())\n",
    "X = X.cuda()\n",
    "Y = Y.cuda()\n",
    "print(\"X.device:\",X.device)\n",
    "print(\"Y.device:\",Y.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f368c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æ¨¡å‹\n",
    "class LinearRegression(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.randn_like(w0))\n",
    "        self.b = nn.Parameter(torch.zeros_like(b0))\n",
    "    #æ­£å‘ä¼ æ’­\n",
    "    def forward(self,x): \n",
    "        return x@self.w.t() + self.b\n",
    "        \n",
    "linear = LinearRegression() \n",
    "\n",
    "# ç§»åŠ¨æ¨¡å‹åˆ°GPUä¸Š\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "linear.to(device)\n",
    "\n",
    "#æŸ¥çœ‹æ¨¡å‹æ˜¯å¦å·²ç»ç§»åŠ¨åˆ°GPUä¸Š\n",
    "print(\"if on cuda:\",next(linear.parameters()).is_cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46296b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒæ¨¡å‹\n",
    "optimizer = torch.optim.Adam(linear.parameters(),lr = 0.1)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def train(epoches):\n",
    "    tic = time.time()\n",
    "    for epoch in range(epoches):\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = linear(X) \n",
    "        loss = loss_fn(Y_pred,Y)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        if epoch%50==0:\n",
    "            print({\"epoch\":epoch,\"loss\":loss.item()})\n",
    "    toc = time.time()\n",
    "    print(\"time used:\",toc-tic)\n",
    "    \n",
    "train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921a4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "978fdb3f",
   "metadata": {},
   "source": [
    "## ä¸‰ï¼Œå›¾ç‰‡åˆ†ç±»èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "import torchvision \n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "ds_train = torchvision.datasets.MNIST(root=\"minist/\",train=True,download=True,transform=transform)\n",
    "ds_val = torchvision.datasets.MNIST(root=\"minist/\",train=False,download=True,transform=transform)\n",
    "\n",
    "dl_train =  torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=4)\n",
    "dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "print(len(ds_train))\n",
    "print(len(ds_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c17ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net():\n",
    "    net = nn.Sequential()\n",
    "    net.add_module(\"conv1\",nn.Conv2d(in_channels=1,out_channels=32,kernel_size = 3))\n",
    "    net.add_module(\"pool1\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"conv2\",nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5))\n",
    "    net.add_module(\"pool2\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"dropout\",nn.Dropout2d(p = 0.1))\n",
    "    net.add_module(\"adaptive_pool\",nn.AdaptiveMaxPool2d((1,1)))\n",
    "    net.add_module(\"flatten\",nn.Flatten())\n",
    "    net.add_module(\"linear1\",nn.Linear(64,32))\n",
    "    net.add_module(\"relu\",nn.ReLU())\n",
    "    net.add_module(\"linear2\",nn.Linear(32,10))\n",
    "    return net\n",
    "\n",
    "net = create_net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93868ff",
   "metadata": {},
   "source": [
    "### 1ï¼Œä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323629db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "from copy import deepcopy\n",
    "from torchmetrics import Accuracy\n",
    "#æ³¨ï¼šå¤šåˆ†ç±»ä½¿ç”¨torchmetricsä¸­çš„è¯„ä¼°æŒ‡æ ‡ï¼ŒäºŒåˆ†ç±»ä½¿ç”¨torchkeras.metricsä¸­çš„è¯„ä¼°æŒ‡æ ‡\n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(str(info)+\"\\n\")\n",
    "    \n",
    "\n",
    "net = create_net() \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   \n",
    "metrics_dict = {\"acc\":Accuracy()}\n",
    "\n",
    "epochs = 20 \n",
    "ckpt_path='checkpoint.pt'\n",
    "\n",
    "#early_stoppingç›¸å…³è®¾ç½®\n",
    "monitor=\"val_acc\"\n",
    "patience=5\n",
    "mode=\"max\"\n",
    "\n",
    "history = {}\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "\n",
    "    # 1ï¼Œtrain -------------------------------------------------  \n",
    "    net.train()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    \n",
    "    loop = tqdm(enumerate(dl_train), total =len(dl_train))\n",
    "    train_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    for i, batch in loop: \n",
    "        \n",
    "        features,labels = batch\n",
    "        #forward\n",
    "        preds = net(features)\n",
    "        loss = loss_fn(preds,labels)\n",
    "        \n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        #metrics\n",
    "        step_metrics = {\"train_\"+name:metric_fn(preds, labels).item() \n",
    "                        for name,metric_fn in train_metrics_dict.items()}\n",
    "        \n",
    "        step_log = dict({\"train_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        step+=1\n",
    "        if i!=len(dl_train)-1:\n",
    "            loop.set_postfix(**step_log)\n",
    "        else:\n",
    "            epoch_loss = total_loss/step\n",
    "            epoch_metrics = {\"train_\"+name:metric_fn.compute().item() \n",
    "                             for name,metric_fn in train_metrics_dict.items()}\n",
    "            epoch_log = dict({\"train_loss\":epoch_loss},**epoch_metrics)\n",
    "            loop.set_postfix(**epoch_log)\n",
    "\n",
    "            for name,metric_fn in train_metrics_dict.items():\n",
    "                metric_fn.reset()\n",
    "                \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "        \n",
    "\n",
    "    # 2ï¼Œvalidate -------------------------------------------------\n",
    "    net.eval()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    loop = tqdm(enumerate(dl_val), total =len(dl_val))\n",
    "    \n",
    "    val_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in loop: \n",
    "\n",
    "            features,labels = batch\n",
    "            \n",
    "            #forward\n",
    "            preds = net(features)\n",
    "            loss = loss_fn(preds,labels)\n",
    "\n",
    "            #metrics\n",
    "            step_metrics = {\"val_\"+name:metric_fn(preds, labels).item() \n",
    "                            for name,metric_fn in val_metrics_dict.items()}\n",
    "\n",
    "            step_log = dict({\"val_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            step+=1\n",
    "            if i!=len(dl_val)-1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                epoch_loss = (total_loss/step)\n",
    "                epoch_metrics = {\"val_\"+name:metric_fn.compute().item() \n",
    "                                 for name,metric_fn in val_metrics_dict.items()}\n",
    "                epoch_log = dict({\"val_loss\":epoch_loss},**epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name,metric_fn in val_metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "                    \n",
    "    epoch_log[\"epoch\"] = epoch           \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "    # 3ï¼Œearly-stopping -------------------------------------------------\n",
    "    arr_scores = history[monitor]\n",
    "    best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "    if best_score_idx==len(arr_scores)-1:\n",
    "        torch.save(net.state_dict(),ckpt_path)\n",
    "        print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "             arr_scores[best_score_idx]),file=sys.stderr)\n",
    "    if len(arr_scores)-best_score_idx>patience:\n",
    "        print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "            monitor,patience),file=sys.stderr)\n",
    "        break \n",
    "    net.load_state_dict(torch.load(ckpt_path))\n",
    "    \n",
    "dfhistory = pd.DataFrame(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0308b51",
   "metadata": {},
   "source": [
    "================================================================================2022-07-17 15:07:03\n",
    "Epoch 1 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:57<00:00,  8.15it/s, train_acc=0.909, train_loss=0.279] \n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 16.80it/s, val_acc=0.956, val_loss=0.147] \n",
    "\n",
    "================================================================================2022-07-17 15:08:06\n",
    "Epoch 2 / 20\n",
    "\n",
    "\n",
    "<<<<<< reach best val_acc : 0.9556000232696533 >>>>>>\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:58<00:00,  8.03it/s, train_acc=0.968, train_loss=0.105] \n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 18.59it/s, val_acc=0.977, val_loss=0.0849]\n",
    "\n",
    "================================================================================2022-07-17 15:09:09\n",
    "Epoch 3 / 20\n",
    "\n",
    "\n",
    "<<<<<< reach best val_acc : 0.9765999913215637 >>>>>>\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:58<00:00,  8.07it/s, train_acc=0.974, train_loss=0.0882]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 17.13it/s, val_acc=0.984, val_loss=0.0554] \n",
    "<<<<<< reach best val_acc : 0.9843000173568726 >>>>>>\n",
    "\n",
    "================================================================================2022-07-17 15:10:12\n",
    "Epoch 4 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [01:01<00:00,  7.63it/s, train_acc=0.976, train_loss=0.0814] \n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 16.34it/s, val_acc=0.979, val_loss=0.0708]\n",
    "\n",
    "================================================================================2022-07-17 15:11:18\n",
    "Epoch 5 / 20\n",
    "\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [01:03<00:00,  7.42it/s, train_acc=0.974, train_loss=0.0896]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:05<00:00, 14.06it/s, val_acc=0.979, val_loss=0.076] \n",
    "\n",
    "================================================================================2022-07-17 15:12:28\n",
    "Epoch 6 / 20\n",
    "\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [01:00<00:00,  7.77it/s, train_acc=0.972, train_loss=0.0937]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 17.45it/s, val_acc=0.976, val_loss=0.0787] \n",
    "\n",
    "================================================================================2022-07-17 15:13:33\n",
    "Epoch 7 / 20\n",
    "\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [01:01<00:00,  7.63it/s, train_acc=0.974, train_loss=0.0858]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:05<00:00, 14.50it/s, val_acc=0.976, val_loss=0.082] \n",
    "\n",
    "================================================================================2022-07-17 15:14:40\n",
    "Epoch 8 / 20\n",
    "\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:59<00:00,  7.85it/s, train_acc=0.972, train_loss=0.0944]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:04<00:00, 17.21it/s, val_acc=0.982, val_loss=0.062] \n",
    "<<<<<< val_acc without improvement in 5 epoch, early stopping >>>>>>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c88222e",
   "metadata": {},
   "source": [
    "CPUæ¯ä¸ªEpochå¤§æ¦‚1åˆ†é’Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f523ad",
   "metadata": {},
   "source": [
    "### 2ï¼Œä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53792236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "from copy import deepcopy\n",
    "from torchmetrics import Accuracy\n",
    "#æ³¨ï¼šå¤šåˆ†ç±»ä½¿ç”¨torchmetricsä¸­çš„è¯„ä¼°æŒ‡æ ‡ï¼ŒäºŒåˆ†ç±»ä½¿ç”¨torchkeras.metricsä¸­çš„è¯„ä¼°æŒ‡æ ‡\n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(str(info)+\"\\n\")\n",
    "    \n",
    "net = create_net() \n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.Adam(net.parameters(),lr = 0.01)   \n",
    "metrics_dict = {\"acc\":Accuracy()}\n",
    "\n",
    "\n",
    "# =========================ç§»åŠ¨æ¨¡å‹åˆ°GPUä¸Š==============================\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "loss_fn.to(device)\n",
    "for name,fn in metrics_dict.items():\n",
    "    fn.to(device)\n",
    "# ====================================================================\n",
    "\n",
    "\n",
    "epochs = 20 \n",
    "ckpt_path='checkpoint.pt'\n",
    "\n",
    "#early_stoppingç›¸å…³è®¾ç½®\n",
    "monitor=\"val_acc\"\n",
    "patience=5\n",
    "mode=\"max\"\n",
    "\n",
    "history = {}\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "\n",
    "    # 1ï¼Œtrain -------------------------------------------------  \n",
    "    net.train()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    \n",
    "    loop = tqdm(enumerate(dl_train), total =len(dl_train))\n",
    "    train_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    for i, batch in loop: \n",
    "        \n",
    "        features,labels = batch\n",
    "        \n",
    "        # =========================ç§»åŠ¨æ•°æ®åˆ°GPUä¸Š==============================\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # ====================================================================\n",
    "        \n",
    "        #forward\n",
    "        preds = net(features)\n",
    "        loss = loss_fn(preds,labels)\n",
    "        \n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        #metrics\n",
    "        step_metrics = {\"train_\"+name:metric_fn(preds, labels).item() \n",
    "                        for name,metric_fn in train_metrics_dict.items()}\n",
    "        \n",
    "        step_log = dict({\"train_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        step+=1\n",
    "        if i!=len(dl_train)-1:\n",
    "            loop.set_postfix(**step_log)\n",
    "        else:\n",
    "            epoch_loss = total_loss/step\n",
    "            epoch_metrics = {\"train_\"+name:metric_fn.compute().item() \n",
    "                             for name,metric_fn in train_metrics_dict.items()}\n",
    "            epoch_log = dict({\"train_loss\":epoch_loss},**epoch_metrics)\n",
    "            loop.set_postfix(**epoch_log)\n",
    "\n",
    "            for name,metric_fn in train_metrics_dict.items():\n",
    "                metric_fn.reset()\n",
    "                \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "        \n",
    "\n",
    "    # 2ï¼Œvalidate -------------------------------------------------\n",
    "    net.eval()\n",
    "    \n",
    "    total_loss,step = 0,0\n",
    "    loop = tqdm(enumerate(dl_val), total =len(dl_val))\n",
    "    \n",
    "    val_metrics_dict = deepcopy(metrics_dict) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in loop: \n",
    "\n",
    "            features,labels = batch\n",
    "            \n",
    "            # =========================ç§»åŠ¨æ•°æ®åˆ°GPUä¸Š==============================\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # ====================================================================\n",
    "            \n",
    "            #forward\n",
    "            preds = net(features)\n",
    "            loss = loss_fn(preds,labels)\n",
    "\n",
    "            #metrics\n",
    "            step_metrics = {\"val_\"+name:metric_fn(preds, labels).item() \n",
    "                            for name,metric_fn in val_metrics_dict.items()}\n",
    "\n",
    "            step_log = dict({\"val_loss\":loss.item()},**step_metrics)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            step+=1\n",
    "            if i!=len(dl_val)-1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                epoch_loss = (total_loss/step)\n",
    "                epoch_metrics = {\"val_\"+name:metric_fn.compute().item() \n",
    "                                 for name,metric_fn in val_metrics_dict.items()}\n",
    "                epoch_log = dict({\"val_loss\":epoch_loss},**epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name,metric_fn in val_metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "                    \n",
    "    epoch_log[\"epoch\"] = epoch           \n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "    # 3ï¼Œearly-stopping -------------------------------------------------\n",
    "    arr_scores = history[monitor]\n",
    "    best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "    if best_score_idx==len(arr_scores)-1:\n",
    "        torch.save(net.state_dict(),ckpt_path)\n",
    "        print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "             arr_scores[best_score_idx]),file=sys.stderr)\n",
    "    if len(arr_scores)-best_score_idx>patience:\n",
    "        print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "            monitor,patience),file=sys.stderr)\n",
    "        break \n",
    "    net.load_state_dict(torch.load(ckpt_path))\n",
    "    \n",
    "dfhistory = pd.DataFrame(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d6009c",
   "metadata": {},
   "source": [
    "```\n",
    "================================================================================2022-07-17 15:20:40\n",
    "Epoch 1 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 37.07it/s, train_acc=0.89, train_loss=0.336]  \n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:02<00:00, 37.31it/s, val_acc=0.95, val_loss=0.16]   \n",
    "\n",
    "================================================================================2022-07-17 15:20:55\n",
    "Epoch 2 / 20\n",
    "\n",
    "\n",
    "<<<<<< reach best val_acc : 0.9498000144958496 >>>>>>\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 37.04it/s, train_acc=0.964, train_loss=0.115] \n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 43.36it/s, val_acc=0.972, val_loss=0.0909]\n",
    "\n",
    "================================================================================2022-07-17 15:21:10\n",
    "Epoch 3 / 20\n",
    "\n",
    "\n",
    "<<<<<< reach best val_acc : 0.9721999764442444 >>>>>>\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 38.05it/s, train_acc=0.971, train_loss=0.0968]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.10it/s, val_acc=0.974, val_loss=0.0878] \n",
    "\n",
    "================================================================================2022-07-17 15:21:24\n",
    "Epoch 4 / 20\n",
    "\n",
    "<<<<<< reach best val_acc : 0.974399983882904 >>>>>>\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:13<00:00, 35.56it/s, train_acc=0.973, train_loss=0.089] \n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:02<00:00, 38.16it/s, val_acc=0.982, val_loss=0.0585]\n",
    "\n",
    "================================================================================2022-07-17 15:21:40\n",
    "Epoch 5 / 20\n",
    "\n",
    "\n",
    "<<<<<< reach best val_acc : 0.9822999835014343 >>>>>>\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 36.80it/s, train_acc=0.977, train_loss=0.0803]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.38it/s, val_acc=0.976, val_loss=0.0791]\n",
    "\n",
    "================================================================================2022-07-17 15:21:55\n",
    "Epoch 6 / 20\n",
    "\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:13<00:00, 34.63it/s, train_acc=0.977, train_loss=0.0787]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:02<00:00, 39.01it/s, val_acc=0.97, val_loss=0.105]   \n",
    "\n",
    "================================================================================2022-07-17 15:22:11\n",
    "Epoch 7 / 20\n",
    "\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 37.39it/s, train_acc=0.975, train_loss=0.0871]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:02<00:00, 39.16it/s, val_acc=0.984, val_loss=0.0611]\n",
    "\n",
    "================================================================================2022-07-17 15:22:26\n",
    "Epoch 8 / 20\n",
    "\n",
    "\n",
    "<<<<<< reach best val_acc : 0.9835000038146973 >>>>>>\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:13<00:00, 35.63it/s, train_acc=0.976, train_loss=0.0774] \n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.92it/s, val_acc=0.982, val_loss=0.0778] \n",
    "\n",
    "================================================================================2022-07-17 15:22:41\n",
    "Epoch 9 / 20\n",
    "\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 37.96it/s, train_acc=0.976, train_loss=0.0819]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.99it/s, val_acc=0.981, val_loss=0.0652] \n",
    "\n",
    "================================================================================2022-07-17 15:22:56\n",
    "Epoch 10 / 20\n",
    "\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:13<00:00, 35.29it/s, train_acc=0.975, train_loss=0.0852]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 41.38it/s, val_acc=0.978, val_loss=0.0808]\n",
    "\n",
    "================================================================================2022-07-17 15:23:12\n",
    "Epoch 11 / 20\n",
    "\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 38.77it/s, train_acc=0.975, train_loss=0.0863] \n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 42.71it/s, val_acc=0.983, val_loss=0.0665] \n",
    "\n",
    "================================================================================2022-07-17 15:23:26\n",
    "Epoch 12 / 20\n",
    "\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:12<00:00, 36.55it/s, train_acc=0.976, train_loss=0.0818]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:02<00:00, 37.44it/s, val_acc=0.979, val_loss=0.0819]\n",
    "<<<<<< val_acc without improvement in 5 epoch, early stopping >>>>>>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc1cc4f",
   "metadata": {},
   "source": [
    "ä½¿ç”¨GPUåæ¯ä¸ªEpochåªéœ€è¦10ç§’é’Ÿå·¦å³ï¼Œæå‡äº†6å€ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a52c7b5",
   "metadata": {},
   "source": [
    "## å››ï¼Œtorchkeras.KerasModelä¸­ä½¿ç”¨GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ä»ä¸Šé¢çš„ä¾‹å­å¯ä»¥çœ‹åˆ°ï¼Œåœ¨pytorchä¸­ä½¿ç”¨GPUå¹¶ä¸å¤æ‚ï¼Œä½†å¯¹äºç»å¸¸ç‚¼ä¸¹çš„åŒå­¦æ¥è¯´ï¼Œæ¨¡å‹å’Œæ•°æ®è€æ˜¯ç§»æ¥ç§»å»è¿˜æ˜¯è›®éº»çƒ¦çš„ã€‚\n",
    "\n",
    "ä¸€ä¸å°å¿ƒå°±ä¼šå¿˜äº†ç§»åŠ¨æŸäº›æ•°æ®æˆ–è€…æŸäº›moduleï¼Œå¯¼è‡´æŠ¥é”™ã€‚\n",
    "\n",
    "torchkeras.KerasModel åœ¨è®¾è®¡çš„æ—¶å€™è€ƒè™‘åˆ°äº†è¿™ä¸€ç‚¹ï¼Œå¦‚æœç¯å¢ƒå½“ä¸­å­˜åœ¨å¯ç”¨çš„GPUï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨GPUï¼Œåä¹‹åˆ™ä½¿ç”¨CPUã€‚\n",
    "\n",
    "é€šè¿‡å¼•å…¥accelerateçš„ä¸€äº›åŸºç¡€åŠŸèƒ½ï¼Œtorchkeras.KerasModelä»¥éå¸¸ä¼˜é›…çš„æ–¹å¼åœ¨GPUå’ŒCPUä¹‹é—´åˆ‡æ¢ã€‚\n",
    "\n",
    "è¯¦ç»†å®ç°å¯ä»¥å‚è€ƒtorchkeras.KerasModelçš„æºç ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc49be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchkeras==3.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  accelerate \n",
    "accelerator = accelerate.Accelerator()\n",
    "print(accelerator.device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import KerasModel \n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "net = create_net() \n",
    "model = KerasModel(net,\n",
    "                   loss_fn=nn.CrossEntropyLoss(),\n",
    "                   metrics_dict = {\"acc\":Accuracy()},\n",
    "                   optimizer = torch.optim.Adam(net.parameters(),lr = 0.01)  )\n",
    "\n",
    "model.fit(\n",
    "    train_data = dl_train,\n",
    "    val_data= dl_val,\n",
    "    epochs=10,\n",
    "    patience=3,\n",
    "    monitor=\"val_acc\", \n",
    "    mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cfd732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e6d799",
   "metadata": {},
   "source": [
    "## äº”ï¼Œtorchkeras.LightModelä¸­ä½¿ç”¨GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230a863d",
   "metadata": {},
   "source": [
    "é€šè¿‡å¼•ç”¨pytorch_lightningçš„åŠŸèƒ½ï¼Œ\n",
    "\n",
    "torchkeras.LightModelä»¥æ›´åŠ æ˜¾å¼çš„æ–¹å¼æ”¯æŒGPUè®­ç»ƒï¼Œ\n",
    "\n",
    "ä¸ä»…å¦‚æ­¤ï¼Œè¿˜èƒ½æ”¯æŒå¤šGPUå’ŒTPUè®­ç»ƒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a075749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy \n",
    "from torchkeras import LightModel \n",
    "\n",
    "net = create_net() \n",
    "model = LightModel(net,\n",
    "                   loss_fn=nn.CrossEntropyLoss(),\n",
    "                   metrics_dict = {\"acc\":Accuracy()},\n",
    "                   optimizer = torch.optim.Adam(net.parameters(),lr = 0.01) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl     \n",
    "\n",
    "#1ï¼Œè®¾ç½®å›è°ƒå‡½æ•°\n",
    "model_ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    save_top_k=1,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "early_stopping = pl.callbacks.EarlyStopping(monitor = 'val_acc',\n",
    "                           patience=3,\n",
    "                           mode = 'max'\n",
    "                          )\n",
    "\n",
    "#2ï¼Œè®¾ç½®è®­ç»ƒå‚æ•°\n",
    "\n",
    "# gpus=0 åˆ™ä½¿ç”¨cpuè®­ç»ƒï¼Œgpus=1åˆ™ä½¿ç”¨1ä¸ªgpuè®­ç»ƒï¼Œgpus=2åˆ™ä½¿ç”¨2ä¸ªgpuè®­ç»ƒï¼Œgpus=-1åˆ™ä½¿ç”¨æ‰€æœ‰gpuè®­ç»ƒï¼Œ\n",
    "# gpus=[0,1]åˆ™æŒ‡å®šä½¿ç”¨0å·å’Œ1å·gpuè®­ç»ƒï¼Œ gpus=\"0,1,2,3\"åˆ™ä½¿ç”¨0,1,2,3å·gpuè®­ç»ƒ\n",
    "# tpus=1 åˆ™ä½¿ç”¨1ä¸ªtpuè®­ç»ƒ\n",
    "trainer = pl.Trainer(logger=True,\n",
    "                     min_epochs=3,max_epochs=20,\n",
    "                     gpus=1,\n",
    "                     callbacks = [model_ckpt,early_stopping],\n",
    "                     enable_progress_bar = True) \n",
    "\n",
    "\n",
    "##4ï¼Œå¯åŠ¨è®­ç»ƒå¾ªç¯\n",
    "trainer.fit(model,dl_train,dl_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad61a3e",
   "metadata": {},
   "source": [
    "```\n",
    "================================================================================2022-07-18 00:18:14\n",
    "{'epoch': 0, 'val_loss': 2.31911301612854, 'val_acc': 0.0546875}\n",
    "<<<<<< reach best val_acc : 0.0546875 >>>>>>\n",
    "\n",
    "================================================================================2022-07-18 00:18:29\n",
    "{'epoch': 0, 'val_loss': 0.10364170372486115, 'val_acc': 0.9693999886512756}\n",
    "{'epoch': 0, 'train_loss': 0.31413567066192627, 'train_acc': 0.8975499868392944}\n",
    "<<<<<< reach best val_acc : 0.9693999886512756 >>>>>>\n",
    "\n",
    "================================================================================2022-07-18 00:18:43\n",
    "{'epoch': 1, 'val_loss': 0.0983758345246315, 'val_acc': 0.9710999727249146}\n",
    "{'epoch': 1, 'train_loss': 0.10680060088634491, 'train_acc': 0.9673333168029785}\n",
    "<<<<<< reach best val_acc : 0.9710999727249146 >>>>>>\n",
    "\n",
    "================================================================================2022-07-18 00:18:58\n",
    "{'epoch': 2, 'val_loss': 0.08315123617649078, 'val_acc': 0.9764999747276306}\n",
    "{'epoch': 2, 'train_loss': 0.09339822083711624, 'train_acc': 0.9722166657447815}\n",
    "<<<<<< reach best val_acc : 0.9764999747276306 >>>>>>\n",
    "\n",
    "================================================================================2022-07-18 00:19:13\n",
    "{'epoch': 3, 'val_loss': 0.06529796123504639, 'val_acc': 0.9799000024795532}\n",
    "{'epoch': 3, 'train_loss': 0.08487282693386078, 'train_acc': 0.9746000170707703}\n",
    "<<<<<< reach best val_acc : 0.9799000024795532 >>>>>>\n",
    "\n",
    "================================================================================2022-07-18 00:19:27\n",
    "{'epoch': 4, 'val_loss': 0.10162600129842758, 'val_acc': 0.9735000133514404}\n",
    "{'epoch': 4, 'train_loss': 0.08439336717128754, 'train_acc': 0.9746666550636292}\n",
    "\n",
    "================================================================================2022-07-18 00:19:42\n",
    "{'epoch': 5, 'val_loss': 0.0818500965833664, 'val_acc': 0.9789000153541565}\n",
    "{'epoch': 5, 'train_loss': 0.08107426762580872, 'train_acc': 0.9763166904449463}\n",
    "\n",
    "================================================================================2022-07-18 00:19:56\n",
    "{'epoch': 6, 'val_loss': 0.08046088367700577, 'val_acc': 0.979200005531311}\n",
    "{'epoch': 6, 'train_loss': 0.08173364400863647, 'train_acc': 0.9772833585739136}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f3faf",
   "metadata": {},
   "source": [
    "**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** \n",
    "\n",
    "å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·\"ç®—æ³•ç¾é£Ÿå±‹\"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚\n",
    "\n",
    "![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
