
# 7-7ï¼ŒDINç½‘ç»œ


é˜¿é‡Œå¦ˆå¦ˆåœ¨CTRé¢„ä¼°é¢†åŸŸæœ‰3ç¯‡æ¯”è¾ƒæœ‰åçš„æ–‡ç« ã€‚

2017å¹´çš„æ·±åº¦å…´è¶£ç½‘ç»œ, DIN(DeepInterestNetwork)ã€‚ 

2018å¹´çš„æ·±åº¦å…´è¶£æ¼”åŒ–ç½‘ç»œ, DIEN(DeepInterestEvolutionNetWork)ã€‚

2019å¹´çš„æ·±åº¦ä¼šè¯å…´è¶£ç½‘ç»œ, DSIN(DeepSessionInterestNetWork)ã€‚

è¿™3ç¯‡æ–‡ç« çš„ä¸»è¦æ€æƒ³å’Œç›¸äº’å…³ç³»ç”¨ä¸€å¥è¯åˆ†åˆ«æ¦‚æ‹¬å¦‚ä¸‹ï¼š

ç¬¬1ç¯‡DINè¯´ï¼Œç”¨æˆ·çš„è¡Œä¸ºæ—¥å¿—ä¸­åªæœ‰ä¸€éƒ¨åˆ†å’Œå½“å‰å€™é€‰å¹¿å‘Šæœ‰å…³ã€‚å¯ä»¥åˆ©ç”¨Attentionæœºåˆ¶ä»ç”¨æˆ·è¡Œä¸ºæ—¥å¿—ä¸­å»ºæ¨¡å‡ºå’Œå½“å‰å€™é€‰å¹¿å‘Šç›¸å…³çš„ç”¨æˆ·å…´è¶£è¡¨ç¤ºã€‚æˆ‘ä»¬è¯•è¿‡æ¶¨ç‚¹äº†å˜»å˜»å˜»ã€‚

ç¬¬2ç¯‡DIENè¯´ï¼Œç”¨æˆ·æœ€è¿‘çš„è¡Œä¸ºå¯èƒ½æ¯”è¾ƒè¿œçš„è¡Œä¸ºæ›´åŠ é‡è¦ã€‚å¯ä»¥ç”¨å¾ªç¯ç¥ç»ç½‘ç»œGRUå»ºæ¨¡ç”¨æˆ·å…´è¶£éšæ—¶é—´çš„æ¼”åŒ–ã€‚æˆ‘ä»¬è¯•è¿‡ä¹Ÿæ¶¨ç‚¹äº†å˜¿å˜¿å˜¿ã€‚

ç¬¬3ç¯‡DSINè¯´ï¼Œç”¨æˆ·åœ¨åŒä¸€æ¬¡ä¼šè¯ä¸­çš„è¡Œä¸ºé«˜åº¦ç›¸å…³ï¼Œåœ¨ä¸åŒä¼šè¯é—´çš„è¡Œä¸ºåˆ™ç›¸å¯¹ç‹¬ç«‹ã€‚å¯ä»¥æŠŠç”¨æˆ·è¡Œä¸ºæ—¥å¿—æŒ‰ç…§æ—¶é—´é—´éš”åˆ†å‰²æˆä¼šè¯å¹¶ç”¨SelfAttentionæœºåˆ¶å»ºæ¨¡å®ƒä»¬ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚æˆ‘ä»¬è¯•è¿‡åˆæ¶¨ç‚¹äº†å“ˆå“ˆå“ˆã€‚


å‚è€ƒææ–™ï¼š

* DINè®ºæ–‡ï¼š https://arxiv.org/pdf/1706.06978.pdf

* æ¨èç³»ç»Ÿä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ï¼š https://zhuanlan.zhihu.com/p/51623339

* é˜¿é‡Œç»å…¸å…´è¶£ç½‘ç»œï¼š https://zhuanlan.zhihu.com/p/429433768

* ä»DINåˆ°DIENçœ‹é˜¿é‡ŒCTRç®—æ³•çš„è¿›åŒ–è„‰ç»œï¼š https://zhuanlan.zhihu.com/p/78365283

* DIN+DIENï¼Œæœºå™¨å­¦ä¹ å”¯ä¸€æŒ‡å®šæ¶¨ç‚¹æŠ€Attentionï¼š https://zhuanlan.zhihu.com/p/431131396

* Attentionæœºåˆ¶ç®€å•æ€»ç»“ï¼š https://zhuanlan.zhihu.com/p/46313756

* ä»£ç å®ç°å‚è€ƒï¼š https://github.com/GitHub-HongweiZhang/prediction-flow


æœ¬ç¯‡æ–‡ç« æˆ‘ä»¬ä¸»è¦ä»‹ç»DINï¼Œä¸‹ä¸€ç¯‡æ–‡ç« æˆ‘ä»¬ä»‹ç»DIENã€‚ 



<br>

<font color="red">
 
å…¬ä¼—å· **ç®—æ³•ç¾é£Ÿå±‹** å›å¤å…³é”®è¯ï¼š**pytorch**ï¼Œ è·å–æœ¬é¡¹ç›®æºç å’Œæ‰€ç”¨æ•°æ®é›†ç™¾åº¦äº‘ç›˜ä¸‹è½½é“¾æ¥ã€‚
    
</font> 



## ã€‡ï¼ŒAttentionåŸç†æ¦‚è¿°

ä¼—æ‰€å‘¨çŸ¥ï¼ŒAttentionæœºåˆ¶åœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸæ˜¯éå¸¸é€šç”¨çš„æ¶¨åˆ†æŠ€å·§ã€‚å…¶ä¸»è¦ä½œç”¨æ˜¯æå‡æ¨¡å‹çš„è‡ªé€‚åº”èƒ½åŠ›ã€‚

Attentionæœºåˆ¶çš„ä¸€äº›å¸¸ç”¨åŠŸèƒ½å’Œå…¸å‹èŒƒä¾‹æ€»ç»“å¦‚ä¸‹ï¼š

* 1,åŠ¨æ€ç‰¹å¾é€‰æ‹©ï¼Œæ ¹æ®æ ·æœ¬ä¸åŒåŠ¨æ€åœ°èµ‹äºˆç‰¹å¾ä»¥ä¸åŒçš„æƒé‡ï¼Œå…¸å‹èŒƒä¾‹å¦‚SENetä¸­çš„SEAttentionï¼ŒDINä¸­çš„Attention.

* 2,åŠ¨æ€ç‰¹å¾äº¤äº’ï¼ŒåŠ¨æ€åœ°æ„å»ºç‰¹å¾ä¹‹é—´çš„äº¤äº’å¼ºå¼±å…³ç³»ï¼Œæå–é«˜é˜¶ç‰¹å¾ã€‚å…¸å‹èŒƒä¾‹å¦‚Transformerä¸­çš„çš„Attentionã€‚

* 3,åŠ¨æ€æ¨¡å—é›†æˆï¼Œç±»ä¼¼å¤šæ¨¡å‹èåˆé›†æˆï¼Œä½†æ˜¯ä¸åŒå­æ¨¡å—çš„æƒé‡æ˜¯åŠ¨æ€çš„ã€‚å…¸å‹èŒƒä¾‹å¦‚MOEä¸­çš„é—¨æ§æ³¨æ„åŠ›æœºåˆ¶ã€‚


åœ¨è®¸å¤šAttentionæœºåˆ¶çš„åº”ç”¨åœºæ™¯ä¸­ï¼Œè¾“å…¥åˆ†æˆQuery(Q)å’ŒKey(K)ã€‚Queryæ˜¯å½“å‰å…³æ³¨é¡¹çš„Embeddingå‘é‡ï¼ŒKeyæ˜¯å¾…å’Œå½“å‰å…³æ³¨é¡¹è¿›è¡ŒåŒ¹é…çš„Embeddingå‘é‡ã€‚

ä¾‹å¦‚åœ¨å¹¿å‘ŠCTRé¢†åŸŸï¼ŒQueryå°±æ˜¯å½“å‰å¾…é¢„ä¼°çš„å¹¿å‘Šï¼ŒKeyå°±æ˜¯ç”¨æˆ·å†å²ä¸Šç‚¹å‡»è¿‡çš„å¹¿å‘Šï¼Œé€šè¿‡Attentionæœºåˆ¶å»ºç«‹å½“å‰å¾…é¢„ä¼°çš„å¹¿å‘Šå’Œç”¨æˆ·å†å²ä¸Šç‚¹å‡»è¿‡çš„å¹¿å‘Šçš„ç›¸å…³æ€§å¼ºå¼±ã€‚

åˆæ¯”å¦‚åœ¨NLPç¿»è¯‘é¢†åŸŸï¼ŒQueryå°±æ˜¯å½“å‰æ­£åœ¨è§£ç çš„è¯‘æ–‡å•è¯è¯å‘é‡ï¼ŒKeyå°±æ˜¯åŸæ–‡å•è¯åºåˆ—çš„è¯å‘é‡ï¼Œé€šè¿‡Attentionæœºåˆ¶å¯ä»¥å»ºç«‹è¯‘æ–‡å•è¯å’ŒåŸæ–‡å•è¯çš„å¯¹åº”å…³ç³»ã€‚


Attentionæœºåˆ¶çš„æ ¸å¿ƒå®ç°æ˜¯è®¡ç®—æ³¨æ„åŠ›æƒé‡ï¼Œä¸€äº›çš„å¸¸ç”¨å®ç°å½¢å¼å¦‚ä¸‹ï¼š

$$attention = f(Q,K)$$


* 1,å¤šå±‚æ„ŸçŸ¥æœºæ–¹æ³•

å…ˆå°†Queryå’ŒKeyè¿›è¡Œæ‹¼æ¥ï¼Œç„¶åæ¥ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºã€‚

è¿™ç§æ–¹æ³•ä¸éœ€è¦Queryå’ŒKeyçš„å‘é‡é•¿åº¦ç›¸ç­‰ï¼ŒQueryå’ŒKeyä¹‹é—´çš„äº¤äº’æ–¹å¼æ˜¯é€šè¿‡å­¦ä¹ è·å¾—çš„ã€‚

$$f(Q,K) = mlp([Q;K])$$


* 2,Bilinearæ–¹æ³•

é€šè¿‡ä¸€ä¸ªæƒé‡çŸ©é˜µç›´æ¥å»ºç«‹Queryå’ŒKeyçš„å…³ç³»æ˜ å°„ï¼Œè®¡ç®—é€Ÿåº¦è¾ƒå¿«ï¼Œä½†æ˜¯éœ€è¦Queryå’ŒKeyçš„å‘é‡é•¿åº¦ç›¸åŒã€‚
$$f(Q,K) = QWK^T$$


* 3,Scaled-Dot Product

è¿™ç§æ–¹å¼ç›´æ¥æ±‚Queryå’ŒKeyçš„å†…ç§¯ç›¸ä¼¼åº¦ï¼Œæ²¡æœ‰éœ€è¦å­¦ä¹ çš„å‚æ•°ï¼Œè®¡ç®—é€Ÿåº¦æå¿«ï¼Œéœ€è¦Queryå’ŒKeyçš„å‘é‡é•¿åº¦ç›¸åŒã€‚è€ƒè™‘åˆ°éšç€å‘é‡ç»´åº¦çš„å¢åŠ ï¼Œæœ€åå¾—åˆ°çš„æƒé‡ä¹Ÿä¼šå¢åŠ ï¼Œå¯¹å…¶è¿›è¡Œscalingã€‚

$$f(Q,K)=softmax(\frac{QK^T}{\sqrt{d_k}})$$



## ä¸€ï¼ŒDINåŸç†è§£æ


é˜¿é‡Œçš„å±•ç¤ºå¹¿å‘Šç³»ç»Ÿä¸»è¦ç”¨åˆ°äº†å¦‚ä¸‹4ç±»ç‰¹å¾

* (1) ç”¨æˆ·ç”»åƒç‰¹å¾ã€‚
* (2) ç”¨æˆ·è¡Œä¸ºç‰¹å¾ï¼Œå³ç”¨æˆ·ç‚¹å‡»è¿‡çš„å•†å“ã€‚
* (3) å¾…æ›å…‰çš„å¹¿å‘Šç‰¹å¾ï¼Œå¹¿å‘Šå…¶å®ä¹Ÿæ˜¯å•†å“ã€‚
* (4) ä¸Šä¸‹æ–‡ç‰¹å¾ã€‚

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h3eet3webnj20jj09rdgq.jpg)


DINã€DIENå’ŒDSINä¸»è¦èšç„¦åœ¨å¯¹ç”¨æˆ·è¡Œä¸ºæ—¥å¿—çš„å»ºæ¨¡ã€‚

ç”¨æˆ·è¡Œä¸ºæ—¥å¿—ååº”çš„æ˜¯ç”¨æˆ·çš„å…´è¶£ï¼Œå¦‚ä½•ä»è¡Œä¸ºæ—¥å¿—ä¸­å»ºæ¨¡å‡ºä¸€ä¸ªå¥½çš„ç”¨æˆ·å…´è¶£çš„è¡¨ç¤ºï¼Ÿ


æœ€åŸºç¡€çš„å»ºæ¨¡æ–¹æ³•æ˜¯ Embedding+SumPooling. æŠŠç”¨æˆ·çš„è¿‡å»æ‰€æœ‰ç‚¹å‡»è¡Œä¸ºåšEmbedding, ç„¶åæ±‚å’Œã€‚


![](https://tva1.sinaimg.cn/large/e6c9d24egy1h3eezc7meij20d908x0t5.jpg)



è¿™ä¸ªSumPoolingçš„å®ç°ä¸è¦å¤ªç®€å•ã€‚

```python
import torch
import torch.nn as nn

class SumPooling(nn.Module):
    def __init__(self, dim):
        super(SumPooling, self).__init__()
        self.dim = dim

    def forward(self, x):
        return torch.sum(x, self.dim)
    
```

è¿™ç§å»ºæ¨¡æ–¹å¼å­˜åœ¨ç€ä¸€ä¸ªå·¨å¤§çš„ç¼ºé™·ï¼Œé‚£å°±æ˜¯ç”¨æˆ·çš„å…´è¶£è¡¨ç¤ºæ˜¯ç¡®å®šçš„ï¼Œå’Œå€™é€‰å¹¿å‘Šæ— å…³ã€‚

ä¸ç®¡æ¥ä¸ªå•¥å€™é€‰å¹¿å‘Šï¼Œç”¨æˆ·è¿‡å»çš„æ‰€æœ‰è¡Œä¸ºæ—¥å¿—å…¨éƒ¨ä¸€æŠŠæ¢­å“ˆä¸¢è¿›å»æ±‚å’Œã€‚

å¾ˆæ˜¾ç„¶ï¼Œå¦‚æœæˆ‘ä»¬å¦‚æœå»ºæ¨¡å‡ºå’Œå€™é€‰å¹¿å‘Šç›¸å…³çš„ç”¨æˆ·å…´è¶£è¡¨ç¤ºï¼Œæ•ˆæœåº”è¯¥ä¼šå¥½å¾ˆå¤šã€‚

é‚£ä¹ˆï¼Œå¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹å‘¢ï¼Ÿæˆ‘ä»¬å¯ä»¥ç”¨å€™é€‰å¹¿å‘Šæ¥å’Œç”¨æˆ·å†å²è¡Œä¸ºæ—¥å¿—æ±‚ç›¸å…³æ€§ï¼Œç”¨ç›¸å…³æ€§å¯¹å†å²è¡Œä¸ºæ—¥å¿—åšåŠ æƒã€‚

è¿™æ˜¯å¾ˆè‡ªç„¶çš„ï¼Œæˆ‘ä»¬ä¸»è¦èšç„¦(Attention)ç”¨æˆ·å†å²è¡Œä¸ºæ—¥å¿—ä¸­é‚£äº›å’Œå€™é€‰å¹¿å‘Šç›¸å…³çš„éƒ¨åˆ†ã€‚

äºæ˜¯ï¼Œduangçš„ä¸€ä¸‹ï¼ŒDINæ¨¡å‹çš„æ¨¡å‹æ¶æ„å°±å‡ºæ¥äº†ã€‚

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h3ef9wpx4uj20mb0c0dh0.jpg) 





è¿™é‡Œæ³¨æ„åŠ›æœºåˆ¶æ¯”è¾ƒå€¼å¾—ç©å‘³ï¼Œå®ƒæ˜¯ä¸€ç§mlpå½¢å¼çš„æ³¨æ„åŠ›ç»“æ„ï¼Œä½†åœ¨è¾“å…¥ç«¯ä¸æ˜¯ç®€å•åœ°æ‹¼æ¥äº†$Q$å’Œ$K$ï¼Œè€Œæ˜¯å°†$Q,K,Q-K,Q*K$éƒ½ä¸€èµ·æ‰“åŒ…æ‹¼æ¥äº†ï¼Œè¿™æ ·æ¨¡å‹æ›´åŠ å®¹æ˜“å­¦ä¹ Qå’ŒKä¹‹é—´çš„ç›¸ä¼¼æ€§å…³ç³»ã€‚

æ­¤å¤–ï¼Œè¿™é‡Œç”¨maskæŠ€å·§å°†keysä¸­å¡«å……çš„çš„éƒ¨åˆ†çš„æ³¨æ„åŠ›èµ‹å€¼ä¸º0ï¼Œä»¥åŠç»´åº¦å˜æ¢ç­‰ä¸€äº›å®ç°ä¸Šçš„ç»†èŠ‚ï¼Œä¹Ÿæ˜¯å¾ˆå€¼å¾—æ£æ‘©çš„ã€‚


```python
import torch
from torch import nn 


class MLP(nn.Module):
    def __init__(self, input_size, hidden_layers,
                 dropout=0.0, batchnorm=True):
        super(MLP, self).__init__()
        modules = OrderedDict()
        previous_size = input_size
        for index, hidden_layer in enumerate(hidden_layers):
            modules[f"dense{index}"] = nn.Linear(previous_size, hidden_layer)
            if batchnorm:
                modules[f"batchnorm{index}"] = nn.BatchNorm1d(hidden_layer)
            modules[f"activation{index}"] = nn.PReLU() 
            if dropout:
                modules[f"dropout{index}"] = nn.Dropout(dropout)
            previous_size = hidden_layer
        self.mlp = nn.Sequential(modules)

    def forward(self, x):
        return self.mlp(x)
    
    
class Attention(nn.Module):
    def __init__(
            self,
            input_size,
            hidden_layers,
            dropout=0.0,
            batchnorm=True,
            return_scores=False):
        
        super().__init__()
        self.return_scores = return_scores
        
        self.mlp = MLP(
            input_size=input_size * 4,
            hidden_layers=hidden_layers,
            dropout=dropout,
            batchnorm=batchnorm,
            activation=activation)
        self.fc = nn.Linear(hidden_layers[-1], 1)

    def forward(self, query, keys, keys_length):
        """
        Parameters
        ----------
        query: 2D tensor, [Batch, Hidden]
        keys: 3D tensor, [Batch, Time, Hidden]
        keys_length: 1D tensor, [Batch]

        Returns
        -------
        outputs: 2D tensor, [Batch, Hidden]
        """
        
        batch_size, max_length, dim = keys.size()

        query = query.unsqueeze(1).expand(-1, max_length, -1)

        din_all = torch.cat(
            [query, keys, query - keys, query * keys], dim=-1)

        din_all = din_all.view(batch_size * max_length, -1)

        outputs = self.mlp(din_all)

        outputs = self.fc(outputs).view(batch_size, max_length)  # [B, T]

        # Scale
        outputs = outputs / (dim ** 0.5)

        # Mask
        mask = (torch.arange(max_length, device=keys_length.device).repeat(
            batch_size, 1) < keys_length.view(-1, 1))
        outputs[~mask] = -np.inf

        # Activation
        outputs = torch.sigmoid(outputs)  # [B, T]

        if not self.return_scores:
            # Weighted sum
            outputs = torch.matmul(
                outputs.unsqueeze(1), keys).squeeze()  # [B, H]
            
        return outputs 
    
```

æˆ‘ä»¬æœŸå¾…çš„æ•ˆæœæ˜¯è¿™æ ·çš„ï¼Œå’Œå€™é€‰å¹¿å‘Š(query)è¶Šç›¸å…³çš„ç”¨æˆ·å†å²æµè§ˆè®°å½•(keys)ï¼Œå…¶æ³¨æ„åŠ›æƒé‡å€¼è¶Šé«˜ğŸ˜‹ã€‚




![](https://tva1.sinaimg.cn/large/e6c9d24egy1h3efhfac81j20i706vaaj.jpg)


é™¤äº†ç”¨Attentionæœºåˆ¶ä»ç”¨æˆ·è¡Œä¸ºæ—¥å¿—ä¸­å»ºæ¨¡å‡ºå’Œå½“å‰å€™é€‰å¹¿å‘Šç›¸å…³çš„ç”¨æˆ·å…´è¶£è¡¨ç¤ºè¿™ä¸ªä¸»è¦åˆ›æ–°å¤–ï¼ŒDINè¿™ç¯‡æ–‡ç« è¿˜æœ‰ä¸€äº›å…¶ä»–çš„å¾®åˆ›æ–°ã€‚

* å¼•å…¥è½¬æŠ˜ç‚¹å¯ä»¥å­¦ä¹ çš„Diceæ¿€æ´»å‡½æ•°ä»£æ›¿PReLUæ¿€æ´»å‡½æ•°
* ä»‹ç»ä¸€ç§Mini-batch Aware çš„L2æ­£åˆ™åŒ–æ–¹æ³•





## äºŒï¼ŒDINçš„pytorchå®ç°


ä¸‹é¢æ˜¯ä¸€ä¸ªDINæ¨¡å‹çš„å®Œæ•´pytorchå®ç°ã€‚

è¿™é‡Œçš„AttentionGroupç±»æ¯”è¾ƒç‰¹åˆ«ï¼Œæ˜¯ä¸ºäº†å»ºç«‹å€™é€‰å¹¿å‘Šå±æ€§å’Œå†å²å¹¿å‘Šå±æ€§çš„pairå…³ç³»ã€‚


```python
import torch
import torch.nn as nn
import torch.nn.functional as F 
from collections import OrderedDict

class MaxPooling(nn.Module):
    def __init__(self, dim):
        super(MaxPooling, self).__init__()
        self.dim = dim

    def forward(self, x):
        return torch.max(x, self.dim)[0]


class SumPooling(nn.Module):
    def __init__(self, dim):
        super(SumPooling, self).__init__()
        self.dim = dim

    def forward(self, x):
        return torch.sum(x, self.dim)

class Dice(nn.Module):
    """
    The Data Adaptive Activation Function in DIN, a generalization of PReLu.
    """
    def __init__(self, emb_size, dim=2, epsilon=1e-8):
        super(Dice, self).__init__()
        assert dim == 2 or dim == 3

        self.bn = nn.BatchNorm1d(emb_size, eps=epsilon)
        self.sigmoid = nn.Sigmoid()
        self.dim = dim
        
        # wrap alpha in nn.Parameter to make it trainable
        self.alpha = nn.Parameter(torch.zeros((emb_size,))) if self.dim == 2 else nn.Parameter(
            torch.zeros((emb_size, 1)))


    def forward(self, x):
        assert x.dim() == self.dim
        if self.dim == 2:
            x_p = self.sigmoid(self.bn(x))
            out = self.alpha * (1 - x_p) * x + x_p * x
        else:
            x = torch.transpose(x, 1, 2)
            x_p = self.sigmoid(self.bn(x))
            out = self.alpha * (1 - x_p) * x + x_p * x
            out = torch.transpose(out, 1, 2)
        return out


class Identity(nn.Module):
    def __init__(self):
        super().__init__()
    def forward(self, x):
        return x
    
def get_activation_layer(name, hidden_size=None, dice_dim=2):
    name = name.lower()
    name_dict = {x.lower():x for x in dir(nn) if '__' not in x and 'Z'>=x[0]>='A'}
    if name=="linear":
        return Identity()
    elif name=="dice":
        assert dice_dim
        return Dice(hidden_size, dice_dim)
    else:
        assert name in name_dict, f'activation type {name} not supported!'
        return getattr(nn,name_dict[name])()
    
def init_weights(model):
    if isinstance(model, nn.Linear):
        if model.weight is not None:
            nn.init.kaiming_uniform_(model.weight.data)
        if model.bias is not None:
            nn.init.normal_(model.bias.data)
    elif isinstance(model, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):
        if model.weight is not None:
            nn.init.normal_(model.weight.data, mean=1, std=0.02)
        if model.bias is not None:
            nn.init.constant_(model.bias.data, 0)
    else:
        pass


class MLP(nn.Module):
    def __init__(self, input_size, hidden_layers,
                 dropout=0.0, batchnorm=True, activation='relu'):
        super(MLP, self).__init__()
        modules = OrderedDict()
        previous_size = input_size
        for index, hidden_layer in enumerate(hidden_layers):
            modules[f"dense{index}"] = nn.Linear(previous_size, hidden_layer)
            if batchnorm:
                modules[f"batchnorm{index}"] = nn.BatchNorm1d(hidden_layer)
            if activation:
                modules[f"activation{index}"] = get_activation_layer(activation,hidden_layer,2)
            if dropout:
                modules[f"dropout{index}"] = nn.Dropout(dropout)
            previous_size = hidden_layer
        self.mlp = nn.Sequential(modules)

    def forward(self, x):
        return self.mlp(x)
    
```

```python
import numpy as np
class Attention(nn.Module):
    def __init__(
            self,
            input_size,
            hidden_layers,
            dropout=0.0,
            batchnorm=True,
            activation='prelu',
            return_scores=False):
        
        super().__init__()
        self.return_scores = return_scores
        
        self.mlp = MLP(
            input_size=input_size * 4,
            hidden_layers=hidden_layers,
            dropout=dropout,
            batchnorm=batchnorm,
            activation=activation)
        self.fc = nn.Linear(hidden_layers[-1], 1)

    def forward(self, query, keys, keys_length):
        """
        Parameters
        ----------
        query: 2D tensor, [Batch, Hidden]
        keys: 3D tensor, [Batch, Time, Hidden]
        keys_length: 1D tensor, [Batch]

        Returns
        -------
        outputs: 2D tensor, [Batch, Hidden]
        """
        
        batch_size, max_length, dim = keys.size()

        query = query.unsqueeze(1).expand(-1, max_length, -1)

        din_all = torch.cat(
            [query, keys, query - keys, query * keys], dim=-1)

        din_all = din_all.view(batch_size * max_length, -1)

        outputs = self.mlp(din_all)

        outputs = self.fc(outputs).view(batch_size, max_length)  # [B, T]

        # Scale
        outputs = outputs / (dim ** 0.5)

        # Mask
        mask = (torch.arange(max_length, device=keys_length.device).repeat(
            batch_size, 1) < keys_length.view(-1, 1))
        outputs[~mask] = -np.inf

        # Activation
        outputs = torch.sigmoid(outputs)  # [B, T]

        if not self.return_scores:
            # Weighted sum
            outputs = torch.matmul(
                outputs.unsqueeze(1), keys).squeeze()  # [B, H]
            
        return outputs 
    
```

```python
class AttentionGroup(object):
    def __init__(self, name, pairs,
                 hidden_layers, activation='dice', att_dropout=0.0):
        self.name = name
        self.pairs = pairs
        self.hidden_layers = hidden_layers
        self.activation = activation
        self.att_dropout = att_dropout

        self.related_feature_names = set()
        for pair in pairs:
            self.related_feature_names.add(pair['ad'])
            self.related_feature_names.add(pair['pos_hist'])

    def is_attention_feature(self, feature_name):
        if feature_name in self.related_feature_names:
            return True
        return False

    @property
    def pairs_count(self):
        return len(self.pairs)
    
```

```python
class DIN(nn.Module):
    def __init__(self, num_features,cat_features,seq_features, 
                 cat_nums,embedding_size, attention_groups,
                 mlp_hidden_layers, mlp_activation='prelu', mlp_dropout=0.0,
                 d_out = 1
                 ):
        super().__init__()
        self.num_features = num_features
        self.cat_features = cat_features
        self.seq_features = seq_features
        self.cat_nums = cat_nums 
        self.embedding_size = embedding_size
        
        self.attention_groups = attention_groups
        
        self.mlp_hidden_layers = mlp_hidden_layers
        self.mlp_activation = mlp_activation
        self.mlp_dropout = mlp_dropout
        
        self.d_out = d_out
        
        #embedding
        self.embeddings = OrderedDict()
        for feature in self.cat_features+self.seq_features:
            self.embeddings[feature] = nn.Embedding(
                self.cat_nums[feature], self.embedding_size, padding_idx=0)
            self.add_module(f"embedding:{feature}",self.embeddings[feature])

        self.sequence_poolings = OrderedDict()
        self.attention_poolings = OrderedDict()
        total_embedding_sizes = 0
        for feature in self.cat_features:
            total_embedding_sizes += self.embedding_size
        for feature in self.seq_features:
            total_embedding_sizes += self.embedding_size
        
        #sequence_pooling
        for feature in self.seq_features:
            if not self.is_attention_feature(feature):
                self.sequence_poolings[feature] = MaxPooling(1)
                self.add_module(f"pooling:{feature}",self.sequence_poolings[feature])

        #attention_pooling
        for attention_group in self.attention_groups:
            self.attention_poolings[attention_group.name] = (
                self.create_attention_fn(attention_group))
            self.add_module(f"attention_pooling:{attention_group.name}",
                self.attention_poolings[attention_group.name])

        total_input_size = total_embedding_sizes+len(self.num_features)
        
        self.mlp = MLP(
            total_input_size,
            mlp_hidden_layers,
            dropout=mlp_dropout, batchnorm=True, activation=mlp_activation)
        
        self.final_layer = nn.Linear(mlp_hidden_layers[-1], self.d_out)
        self.apply(init_weights)

    def forward(self, x):
        
        final_layer_inputs = list()

        number_inputs = list()
        for feature in self.num_features:
            number_inputs.append(x[feature].view(-1, 1))

        embeddings = OrderedDict()
        for feature in self.cat_features:
            embeddings[feature] = self.embeddings[feature](x[feature])

        for feature in self.seq_features:
            if not self.is_attention_feature(feature):
                embeddings[feature] = self.sequence_poolings[feature](
                    self.embeddings[feature](x[feature]))
                
        for attention_group in self.attention_groups:
            query = torch.cat(
                [embeddings[pair['ad']]
                 for pair in attention_group.pairs],
                dim=-1)
            keys = torch.cat(
                [self.embeddings[pair['pos_hist']](
                    x[pair['pos_hist']]) for pair in attention_group.pairs],
                dim=-1)
            #hist_length = torch.sum(hist>0,axis=1)
            keys_length = torch.min(torch.cat(
                [torch.sum(x[pair['pos_hist']]>0,axis=1).view(-1, 1)
                 for pair in attention_group.pairs],
                dim=-1), dim=-1)[0]
            
            embeddings[attention_group.name] = self.attention_poolings[
                attention_group.name](query, keys, keys_length)

        emb_concat = torch.cat(number_inputs + [
            emb for emb in embeddings.values()], dim=-1)

        final_layer_inputs = self.mlp(emb_concat)
        output = self.final_layer(final_layer_inputs)
        if  self.d_out==1:
            output = output.squeeze() 

        return output

    def create_attention_fn(self, attention_group):
        return Attention(
            attention_group.pairs_count * self.embedding_size,
            hidden_layers=attention_group.hidden_layers,
            dropout=attention_group.att_dropout,
            activation=attention_group.activation)
    
    def is_attention_feature(self, feature):
        for group in self.attention_groups:
            if group.is_attention_feature(feature):
                return True
        return False
    
```

```python

```

## ä¸‰ï¼ŒMovielensæ•°æ®é›†å®Œæ•´èŒƒä¾‹


ä¸‹é¢æ˜¯ä¸€ä¸ªåŸºäºMovielensè¯„ä»·æ•°æ®é›†çš„å®Œæ•´èŒƒä¾‹ï¼Œæ ¹æ®ç”¨æˆ·è¿‡å»å¯¹ä¸€äº›ç”µå½±çš„è¯„ä»·ç»“æœï¼Œæ¥é¢„æµ‹ç”¨æˆ·å¯¹å€™é€‰ç”µå½±æ˜¯å¦ä¼šç»™å¥½è¯„ã€‚

è¿™ä¸ªæ•°æ®é›†ä¸å¤§ï¼Œç”¨CPUå°±èƒ½è·‘ã€‚ğŸ˜



### 1ï¼Œå‡†å¤‡æ•°æ®

```python
import numpy as np 
import pandas as pd 
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import QuantileTransformer
from sklearn.pipeline import Pipeline, FeatureUnion 
from sklearn.impute import SimpleImputer 
from collections import Counter

#ç±»åˆ«ç‰¹å¾é¢„å¤„ç†
class CategoryEncoder(BaseEstimator, TransformerMixin):
    
    def __init__(self, min_cnt=5, word2idx=None, idx2word=None):
        super().__init__() 
        self.min_cnt = min_cnt
        self.word2idx = word2idx if word2idx else dict()
        self.idx2word = idx2word if idx2word else dict()

    def fit(self, x, y=None):
        if not self.word2idx:
            counter = Counter(np.asarray(x).ravel())

            selected_terms = sorted(
                list(filter(lambda x: counter[x] >= self.min_cnt, counter)))

            self.word2idx = dict(
                zip(selected_terms, range(1, len(selected_terms) + 1)))
            self.word2idx['__PAD__'] = 0
            if '__UNKNOWN__' not in self.word2idx:
                self.word2idx['__UNKNOWN__'] = len(self.word2idx)

        if not self.idx2word:
            self.idx2word = {
                index: word for word, index in self.word2idx.items()}

        return self

    def transform(self, x):
        transformed_x = list()
        for term in np.asarray(x).ravel():
            try:
                transformed_x.append(self.word2idx[term])
            except KeyError:
                transformed_x.append(self.word2idx['__UNKNOWN__'])

        return np.asarray(transformed_x, dtype=np.int64)

    def dimension(self):
        return len(self.word2idx)

#åºåˆ—ç‰¹å¾é¢„å¤„ç†ï¼ˆç±»åˆ«åºåˆ—ï¼‰ 
class SequenceEncoder(BaseEstimator, TransformerMixin):
    def __init__(self, sep=' ', min_cnt=5, max_len=None,
                 word2idx=None, idx2word=None):
        super().__init__() 
        self.sep = sep
        self.min_cnt = min_cnt
        self.max_len = max_len

        self.word2idx = word2idx if word2idx else dict()
        self.idx2word = idx2word if idx2word else dict()

    def fit(self, x, y=None):
        if not self.word2idx:
            counter = Counter()

            max_len = 0
            for sequence in np.array(x).ravel():
                words = sequence.split(self.sep)
                counter.update(words)
                max_len = max(max_len, len(words))

            if self.max_len is None:
                self.max_len = max_len

            # drop rare words
            words = sorted(
                list(filter(lambda x: counter[x] >= self.min_cnt, counter)))

            self.word2idx = dict(zip(words, range(1, len(words) + 1)))
            self.word2idx['__PAD__'] = 0
            if '__UNKNOWN__' not in self.word2idx:
                self.word2idx['__UNKNOWN__'] = len(self.word2idx)

        if not self.idx2word:
            self.idx2word = {
                index: word for word, index in self.word2idx.items()}

        if not self.max_len:
            max_len = 0
            for sequence in np.array(x).ravel():
                words = sequence.split(self.sep)
                max_len = max(max_len, len(words))
            self.max_len = max_len

        return self

    def transform(self, x):
        transformed_x = list()

        for sequence in np.asarray(x).ravel():
            words = list()
            for word in sequence.split(self.sep):
                try:
                    words.append(self.word2idx[word])
                except KeyError:
                    words.append(self.word2idx['__UNKNOWN__'])

            transformed_x.append(
                np.asarray(words[0:self.max_len], dtype=np.int64))

        return np.asarray(transformed_x, dtype=object)
    
    def dimension(self):
        return len(self.word2idx)

    def max_length(self):
        return self.max_len

    
```

```python

```

```python
from sklearn.preprocessing import QuantileTransformer
from sklearn.pipeline import Pipeline 
from sklearn.impute import SimpleImputer 
from tqdm import tqdm 

dftrain = pd.read_csv("./eat_pytorch_datasets/ml_1m/train.csv")
dfval = pd.read_csv("./eat_pytorch_datasets/ml_1m/test.csv")

for col in ["movieId","histHighRatedMovieIds","negHistMovieIds","genres"]:
    dftrain[col] = dftrain[col].astype(str)
    dfval[col] = dfval[col].astype(str)

num_features = ['age']
cat_features = ['gender', 'movieId', 'occupation', 'zipCode']
seq_features = ['genres', 'histHighRatedMovieIds', 'negHistMovieIds']

num_pipe = Pipeline(steps = [('impute',SimpleImputer()),('quantile',QuantileTransformer())])

encoders = {}

print("preprocess number features...")
dftrain[num_features] = num_pipe.fit_transform(dftrain[num_features]).astype(np.float32)
dfval[num_features] = num_pipe.transform(dfval[num_features]).astype(np.float32)

print("preprocess category features...")
for col in tqdm(cat_features):
    encoders[col] = CategoryEncoder(min_cnt=5)
    dftrain[col]  = encoders[col].fit_transform(dftrain[col])
    dfval[col] =  encoders[col].transform(dfval[col])
    
print("preprocess sequence features...")
for col in tqdm(seq_features):
    encoders[col] = SequenceEncoder(sep="|",min_cnt=5)
    dftrain[col]  = encoders[col].fit_transform(dftrain[col])
    dfval[col] =  encoders[col].transform(dfval[col])
    
from collections import OrderedDict
from itertools import chain
from torch.utils.data import Dataset,DataLoader 

class Df2Dataset(Dataset):
    def __init__(self, dfdata, num_features, cat_features,
                 seq_features, encoders, label_col="label"):
        self.dfdata = dfdata
        self.num_features = num_features
        self.cat_features = cat_features 
        self.seq_features = seq_features
        self.encoders = encoders
        self.label_col = label_col
        self.size = len(self.dfdata)

    def __len__(self):
        return self.size

    @staticmethod
    def pad_sequence(sequence,max_length):
        #zero is special index for padding
        padded_seq = np.zeros(max_length, np.int32)
        padded_seq[0: sequence.shape[0]] = sequence
        return padded_seq

    def __getitem__(self, idx):
        record = OrderedDict()
        for col in self.num_features:
            record[col] = self.dfdata[col].iloc[idx].astype(np.float32)
            
        for col in self.cat_features:
            record[col] = self.dfdata[col].iloc[idx].astype(np.int64)
            
        for col in self.seq_features:
            seq = self.dfdata[col].iloc[idx]
            max_length = self.encoders[col].max_length()
            record[col] = Df2Dataset.pad_sequence(seq,max_length)

        if self.label_col is not None:
            record['label'] = self.dfdata[self.label_col].iloc[idx].astype(np.float32)
        return record

    def get_num_batches(self, batch_size):
        return np.ceil(self.size / batch_size)
    
ds_train = Df2Dataset(dftrain, num_features, cat_features, seq_features, encoders)
ds_val = Df2Dataset(dfval,num_features, cat_features, seq_features, encoders)
dl_train = DataLoader(ds_train, batch_size=128,shuffle=True)
dl_val = DataLoader(ds_val,batch_size=128,shuffle=False)

cat_nums = {k:v.dimension() for k,v in encoders.items()} 

```

```python
for batch in dl_train:
    break 
```

```python

```

### 2ï¼Œå®šä¹‰æ¨¡å‹

```python
def create_net():
    din_attention_groups = [
        AttentionGroup(
            name='group1',
            pairs=[{'ad': 'movieId', 'pos_hist': 'histHighRatedMovieIds'}],
            activation='dice',
            hidden_layers=[16, 8], att_dropout=0.1)
    ]

    net = DIN(num_features=num_features,
               cat_features=cat_features,
               seq_features=seq_features,
               cat_nums = cat_nums,
               embedding_size=16,
               attention_groups=din_attention_groups,
               mlp_hidden_layers=[32,16],
               mlp_activation="prelu",
               mlp_dropout=0.25,
               d_out=1
               )
    return net 

net = create_net() 

out = net.forward(batch)

```

```python

```

```python
from torchkeras.summary import summary 
summary(net,input_data=batch);

```

### 3ï¼Œè®­ç»ƒæ¨¡å‹

```python

```

```python
import os,sys,time
import numpy as np
import pandas as pd
import datetime 
from tqdm import tqdm 

import torch
from torch import nn 
from accelerate import Accelerator
from copy import deepcopy


def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(str(info)+"\n")
    
class StepRunner:
    def __init__(self, net, loss_fn,stage = "train", metrics_dict = None, 
                 optimizer = None, lr_scheduler = None,
                 accelerator = None
                 ):
        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage
        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler
        self.accelerator = accelerator
    
    def __call__(self, batch):
        #loss
        preds = self.net(batch)
        loss = self.loss_fn(preds,batch["label"])

        #backward()
        if self.optimizer is not None and self.stage=="train":
            if self.accelerator is  None:
                loss.backward()
            else:
                self.accelerator.backward(loss)
            self.optimizer.step()
            if self.lr_scheduler is not None:
                self.lr_scheduler.step()
            self.optimizer.zero_grad()
            
        #metrics
        step_metrics = {self.stage+"_"+name:metric_fn(preds, batch["label"]).item() 
                        for name,metric_fn in self.metrics_dict.items()}
        return loss.item(),step_metrics
    
    
class EpochRunner:
    def __init__(self,steprunner):
        self.steprunner = steprunner
        self.stage = steprunner.stage
        self.steprunner.net.train() if self.stage=="train" else self.steprunner.net.eval()
        
    def __call__(self,dataloader):
        total_loss,step = 0,0
        loop = tqdm(enumerate(dataloader), total =len(dataloader))
        for i, batch in loop:
            if self.stage=="train":
                loss, step_metrics = self.steprunner(batch)
            else:
                with torch.no_grad():
                    loss, step_metrics = self.steprunner(batch)

            step_log = dict({self.stage+"_loss":loss},**step_metrics)

            total_loss += loss
            step+=1
            if i!=len(dataloader)-1:
                loop.set_postfix(**step_log)
            else:
                epoch_loss = total_loss/step
                epoch_metrics = {self.stage+"_"+name:metric_fn.compute().item() 
                                 for name,metric_fn in self.steprunner.metrics_dict.items()}
                epoch_log = dict({self.stage+"_loss":epoch_loss},**epoch_metrics)
                loop.set_postfix(**epoch_log)

                for name,metric_fn in self.steprunner.metrics_dict.items():
                    metric_fn.reset()
        return epoch_log

class KerasModel(torch.nn.Module):
    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None):
        super().__init__()
        self.accelerator = Accelerator()
        self.history = {}
        
        self.net = net
        self.loss_fn = loss_fn
        self.metrics_dict = nn.ModuleDict(metrics_dict) 
        
        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(
            self.parameters(), lr=1e-2)
        self.lr_scheduler = lr_scheduler
        
        self.net,self.loss_fn,self.metrics_dict,self.optimizer = self.accelerator.prepare(
            self.net,self.loss_fn,self.metrics_dict,self.optimizer)

    def forward(self, x):
        if self.net:
            return self.net.forward(x)
        else:
            raise NotImplementedError


    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint.pt', 
            patience=5, monitor="val_loss", mode="min"):
        
        train_data = self.accelerator.prepare(train_data)
        val_data = self.accelerator.prepare(val_data) if val_data else []

        for epoch in range(1, epochs+1):
            printlog("Epoch {0} / {1}".format(epoch, epochs))
            
            # 1ï¼Œtrain -------------------------------------------------  
            train_step_runner = StepRunner(net = self.net,stage="train",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    optimizer = self.optimizer, lr_scheduler = self.lr_scheduler,
                    accelerator = self.accelerator)
            train_epoch_runner = EpochRunner(train_step_runner)
            train_metrics = train_epoch_runner(train_data)
            
            for name, metric in train_metrics.items():
                self.history[name] = self.history.get(name, []) + [metric]

            # 2ï¼Œvalidate -------------------------------------------------
            if val_data:
                val_step_runner = StepRunner(net = self.net,stage="val",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    accelerator = self.accelerator)
                val_epoch_runner = EpochRunner(val_step_runner)
                with torch.no_grad():
                    val_metrics = val_epoch_runner(val_data)
                val_metrics["epoch"] = epoch
                for name, metric in val_metrics.items():
                    self.history[name] = self.history.get(name, []) + [metric]
            
            # 3ï¼Œearly-stopping -------------------------------------------------
            arr_scores = self.history[monitor]
            best_score_idx = np.argmax(arr_scores) if mode=="max" else np.argmin(arr_scores)
            if best_score_idx==len(arr_scores)-1:
                torch.save(self.net.state_dict(),ckpt_path)
                print("<<<<<< reach best {0} : {1} >>>>>>".format(monitor,
                     arr_scores[best_score_idx]),file=sys.stderr)
            if len(arr_scores)-best_score_idx>patience:
                print("<<<<<< {} without improvement in {} epoch, early stopping >>>>>>".format(
                    monitor,patience),file=sys.stderr)
                break 
                
        self.net.load_state_dict(torch.load(ckpt_path))
        return pd.DataFrame(self.history)

    @torch.no_grad()
    def evaluate(self, val_data):
        val_data = self.accelerator.prepare(val_data)
        val_step_runner = StepRunner(net = self.net,stage="val",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    accelerator = self.accelerator)
        val_epoch_runner = EpochRunner(val_step_runner)
        val_metrics = val_epoch_runner(val_data)
        return val_metrics
        
       
    @torch.no_grad()
    def predict(self, dataloader):
        dataloader = self.accelerator.prepare(dataloader)
        self.net.eval()
        result = torch.cat([self.forward(t) for t in dataloader])
        return result.data
    
```

```python

```

```python
from torchkeras.metrics import AUC

loss_fn = nn.BCEWithLogitsLoss()

metrics_dict = {"auc":AUC()}

optimizer = torch.optim.Adam(net.parameters(), lr=0.002, weight_decay=0.001) 


model = KerasModel(net,
                   loss_fn = loss_fn,
                   metrics_dict= metrics_dict,
                   optimizer = optimizer,
                  )    

```

```python
dfhistory = model.fit(train_data=dl_train,val_data=dl_val,epochs=100, patience=5,
                      monitor = "val_auc",mode="max",ckpt_path='checkpoint.pt')

```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h3sbs7wl0lj20r107nab5.jpg)


### 4ï¼Œè¯„ä¼°æ¨¡å‹

```python
%matplotlib inline
%config InlineBackend.figure_format = 'svg'

import matplotlib.pyplot as plt

def plot_metric(dfhistory, metric):
    train_metrics = dfhistory["train_"+metric]
    val_metrics = dfhistory['val_'+metric]
    epochs = range(1, len(train_metrics) + 1)
    plt.plot(epochs, train_metrics, 'bo--')
    plt.plot(epochs, val_metrics, 'ro-')
    plt.title('Training and validation '+ metric)
    plt.xlabel("Epochs")
    plt.ylabel(metric)
    plt.legend(["train_"+metric, 'val_'+metric])
    plt.show()
```

```python
plot_metric(dfhistory,"loss")
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h3sbs8ryajj20h20a1gly.jpg)




```python
plot_metric(dfhistory,"auc")
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h3sbsf8b1wj20f30a70t3.jpg)

```python
model.evaluate(dl_val)
```

{'val_loss': 0.6842133283615113, 'val_auc': 0.6392135620117188}

```python

```

### 4ï¼Œä½¿ç”¨æ¨¡å‹

```python
labels = torch.tensor([x["label"] for x in ds_val])
preds = model.predict(dl_val)
val_auc = roc_auc_score(labels.cpu().numpy(),preds.cpu().numpy())
print(val_auc)
```

0.6392135469811272

```python

```

```python

```

### 5, ä¿å­˜æ¨¡å‹

```python
torch.save(model.net.state_dict(),"best_din.pt")
net_clone = create_net()
net_clone.load_state_dict(torch.load("best_din.pt"))
```

```python
net_clone.eval()
labels = torch.tensor([x["label"] for x in ds_val])
preds = torch.cat([net_clone(x).data for x in dl_val]) 
val_auc = roc_auc_score(labels.cpu().numpy(),preds.cpu().numpy())
print(val_auc)
```

0.6392135469811272

```python

```

**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)
