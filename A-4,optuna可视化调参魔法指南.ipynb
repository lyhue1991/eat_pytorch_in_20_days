{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6086209-af84-4acc-9882-96896080051b",
   "metadata": {},
   "source": [
    "# A-4,optunaå¯è§†åŒ–è°ƒå‚é­”æ³•æŒ‡å—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69f27c",
   "metadata": {},
   "source": [
    "Optunaæ˜¯ä¸€æ¬¾å¼€æºçš„è°ƒå‚å·¥å…·ï¼Œgithub staræ•°é‡è¶…è¿‡7k, æ˜¯ç›®å‰æœ€å—æ¬¢è¿çš„è°ƒå‚æ¡†æ¶ä¹‹ä¸€ã€‚\n",
    "\n",
    "å…¶ä¸»è¦ä¼˜ç‚¹å¦‚ä¸‹ï¼š\n",
    "\n",
    "1ï¼ŒOptunaæ‹¥æœ‰è®¸å¤šéå¸¸å…ˆè¿›çš„è°ƒå‚ç®—æ³•(å¦‚è´å¶æ–¯ä¼˜åŒ–ï¼Œé—ä¼ ç®—æ³•é‡‡æ ·ç­‰)ï¼Œè¿™äº›ç®—æ³•å¾€å¾€å¯ä»¥åœ¨å‡ åä¸Šç™¾æ¬¡çš„å°è¯•è¿‡ç¨‹ä¸­æ‰¾åˆ°ä¸€ä¸ªä¸å¯å¾®é—®é¢˜çš„è¾ƒä¼˜è§£ã€‚\n",
    "\n",
    "2ï¼Œé€šè¿‡é…åˆoptuna-dashboardï¼Œå¯ä»¥å¯è§†åŒ–æ•´ä¸ªè°ƒå‚è¿‡ç¨‹ï¼Œä»å„ä¸ªæ–¹é¢åŠ æ·±å¯¹é—®é¢˜çš„ç†è§£ï¼Œè¿™æ˜¯ä¸€ä¸ªä»¤äººå¿ƒåŠ¨çš„ç‰¹æ€§ğŸ˜‹ï¼\n",
    "\n",
    "\n",
    "å¦å¤–ï¼ŒOptunaè¿˜æœ‰å¦‚ä¸‹ä¸€äº›éå¸¸å®ç”¨çš„ç‰¹æ€§ï¼š\n",
    "\n",
    "1ï¼Œé€šè¿‡å°†æœç´¢ç»“æœå­˜å‚¨åˆ°sqliteæˆ–mysqlã€postgresqlï¼ŒOptunaæ”¯æŒæ–­ç‚¹ç»­æœã€‚\n",
    "\n",
    "2ï¼ŒOptunaæ”¯æŒå‰ªæç­–ç•¥ï¼Œæå‰ç»“æŸä¸€äº›ä¸­é—´è¿”å›ç»“æœè¾ƒå·®çš„é‡‡æ ·ç‚¹ä»è€ŒåŠ å¿«æœç´¢è¿›ç¨‹ã€‚\n",
    "\n",
    "3ï¼ŒOptunaæ”¯æŒæ‰‹åŠ¨æŒ‡å®šä¸€äº›è¶…å‚é‡‡æ ·ç‚¹ï¼Œä¹Ÿå¯ä»¥æ·»åŠ å·²ç»è®¡ç®—è¿‡çš„é‡‡æ ·ç‚¹åŠå…¶ç»“æœä½œä¸ºåˆå§‹åŒ–æ ·æœ¬ç‚¹ã€‚\n",
    "\n",
    "4ï¼ŒOptunaæä¾›ask and tell æ¥å£æ¨¡å¼ï¼Œæ— éœ€æ˜¾å¼å®šä¹‰ç›®æ ‡å‡½æ•°ï¼Œç›´æ¥åœ¨å¾ªç¯ä¸­è°ƒä¼˜è¶…å‚ã€‚\n",
    "\n",
    "5ï¼ŒOptunaå°è£…äº†éå¸¸ä¸°å¯Œçš„åŸºäºplotlyçš„å¯è§†åŒ–å‡½æ•°ï¼Œä¾¿äºåˆ†æè°ƒå‚ç»“æœã€‚\n",
    "\n",
    "6ï¼Œé€šè¿‡å°†æœç´¢ç»“æœå­˜å‚¨åˆ°mysqlæˆ–postgresqlï¼Œå¹¶è®¾ç½®åˆ†å¸ƒå¼æ¨¡å¼ï¼ŒOptunaæ”¯æŒå¤šæœºåˆ†å¸ƒå¼æœç´¢ï¼Œé€šè¿‡å¹¶è¡Œæ–¹å¼åŠ å¿«æœç´¢è¿›ç¨‹ã€‚\n",
    "\n",
    "\n",
    "æˆ‘ä»¬å°†é¦–å…ˆå±•ç¤ºä¸€äº›éå¸¸å®ç”¨çš„ç»¼åˆåº”ç”¨èŒƒä¾‹æ¼”ç¤ºoptunaåœ¨ç®—æ³•è°ƒä¼˜å®è·µä¸­çš„é­”åŠ›ã€‚\n",
    "\n",
    "ç„¶åå±•ç¤ºä¸€äº›optunaçš„åŸºç¡€ç‰¹æ€§èŒƒä¾‹è¯¦ç»†è®²è§£optunaçš„ä¸»è¦ç‰¹æ€§å’ŒAPIåº”ç”¨æ–¹æ³•ã€‚\n",
    "\n",
    "\n",
    "ç»¼åˆåº”ç”¨èŒƒä¾‹ï¼š\n",
    "\n",
    "ä¸€ï¼Œoptunaå¯¹pytorchæ¨¡å‹è°ƒå‚èŒƒä¾‹\n",
    "\n",
    "äºŒï¼Œoptunaå¯¹tensorflowæ¨¡å‹è°ƒå‚èŒƒä¾‹\n",
    "\n",
    "ä¸‰ï¼Œoptunaå¯¹å¤šæ¨¡å‹åŠ æƒèåˆèŒƒä¾‹\n",
    "\n",
    "\n",
    "åŸºç¡€ç‰¹æ€§èŒƒä¾‹ï¼š\n",
    "\n",
    "å››ï¼Œå•å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹\n",
    "\n",
    "äº”ï¼Œç½‘æ ¼å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹\n",
    "\n",
    "å…­ï¼Œæ–­ç‚¹ç»­æœèŒƒä¾‹\n",
    "\n",
    "ä¸ƒï¼Œå‰ªæç­–ç•¥èŒƒä¾‹\n",
    "\n",
    "å…«ï¼Œå„ç§è°ƒå‚å¯è§†åŒ–å‡½æ•°èŒƒä¾‹\n",
    "\n",
    "ä¹ï¼Œæ‰‹åŠ¨æ·»åŠ è¶…å‚æ•°é‡‡æ ·ç‚¹èŒƒä¾‹\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef690b43",
   "metadata": {},
   "source": [
    "å‚è€ƒæ–‡æ¡£\n",
    "\n",
    "optunaå®˜æ–¹æ–‡æ¡£ï¼š https://optuna.readthedocs.io/en/stable/tutorial/index.html\n",
    "\n",
    "optunaæ›´å¤šèŒƒä¾‹åº“ï¼šhttps://github.com/optuna/optuna-examples ã€ä»·å€¼éå¸¸å¤§ï¼Œå¼ºçƒˆå»ºè®®å‚è€ƒã€‘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f1556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f05b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2464efce",
   "metadata": {},
   "source": [
    "### ã€‡ï¼Œç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18914cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install optuna-dashboard -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install plotly -i https://pypi.tuna.tsinghua.edu.cn/simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3965f23",
   "metadata": {},
   "source": [
    "åœ¨åå°å¼‚æ­¥æ‰§è¡Œæ‰“å¼€ optuna-dashboard å¯è§†åŒ– ç›‘æ§é¡µé¢ï¼Œ\n",
    "\n",
    "ç„¶åæµè§ˆå™¨ä¸­è¾“å…¥ï¼šhttp://localhost:8083/dashboard/ æŸ¥çœ‹ç›‘æ§é¡µé¢ï¼Œç±»ä¼¼tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16475b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nohup optuna-dashboard --host 0.0.0.0  --port 8083 sqlite:///optuna.db & "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88892447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ€æ­» optuna-dashboard\n",
    "#!ps aux|grep optuna-dashboard \n",
    "#!kill -9 1161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f60344",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps aux|grep optuna-dashboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d22240",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 2748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050bcccf-f945-4678-800f-2d07643d5398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e5912-38fd-4347-807d-54f99757da81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4804599",
   "metadata": {},
   "source": [
    "### ä¸€ï¼Œoptunaå¯¹pytorchæ¨¡å‹è°ƒå‚èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f63ccf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-02 11:12:27,388]\u001b[0m A new study created in RDB with name: fashion_mnist_torch\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:12:36,425]\u001b[0m Trial 0 finished with value: 0.12109375 and parameters: {'n_layers': 1, 'n_units_0': 33, 'dropout_0': 0.20531457816467388, 'optimizer': 'SGD', 'lr': 0.00020073279217809514}. Best is trial 0 with value: 0.12109375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:12:45,756]\u001b[0m Trial 1 finished with value: 0.015625 and parameters: {'n_layers': 1, 'n_units_0': 28, 'dropout_0': 0.4764051188298254, 'optimizer': 'SGD', 'lr': 2.0178216564894824e-05}. Best is trial 0 with value: 0.12109375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:12:57,205]\u001b[0m Trial 2 finished with value: 0.6546875 and parameters: {'n_layers': 1, 'n_units_0': 40, 'dropout_0': 0.14037759456974044, 'optimizer': 'Adam', 'lr': 8.60871937501394e-05}. Best is trial 2 with value: 0.6546875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:08,053]\u001b[0m Trial 3 finished with value: 0.6484375 and parameters: {'n_layers': 3, 'n_units_0': 38, 'dropout_0': 0.37926119391093016, 'n_units_1': 36, 'dropout_1': 0.33599849632612383, 'n_units_2': 57, 'dropout_2': 0.429382635588918, 'optimizer': 'Adam', 'lr': 0.0006834533942776057}. Best is trial 2 with value: 0.6546875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:18,139]\u001b[0m Trial 4 finished with value: 0.746875 and parameters: {'n_layers': 1, 'n_units_0': 33, 'dropout_0': 0.22958726580767908, 'optimizer': 'Adam', 'lr': 0.0005007113308470857}. Best is trial 4 with value: 0.746875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:22,352]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:26,266]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:39,066]\u001b[0m Trial 7 finished with value: 0.81171875 and parameters: {'n_layers': 1, 'n_units_0': 60, 'dropout_0': 0.27690840083718893, 'optimizer': 'Adam', 'lr': 0.014474568880211276}. Best is trial 7 with value: 0.81171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:13:51,440]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:14:12,769]\u001b[0m Trial 9 finished with value: 0.7953125 and parameters: {'n_layers': 2, 'n_units_0': 46, 'dropout_0': 0.2789763876085257, 'n_units_1': 60, 'dropout_1': 0.24080568452657578, 'optimizer': 'Adam', 'lr': 0.0016105658953456323}. Best is trial 7 with value: 0.81171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:14:23,161]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:14:36,389]\u001b[0m Trial 11 finished with value: 0.68046875 and parameters: {'n_layers': 2, 'n_units_0': 19, 'dropout_0': 0.31578402444151393, 'n_units_1': 64, 'dropout_1': 0.1128847476490055, 'optimizer': 'Adam', 'lr': 0.01998175022704327}. Best is trial 7 with value: 0.81171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:14:50,747]\u001b[0m Trial 12 finished with value: 0.7625 and parameters: {'n_layers': 3, 'n_units_0': 51, 'dropout_0': 0.423224371640225, 'n_units_1': 60, 'dropout_1': 0.20436751520436375, 'n_units_2': 18, 'dropout_2': 0.11530458917187913, 'optimizer': 'Adam', 'lr': 0.0036209018310348127}. Best is trial 7 with value: 0.81171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:14:55,339]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:10,687]\u001b[0m Trial 14 finished with value: 0.76171875 and parameters: {'n_layers': 2, 'n_units_0': 44, 'dropout_0': 0.3123331949410603, 'n_units_1': 47, 'dropout_1': 0.22642603607948086, 'optimizer': 'Adam', 'lr': 0.01390195036980933}. Best is trial 7 with value: 0.81171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:17,925]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:29,468]\u001b[0m Trial 16 finished with value: 0.81875 and parameters: {'n_layers': 2, 'n_units_0': 58, 'dropout_0': 0.18102784883351564, 'n_units_1': 53, 'dropout_1': 0.11593599889948075, 'optimizer': 'Adam', 'lr': 0.0016479869178747432}. Best is trial 16 with value: 0.81875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:34,123]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:39,098]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:15:50,590]\u001b[0m Trial 19 finished with value: 0.82734375 and parameters: {'n_layers': 2, 'n_units_0': 57, 'dropout_0': 0.10186665202462081, 'n_units_1': 53, 'dropout_1': 0.38459041401832517, 'optimizer': 'Adam', 'lr': 0.007727434890198083}. Best is trial 19 with value: 0.82734375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "best_value = 0.82734375\n",
      "best_params:\n",
      "{'dropout_0': 0.10186665202462081, 'dropout_1': 0.38459041401832517, 'lr': 0.007727434890198083, 'n_layers': 2, 'n_units_0': 57, 'n_units_1': 53, 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
    "\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_{}\".format(i), 16, 64)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_{}\".format(i), 0.1, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        \n",
    "        #attention here \n",
    "        trial.report(accuracy, epoch)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=3), direction=\"maximize\",\n",
    "        study_name=\"fashion_mnist_torch\", storage=storage_name,load_if_exists=True\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=20, timeout=1200)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b92d7",
   "metadata": {},
   "source": [
    "![](https://p.ipic.vip/4fjrpv.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6987bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48f79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed7a1147",
   "metadata": {},
   "source": [
    "### äºŒï¼Œoptunaå¯¹tensorflowæ¨¡å‹è°ƒå‚èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf3031fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-02 11:07:56,295]\u001b[0m A new study created in RDB with name: mnist-tf\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:02,793]\u001b[0m Trial 0 finished with value: 0.12600000202655792 and parameters: {'n_layers': 3, 'n_units_0': 42, 'dropout_0': 0.28984103665666494, 'n_units_1': 39, 'dropout_1': 0.2603956381566199, 'n_units_2': 5, 'dropout_2': 0.2557919509084582, 'learning_rate': 0.043984526529105235}. Best is trial 0 with value: 0.12600000202655792.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:07,465]\u001b[0m Trial 1 finished with value: 0.8799999952316284 and parameters: {'n_layers': 1, 'n_units_0': 32, 'dropout_0': 0.15469731865044578, 'learning_rate': 0.01845450781604031}. Best is trial 1 with value: 0.8799999952316284.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:13,867]\u001b[0m Trial 2 finished with value: 0.781000018119812 and parameters: {'n_layers': 3, 'n_units_0': 19, 'dropout_0': 0.11448373690608848, 'n_units_1': 27, 'dropout_1': 0.34349713407049337, 'n_units_2': 13, 'dropout_2': 0.4170670510656864, 'learning_rate': 0.02153707314303828}. Best is trial 1 with value: 0.8799999952316284.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:18,318]\u001b[0m Trial 3 finished with value: 0.6399999856948853 and parameters: {'n_layers': 2, 'n_units_0': 7, 'dropout_0': 0.3149109532566708, 'n_units_1': 34, 'dropout_1': 0.21675495761949304, 'learning_rate': 0.011811988149809969}. Best is trial 1 with value: 0.8799999952316284.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:24,295]\u001b[0m Trial 4 finished with value: 0.5049999952316284 and parameters: {'n_layers': 3, 'n_units_0': 6, 'dropout_0': 0.2267345387858625, 'n_units_1': 11, 'dropout_1': 0.4695925079219597, 'n_units_2': 28, 'dropout_2': 0.4009393810562977, 'learning_rate': 0.0005079052014906984}. Best is trial 1 with value: 0.8799999952316284.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:28,042]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:33,562]\u001b[0m Trial 6 finished with value: 0.8830000162124634 and parameters: {'n_layers': 2, 'n_units_0': 51, 'dropout_0': 0.41858653169684945, 'n_units_1': 47, 'dropout_1': 0.3302950378535904, 'learning_rate': 0.00505482940342642}. Best is trial 6 with value: 0.8830000162124634.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:37,449]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:42,384]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:47,582]\u001b[0m Trial 9 finished with value: 0.8920000195503235 and parameters: {'n_layers': 1, 'n_units_0': 29, 'dropout_0': 0.19122436741466836, 'learning_rate': 0.007698814404681437}. Best is trial 9 with value: 0.8920000195503235.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:52,558]\u001b[0m Trial 10 finished with value: 0.8510000109672546 and parameters: {'n_layers': 1, 'n_units_0': 17, 'dropout_0': 0.4766819949314297, 'learning_rate': 0.0015224565276997705}. Best is trial 9 with value: 0.8920000195503235.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:08:57,762]\u001b[0m Trial 11 finished with value: 0.9049999713897705 and parameters: {'n_layers': 1, 'n_units_0': 62, 'dropout_0': 0.45611973124885824, 'learning_rate': 0.003504024162733378}. Best is trial 11 with value: 0.9049999713897705.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:02,464]\u001b[0m Trial 12 finished with value: 0.9079999923706055 and parameters: {'n_layers': 1, 'n_units_0': 59, 'dropout_0': 0.22384888955958546, 'learning_rate': 0.0024974162743369756}. Best is trial 12 with value: 0.9079999923706055.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:06,532]\u001b[0m Trial 13 finished with value: 0.8889999985694885 and parameters: {'n_layers': 1, 'n_units_0': 62, 'dropout_0': 0.4964493759229309, 'learning_rate': 0.0007854601822750143}. Best is trial 12 with value: 0.9079999923706055.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:10,860]\u001b[0m Trial 14 finished with value: 0.906000018119812 and parameters: {'n_layers': 1, 'n_units_0': 64, 'dropout_0': 0.24928045309792424, 'learning_rate': 0.0021728199859401918}. Best is trial 12 with value: 0.9079999923706055.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:13,891]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:16,810]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:19,932]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:23,064]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2023-01-02 11:09:26,487]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 10.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "best_value = 0.9079999923706055\n",
      "best_params:\n",
      "{'dropout_0': 0.22384888955958546, 'learning_rate': 0.0024974162743369756, 'n_layers': 1, 'n_units_0': 59}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "N_TRAIN_EXAMPLES = 3000\n",
    "N_VALID_EXAMPLES = 1000\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout in each layer and\n",
    "    # the learning rate of RMSProp optimizer.\n",
    "\n",
    "    # We define our MLP.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    model = keras.models.Sequential()\n",
    "    for i in range(n_layers):\n",
    "        num_hidden = trial.suggest_int(\"n_units_{}\".format(i), 4, 64, log=True)\n",
    "        model.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "        dropout = trial.suggest_float(\"dropout_{}\".format(i), 0.1, 0.5)\n",
    "        model.add(layers.Dropout(rate=dropout))\n",
    "    model.add(layers.Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=RMSprop(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # The data is split between train and validation sets.\n",
    "    (x_train, y_train), (x_valid, y_valid) = keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.reshape(60000, 784)[:N_TRAIN_EXAMPLES].astype(\"float32\") / 255\n",
    "    x_valid = x_valid.reshape(10000, 784)[:N_VALID_EXAMPLES].astype(\"float32\") / 255\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = to_categorical(y_train[:N_TRAIN_EXAMPLES], CLASSES)\n",
    "    y_valid = to_categorical(y_valid[:N_VALID_EXAMPLES], CLASSES)\n",
    "\n",
    "    # Generate our trial model.\n",
    "    model = create_model(trial)\n",
    "\n",
    "    # Fit the model on the training data.\n",
    "    # The KerasPruningCallback checks for pruning condition every epoch.\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCHSIZE,\n",
    "        callbacks=[TFKerasPruningCallback(trial, \"val_accuracy\")],\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n",
    "        study_name=\"mnist-tf\", storage=storage_name,load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62aa6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2642555",
   "metadata": {},
   "source": [
    "### ä¸‰ï¼Œoptunaå¯¹å¤šæ¨¡å‹åŠ æƒèåˆèŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497e262",
   "metadata": {},
   "source": [
    "å¤šæ¨¡å‹åŠ æƒèåˆæ˜¯ä¸€ä¸ªå¸¸è§çš„æå‡æœºå™¨å­¦ä¹ æ•ˆæœçš„æ–¹æ¡ˆã€‚\n",
    "\n",
    "ä½†æ˜¯å„ä¸ªæ¨¡å‹çš„æƒé‡å¦‚ä½•ç¡®å®šå‘¢ï¼Ÿ\n",
    "\n",
    "æœ‰äº›æ–¹æ¡ˆæ˜¯ä½¿ç”¨çº¿æ€§å›å½’æˆ–è€…é€»è¾‘å›å½’æ¨¡å‹è¿›è¡Œå­¦ä¹ ï¼Œè¿™ç§æ–¹æ¡ˆä¸€èˆ¬å«åšstacking ensembleï¼Œä½†æ˜¯è¿™ç§æ–¹æ¡ˆä¸€èˆ¬æ˜¯å¯¹å¯å¾®çš„Lossè¿›è¡Œä¼˜åŒ–çš„ï¼Œæ— æ³•ç›´æ¥å¯¹auc,accç­‰ä¸å¯å¾®çš„è¯„ä»·æŒ‡æ ‡è¿›è¡Œä¼˜åŒ–ã€‚\n",
    "\n",
    "ç”±äºoptunaæ˜¯ä¸€ä¸ªå¼ºå¤§çš„ä¸å¯å¾®é—®é¢˜è°ƒä¼˜å·¥å…·ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒæ¥å¯»æ‰¾æ¨¡å‹èåˆçš„æƒé‡ï¼Œç›´æ¥å¯¹auc,accç­‰ä¸å¯å¾®çš„è¯„ä»·æŒ‡æ ‡è¿›è¡Œä¼˜åŒ–ï¼Œå½“ç»™äºˆè¶³å¤Ÿçš„æœç´¢æ¬¡æ•°æ—¶ï¼Œå…¶ç»“æœç›¸æ¯”stacking ensembleé€šå¸¸æ›´åŠ æœ‰ç«äº‰åŠ›ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "90d5ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "# ä¸€ï¼Œå‡†å¤‡æ•°æ®\n",
    "data,target = make_classification(n_samples=2000,n_features=20,\n",
    "        n_informative=12,n_redundant=4,n_repeated=0,n_classes=2,\n",
    "        n_clusters_per_class=4)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c21c2a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# äºŒï¼Œè®­ç»ƒ3ä¸ªåŸºç¡€æ¨¡å‹\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "mlp = MLPClassifier()\n",
    "svc = SVC(probability=True) \n",
    "\n",
    "mlp.fit(x_train,y_train)\n",
    "tree.fit(x_train,y_train)\n",
    "svc.fit(x_train,y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "737d582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_score: 0.9381438344093945\n",
      "tree_score: 0.7036158861885002\n",
      "svc_score: 0.9356125538698153\n"
     ]
    }
   ],
   "source": [
    "# ä¸‰ï¼Œè¯„ä¼°å•æ¨¡å‹æ•ˆæœ\n",
    "def get_test_auc(model):\n",
    "    probs = model.predict_proba(x_test)[:,1]\n",
    "    val_auc = roc_auc_score(y_test,probs)\n",
    "    return val_auc\n",
    "\n",
    "print(\"mlp_score:\",get_test_auc(mlp))\n",
    "print(\"tree_score:\",get_test_auc(tree))\n",
    "print(\"svc_score:\",get_test_auc(svc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f52f16f5-7fdd-4f74-aa61-a2ab2f4302be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking_score: 0.9440074336339896\n"
     ]
    }
   ],
   "source": [
    "# å››ï¼Œ stackingæ–¹æ¡ˆæ•ˆæœ\n",
    "from sklearn.ensemble import StackingClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[('mlp',mlp),('tree',tree),('svc',svc)],\n",
    "    final_estimator=LogisticRegression())\n",
    "stacking.fit(x_train,y_train)\n",
    "print(\"stacking_score:\",get_test_auc(stacking))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21f7cb-7a4d-4151-adb3-7db3788cd9aa",
   "metadata": {},
   "source": [
    "![](./data/stackingèåˆ.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda6f57-9b49-4057-a97a-c72980f5ad61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77b0fdaf-28be-45d1-9336-a9149145219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/liangyun2/miniforge3/envs/tf26/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# äº”ï¼Œè·å–CVé¢„æµ‹ç»“æœ\n",
    "\n",
    "# ä¸ºäº†å……åˆ†åˆ©ç”¨è®­ç»ƒæ•°æ®é›†ï¼Œé‡‡ç”¨ç±»ä¼¼stackingçš„æ–¹å¼ï¼Œç”¨5æŠ˜CVçš„æ–¹å¼è·å–å„ä¸ªæ¨¡å‹åœ¨è®­ç»ƒé›†çš„é¢„æµ‹ç»“æœ\n",
    "\n",
    "def get_cv_preds(model,x_train,y_train):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    cv_preds = np.zeros(len(y_train))\n",
    "    \n",
    "    for idx, (train_idx, valid_idx) in enumerate(cv.split(x_train, y_train)):\n",
    "        xtrain_i, xvalid_i = x_train[train_idx], x_train[valid_idx]\n",
    "        ytrain_i, yvalid_i = y_train[train_idx], y_train[valid_idx]\n",
    "        model_idx = deepcopy(model)\n",
    "        model_idx.fit(xtrain_i,ytrain_i)\n",
    "        probs_valid_idx = model_idx.predict_proba(xvalid_i)[:,1]\n",
    "        cv_preds[valid_idx] = probs_valid_idx\n",
    "    return cv_preds\n",
    "\n",
    "preds_cv = {name: get_cv_preds(eval(name),x_train,y_train)\n",
    "             for name in ['mlp','tree','svc']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ba4b770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "best_value = 0.9685616736555074\n",
      "best_params:\n",
      "{'mlp': 51, 'svc': 98, 'tree': 1}\n"
     ]
    }
   ],
   "source": [
    "# å…­ï¼Œ optunaæœç´¢èåˆæƒé‡\n",
    "\n",
    "import optuna \n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def objective(trial):\n",
    "    weights = {name:trial.suggest_int(name, 1, 100) for name in ['mlp','tree','svc']}\n",
    "    probs = sum([weights[name]*preds_cv[name] for name in ['mlp','tree','svc']])/sum(\n",
    "        [weights[name] for name in ['mlp','tree','svc']])\n",
    "    \n",
    "    cv_auc = roc_auc_score(y_train,probs)\n",
    "    trial.report(cv_auc, 0)\n",
    "    return cv_auc\n",
    "\n",
    "storage_name = \"sqlite:///optuna.db\"\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"optuna_ensemble\", storage=storage_name,load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=500, timeout=600)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aaa37176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna_ensemble_score: 0.9441195789743508\n"
     ]
    }
   ],
   "source": [
    "# ä¸ƒï¼Œ optunaæƒé‡èåˆæ•ˆæœ\n",
    "preds_test = {name:(eval(name)).predict_proba(x_test)[:,1] for name in ['mlp','tree','svc']}\n",
    "def test_score(weights):\n",
    "    probs = sum([weights[name]*preds_test[name] for name in ['mlp','tree','svc']])/sum(\n",
    "        [weights[name] for name in ['mlp','tree','svc']])\n",
    "    test_auc = roc_auc_score(y_test,probs)\n",
    "    return test_auc\n",
    "print('optuna_ensemble_score:',test_score(best_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a57d09-7571-4bc9-829b-542b7a77741c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85997229",
   "metadata": {},
   "source": [
    "æ¯”å•æ¨¡å‹çš„æœ€ä¼˜å€¼svcçš„å¾—åˆ†(0.9690)æœ‰äº›è®¸æå‡ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d4223-3f11-4cea-91df-eb41d5af382c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca2f39-5b5d-4351-8c4b-b9e4a09c97a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5235ea-d5f8-41dd-84d4-fbf8d2ad826a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28fe42-055c-49d3-91d9-f468d331c4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d2ff21-db88-4982-a639-fe9170db5136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa8b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2443798c",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹èŒƒä¾‹ä¸ºåŸºç¡€ç‰¹æ€§èŒƒä¾‹è®²è§£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4e9eb",
   "metadata": {},
   "source": [
    "### å››ï¼Œå•å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6b19f3",
   "metadata": {},
   "source": [
    "Optunaæ”¯æŒçš„è°ƒå‚ç®—æ³•ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹è¿™äº›ï¼š\n",
    "\n",
    "```\n",
    "optuna.samplers.GridSampler(ç½‘æ ¼æœç´¢é‡‡æ ·)\n",
    "optuna.samplers.RandomSampler(éšæœºæœç´¢é‡‡æ ·)\n",
    "optuna.samplers.TPESampler(è´å¶æ–¯ä¼˜åŒ–é‡‡æ ·)\n",
    "optuna.samplers.NSGAIISampler(é—ä¼ ç®—æ³•é‡‡æ ·)\n",
    "optuna.samplers.CmaEsSampler(åæ–¹å·®çŸ©é˜µè‡ªé€‚åº”æ¼”åŒ–ç­–ç•¥é‡‡æ ·ï¼Œéå¸¸å…ˆè¿›çš„ä¼˜åŒ–ç®—æ³•)\n",
    "```\n",
    "\n",
    "æ­¤å¤–ï¼Œè¿˜å¯ä»¥ç”¨ä»¥ä¸‹æ–¹æ³•å°†éƒ¨åˆ†è¶…å‚å›ºå®šï¼Œä»…å¯¹å…¶å®ƒä¸€äº›å‚æ•°è¿›è¡Œè¶…å‚ä¼˜åŒ–ã€‚\n",
    "```\n",
    "optuna.samplers.PartialFixedSampler(éƒ¨åˆ†å‚æ•°å›ºå®šé‡‡æ ·ç®—æ³•)\n",
    "```\n",
    "\n",
    "å¯ä»¥åœ¨optuna.create_studyæ—¶å€™ç”¨samplerå‚æ•°æŒ‡å®šã€‚\n",
    "\n",
    "å¦‚æœä¸æŒ‡å®šçš„è¯ï¼Œä¸€èˆ¬åœ¨å•ç›®æ ‡ä¼˜åŒ–ç®—æ³•ä¸­ï¼Œä½¿ç”¨çš„æ˜¯optuna.samplers.TPESamplerè°ƒå‚ç®—æ³•ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088930c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "import optuna\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import plotly.graph_objs as go \n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 1, å®šä¹‰ç›®æ ‡å‡½æ•°\n",
    "def objective(trial:optuna.trial.Trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "# 2, æ‰§è¡Œæœç´¢è¿‡ç¨‹\n",
    "study = optuna.create_study(\n",
    "    sampler=optuna.samplers.CmaEsSampler(),\n",
    "    direction = \"minimize\",\n",
    "    study_name = \"simple_task\")\n",
    "\n",
    "study.optimize(objective, n_trials=1000,show_progress_bar = True)\n",
    "\n",
    "# 3, è·å–æœ€ä¼˜è¶…å‚\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "# 4, ç»˜åˆ¶æœç´¢è¿‡ç¨‹\n",
    "\n",
    "dftrials = study.trials_dataframe()[[\"number\",\"value\"]]\n",
    "losses = dftrials[\"value\"].tolist()\n",
    "\n",
    "minlosses = [np.min(losses[0:i+1]) for i in range(len(losses))] \n",
    "steps = range(len(losses))\n",
    "\n",
    "dflog = pd.DataFrame({\"steps\":steps,\"losses\":losses,\"minlosses\":minlosses})\n",
    "fig = px.scatter(data_frame=dflog,x = \"steps\",y = \"losses\", size_max = 500,log_y=True)\n",
    "fig.update_traces(marker = dict(size = 20, color = \"rgba(0,0,255,0.4)\"),name = \"all\",showlegend = True)\n",
    "fig.add_traces(go.Scatter(x=list(steps), y=minlosses, name = \"best\", showlegend=True)) \n",
    "fig.update_layout(legend=dict(orientation=\"v\"))\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe93047",
   "metadata": {},
   "source": [
    "```\n",
    "best_value = 0.0013535850035239266\n",
    "best_params:\n",
    "{'x': 2.0367910995150176}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3befc61",
   "metadata": {},
   "source": [
    "![](https://p.ipic.vip/cq006d.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730afa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6986e39a",
   "metadata": {},
   "source": [
    "### äº”ï¼Œç½‘æ ¼å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef7eac",
   "metadata": {},
   "source": [
    "å¤šä¸ªå‚æ•°å¯ä»¥ç”¨å­—å…¸è¡¨è¿°æˆç½‘æ ¼å‚æ•°ç©ºé—´å½¢å¼ã€‚\n",
    "\n",
    "optunaæ”¯æŒå„ç§å„æ ·çš„è¾“å…¥å‚æ•°ç±»å‹ã€‚å¸¸è§çš„æœ‰ä»¥ä¸‹ä¸€äº›\n",
    "\n",
    "``` python\n",
    "trail = optuna.trial.Trial\n",
    "trail.suggest_categorical\n",
    "trail.suggest_discrete_uniform\n",
    "trail.suggest_float\n",
    "trail.suggest_int\n",
    "trail.suggest_loguniform\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f497ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644420f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import optuna \n",
    "\n",
    "import plotly.graph_objs as go \n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 1, å®šä¹‰ç›®æ ‡å‡½æ•°\n",
    "def objective(trial:optuna.trial.Trial):\n",
    "    x = trial.suggest_float(\"x\", -1, 1)\n",
    "    f = trial.suggest_categorical(\"f\",['sin','sinh','cos','cosh'])\n",
    "    dic = {'sin':np.sin,'cos':np.cos,'sinh':np.sinh,'cosh':np.cosh}\n",
    "    fn = dic[f]\n",
    "    return fn(x)\n",
    "\n",
    "\n",
    "# 2, æ‰§è¡Œæœç´¢è¿‡ç¨‹\n",
    "study = optuna.create_study(\n",
    "    sampler=optuna.samplers.TPESampler(seed=123),\n",
    "    direction = \"minimize\",\n",
    "    study_name = \"grid_task\")\n",
    "\n",
    "study.optimize(objective, n_trials=100,show_progress_bar = True)\n",
    "\n",
    "# 3, è·å–æœ€ä¼˜è¶…å‚\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "# 4, ç»˜åˆ¶æœç´¢è¿‡ç¨‹\n",
    "dftrials = study.trials_dataframe()[[\"number\",\"value\"]]\n",
    "display(dftrials)\n",
    "losses = dftrials[\"value\"].tolist()\n",
    "\n",
    "minlosses = [np.min(losses[0:i+1]) for i in range(len(losses))] \n",
    "steps = range(len(losses))\n",
    "\n",
    "dflog = pd.DataFrame({\"steps\":steps,\"losses\":losses,\"minlosses\":minlosses})\n",
    "fig = px.scatter(data_frame=dflog,x = \"steps\",y = \"losses\", size_max = 500)\n",
    "fig.update_traces(marker = dict(size = 20, color = \"rgba(0,0,255,0.4)\"),name = \"all\",showlegend = True)\n",
    "fig.add_traces(go.Scatter(x=list(steps), y=minlosses, name = \"best\", showlegend=True)) \n",
    "fig.update_layout(legend=dict(orientation=\"v\"))\n",
    "fig.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6a2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e593c3",
   "metadata": {},
   "source": [
    "### å…­ï¼Œæ–­ç‚¹ç»­æœèŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55235ae4",
   "metadata": {},
   "source": [
    "æœ‰æ—¶å€™è¶…å‚æœç´¢è¿‡ç¨‹ä¸­æœ‰å¯èƒ½ä¸­é—´æœºå™¨ä¼šæ­»æ‰ï¼Œå¯ä»¥ä½¿ç”¨sqlite/mysqlç­‰å­˜å‚¨æ–¹å¼å­˜å‚¨æœç´¢ç»“æœåˆ°æ•°æ®åº“æ–‡ä»¶ã€‚\n",
    "\n",
    "è¿™æ ·ä¾¿å¯ä»¥è¯»å–å†å²æœç´¢ç»“æœï¼Œç»§ç»­æœç´¢ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# 1, å®šä¹‰ç›®æ ‡å‡½æ•°\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "\n",
    "# 2, æ‰§è¡Œæœç´¢è¿‡ç¨‹\n",
    "study_name = \"example-study\"  \n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "#period0\n",
    "study0 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study0.optimize(objective, n_trials=10)\n",
    "\n",
    "#period1\n",
    "study1 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study1.optimize(objective, n_trials=10)\n",
    "\n",
    "#period2\n",
    "study2 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "dftrials = study2.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\n",
    "\n",
    "# 3, è·å–æœ€ä¼˜è¶…å‚\n",
    "best_params = study2.best_params\n",
    "best_value = study2.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "display(dftrials)\n",
    "\n",
    "\n",
    "# 4, ç»˜åˆ¶æœç´¢è¿‡ç¨‹\n",
    "fig = optuna.visualization.plot_optimization_history(study2)\n",
    "#fig.layout.yaxis.type = 'log'\n",
    "fig.update_layout({\"yaxis.type\":\"log\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c0d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd117eda",
   "metadata": {},
   "source": [
    "### ä¸ƒï¼Œå‰ªæç­–ç•¥èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89458262",
   "metadata": {},
   "source": [
    "optunaæ”¯æŒå¤šç§å‰ªæç­–ç•¥ï¼Œå¦‚æœæŸä¸ªè¶…å‚é‡‡æ ·ç‚¹è¿”å›çš„ä¸­é—´ç»“æœå’Œä¹‹å‰é‡‡æ ·ç‚¹ç›¸æ¯”è¡¨ç°å¾—æ²¡æœ‰å¸Œæœ›ï¼Œoptunaå¯ä»¥æå‰ç»“æŸè¿™ä¸ªé‡‡æ ·ç‚¹çš„è®­ç»ƒï¼Œä»è€ŒèŠ‚çº¦æ—¶é—´ã€‚\n",
    "\n",
    "* optuna.pruners.HyperbandPruner: pruner refers to http://www.jmlr.org/papers/volume18/16-558/16-558.pdf\n",
    "\n",
    "* optuna.pruners.MedianPruner: Prune if the trial's best intermediate result is worse than median of intermediate results of previous trials at the same step.\n",
    "\n",
    "* optuna.pruners.ThresholdPruner: Pruner to detect outlying metrics of the trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646efdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    iris = load_iris() \n",
    "    data,target = iris[\"data\"],iris[\"target\"]\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "    classes = list(set(target))\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=tuple(\n",
    "            [trial.suggest_int(\"n_units_l{}\".format(i), 32, 64) for i in range(3)]\n",
    "        ),\n",
    "        learning_rate_init=trial.suggest_float(\"lr_init\", 1e-5, 1e-1, log=True),\n",
    "    )\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(x_train, y_train, classes=classes)\n",
    "        value = clf.score(x_valid, y_valid)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        trial.report(value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    plot_optimization_history(study).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab7171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c095c9f",
   "metadata": {},
   "source": [
    "### å…«ï¼Œå„ç§è°ƒå‚å¯è§†åŒ–å‡½æ•°èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    iris = load_iris() \n",
    "    data,target = iris[\"data\"],iris[\"target\"]\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "    classes = list(set(target))\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=tuple(\n",
    "            [trial.suggest_int(\"n_units_l{}\".format(i), 32, 64) for i in range(3)]\n",
    "        ),\n",
    "        learning_rate_init=trial.suggest_float(\"lr_init\", 1e-5, 1e-1, log=True),\n",
    "    )\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(x_train, y_train, classes=classes)\n",
    "        value = clf.score(x_valid, y_valid)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        trial.report(value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    # Visualize the optimization history.\n",
    "    plot_optimization_history(study).show()\n",
    "\n",
    "    # Visualize the learning curves of the trials.\n",
    "    plot_intermediate_values(study).show()\n",
    "\n",
    "    # Visualize high-dimensional parameter relationships.\n",
    "    plot_parallel_coordinate(study).show()\n",
    "\n",
    "    # Select parameters to visualize.\n",
    "    plot_parallel_coordinate(study, params=[\"lr_init\", \"n_units_l0\"]).show()\n",
    "\n",
    "    # Visualize hyperparameter relationships.\n",
    "    plot_contour(study).show()\n",
    "\n",
    "    # Select parameters to visualize.\n",
    "    plot_contour(study, params=[\"n_units_l0\", \"n_units_l1\"]).show()\n",
    "\n",
    "    # Visualize individual hyperparameters.\n",
    "    plot_slice(study).show()\n",
    "\n",
    "    # Select parameter\n",
    "    # Visualize parameter importances.\n",
    "    plot_param_importances(study).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6317441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b4c1362",
   "metadata": {},
   "source": [
    "### ä¹ï¼Œæ‰‹åŠ¨æ·»åŠ è¶…å‚æ•°é‡‡æ ·ç‚¹èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d9658",
   "metadata": {},
   "source": [
    "æœ‰æ—¶å€™ï¼Œæˆ‘ä»¬åœ¨ä½¿ç”¨ç‰¹å®šçš„é‡‡æ ·ç®—æ³•ä¹‹å‰ï¼Œæƒ³å°è¯•ä¸€äº›äººå·¥æŒ‡å®šçš„è¶…å‚é‡‡æ ·ç‚¹ï¼Œåœ¨Optunaä¸­æˆ‘ä»¬å¯ä»¥ç”¨\n",
    "\n",
    "study.enqueue_trial å°†è¿™äº›äººå·¥æŒ‡å®šè¶…å‚é‡‡æ ·ç‚¹æ¨å…¥æµ‹è¯•é˜Ÿåˆ—ã€‚\n",
    "\n",
    "å¦å¤–ï¼Œå¦‚æœæˆ‘ä»¬å·²ç»æ‰‹åŠ¨æ‰§è¡Œäº†ä¸€äº›è¶…å‚é‡‡æ ·ç‚¹ï¼Œå¹¶è·å¾—äº†ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ study.add_trailçš„æ–¹æ³•\n",
    "\n",
    "å°†è¿™äº›ç»“æœæ·»åŠ åˆ°å·²è¯„ä¼°çš„è¶…å‚é‡‡æ ·ç‚¹åˆ—è¡¨ä¸­ã€‚åç»­çš„è¶…å‚æ•°é‡‡æ ·å°†ä¼šè€ƒè™‘è¿™äº›é‡‡æ ·ç‚¹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a790e2",
   "metadata": {},
   "source": [
    "**1ï¼ŒæŒ‡å®šæ‰‹å·¥é‡‡æ ·ç‚¹**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e60c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_fraction\": min(trial.suggest_float(\"bagging_fraction\", 0.4, 1.0 + 1e-12), 1),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "\n",
    "study.enqueue_trial(\n",
    "    {\n",
    "        \"bagging_fraction\": 1.0,\n",
    "        \"bagging_freq\": 0,\n",
    "        \"min_child_samples\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "study.enqueue_trial(\n",
    "    {\n",
    "        \"bagging_fraction\": 0.75,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"min_child_samples\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Add stream handler of stdout to show the messages to see Optuna works expectedly.\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45bb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd9102e",
   "metadata": {},
   "source": [
    "**2ï¼Œæ·»åŠ å·²è¯„ä¼°é‡‡æ ·ç‚¹**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7da213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_fraction\": min(trial.suggest_float(\"bagging_fraction\", 0.4, 1.0 + 1e-12), 1),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "study.add_trial(\n",
    "    optuna.trial.create_trial(\n",
    "        params={\n",
    "            \"bagging_fraction\": 1.0,\n",
    "            \"bagging_freq\": 0,\n",
    "            \"min_child_samples\": 20,\n",
    "        },\n",
    "        distributions={\n",
    "            \"bagging_fraction\": optuna.distributions.UniformDistribution(0.4, 1.0 + 1e-12),\n",
    "            \"bagging_freq\": optuna.distributions.IntUniformDistribution(0, 7),\n",
    "            \"min_child_samples\": optuna.distributions.IntUniformDistribution(5, 100),\n",
    "        },\n",
    "        value=0.94,\n",
    "    )\n",
    ")\n",
    "study.add_trial(\n",
    "    optuna.trial.create_trial(\n",
    "        params={\n",
    "            \"bagging_fraction\": 0.75,\n",
    "            \"bagging_freq\": 5,\n",
    "            \"min_child_samples\": 20,\n",
    "        },\n",
    "        distributions={\n",
    "            \"bagging_fraction\": optuna.distributions.UniformDistribution(0.4, 1.0 + 1e-12),\n",
    "            \"bagging_freq\": optuna.distributions.IntUniformDistribution(0, 7),\n",
    "            \"min_child_samples\": optuna.distributions.IntUniformDistribution(5, 100),\n",
    "        },\n",
    "        value=0.95,\n",
    "    )\n",
    ")\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56c56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
