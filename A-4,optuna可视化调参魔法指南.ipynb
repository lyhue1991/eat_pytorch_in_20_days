{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6086209-af84-4acc-9882-96896080051b",
   "metadata": {},
   "source": [
    "# A-4,optunaå¯è§†åŒ–è°ƒå‚é­”æ³•æŒ‡å—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69f27c",
   "metadata": {},
   "source": [
    "Optunaæ˜¯ä¸€æ¬¾å¼€æºçš„è°ƒå‚å·¥å…·ï¼Œgithub staræ•°é‡è¶…è¿‡7k, æ˜¯ç›®å‰æœ€å—æ¬¢è¿çš„è°ƒå‚æ¡†æ¶ä¹‹ä¸€ã€‚\n",
    "\n",
    "å…¶ä¸»è¦ä¼˜ç‚¹å¦‚ä¸‹ï¼š\n",
    "\n",
    "1ï¼ŒOptunaæ‹¥æœ‰è®¸å¤šéå¸¸å…ˆè¿›çš„è°ƒå‚ç®—æ³•(å¦‚è´å¶æ–¯ä¼˜åŒ–ï¼Œé—ä¼ ç®—æ³•é‡‡æ ·ç­‰)ï¼Œè¿™äº›ç®—æ³•å¾€å¾€å¯ä»¥åœ¨å‡ åä¸Šç™¾æ¬¡çš„å°è¯•è¿‡ç¨‹ä¸­æ‰¾åˆ°ä¸€ä¸ªä¸å¯å¾®é—®é¢˜çš„è¾ƒä¼˜è§£ã€‚\n",
    "\n",
    "2ï¼Œé€šè¿‡é…åˆoptuna-dashboardï¼Œå¯ä»¥å¯è§†åŒ–æ•´ä¸ªè°ƒå‚è¿‡ç¨‹ï¼Œä»å„ä¸ªæ–¹é¢åŠ æ·±å¯¹é—®é¢˜çš„ç†è§£ï¼Œè¿™æ˜¯ä¸€ä¸ªä»¤äººå¿ƒåŠ¨çš„ç‰¹æ€§ğŸ˜‹ï¼\n",
    "\n",
    "\n",
    "å¦å¤–ï¼ŒOptunaè¿˜æœ‰å¦‚ä¸‹ä¸€äº›éå¸¸å®ç”¨çš„ç‰¹æ€§ï¼š\n",
    "\n",
    "1ï¼Œé€šè¿‡å°†æœç´¢ç»“æœå­˜å‚¨åˆ°sqliteæˆ–mysqlã€postgresqlï¼ŒOptunaæ”¯æŒæ–­ç‚¹ç»­æœã€‚\n",
    "\n",
    "2ï¼ŒOptunaæ”¯æŒå‰ªæç­–ç•¥ï¼Œæå‰ç»“æŸä¸€äº›ä¸­é—´è¿”å›ç»“æœè¾ƒå·®çš„é‡‡æ ·ç‚¹ä»è€ŒåŠ å¿«æœç´¢è¿›ç¨‹ã€‚\n",
    "\n",
    "3ï¼ŒOptunaæ”¯æŒæ‰‹åŠ¨æŒ‡å®šä¸€äº›è¶…å‚é‡‡æ ·ç‚¹ï¼Œä¹Ÿå¯ä»¥æ·»åŠ å·²ç»è®¡ç®—è¿‡çš„é‡‡æ ·ç‚¹åŠå…¶ç»“æœä½œä¸ºåˆå§‹åŒ–æ ·æœ¬ç‚¹ã€‚\n",
    "\n",
    "4ï¼ŒOptunaæä¾›ask and tell æ¥å£æ¨¡å¼ï¼Œæ— éœ€æ˜¾å¼å®šä¹‰ç›®æ ‡å‡½æ•°ï¼Œç›´æ¥åœ¨å¾ªç¯ä¸­è°ƒä¼˜è¶…å‚ã€‚\n",
    "\n",
    "5ï¼ŒOptunaå°è£…äº†éå¸¸ä¸°å¯Œçš„åŸºäºplotlyçš„å¯è§†åŒ–å‡½æ•°ï¼Œä¾¿äºåˆ†æè°ƒå‚ç»“æœã€‚\n",
    "\n",
    "6ï¼Œé€šè¿‡å°†æœç´¢ç»“æœå­˜å‚¨åˆ°mysqlæˆ–postgresqlï¼Œå¹¶è®¾ç½®åˆ†å¸ƒå¼æ¨¡å¼ï¼ŒOptunaæ”¯æŒå¤šæœºåˆ†å¸ƒå¼æœç´¢ï¼Œé€šè¿‡å¹¶è¡Œæ–¹å¼åŠ å¿«æœç´¢è¿›ç¨‹ã€‚\n",
    "\n",
    "\n",
    "æˆ‘ä»¬å°†é¦–å…ˆå±•ç¤ºä¸€äº›éå¸¸å®ç”¨çš„ç»¼åˆåº”ç”¨èŒƒä¾‹æ¼”ç¤ºoptunaåœ¨ç®—æ³•è°ƒä¼˜å®è·µä¸­çš„é­”åŠ›ã€‚\n",
    "\n",
    "ç„¶åå±•ç¤ºä¸€äº›optunaçš„åŸºç¡€ç‰¹æ€§èŒƒä¾‹è¯¦ç»†è®²è§£optunaçš„ä¸»è¦ç‰¹æ€§å’ŒAPIåº”ç”¨æ–¹æ³•ã€‚\n",
    "\n",
    "\n",
    "ç»¼åˆåº”ç”¨èŒƒä¾‹ï¼š\n",
    "\n",
    "ä¸€ï¼Œoptunaå¯¹pytorchæ¨¡å‹è°ƒå‚èŒƒä¾‹\n",
    "\n",
    "äºŒï¼Œoptunaå¯¹tensorflowæ¨¡å‹è°ƒå‚èŒƒä¾‹\n",
    "\n",
    "ä¸‰ï¼Œoptunaå¯¹å¤šæ¨¡å‹åŠ æƒèåˆèŒƒä¾‹\n",
    "\n",
    "\n",
    "åŸºç¡€ç‰¹æ€§èŒƒä¾‹ï¼š\n",
    "\n",
    "å››ï¼Œå•å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹\n",
    "\n",
    "äº”ï¼Œç½‘æ ¼å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹\n",
    "\n",
    "å…­ï¼Œæ–­ç‚¹ç»­æœèŒƒä¾‹\n",
    "\n",
    "ä¸ƒï¼Œå‰ªæç­–ç•¥èŒƒä¾‹\n",
    "\n",
    "å…«ï¼Œå„ç§è°ƒå‚å¯è§†åŒ–å‡½æ•°èŒƒä¾‹\n",
    "\n",
    "ä¹ï¼Œæ‰‹åŠ¨æ·»åŠ è¶…å‚æ•°é‡‡æ ·ç‚¹èŒƒä¾‹\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef690b43",
   "metadata": {},
   "source": [
    "å‚è€ƒæ–‡æ¡£\n",
    "\n",
    "optunaå®˜æ–¹æ–‡æ¡£ï¼š https://optuna.readthedocs.io/en/stable/tutorial/index.html\n",
    "\n",
    "optunaæ›´å¤šèŒƒä¾‹åº“ï¼šhttps://github.com/optuna/optuna-examples ã€ä»·å€¼éå¸¸å¤§ï¼Œå¼ºçƒˆå»ºè®®å‚è€ƒã€‘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f1556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f05b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2464efce",
   "metadata": {},
   "source": [
    "### ã€‡ï¼Œç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18914cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install optuna-dashboard -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install plotly -i https://pypi.tuna.tsinghua.edu.cn/simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3965f23",
   "metadata": {},
   "source": [
    "åœ¨åå°å¼‚æ­¥æ‰§è¡Œæ‰“å¼€ optuna-dashboard å¯è§†åŒ– ç›‘æ§é¡µé¢ï¼Œ\n",
    "\n",
    "ç„¶åæµè§ˆå™¨ä¸­è¾“å…¥ï¼šhttp://localhost:8083/ æŸ¥çœ‹ç›‘æ§é¡µé¢ï¼Œç±»ä¼¼tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16475b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nohup optuna-dashboard --host 0.0.0.0  --port 8083 sqlite:///optuna.db & "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88892447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ€æ­» optuna-dashboard\n",
    "#!ps aux|grep optuna-dashboard \n",
    "#!kill -9 1161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f60344",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps aux|grep optuna-dashboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d22240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4804599",
   "metadata": {},
   "source": [
    "### ä¸€ï¼Œoptunaå¯¹pytorchæ¨¡å‹è°ƒå‚èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ccf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
    "\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_{}\".format(i), 4, 64)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_{}\".format(i), 0.1, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        \n",
    "        #attention here \n",
    "        trial.report(accuracy, epoch)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n",
    "        study_name=\"mnist-torch\", storage=storage_name,load_if_exists=False\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=20, timeout=600)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48f79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed7a1147",
   "metadata": {},
   "source": [
    "### äºŒï¼Œoptunaå¯¹tensorflowæ¨¡å‹è°ƒå‚èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3031fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "N_TRAIN_EXAMPLES = 3000\n",
    "N_VALID_EXAMPLES = 1000\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout in each layer and\n",
    "    # the learning rate of RMSProp optimizer.\n",
    "\n",
    "    # We define our MLP.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    model = keras.models.Sequential()\n",
    "    for i in range(n_layers):\n",
    "        num_hidden = trial.suggest_int(\"n_units_{}\".format(i), 4, 64, log=True)\n",
    "        model.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "        dropout = trial.suggest_float(\"dropout_{}\".format(i), 0.1, 0.5)\n",
    "        model.add(layers.Dropout(rate=dropout))\n",
    "    model.add(layers.Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=RMSprop(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # The data is split between train and validation sets.\n",
    "    (x_train, y_train), (x_valid, y_valid) = keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.reshape(60000, 784)[:N_TRAIN_EXAMPLES].astype(\"float32\") / 255\n",
    "    x_valid = x_valid.reshape(10000, 784)[:N_VALID_EXAMPLES].astype(\"float32\") / 255\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = to_categorical(y_train[:N_TRAIN_EXAMPLES], CLASSES)\n",
    "    y_valid = to_categorical(y_valid[:N_VALID_EXAMPLES], CLASSES)\n",
    "\n",
    "    # Generate our trial model.\n",
    "    model = create_model(trial)\n",
    "\n",
    "    # Fit the model on the training data.\n",
    "    # The KerasPruningCallback checks for pruning condition every epoch.\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCHSIZE,\n",
    "        callbacks=[TFKerasPruningCallback(trial, \"val_accuracy\")],\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n",
    "        study_name=\"mnist-tf\", storage=storage_name,load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62aa6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2642555",
   "metadata": {},
   "source": [
    "### ä¸‰ï¼Œoptunaå¯¹å¤šæ¨¡å‹åŠ æƒèåˆèŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4d046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "data,target = make_classification(n_samples=2000,n_features=20,\n",
    "        n_informative=12,n_redundant=4,n_repeated=0,n_classes=2,\n",
    "        n_clusters_per_class=4)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "mlp = MLPClassifier()\n",
    "svc = SVC(probability=True) \n",
    "\n",
    "\n",
    "mlp.fit(x_train,y_train)\n",
    "tree.fit(x_train,y_train)\n",
    "svc.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "def get_val_auc(model):\n",
    "    probs = model.predict_proba(x_valid)[:,1]\n",
    "    val_auc = roc_auc_score(y_valid,probs)\n",
    "    return val_auc\n",
    "\n",
    "print(\"mlp_score:\",get_val_auc(mlp))\n",
    "print(\"tree_score:\",get_val_auc(tree))\n",
    "print(\"svc_score:\",get_val_auc(svc))\n",
    "\n",
    "\n",
    "preds_val = {name:(eval(name)).predict_proba(x_valid)[:,1] for name in ['mlp','tree','svc']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa37176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna \n",
    "\n",
    "def objective(trial):\n",
    "    weights = {name:trial.suggest_int(name, 1, 100) for name in ['mlp','tree','svc']}\n",
    "    probs = sum([weights[name]*preds_val[name] for name in ['mlp','tree','svc']])/sum(\n",
    "        [weights[name] for name in ['mlp','tree','svc']])\n",
    "    \n",
    "    val_auc = roc_auc_score(y_valid,probs)\n",
    "    trial.report(val_auc, 0)\n",
    "    return val_auc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        study_name=\"ensemble\", storage=storage_name,load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e17174-a141-4184-96b8-041c3e4fc8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2443798c",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹èŒƒä¾‹ä¸ºåŸºç¡€ç‰¹æ€§èŒƒä¾‹è®²è§£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4e9eb",
   "metadata": {},
   "source": [
    "### å››ï¼Œå•å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6b19f3",
   "metadata": {},
   "source": [
    "Optunaæ”¯æŒçš„è°ƒå‚ç®—æ³•ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹è¿™äº›ï¼š\n",
    "\n",
    "```\n",
    "optuna.samplers.GridSampler(ç½‘æ ¼æœç´¢é‡‡æ ·)\n",
    "optuna.samplers.RandomSampler(éšæœºæœç´¢é‡‡æ ·)\n",
    "optuna.samplers.TPESampler(è´å¶æ–¯ä¼˜åŒ–é‡‡æ ·)\n",
    "optuna.samplers.NSGAIISampler(é—ä¼ ç®—æ³•é‡‡æ ·)\n",
    "optuna.samplers.CmaEsSampler(åæ–¹å·®çŸ©é˜µè‡ªé€‚åº”æ¼”åŒ–ç­–ç•¥é‡‡æ ·ï¼Œéå¸¸å…ˆè¿›çš„ä¼˜åŒ–ç®—æ³•)\n",
    "```\n",
    "\n",
    "æ­¤å¤–ï¼Œè¿˜å¯ä»¥ç”¨ä»¥ä¸‹æ–¹æ³•å°†éƒ¨åˆ†è¶…å‚å›ºå®šï¼Œä»…å¯¹å…¶å®ƒä¸€äº›å‚æ•°è¿›è¡Œè¶…å‚ä¼˜åŒ–ã€‚\n",
    "```\n",
    "optuna.samplers.PartialFixedSampler(éƒ¨åˆ†å‚æ•°å›ºå®šé‡‡æ ·ç®—æ³•)\n",
    "```\n",
    "\n",
    "å¯ä»¥åœ¨optuna.create_studyæ—¶å€™ç”¨samplerå‚æ•°æŒ‡å®šã€‚\n",
    "\n",
    "å¦‚æœä¸æŒ‡å®šçš„è¯ï¼Œä¸€èˆ¬åœ¨å•ç›®æ ‡ä¼˜åŒ–ç®—æ³•ä¸­ï¼Œä½¿ç”¨çš„æ˜¯optuna.samplers.TPESamplerè°ƒå‚ç®—æ³•ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088930c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "import optuna\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import plotly.graph_objs as go \n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 1, å®šä¹‰ç›®æ ‡å‡½æ•°\n",
    "def objective(trial:optuna.trial.Trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "# 2, æ‰§è¡Œæœç´¢è¿‡ç¨‹\n",
    "study = optuna.create_study(\n",
    "    sampler=optuna.samplers.CmaEsSampler(),\n",
    "    direction = \"minimize\",\n",
    "    study_name = \"simple_task\")\n",
    "\n",
    "study.optimize(objective, n_trials=1000,show_progress_bar = True)\n",
    "\n",
    "# 3, è·å–æœ€ä¼˜è¶…å‚\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "# 4, ç»˜åˆ¶æœç´¢è¿‡ç¨‹\n",
    "\n",
    "dftrials = study.trials_dataframe()[[\"number\",\"value\"]]\n",
    "losses = dftrials[\"value\"].tolist()\n",
    "\n",
    "minlosses = [np.min(losses[0:i+1]) for i in range(len(losses))] \n",
    "steps = range(len(losses))\n",
    "\n",
    "dflog = pd.DataFrame({\"steps\":steps,\"losses\":losses,\"minlosses\":minlosses})\n",
    "fig = px.scatter(data_frame=dflog,x = \"steps\",y = \"losses\", size_max = 500,log_y=True)\n",
    "fig.update_traces(marker = dict(size = 20, color = \"rgba(0,0,255,0.4)\"),name = \"all\",showlegend = True)\n",
    "fig.add_traces(go.Scatter(x=list(steps), y=minlosses, name = \"best\", showlegend=True)) \n",
    "fig.update_layout(legend=dict(orientation=\"v\"))\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6986e39a",
   "metadata": {},
   "source": [
    "### äº”ï¼Œç½‘æ ¼å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef7eac",
   "metadata": {},
   "source": [
    "å¤šä¸ªå‚æ•°å¯ä»¥ç”¨å­—å…¸è¡¨è¿°æˆç½‘æ ¼å‚æ•°ç©ºé—´å½¢å¼ã€‚\n",
    "\n",
    "optunaæ”¯æŒå„ç§å„æ ·çš„è¾“å…¥å‚æ•°ç±»å‹ã€‚å¸¸è§çš„æœ‰ä»¥ä¸‹ä¸€äº›\n",
    "\n",
    "``` python\n",
    "trail = optuna.trial.Trial\n",
    "trail.suggest_categorical\n",
    "trail.suggest_discrete_uniform\n",
    "trail.suggest_float\n",
    "trail.suggest_int\n",
    "trail.suggest_loguniform\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f497ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644420f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import optuna \n",
    "\n",
    "import plotly.graph_objs as go \n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 1, å®šä¹‰ç›®æ ‡å‡½æ•°\n",
    "def objective(trial:optuna.trial.Trial):\n",
    "    x = trial.suggest_float(\"x\", -1, 1)\n",
    "    f = trial.suggest_categorical(\"f\",['sin','sinh','cos','cosh'])\n",
    "    dic = {'sin':np.sin,'cos':np.cos,'sinh':np.sinh,'cosh':np.cosh}\n",
    "    fn = dic[f]\n",
    "    return fn(x)\n",
    "\n",
    "\n",
    "# 2, æ‰§è¡Œæœç´¢è¿‡ç¨‹\n",
    "study = optuna.create_study(\n",
    "    sampler=optuna.samplers.TPESampler(seed=123),\n",
    "    direction = \"minimize\",\n",
    "    study_name = \"grid_task\")\n",
    "\n",
    "study.optimize(objective, n_trials=100,show_progress_bar = True)\n",
    "\n",
    "# 3, è·å–æœ€ä¼˜è¶…å‚\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "# 4, ç»˜åˆ¶æœç´¢è¿‡ç¨‹\n",
    "dftrials = study.trials_dataframe()[[\"number\",\"value\"]]\n",
    "display(dftrials)\n",
    "losses = dftrials[\"value\"].tolist()\n",
    "\n",
    "minlosses = [np.min(losses[0:i+1]) for i in range(len(losses))] \n",
    "steps = range(len(losses))\n",
    "\n",
    "dflog = pd.DataFrame({\"steps\":steps,\"losses\":losses,\"minlosses\":minlosses})\n",
    "fig = px.scatter(data_frame=dflog,x = \"steps\",y = \"losses\", size_max = 500)\n",
    "fig.update_traces(marker = dict(size = 20, color = \"rgba(0,0,255,0.4)\"),name = \"all\",showlegend = True)\n",
    "fig.add_traces(go.Scatter(x=list(steps), y=minlosses, name = \"best\", showlegend=True)) \n",
    "fig.update_layout(legend=dict(orientation=\"v\"))\n",
    "fig.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6a2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e593c3",
   "metadata": {},
   "source": [
    "### å…­ï¼Œæ–­ç‚¹ç»­æœèŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55235ae4",
   "metadata": {},
   "source": [
    "æœ‰æ—¶å€™è¶…å‚æœç´¢è¿‡ç¨‹ä¸­æœ‰å¯èƒ½ä¸­é—´æœºå™¨ä¼šæ­»æ‰ï¼Œå¯ä»¥ä½¿ç”¨sqlite/mysqlç­‰å­˜å‚¨æ–¹å¼å­˜å‚¨æœç´¢ç»“æœåˆ°æ•°æ®åº“æ–‡ä»¶ã€‚\n",
    "\n",
    "è¿™æ ·ä¾¿å¯ä»¥è¯»å–å†å²æœç´¢ç»“æœï¼Œç»§ç»­æœç´¢ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# 1, å®šä¹‰ç›®æ ‡å‡½æ•°\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "\n",
    "# 2, æ‰§è¡Œæœç´¢è¿‡ç¨‹\n",
    "study_name = \"example-study\"  \n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "#period0\n",
    "study0 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study0.optimize(objective, n_trials=10)\n",
    "\n",
    "#period1\n",
    "study1 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study1.optimize(objective, n_trials=10)\n",
    "\n",
    "#period2\n",
    "study2 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "dftrials = study2.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\n",
    "\n",
    "# 3, è·å–æœ€ä¼˜è¶…å‚\n",
    "best_params = study2.best_params\n",
    "best_value = study2.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "display(dftrials)\n",
    "\n",
    "\n",
    "# 4, ç»˜åˆ¶æœç´¢è¿‡ç¨‹\n",
    "fig = optuna.visualization.plot_optimization_history(study2)\n",
    "#fig.layout.yaxis.type = 'log'\n",
    "fig.update_layout({\"yaxis.type\":\"log\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c0d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd117eda",
   "metadata": {},
   "source": [
    "### ä¸ƒï¼Œå‰ªæç­–ç•¥èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89458262",
   "metadata": {},
   "source": [
    "optunaæ”¯æŒå¤šç§å‰ªæç­–ç•¥ï¼Œå¦‚æœæŸä¸ªè¶…å‚é‡‡æ ·ç‚¹è¿”å›çš„ä¸­é—´ç»“æœå’Œä¹‹å‰é‡‡æ ·ç‚¹ç›¸æ¯”è¡¨ç°å¾—æ²¡æœ‰å¸Œæœ›ï¼Œoptunaå¯ä»¥æå‰ç»“æŸè¿™ä¸ªé‡‡æ ·ç‚¹çš„è®­ç»ƒï¼Œä»è€ŒèŠ‚çº¦æ—¶é—´ã€‚\n",
    "\n",
    "* optuna.pruners.HyperbandPruner: pruner refers to http://www.jmlr.org/papers/volume18/16-558/16-558.pdf\n",
    "\n",
    "* optuna.pruners.MedianPruner: Prune if the trial's best intermediate result is worse than median of intermediate results of previous trials at the same step.\n",
    "\n",
    "* optuna.pruners.ThresholdPruner: Pruner to detect outlying metrics of the trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646efdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    iris = load_iris() \n",
    "    data,target = iris[\"data\"],iris[\"target\"]\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "    classes = list(set(target))\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=tuple(\n",
    "            [trial.suggest_int(\"n_units_l{}\".format(i), 32, 64) for i in range(3)]\n",
    "        ),\n",
    "        learning_rate_init=trial.suggest_float(\"lr_init\", 1e-5, 1e-1, log=True),\n",
    "    )\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(x_train, y_train, classes=classes)\n",
    "        value = clf.score(x_valid, y_valid)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        trial.report(value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    plot_optimization_history(study).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab7171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c095c9f",
   "metadata": {},
   "source": [
    "### å…«ï¼Œå„ç§è°ƒå‚å¯è§†åŒ–å‡½æ•°èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    iris = load_iris() \n",
    "    data,target = iris[\"data\"],iris[\"target\"]\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "    classes = list(set(target))\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=tuple(\n",
    "            [trial.suggest_int(\"n_units_l{}\".format(i), 32, 64) for i in range(3)]\n",
    "        ),\n",
    "        learning_rate_init=trial.suggest_float(\"lr_init\", 1e-5, 1e-1, log=True),\n",
    "    )\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(x_train, y_train, classes=classes)\n",
    "        value = clf.score(x_valid, y_valid)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        trial.report(value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    # Visualize the optimization history.\n",
    "    plot_optimization_history(study).show()\n",
    "\n",
    "    # Visualize the learning curves of the trials.\n",
    "    plot_intermediate_values(study).show()\n",
    "\n",
    "    # Visualize high-dimensional parameter relationships.\n",
    "    plot_parallel_coordinate(study).show()\n",
    "\n",
    "    # Select parameters to visualize.\n",
    "    plot_parallel_coordinate(study, params=[\"lr_init\", \"n_units_l0\"]).show()\n",
    "\n",
    "    # Visualize hyperparameter relationships.\n",
    "    plot_contour(study).show()\n",
    "\n",
    "    # Select parameters to visualize.\n",
    "    plot_contour(study, params=[\"n_units_l0\", \"n_units_l1\"]).show()\n",
    "\n",
    "    # Visualize individual hyperparameters.\n",
    "    plot_slice(study).show()\n",
    "\n",
    "    # Select parameter\n",
    "    # Visualize parameter importances.\n",
    "    plot_param_importances(study).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6317441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b4c1362",
   "metadata": {},
   "source": [
    "### ä¹ï¼Œæ‰‹åŠ¨æ·»åŠ è¶…å‚æ•°é‡‡æ ·ç‚¹èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d9658",
   "metadata": {},
   "source": [
    "æœ‰æ—¶å€™ï¼Œæˆ‘ä»¬åœ¨ä½¿ç”¨ç‰¹å®šçš„é‡‡æ ·ç®—æ³•ä¹‹å‰ï¼Œæƒ³å°è¯•ä¸€äº›äººå·¥æŒ‡å®šçš„è¶…å‚é‡‡æ ·ç‚¹ï¼Œåœ¨Optunaä¸­æˆ‘ä»¬å¯ä»¥ç”¨\n",
    "\n",
    "study.enqueue_trial å°†è¿™äº›äººå·¥æŒ‡å®šè¶…å‚é‡‡æ ·ç‚¹æ¨å…¥æµ‹è¯•é˜Ÿåˆ—ã€‚\n",
    "\n",
    "å¦å¤–ï¼Œå¦‚æœæˆ‘ä»¬å·²ç»æ‰‹åŠ¨æ‰§è¡Œäº†ä¸€äº›è¶…å‚é‡‡æ ·ç‚¹ï¼Œå¹¶è·å¾—äº†ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ study.add_trailçš„æ–¹æ³•\n",
    "\n",
    "å°†è¿™äº›ç»“æœæ·»åŠ åˆ°å·²è¯„ä¼°çš„è¶…å‚é‡‡æ ·ç‚¹åˆ—è¡¨ä¸­ã€‚åç»­çš„è¶…å‚æ•°é‡‡æ ·å°†ä¼šè€ƒè™‘è¿™äº›é‡‡æ ·ç‚¹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a790e2",
   "metadata": {},
   "source": [
    "**1ï¼ŒæŒ‡å®šæ‰‹å·¥é‡‡æ ·ç‚¹**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e60c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_fraction\": min(trial.suggest_float(\"bagging_fraction\", 0.4, 1.0 + 1e-12), 1),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "\n",
    "study.enqueue_trial(\n",
    "    {\n",
    "        \"bagging_fraction\": 1.0,\n",
    "        \"bagging_freq\": 0,\n",
    "        \"min_child_samples\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "study.enqueue_trial(\n",
    "    {\n",
    "        \"bagging_fraction\": 0.75,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"min_child_samples\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Add stream handler of stdout to show the messages to see Optuna works expectedly.\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45bb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd9102e",
   "metadata": {},
   "source": [
    "**2ï¼Œæ·»åŠ å·²è¯„ä¼°é‡‡æ ·ç‚¹**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7da213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_fraction\": min(trial.suggest_float(\"bagging_fraction\", 0.4, 1.0 + 1e-12), 1),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "study.add_trial(\n",
    "    optuna.trial.create_trial(\n",
    "        params={\n",
    "            \"bagging_fraction\": 1.0,\n",
    "            \"bagging_freq\": 0,\n",
    "            \"min_child_samples\": 20,\n",
    "        },\n",
    "        distributions={\n",
    "            \"bagging_fraction\": optuna.distributions.UniformDistribution(0.4, 1.0 + 1e-12),\n",
    "            \"bagging_freq\": optuna.distributions.IntUniformDistribution(0, 7),\n",
    "            \"min_child_samples\": optuna.distributions.IntUniformDistribution(5, 100),\n",
    "        },\n",
    "        value=0.94,\n",
    "    )\n",
    ")\n",
    "study.add_trial(\n",
    "    optuna.trial.create_trial(\n",
    "        params={\n",
    "            \"bagging_fraction\": 0.75,\n",
    "            \"bagging_freq\": 5,\n",
    "            \"min_child_samples\": 20,\n",
    "        },\n",
    "        distributions={\n",
    "            \"bagging_fraction\": optuna.distributions.UniformDistribution(0.4, 1.0 + 1e-12),\n",
    "            \"bagging_freq\": optuna.distributions.IntUniformDistribution(0, 7),\n",
    "            \"min_child_samples\": optuna.distributions.IntUniformDistribution(5, 100),\n",
    "        },\n",
    "        value=0.95,\n",
    "    )\n",
    ")\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56c56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
