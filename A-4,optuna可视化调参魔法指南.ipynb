{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6086209-af84-4acc-9882-96896080051b",
   "metadata": {},
   "source": [
    "# optunaå¯è§†åŒ–è°ƒå‚é­”æ³•æŒ‡å—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69f27c",
   "metadata": {},
   "source": [
    "Optunaæ˜¯ä¸€æ¬¾å¼€æºçš„è°ƒå‚å·¥å…·ï¼Œgithub staræ•°é‡è¶…è¿‡7k, æ˜¯ç›®å‰æœ€å—æ¬¢è¿çš„è°ƒå‚æ¡†æ¶ä¹‹ä¸€ã€‚\n",
    "\n",
    "å…¶ä¸»è¦ä¼˜ç‚¹å¦‚ä¸‹ï¼š\n",
    "\n",
    "1ï¼ŒOptunaæ‹¥æœ‰è®¸å¤šéå¸¸å…ˆè¿›çš„è°ƒå‚ç®—æ³•(å¦‚è´å¶æ–¯ä¼˜åŒ–ï¼Œé—ä¼ ç®—æ³•é‡‡æ ·ç­‰)ï¼Œè¿™äº›ç®—æ³•å¾€å¾€å¯ä»¥åœ¨å‡ åæˆ–è€…ä¸Šç™¾æ¬¡çš„å°è¯•è¿‡ç¨‹ä¸­æ‰¾åˆ°ä¸€ä¸ªä¸å¯å¾®é—®é¢˜çš„è¾ƒä¼˜è§£ã€‚\n",
    "\n",
    "2ï¼Œé€šè¿‡é…åˆoptuna-dashboardï¼Œå¯ä»¥å¯è§†åŒ–æ•´ä¸ªè°ƒå‚è¿‡ç¨‹ï¼Œä»å„ä¸ªæ–¹é¢åŠ æ·±å¯¹é—®é¢˜çš„ç†è§£ï¼Œè¿™æ˜¯ä¸€ä¸ªä»¤äººå¿ƒåŠ¨çš„ç‰¹æ€§ğŸ˜‹ï¼\n",
    "\n",
    "\n",
    "å¦å¤–ï¼ŒOptunaè¿˜æœ‰å¦‚ä¸‹ä¸€äº›éå¸¸å®ç”¨çš„ç‰¹æ€§ï¼š\n",
    "\n",
    "1ï¼Œé€šè¿‡å°†æœç´¢ç»“æœå­˜å‚¨åˆ°sqliteæˆ–mysqlã€postgresqlï¼ŒOptunaæ”¯æŒæ–­ç‚¹ç»­æœã€‚\n",
    "\n",
    "2ï¼ŒOptunaæ”¯æŒå‰ªæç­–ç•¥ï¼Œæå‰ç»“æŸä¸€äº›ä¸­é—´è¿”å›ç»“æœè¾ƒå·®çš„é‡‡æ ·ç‚¹ä»è€ŒåŠ å¿«æœç´¢è¿›ç¨‹ã€‚\n",
    "\n",
    "3ï¼ŒOptunaæ”¯æŒæ‰‹åŠ¨æŒ‡å®šä¸€äº›è¶…å‚é‡‡æ ·ç‚¹ï¼Œä¹Ÿå¯ä»¥æ·»åŠ å·²ç»è®¡ç®—è¿‡çš„é‡‡æ ·ç‚¹åŠå…¶ç»“æœä½œä¸ºåˆå§‹åŒ–æ ·æœ¬ç‚¹ã€‚\n",
    "\n",
    "4ï¼ŒOptunaæä¾›ask and tell æ¥å£æ¨¡å¼ï¼Œæ— éœ€æ˜¾å¼å®šä¹‰ç›®æ ‡å‡½æ•°ï¼Œç›´æ¥åœ¨å¾ªç¯ä¸­è°ƒä¼˜è¶…å‚ã€‚\n",
    "\n",
    "5ï¼ŒOptunaå°è£…äº†éå¸¸ä¸°å¯Œçš„åŸºäºplotlyçš„å¯è§†åŒ–å‡½æ•°ï¼Œä¾¿äºåˆ†æè°ƒå‚ç»“æœã€‚\n",
    "\n",
    "6ï¼Œé€šè¿‡å°†æœç´¢ç»“æœå­˜å‚¨åˆ°mysqlæˆ–postgresqlï¼Œå¹¶è®¾ç½®åˆ†å¸ƒå¼æ¨¡å¼ï¼ŒOptunaæ”¯æŒå¤šæœºåˆ†å¸ƒå¼æœç´¢ï¼Œé€šè¿‡å¹¶è¡Œæ–¹å¼åŠ å¿«æœç´¢è¿›ç¨‹ã€‚\n",
    "\n",
    "\n",
    "æˆ‘ä»¬å°†é¦–å…ˆå±•ç¤ºä¸€äº›éå¸¸å®ç”¨çš„ç»¼åˆåº”ç”¨èŒƒä¾‹æ¼”ç¤ºoptunaåœ¨ç®—æ³•è°ƒä¼˜å®è·µä¸­çš„é­”åŠ›ã€‚\n",
    "\n",
    "ç„¶åå±•ç¤ºä¸€äº›optunaçš„åŸºç¡€ç‰¹æ€§èŒƒä¾‹è¯¦ç»†è®²è§£optunaçš„ä¸»è¦ç‰¹æ€§å’ŒAPIåº”ç”¨æ–¹æ³•ã€‚\n",
    "\n",
    "\n",
    "ç»¼åˆåº”ç”¨èŒƒä¾‹ï¼š\n",
    "\n",
    "ä¸€ï¼Œoptunaå¯¹pytorchæ¨¡å‹è°ƒå‚èŒƒä¾‹\n",
    "\n",
    "äºŒï¼Œoptunaå¯¹tensorflowæ¨¡å‹è°ƒå‚èŒƒä¾‹\n",
    "\n",
    "ä¸‰ï¼Œoptunaå¯¹å¤šæ¨¡å‹åŠ æƒèåˆèŒƒä¾‹\n",
    "\n",
    "\n",
    "åŸºç¡€ç‰¹æ€§èŒƒä¾‹ï¼š\n",
    "\n",
    "å››ï¼Œå•å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹\n",
    "\n",
    "äº”ï¼Œç½‘æ ¼å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹\n",
    "\n",
    "å…­ï¼Œæ–­ç‚¹ç»­æœèŒƒä¾‹\n",
    "\n",
    "ä¸ƒï¼Œå‰ªæç­–ç•¥èŒƒä¾‹\n",
    "\n",
    "å…«ï¼Œå„ç§è°ƒå‚å¯è§†åŒ–å‡½æ•°èŒƒä¾‹\n",
    "\n",
    "ä¹ï¼Œæ‰‹åŠ¨æ·»åŠ è¶…å‚æ•°é‡‡æ ·ç‚¹èŒƒä¾‹\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef690b43",
   "metadata": {},
   "source": [
    "å‚è€ƒæ–‡æ¡£\n",
    "\n",
    "optunaå®˜æ–¹æ–‡æ¡£ï¼š https://optuna.readthedocs.io/en/stable/tutorial/index.html\n",
    "\n",
    "optunaæ›´å¤šèŒƒä¾‹åº“ï¼šhttps://github.com/optuna/optuna-examples ã€ä»·å€¼éå¸¸å¤§ï¼Œå¼ºçƒˆå»ºè®®å‚è€ƒã€‘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f1556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f05b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2464efce",
   "metadata": {},
   "source": [
    "### ã€‡ï¼Œç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18914cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install optuna-dashboard -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install plotly -i https://pypi.tuna.tsinghua.edu.cn/simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3965f23",
   "metadata": {},
   "source": [
    "åœ¨åå°å¼‚æ­¥æ‰§è¡Œæ‰“å¼€ optuna-dashboard å¯è§†åŒ– ç›‘æ§é¡µé¢ï¼Œ\n",
    "\n",
    "ç„¶åæµè§ˆå™¨ä¸­è¾“å…¥ï¼šhttp://localhost:8083/ æŸ¥çœ‹ç›‘æ§é¡µé¢ï¼Œç±»ä¼¼tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16475b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "nohup optuna-dashboard --host 0.0.0.0  --port 8083 sqlite:///optuna.db & "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88892447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ€æ­» optuna-dashboard\n",
    "#!ps aux|grep optuna-dashboard \n",
    "#!kill -9 1161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f60344",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps aux|grep optuna-dashboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d22240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4804599",
   "metadata": {},
   "source": [
    "### ä¸€ï¼Œoptunaå¯¹pytorchæ¨¡å‹è°ƒå‚èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63ccf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-01 20:45:28,913]\u001b[0m A new study created in RDB with name: mnist-torch\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:45:37,689]\u001b[0m Trial 0 finished with value: 0.728125 and parameters: {'n_layers': 3, 'n_units_0': 42, 'dropout_0': 0.3973726172339308, 'n_units_1': 8, 'dropout_1': 0.1347779862385118, 'n_units_2': 15, 'dropout_2': 0.28132937564786487, 'optimizer': 'Adam', 'lr': 0.006406277616693176}. Best is trial 0 with value: 0.728125.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:45:47,095]\u001b[0m Trial 1 finished with value: 0.7359375 and parameters: {'n_layers': 2, 'n_units_0': 22, 'dropout_0': 0.3311503966703147, 'n_units_1': 12, 'dropout_1': 0.39786396073563846, 'optimizer': 'Adam', 'lr': 0.003226174530544022}. Best is trial 1 with value: 0.7359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:45:55,493]\u001b[0m Trial 2 finished with value: 0.5109375 and parameters: {'n_layers': 2, 'n_units_0': 41, 'dropout_0': 0.22723056983664588, 'n_units_1': 30, 'dropout_1': 0.3959097858977374, 'optimizer': 'Adam', 'lr': 0.06004194900526427}. Best is trial 1 with value: 0.7359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:46:04,952]\u001b[0m Trial 3 finished with value: 0.096875 and parameters: {'n_layers': 3, 'n_units_0': 62, 'dropout_0': 0.15080116335088056, 'n_units_1': 46, 'dropout_1': 0.29048103730405395, 'n_units_2': 46, 'dropout_2': 0.22851774815955564, 'optimizer': 'SGD', 'lr': 1.1518160611048243e-05}. Best is trial 1 with value: 0.7359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:46:13,435]\u001b[0m Trial 4 finished with value: 0.22265625 and parameters: {'n_layers': 1, 'n_units_0': 8, 'dropout_0': 0.4973124633516176, 'optimizer': 'Adam', 'lr': 3.212399901476767e-05}. Best is trial 1 with value: 0.7359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:46:22,492]\u001b[0m Trial 5 finished with value: 0.290625 and parameters: {'n_layers': 2, 'n_units_0': 58, 'dropout_0': 0.20998026655521948, 'n_units_1': 59, 'dropout_1': 0.3869521453882322, 'optimizer': 'Adam', 'lr': 0.06623131930431714}. Best is trial 1 with value: 0.7359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:46:31,275]\u001b[0m Trial 6 finished with value: 0.11953125 and parameters: {'n_layers': 1, 'n_units_0': 32, 'dropout_0': 0.12386290449272935, 'optimizer': 'SGD', 'lr': 1.8440517224954872e-05}. Best is trial 1 with value: 0.7359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:46:39,999]\u001b[0m Trial 7 finished with value: 0.8171875 and parameters: {'n_layers': 2, 'n_units_0': 61, 'dropout_0': 0.21910559365164334, 'n_units_1': 60, 'dropout_1': 0.26865843992578076, 'optimizer': 'RMSprop', 'lr': 0.0015546177266116976}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:46:48,699]\u001b[0m Trial 8 finished with value: 0.73828125 and parameters: {'n_layers': 3, 'n_units_0': 56, 'dropout_0': 0.26062367903733485, 'n_units_1': 52, 'dropout_1': 0.3986828954526025, 'n_units_2': 31, 'dropout_2': 0.21661209723395097, 'optimizer': 'Adam', 'lr': 0.0009665700498254316}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:46:56,498]\u001b[0m Trial 9 finished with value: 0.68671875 and parameters: {'n_layers': 2, 'n_units_0': 21, 'dropout_0': 0.2830419224740134, 'n_units_1': 17, 'dropout_1': 0.3066144747221796, 'optimizer': 'RMSprop', 'lr': 0.00032263969123574654}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:47:05,025]\u001b[0m Trial 10 finished with value: 0.69375 and parameters: {'n_layers': 1, 'n_units_0': 48, 'dropout_0': 0.361880033162381, 'optimizer': 'RMSprop', 'lr': 0.00014654526758694987}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:47:14,476]\u001b[0m Trial 11 finished with value: 0.71171875 and parameters: {'n_layers': 3, 'n_units_0': 53, 'dropout_0': 0.2524388760210976, 'n_units_1': 61, 'dropout_1': 0.4948950021552012, 'n_units_2': 27, 'dropout_2': 0.47934207847400645, 'optimizer': 'RMSprop', 'lr': 0.0012914629522542559}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:47:24,190]\u001b[0m Trial 12 finished with value: 0.74609375 and parameters: {'n_layers': 3, 'n_units_0': 59, 'dropout_0': 0.18316641500556743, 'n_units_1': 47, 'dropout_1': 0.20881269973709735, 'n_units_2': 64, 'dropout_2': 0.1311710473809658, 'optimizer': 'RMSprop', 'lr': 0.006442793561161351}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:47:32,954]\u001b[0m Trial 13 finished with value: 0.77265625 and parameters: {'n_layers': 2, 'n_units_0': 63, 'dropout_0': 0.18349143630280376, 'n_units_1': 41, 'dropout_1': 0.1779830405362956, 'optimizer': 'RMSprop', 'lr': 0.012379496209847931}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:47:42,300]\u001b[0m Trial 14 finished with value: 0.63125 and parameters: {'n_layers': 2, 'n_units_0': 63, 'dropout_0': 0.16574872731784243, 'n_units_1': 34, 'dropout_1': 0.18088793240090018, 'optimizer': 'RMSprop', 'lr': 0.017512849313779746}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:47:50,778]\u001b[0m Trial 15 finished with value: 0.73046875 and parameters: {'n_layers': 2, 'n_units_0': 48, 'dropout_0': 0.10635084388014887, 'n_units_1': 41, 'dropout_1': 0.25053370901656685, 'optimizer': 'RMSprop', 'lr': 0.020080322507541135}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:47:59,030]\u001b[0m Trial 16 finished with value: 0.7984375 and parameters: {'n_layers': 1, 'n_units_0': 31, 'dropout_0': 0.2060722561343224, 'optimizer': 'RMSprop', 'lr': 0.0007342091346173742}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:48:06,930]\u001b[0m Trial 17 finished with value: 0.16640625 and parameters: {'n_layers': 1, 'n_units_0': 28, 'dropout_0': 0.4205353671852473, 'optimizer': 'SGD', 'lr': 0.00014524006074697056}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:48:14,173]\u001b[0m Trial 18 finished with value: 0.75546875 and parameters: {'n_layers': 1, 'n_units_0': 18, 'dropout_0': 0.292091262939927, 'optimizer': 'RMSprop', 'lr': 0.0008950676488352882}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:48:21,304]\u001b[0m Trial 19 finished with value: 0.76171875 and parameters: {'n_layers': 1, 'n_units_0': 39, 'dropout_0': 0.20942160952846622, 'optimizer': 'RMSprop', 'lr': 0.00033442548752637686}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:48:28,691]\u001b[0m Trial 20 finished with value: 0.515625 and parameters: {'n_layers': 1, 'n_units_0': 10, 'dropout_0': 0.332763095322947, 'optimizer': 'RMSprop', 'lr': 7.180898748092936e-05}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:48:36,467]\u001b[0m Trial 21 finished with value: 0.79453125 and parameters: {'n_layers': 2, 'n_units_0': 50, 'dropout_0': 0.18605598470386153, 'n_units_1': 25, 'dropout_1': 0.12469171293240566, 'optimizer': 'RMSprop', 'lr': 0.0029265693464428587}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:48:44,216]\u001b[0m Trial 22 finished with value: 0.803125 and parameters: {'n_layers': 2, 'n_units_0': 50, 'dropout_0': 0.24404136956722333, 'n_units_1': 26, 'dropout_1': 0.10046802762142358, 'optimizer': 'RMSprop', 'lr': 0.002479804284021776}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:48:51,509]\u001b[0m Trial 23 finished with value: 0.7546875 and parameters: {'n_layers': 2, 'n_units_0': 34, 'dropout_0': 0.2498929747886867, 'n_units_1': 22, 'dropout_1': 0.32522896608091806, 'optimizer': 'RMSprop', 'lr': 0.001902117823924209}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:49:00,807]\u001b[0m Trial 24 finished with value: 0.7953125 and parameters: {'n_layers': 2, 'n_units_0': 46, 'dropout_0': 0.23782951552161016, 'n_units_1': 64, 'dropout_1': 0.24281560758436765, 'optimizer': 'RMSprop', 'lr': 0.0004192459987528893}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:49:09,463]\u001b[0m Trial 25 finished with value: 0.32265625 and parameters: {'n_layers': 1, 'n_units_0': 28, 'dropout_0': 0.13862719652975014, 'optimizer': 'SGD', 'lr': 0.0008127732056492315}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:49:18,934]\u001b[0m Trial 26 finished with value: 0.6453125 and parameters: {'n_layers': 3, 'n_units_0': 54, 'dropout_0': 0.3107248910074605, 'n_units_1': 4, 'dropout_1': 0.10095777009242457, 'n_units_2': 64, 'dropout_2': 0.44415085240487173, 'optimizer': 'RMSprop', 'lr': 0.0041939997044832394}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:49:27,394]\u001b[0m Trial 27 finished with value: 0.74296875 and parameters: {'n_layers': 2, 'n_units_0': 37, 'dropout_0': 0.21584935733870983, 'n_units_1': 22, 'dropout_1': 0.4645734554525547, 'optimizer': 'RMSprop', 'lr': 0.0017844453791947853}. Best is trial 7 with value: 0.8171875.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-01 20:49:36,153]\u001b[0m Trial 28 finished with value: 0.79609375 and parameters: {'n_layers': 1, 'n_units_0': 43, 'dropout_0': 0.26861880352536294, 'optimizer': 'RMSprop', 'lr': 0.0006070953136343156}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:49:44,332]\u001b[0m Trial 29 finished with value: 0.0984375 and parameters: {'n_layers': 3, 'n_units_0': 14, 'dropout_0': 0.3096917736184799, 'n_units_1': 35, 'dropout_1': 0.3553691052183287, 'n_units_2': 6, 'dropout_2': 0.37507530160619185, 'optimizer': 'SGD', 'lr': 0.008192792993332584}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:49:53,243]\u001b[0m Trial 30 finished with value: 0.66953125 and parameters: {'n_layers': 2, 'n_units_0': 44, 'dropout_0': 0.4042441825312127, 'n_units_1': 56, 'dropout_1': 0.2659894549234641, 'optimizer': 'RMSprop', 'lr': 0.0001931170912252941}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:50:02,497]\u001b[0m Trial 31 finished with value: 0.803125 and parameters: {'n_layers': 1, 'n_units_0': 51, 'dropout_0': 0.26319928005470794, 'optimizer': 'RMSprop', 'lr': 0.000697463373979943}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:50:11,319]\u001b[0m Trial 32 finished with value: 0.8171875 and parameters: {'n_layers': 1, 'n_units_0': 51, 'dropout_0': 0.19926346798411637, 'optimizer': 'RMSprop', 'lr': 0.0025412662903661317}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:50:20,938]\u001b[0m Trial 33 finished with value: 0.79296875 and parameters: {'n_layers': 1, 'n_units_0': 52, 'dropout_0': 0.23689337246404077, 'optimizer': 'RMSprop', 'lr': 0.0029400210689762537}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:50:31,653]\u001b[0m Trial 34 finished with value: 0.7875 and parameters: {'n_layers': 2, 'n_units_0': 59, 'dropout_0': 0.3550443423103566, 'n_units_1': 29, 'dropout_1': 0.2037719074946164, 'optimizer': 'RMSprop', 'lr': 0.0019333364019151653}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:50:40,661]\u001b[0m Trial 35 finished with value: 0.81328125 and parameters: {'n_layers': 1, 'n_units_0': 55, 'dropout_0': 0.2836526069095708, 'optimizer': 'Adam', 'lr': 0.004770365783414522}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:50:49,395]\u001b[0m Trial 36 finished with value: 0.7859375 and parameters: {'n_layers': 2, 'n_units_0': 56, 'dropout_0': 0.16326669034605823, 'n_units_1': 39, 'dropout_1': 0.44188776606191993, 'optimizer': 'Adam', 'lr': 0.004674180558681793}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:50:58,950]\u001b[0m Trial 37 finished with value: 0.78125 and parameters: {'n_layers': 1, 'n_units_0': 60, 'dropout_0': 0.2759468245421151, 'optimizer': 'Adam', 'lr': 0.03808365502536313}. Best is trial 7 with value: 0.8171875.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:51:07,992]\u001b[0m Trial 38 finished with value: 0.83359375 and parameters: {'n_layers': 1, 'n_units_0': 56, 'dropout_0': 0.33376974350150346, 'optimizer': 'Adam', 'lr': 0.00941298075183155}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:51:17,502]\u001b[0m Trial 39 finished with value: 0.8015625 and parameters: {'n_layers': 1, 'n_units_0': 64, 'dropout_0': 0.330545515963461, 'optimizer': 'Adam', 'lr': 0.010381245027041177}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:51:27,559]\u001b[0m Trial 40 finished with value: 0.71953125 and parameters: {'n_layers': 1, 'n_units_0': 56, 'dropout_0': 0.3912286532933859, 'optimizer': 'Adam', 'lr': 0.029092419277426725}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:51:36,824]\u001b[0m Trial 41 finished with value: 0.82890625 and parameters: {'n_layers': 1, 'n_units_0': 56, 'dropout_0': 0.2308936950920121, 'optimizer': 'Adam', 'lr': 0.005239477287671573}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:51:46,392]\u001b[0m Trial 42 finished with value: 0.81875 and parameters: {'n_layers': 1, 'n_units_0': 57, 'dropout_0': 0.46689908010370895, 'optimizer': 'Adam', 'lr': 0.005479392018355863}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:51:55,906]\u001b[0m Trial 43 finished with value: 0.80546875 and parameters: {'n_layers': 1, 'n_units_0': 60, 'dropout_0': 0.46687136727322254, 'optimizer': 'Adam', 'lr': 0.008875541814758931}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:52:04,644]\u001b[0m Trial 44 finished with value: 0.81015625 and parameters: {'n_layers': 1, 'n_units_0': 57, 'dropout_0': 0.46532057074013683, 'optimizer': 'Adam', 'lr': 0.0013847822322467607}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:52:13,062]\u001b[0m Trial 45 finished with value: 0.775 and parameters: {'n_layers': 1, 'n_units_0': 61, 'dropout_0': 0.49072265370914103, 'optimizer': 'Adam', 'lr': 0.014416376131096916}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:52:21,406]\u001b[0m Trial 46 finished with value: 0.82421875 and parameters: {'n_layers': 1, 'n_units_0': 47, 'dropout_0': 0.1921138942870542, 'optimizer': 'Adam', 'lr': 0.006195546350478788}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:52:30,161]\u001b[0m Trial 47 finished with value: 0.34375 and parameters: {'n_layers': 1, 'n_units_0': 4, 'dropout_0': 0.22634546298223476, 'optimizer': 'Adam', 'lr': 0.006674687891238209}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:52:38,793]\u001b[0m Trial 48 finished with value: 0.7328125 and parameters: {'n_layers': 1, 'n_units_0': 46, 'dropout_0': 0.195459298717711, 'optimizer': 'Adam', 'lr': 0.03944185130333013}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:52:47,359]\u001b[0m Trial 49 finished with value: 0.8328125 and parameters: {'n_layers': 1, 'n_units_0': 41, 'dropout_0': 0.13833401547274096, 'optimizer': 'Adam', 'lr': 0.003695656823840766}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:52:55,798]\u001b[0m Trial 50 finished with value: 0.79765625 and parameters: {'n_layers': 1, 'n_units_0': 41, 'dropout_0': 0.12413927258007831, 'optimizer': 'Adam', 'lr': 0.024166843734971383}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:53:04,253]\u001b[0m Trial 51 finished with value: 0.83125 and parameters: {'n_layers': 1, 'n_units_0': 47, 'dropout_0': 0.17294450256135116, 'optimizer': 'Adam', 'lr': 0.004123682516192166}. Best is trial 38 with value: 0.83359375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:53:13,043]\u001b[0m Trial 52 finished with value: 0.83828125 and parameters: {'n_layers': 1, 'n_units_0': 47, 'dropout_0': 0.1338785643158858, 'optimizer': 'Adam', 'lr': 0.004279568302143956}. Best is trial 52 with value: 0.83828125.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:53:21,656]\u001b[0m Trial 53 finished with value: 0.8203125 and parameters: {'n_layers': 1, 'n_units_0': 38, 'dropout_0': 0.15129841741823596, 'optimizer': 'Adam', 'lr': 0.003575778920114686}. Best is trial 52 with value: 0.83828125.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:53:30,218]\u001b[0m Trial 54 finished with value: 0.81328125 and parameters: {'n_layers': 1, 'n_units_0': 47, 'dropout_0': 0.1137724970385612, 'optimizer': 'Adam', 'lr': 0.014326452019698193}. Best is trial 52 with value: 0.83828125.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:53:38,466]\u001b[0m Trial 55 finished with value: 0.8140625 and parameters: {'n_layers': 1, 'n_units_0': 41, 'dropout_0': 0.1709860480196868, 'optimizer': 'Adam', 'lr': 0.007112970688668735}. Best is trial 52 with value: 0.83828125.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:53:47,587]\u001b[0m Trial 56 finished with value: 0.43984375 and parameters: {'n_layers': 1, 'n_units_0': 44, 'dropout_0': 0.13785255092697957, 'optimizer': 'Adam', 'lr': 0.08194627333556385}. Best is trial 52 with value: 0.83828125.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:53:57,019]\u001b[0m Trial 57 finished with value: 0.8390625 and parameters: {'n_layers': 1, 'n_units_0': 48, 'dropout_0': 0.14625816113308787, 'optimizer': 'Adam', 'lr': 0.010420978226017195}. Best is trial 57 with value: 0.8390625.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:54:06,489]\u001b[0m Trial 58 finished with value: 0.82578125 and parameters: {'n_layers': 1, 'n_units_0': 49, 'dropout_0': 0.10044992724528966, 'optimizer': 'Adam', 'lr': 0.011803183059144014}. Best is trial 57 with value: 0.8390625.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:54:14,910]\u001b[0m Trial 59 finished with value: 0.80625 and parameters: {'n_layers': 1, 'n_units_0': 45, 'dropout_0': 0.14692798921502048, 'optimizer': 'Adam', 'lr': 0.01929474146218729}. Best is trial 57 with value: 0.8390625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-01 20:54:23,994]\u001b[0m Trial 60 finished with value: 0.8203125 and parameters: {'n_layers': 1, 'n_units_0': 35, 'dropout_0': 0.12455390934914742, 'optimizer': 'Adam', 'lr': 0.003705816178015467}. Best is trial 57 with value: 0.8390625.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:54:33,856]\u001b[0m Trial 61 finished with value: 0.84375 and parameters: {'n_layers': 1, 'n_units_0': 49, 'dropout_0': 0.10272812498535691, 'optimizer': 'Adam', 'lr': 0.008898259461738552}. Best is trial 61 with value: 0.84375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:54:42,572]\u001b[0m Trial 62 finished with value: 0.840625 and parameters: {'n_layers': 1, 'n_units_0': 42, 'dropout_0': 0.16793875633757052, 'optimizer': 'Adam', 'lr': 0.008924293690800906}. Best is trial 61 with value: 0.84375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:54:51,664]\u001b[0m Trial 63 finished with value: 0.82734375 and parameters: {'n_layers': 1, 'n_units_0': 40, 'dropout_0': 0.1741341486774264, 'optimizer': 'Adam', 'lr': 0.008735884456016868}. Best is trial 61 with value: 0.84375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:55:01,079]\u001b[0m Trial 64 finished with value: 0.66796875 and parameters: {'n_layers': 1, 'n_units_0': 53, 'dropout_0': 0.11331535742210189, 'optimizer': 'SGD', 'lr': 0.016693054937030563}. Best is trial 61 with value: 0.84375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:55:10,608]\u001b[0m Trial 65 finished with value: 0.8015625 and parameters: {'n_layers': 1, 'n_units_0': 42, 'dropout_0': 0.1387929896102925, 'optimizer': 'Adam', 'lr': 0.030119067507866904}. Best is trial 61 with value: 0.84375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:55:18,973]\u001b[0m Trial 66 finished with value: 0.71796875 and parameters: {'n_layers': 1, 'n_units_0': 49, 'dropout_0': 0.15901707218282118, 'optimizer': 'Adam', 'lr': 0.05260438289660389}. Best is trial 61 with value: 0.84375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:55:27,707]\u001b[0m Trial 67 finished with value: 0.8265625 and parameters: {'n_layers': 1, 'n_units_0': 32, 'dropout_0': 0.12812956519074292, 'optimizer': 'Adam', 'lr': 0.010673188186936142}. Best is trial 61 with value: 0.84375.\u001b[0m\n",
      "\u001b[32m[I 2023-01-01 20:55:36,718]\u001b[0m Trial 68 finished with value: 0.82890625 and parameters: {'n_layers': 1, 'n_units_0': 36, 'dropout_0': 0.1798579880847268, 'optimizer': 'Adam', 'lr': 0.0034797491774435385}. Best is trial 61 with value: 0.84375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "best_value = 0.84375\n",
      "best_params:\n",
      "{'dropout_0': 0.10272812498535691, 'lr': 0.008898259461738552, 'n_layers': 1, 'n_units_0': 49, 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
    "\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_{}\".format(i), 4, 64)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_{}\".format(i), 0.1, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        \n",
    "        #attention here \n",
    "        trial.report(accuracy, epoch)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n",
    "        study_name=\"mnist-torch\", storage=storage_name,load_if_exists=False\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=20, timeout=600)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48f79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed7a1147",
   "metadata": {},
   "source": [
    "### äºŒï¼Œoptunaå¯¹tensorflowæ¨¡å‹è°ƒå‚èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3031fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "N_TRAIN_EXAMPLES = 3000\n",
    "N_VALID_EXAMPLES = 1000\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout in each layer and\n",
    "    # the learning rate of RMSProp optimizer.\n",
    "\n",
    "    # We define our MLP.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    model = keras.models.Sequential()\n",
    "    for i in range(n_layers):\n",
    "        num_hidden = trial.suggest_int(\"n_units_{}\".format(i), 4, 64, log=True)\n",
    "        model.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "        dropout = trial.suggest_float(\"dropout_{}\".format(i), 0.1, 0.5)\n",
    "        model.add(layers.Dropout(rate=dropout))\n",
    "    model.add(layers.Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=RMSprop(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # The data is split between train and validation sets.\n",
    "    (x_train, y_train), (x_valid, y_valid) = keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.reshape(60000, 784)[:N_TRAIN_EXAMPLES].astype(\"float32\") / 255\n",
    "    x_valid = x_valid.reshape(10000, 784)[:N_VALID_EXAMPLES].astype(\"float32\") / 255\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = to_categorical(y_train[:N_TRAIN_EXAMPLES], CLASSES)\n",
    "    y_valid = to_categorical(y_valid[:N_VALID_EXAMPLES], CLASSES)\n",
    "\n",
    "    # Generate our trial model.\n",
    "    model = create_model(trial)\n",
    "\n",
    "    # Fit the model on the training data.\n",
    "    # The KerasPruningCallback checks for pruning condition every epoch.\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCHSIZE,\n",
    "        callbacks=[TFKerasPruningCallback(trial, \"val_accuracy\")],\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n",
    "        study_name=\"mnist-tf\", storage=storage_name,load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62aa6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2642555",
   "metadata": {},
   "source": [
    "### ä¸‰ï¼Œoptunaå¯¹å¤šæ¨¡å‹åŠ æƒèåˆèŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4d046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "data,target = make_classification(n_samples=2000,n_features=20,\n",
    "        n_informative=12,n_redundant=4,n_repeated=0,n_classes=2,\n",
    "        n_clusters_per_class=4)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "mlp = MLPClassifier()\n",
    "svc = SVC(probability=True) \n",
    "\n",
    "\n",
    "mlp.fit(x_train,y_train)\n",
    "tree.fit(x_train,y_train)\n",
    "svc.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "def get_val_auc(model):\n",
    "    probs = model.predict_proba(x_valid)[:,1]\n",
    "    val_auc = roc_auc_score(y_valid,probs)\n",
    "    return val_auc\n",
    "\n",
    "print(\"mlp_score:\",get_val_auc(mlp))\n",
    "print(\"tree_score:\",get_val_auc(tree))\n",
    "print(\"svc_score:\",get_val_auc(svc))\n",
    "\n",
    "\n",
    "preds_val = {name:(eval(name)).predict_proba(x_valid)[:,1] for name in ['mlp','tree','svc']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa37176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna \n",
    "\n",
    "def objective(trial):\n",
    "    weights = {name:trial.suggest_int(name, 1, 100) for name in ['mlp','tree','svc']}\n",
    "    probs = sum([weights[name]*preds_val[name] for name in ['mlp','tree','svc']])/sum(\n",
    "        [weights[name] for name in ['mlp','tree','svc']])\n",
    "    \n",
    "    val_auc = roc_auc_score(y_valid,probs)\n",
    "    trial.report(val_auc, 0)\n",
    "    return val_auc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    storage_name = \"sqlite:///optuna.db\"\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        study_name=\"ensemble\", storage=storage_name,load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "    print(\"best_params:\")\n",
    "    print(best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e17174-a141-4184-96b8-041c3e4fc8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2443798c",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹èŒƒä¾‹ä¸ºåŸºç¡€ç‰¹æ€§èŒƒä¾‹è®²è§£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4e9eb",
   "metadata": {},
   "source": [
    "### å››ï¼Œå•å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6b19f3",
   "metadata": {},
   "source": [
    "Optunaæ”¯æŒçš„è°ƒå‚ç®—æ³•ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹è¿™äº›ï¼š\n",
    "\n",
    "```\n",
    "optuna.samplers.GridSampler(ç½‘æ ¼æœç´¢é‡‡æ ·)\n",
    "optuna.samplers.RandomSampler(éšæœºæœç´¢é‡‡æ ·)\n",
    "optuna.samplers.TPESampler(è´å¶æ–¯ä¼˜åŒ–é‡‡æ ·)\n",
    "optuna.samplers.NSGAIISampler(é—ä¼ ç®—æ³•é‡‡æ ·)\n",
    "optuna.samplers.CmaEsSampler(åæ–¹å·®çŸ©é˜µè‡ªé€‚åº”æ¼”åŒ–ç­–ç•¥é‡‡æ ·ï¼Œéå¸¸å…ˆè¿›çš„ä¼˜åŒ–ç®—æ³•)\n",
    "```\n",
    "\n",
    "æ­¤å¤–ï¼Œè¿˜å¯ä»¥ç”¨ä»¥ä¸‹æ–¹æ³•å°†éƒ¨åˆ†è¶…å‚å›ºå®šï¼Œä»…å¯¹å…¶å®ƒä¸€äº›å‚æ•°è¿›è¡Œè¶…å‚ä¼˜åŒ–ã€‚\n",
    "```\n",
    "optuna.samplers.PartialFixedSampler(éƒ¨åˆ†å‚æ•°å›ºå®šé‡‡æ ·ç®—æ³•)\n",
    "```\n",
    "\n",
    "å¯ä»¥åœ¨optuna.create_studyæ—¶å€™ç”¨samplerå‚æ•°æŒ‡å®šã€‚\n",
    "\n",
    "å¦‚æœä¸æŒ‡å®šçš„è¯ï¼Œä¸€èˆ¬åœ¨å•ç›®æ ‡ä¼˜åŒ–ç®—æ³•ä¸­ï¼Œä½¿ç”¨çš„æ˜¯optuna.samplers.TPESamplerè°ƒå‚ç®—æ³•ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088930c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "import optuna\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import plotly.graph_objs as go \n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 1, å®šä¹‰ç›®æ ‡å‡½æ•°\n",
    "def objective(trial:optuna.trial.Trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "# 2, æ‰§è¡Œæœç´¢è¿‡ç¨‹\n",
    "study = optuna.create_study(\n",
    "    sampler=optuna.samplers.CmaEsSampler(),\n",
    "    direction = \"minimize\",\n",
    "    study_name = \"simple_task\")\n",
    "\n",
    "study.optimize(objective, n_trials=1000,show_progress_bar = True)\n",
    "\n",
    "# 3, è·å–æœ€ä¼˜è¶…å‚\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "# 4, ç»˜åˆ¶æœç´¢è¿‡ç¨‹\n",
    "\n",
    "dftrials = study.trials_dataframe()[[\"number\",\"value\"]]\n",
    "losses = dftrials[\"value\"].tolist()\n",
    "\n",
    "minlosses = [np.min(losses[0:i+1]) for i in range(len(losses))] \n",
    "steps = range(len(losses))\n",
    "\n",
    "dflog = pd.DataFrame({\"steps\":steps,\"losses\":losses,\"minlosses\":minlosses})\n",
    "fig = px.scatter(data_frame=dflog,x = \"steps\",y = \"losses\", size_max = 500,log_y=True)\n",
    "fig.update_traces(marker = dict(size = 20, color = \"rgba(0,0,255,0.4)\"),name = \"all\",showlegend = True)\n",
    "fig.add_traces(go.Scatter(x=list(steps), y=minlosses, name = \"best\", showlegend=True)) \n",
    "fig.update_layout(legend=dict(orientation=\"v\"))\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6986e39a",
   "metadata": {},
   "source": [
    "### äº”ï¼Œç½‘æ ¼å‚æ•°ç©ºé—´æœç´¢èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef7eac",
   "metadata": {},
   "source": [
    "å¤šä¸ªå‚æ•°å¯ä»¥ç”¨å­—å…¸è¡¨è¿°æˆç½‘æ ¼å‚æ•°ç©ºé—´å½¢å¼ã€‚\n",
    "\n",
    "optunaæ”¯æŒå„ç§å„æ ·çš„è¾“å…¥å‚æ•°ç±»å‹ã€‚å¸¸è§çš„æœ‰ä»¥ä¸‹ä¸€äº›\n",
    "\n",
    "``` python\n",
    "trail = optuna.trial.Trial\n",
    "trail.suggest_categorical\n",
    "trail.suggest_discrete_uniform\n",
    "trail.suggest_float\n",
    "trail.suggest_int\n",
    "trail.suggest_loguniform\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f497ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644420f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import optuna \n",
    "\n",
    "import plotly.graph_objs as go \n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 1, å®šä¹‰ç›®æ ‡å‡½æ•°\n",
    "def objective(trial:optuna.trial.Trial):\n",
    "    x = trial.suggest_float(\"x\", -1, 1)\n",
    "    f = trial.suggest_categorical(\"f\",['sin','sinh','cos','cosh'])\n",
    "    dic = {'sin':np.sin,'cos':np.cos,'sinh':np.sinh,'cosh':np.cosh}\n",
    "    fn = dic[f]\n",
    "    return fn(x)\n",
    "\n",
    "\n",
    "# 2, æ‰§è¡Œæœç´¢è¿‡ç¨‹\n",
    "study = optuna.create_study(\n",
    "    sampler=optuna.samplers.TPESampler(seed=123),\n",
    "    direction = \"minimize\",\n",
    "    study_name = \"grid_task\")\n",
    "\n",
    "study.optimize(objective, n_trials=100,show_progress_bar = True)\n",
    "\n",
    "# 3, è·å–æœ€ä¼˜è¶…å‚\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "# 4, ç»˜åˆ¶æœç´¢è¿‡ç¨‹\n",
    "dftrials = study.trials_dataframe()[[\"number\",\"value\"]]\n",
    "display(dftrials)\n",
    "losses = dftrials[\"value\"].tolist()\n",
    "\n",
    "minlosses = [np.min(losses[0:i+1]) for i in range(len(losses))] \n",
    "steps = range(len(losses))\n",
    "\n",
    "dflog = pd.DataFrame({\"steps\":steps,\"losses\":losses,\"minlosses\":minlosses})\n",
    "fig = px.scatter(data_frame=dflog,x = \"steps\",y = \"losses\", size_max = 500)\n",
    "fig.update_traces(marker = dict(size = 20, color = \"rgba(0,0,255,0.4)\"),name = \"all\",showlegend = True)\n",
    "fig.add_traces(go.Scatter(x=list(steps), y=minlosses, name = \"best\", showlegend=True)) \n",
    "fig.update_layout(legend=dict(orientation=\"v\"))\n",
    "fig.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6a2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e593c3",
   "metadata": {},
   "source": [
    "### å…­ï¼Œæ–­ç‚¹ç»­æœèŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55235ae4",
   "metadata": {},
   "source": [
    "æœ‰æ—¶å€™è¶…å‚æœç´¢è¿‡ç¨‹ä¸­æœ‰å¯èƒ½ä¸­é—´æœºå™¨ä¼šæ­»æ‰ï¼Œå¯ä»¥ä½¿ç”¨sqlite/mysqlç­‰å­˜å‚¨æ–¹å¼å­˜å‚¨æœç´¢ç»“æœåˆ°æ•°æ®åº“æ–‡ä»¶ã€‚\n",
    "\n",
    "è¿™æ ·ä¾¿å¯ä»¥è¯»å–å†å²æœç´¢ç»“æœï¼Œç»§ç»­æœç´¢ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# 1, å®šä¹‰ç›®æ ‡å‡½æ•°\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "\n",
    "# 2, æ‰§è¡Œæœç´¢è¿‡ç¨‹\n",
    "study_name = \"example-study\"  \n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "#period0\n",
    "study0 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study0.optimize(objective, n_trials=10)\n",
    "\n",
    "#period1\n",
    "study1 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "study1.optimize(objective, n_trials=10)\n",
    "\n",
    "#period2\n",
    "study2 = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "dftrials = study2.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\n",
    "\n",
    "# 3, è·å–æœ€ä¼˜è¶…å‚\n",
    "best_params = study2.best_params\n",
    "best_value = study2.best_value\n",
    "print(\"\\n\\nbest_value = \"+str(best_value))\n",
    "print(\"best_params:\")\n",
    "print(best_params)\n",
    "\n",
    "display(dftrials)\n",
    "\n",
    "\n",
    "# 4, ç»˜åˆ¶æœç´¢è¿‡ç¨‹\n",
    "fig = optuna.visualization.plot_optimization_history(study2)\n",
    "#fig.layout.yaxis.type = 'log'\n",
    "fig.update_layout({\"yaxis.type\":\"log\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c0d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd117eda",
   "metadata": {},
   "source": [
    "### ä¸ƒï¼Œå‰ªæç­–ç•¥èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89458262",
   "metadata": {},
   "source": [
    "optunaæ”¯æŒå¤šç§å‰ªæç­–ç•¥ï¼Œå¦‚æœæŸä¸ªè¶…å‚é‡‡æ ·ç‚¹è¿”å›çš„ä¸­é—´ç»“æœå’Œä¹‹å‰é‡‡æ ·ç‚¹ç›¸æ¯”è¡¨ç°å¾—æ²¡æœ‰å¸Œæœ›ï¼Œoptunaå¯ä»¥æå‰ç»“æŸè¿™ä¸ªé‡‡æ ·ç‚¹çš„è®­ç»ƒï¼Œä»è€ŒèŠ‚çº¦æ—¶é—´ã€‚\n",
    "\n",
    "* optuna.pruners.HyperbandPruner: pruner refers to http://www.jmlr.org/papers/volume18/16-558/16-558.pdf\n",
    "\n",
    "* optuna.pruners.MedianPruner: Prune if the trial's best intermediate result is worse than median of intermediate results of previous trials at the same step.\n",
    "\n",
    "* optuna.pruners.ThresholdPruner: Pruner to detect outlying metrics of the trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646efdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    iris = load_iris() \n",
    "    data,target = iris[\"data\"],iris[\"target\"]\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "    classes = list(set(target))\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=tuple(\n",
    "            [trial.suggest_int(\"n_units_l{}\".format(i), 32, 64) for i in range(3)]\n",
    "        ),\n",
    "        learning_rate_init=trial.suggest_float(\"lr_init\", 1e-5, 1e-1, log=True),\n",
    "    )\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(x_train, y_train, classes=classes)\n",
    "        value = clf.score(x_valid, y_valid)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        trial.report(value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    plot_optimization_history(study).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab7171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c095c9f",
   "metadata": {},
   "source": [
    "### å…«ï¼Œå„ç§è°ƒå‚å¯è§†åŒ–å‡½æ•°èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    iris = load_iris() \n",
    "    data,target = iris[\"data\"],iris[\"target\"]\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, target)\n",
    "    classes = list(set(target))\n",
    "\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=tuple(\n",
    "            [trial.suggest_int(\"n_units_l{}\".format(i), 32, 64) for i in range(3)]\n",
    "        ),\n",
    "        learning_rate_init=trial.suggest_float(\"lr_init\", 1e-5, 1e-1, log=True),\n",
    "    )\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(x_train, y_train, classes=classes)\n",
    "        value = clf.score(x_valid, y_valid)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        trial.report(value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    # Visualize the optimization history.\n",
    "    plot_optimization_history(study).show()\n",
    "\n",
    "    # Visualize the learning curves of the trials.\n",
    "    plot_intermediate_values(study).show()\n",
    "\n",
    "    # Visualize high-dimensional parameter relationships.\n",
    "    plot_parallel_coordinate(study).show()\n",
    "\n",
    "    # Select parameters to visualize.\n",
    "    plot_parallel_coordinate(study, params=[\"lr_init\", \"n_units_l0\"]).show()\n",
    "\n",
    "    # Visualize hyperparameter relationships.\n",
    "    plot_contour(study).show()\n",
    "\n",
    "    # Select parameters to visualize.\n",
    "    plot_contour(study, params=[\"n_units_l0\", \"n_units_l1\"]).show()\n",
    "\n",
    "    # Visualize individual hyperparameters.\n",
    "    plot_slice(study).show()\n",
    "\n",
    "    # Select parameter\n",
    "    # Visualize parameter importances.\n",
    "    plot_param_importances(study).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6317441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b4c1362",
   "metadata": {},
   "source": [
    "### ä¹ï¼Œæ‰‹åŠ¨æ·»åŠ è¶…å‚æ•°é‡‡æ ·ç‚¹èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d9658",
   "metadata": {},
   "source": [
    "æœ‰æ—¶å€™ï¼Œæˆ‘ä»¬åœ¨ä½¿ç”¨ç‰¹å®šçš„é‡‡æ ·ç®—æ³•ä¹‹å‰ï¼Œæƒ³å°è¯•ä¸€äº›äººå·¥æŒ‡å®šçš„è¶…å‚é‡‡æ ·ç‚¹ï¼Œåœ¨Optunaä¸­æˆ‘ä»¬å¯ä»¥ç”¨\n",
    "\n",
    "study.enqueue_trial å°†è¿™äº›äººå·¥æŒ‡å®šè¶…å‚é‡‡æ ·ç‚¹æ¨å…¥æµ‹è¯•é˜Ÿåˆ—ã€‚\n",
    "\n",
    "å¦å¤–ï¼Œå¦‚æœæˆ‘ä»¬å·²ç»æ‰‹åŠ¨æ‰§è¡Œäº†ä¸€äº›è¶…å‚é‡‡æ ·ç‚¹ï¼Œå¹¶è·å¾—äº†ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ study.add_trailçš„æ–¹æ³•\n",
    "\n",
    "å°†è¿™äº›ç»“æœæ·»åŠ åˆ°å·²è¯„ä¼°çš„è¶…å‚é‡‡æ ·ç‚¹åˆ—è¡¨ä¸­ã€‚åç»­çš„è¶…å‚æ•°é‡‡æ ·å°†ä¼šè€ƒè™‘è¿™äº›é‡‡æ ·ç‚¹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a790e2",
   "metadata": {},
   "source": [
    "**1ï¼ŒæŒ‡å®šæ‰‹å·¥é‡‡æ ·ç‚¹**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e60c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_fraction\": min(trial.suggest_float(\"bagging_fraction\", 0.4, 1.0 + 1e-12), 1),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "\n",
    "study.enqueue_trial(\n",
    "    {\n",
    "        \"bagging_fraction\": 1.0,\n",
    "        \"bagging_freq\": 0,\n",
    "        \"min_child_samples\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "study.enqueue_trial(\n",
    "    {\n",
    "        \"bagging_fraction\": 0.75,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"min_child_samples\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Add stream handler of stdout to show the messages to see Optuna works expectedly.\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45bb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd9102e",
   "metadata": {},
   "source": [
    "**2ï¼Œæ·»åŠ å·²è¯„ä¼°é‡‡æ ·ç‚¹**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7da213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_fraction\": min(trial.suggest_float(\"bagging_fraction\", 0.4, 1.0 + 1e-12), 1),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(\n",
    "        param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "study.add_trial(\n",
    "    optuna.trial.create_trial(\n",
    "        params={\n",
    "            \"bagging_fraction\": 1.0,\n",
    "            \"bagging_freq\": 0,\n",
    "            \"min_child_samples\": 20,\n",
    "        },\n",
    "        distributions={\n",
    "            \"bagging_fraction\": optuna.distributions.UniformDistribution(0.4, 1.0 + 1e-12),\n",
    "            \"bagging_freq\": optuna.distributions.IntUniformDistribution(0, 7),\n",
    "            \"min_child_samples\": optuna.distributions.IntUniformDistribution(5, 100),\n",
    "        },\n",
    "        value=0.94,\n",
    "    )\n",
    ")\n",
    "study.add_trial(\n",
    "    optuna.trial.create_trial(\n",
    "        params={\n",
    "            \"bagging_fraction\": 0.75,\n",
    "            \"bagging_freq\": 5,\n",
    "            \"min_child_samples\": 20,\n",
    "        },\n",
    "        distributions={\n",
    "            \"bagging_fraction\": optuna.distributions.UniformDistribution(0.4, 1.0 + 1e-12),\n",
    "            \"bagging_freq\": optuna.distributions.IntUniformDistribution(0, 7),\n",
    "            \"min_child_samples\": optuna.distributions.IntUniformDistribution(5, 100),\n",
    "        },\n",
    "        value=0.95,\n",
    "    )\n",
    ")\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56c56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
