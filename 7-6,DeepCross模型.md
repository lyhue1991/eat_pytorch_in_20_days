
# 7-6ï¼ŒDeepCrossæ¨¡å‹


è°·æ­Œåœ¨CTRé¢„ä¼°å’Œæ¨èæ’åºæ¨¡å‹æ–¹é¢æœ‰3ç¯‡ç›¸å¯¹é‡è¦çš„æ–‡ç« ã€‚

ç¬¬1ç¯‡æ˜¯2016å¹´çš„Deep&Wide,ç¬¬2ç¯‡æ˜¯2017å¹´çš„Deep&Cross(DCN),ç¬¬3ç¯‡æ˜¯2020å¹´çš„DCN-V2.

è¿™3ç¯‡æ–‡ç« çš„æ ¸å¿ƒæ€æƒ³åˆ†åˆ«ç”¨1å¥è¯æ¦‚æ‹¬å¦‚ä¸‹ï¼š

ç¬¬1ç¯‡Deep&Wideè¯´ï¼Œçº¿æ€§å›å½’LRå…·æœ‰å¥½çš„è®°å¿†èƒ½åŠ›(Wideéƒ¨åˆ†),å¤šå±‚æ„ŸçŸ¥æœºDNNå…·æœ‰å¥½çš„æ³›åŒ–èƒ½åŠ›(Deepéƒ¨åˆ†),æŠŠå®ƒä»¬å¹¶è¡Œçš„ç»“åˆèµ·æ¥é£Ÿç”¨å£æ„ŸçœŸé¦™.

ç¬¬2ç¯‡Deep&Crossè¯´ï¼Œå°†Deep&Wideçš„Wideéƒ¨åˆ†æ¢æˆä¸€ä¸ªCrossNetï¼Œå¯ä»¥è‡ªåŠ¨æ•è·å¤šå±‚çº§ç‰¹å¾äº¤å‰ï¼Œå‡å°‘äººå·¥ç‰¹å¾å·¥ç¨‹ã€‚æ–°çš„æ¨¡å‹å«åšDCNå£æ„Ÿæ›´é¦™ï¼

ç¬¬3ç¯‡DCNV2è¯´ï¼ŒDCNçš„CrossNetçš„ä»…ä»…ç”¨ä¸€ä¸ªå‘é‡æ¥å»ºæ¨¡äº¤å‰èƒ½åŠ›, æ‹Ÿåˆèƒ½åŠ›å¤ªå¼±, é…æ–¹å‡çº§æ¢æˆçŸ©é˜µå§ã€‚å‡çº§åçš„DCNV2é‡å¤§ç®¡é¥±ï¼Œåˆé¦™åˆé¥±ï¼ä»€ä¹ˆï¼ŒçŸ©é˜µå¤ªå¤§è·‘çš„æ…¢ï¼Œä¸å¤ªå¥½æ¶ˆåŒ–? åˆ«æ€¥ï¼Œæˆ‘ä»¬è¿˜æœ‰ç§˜åˆ¶é…æ–¹ï¼ŒæŠŠçŸ©é˜µæ¢æˆä¸¤ä¸ªä½ç§©çŸ©é˜µçš„ä¹˜ç§¯ï¼Œè¿™ä¸ªç”¨äº†ç§˜åˆ¶é…æ–¹çš„æ¨¡å‹å«åšDCN-Mixï¼Œå˜å˜£è„†ï¼Œåˆé¦™åˆé¥±è¿˜å¥½æ¶ˆåŒ–ï¼Œä½ å€¼å¾—æ‹¥æœ‰ï¼

ä»Šå¤©æˆ‘ä»¬å°±æ¥å°å°DCNã€DCNV2ä»¥åŠå˜å˜£è„†çš„DCN-Mixï¼


å‚è€ƒæ–‡æ¡£ï¼š

* Deep&Wideè®ºæ–‡ï¼š https://arxiv.org/pdf/1606.07792v1.pdf

* DCNè®ºæ–‡ï¼šhttps://arxiv.org/pdf/1708.05123.pdf 

* DCNV2è®ºæ–‡ï¼š https://arxiv.org/pdf/2008.13535.pdf

* è§£å¯†Deep&Cross: https://zhuanlan.zhihu.com/p/55234968 

* å¤§è§„æ¨¡æ’åºç³»ç»Ÿä¸­çš„ç‰¹å¾äº¤å‰DCN-V2: https://zhuanlan.zhihu.com/p/353223660

* ä»£ç å®ç°å‚è€ƒï¼šhttps://github.com/shenweichen/DeepCTR-Torch/blob/bc881dcd417fec64f840b0cacce124bc86b3687c/deepctr_torch/layers/interaction.py#L406-L537





<br>

<font color="red">
 
å…¬ä¼—å· **ç®—æ³•ç¾é£Ÿå±‹** å›å¤å…³é”®è¯ï¼š**pytorch**ï¼Œ è·å–æœ¬é¡¹ç›®æºç å’Œæ‰€ç”¨æ•°æ®é›†ç™¾åº¦äº‘ç›˜ä¸‹è½½é“¾æ¥ã€‚
    
</font> 



## ä¸€ï¼ŒDeepCrossåŸç†è§£æ


è°·æ­Œçš„DeepCrossç³»åˆ—æ¨¡å‹(DCN-vector, DCN-matrix, DCN-mix) å›´ç»•è§£å†³çš„æ ¸å¿ƒé—®é¢˜ä¸‰é«˜é—®é¢˜ã€‚

å¦‚ä½•å®ç° é«˜æ•ˆç‡ï¼Œé«˜è¡¨è¾¾èƒ½åŠ› çš„ é«˜é˜¶æ˜¾å¼ç‰¹å¾äº¤å‰ï¼Ÿ

è¿™ä¸‰é«˜é—®é¢˜åˆ†åˆ«æ˜¯ä»€ä¹ˆå«ä¹‰å‘¢ï¼Ÿ

1ï¼Œé«˜é˜¶ï¼šè‡³å°‘æ”¯æŒä¸‰é˜¶ç‰¹å¾äº¤å‰ã€‚å®è·µè¯æ˜ï¼Œåœ¨CTRå’Œæ¨èé¢†åŸŸï¼ŒäºŒé˜¶ç‰¹å¾äº¤å‰å’Œä¸‰é˜¶ç‰¹å¾äº¤å‰æ˜¯æœ‰ç”¨çš„ï¼Œå››é˜¶åŠä»¥ä¸Šçš„ç‰¹å¾äº¤å‰æ²¡å•¥ç”¨ã€‚FMåªæ˜¯äºŒé˜¶æ˜¾å¼ç‰¹å¾äº¤å‰ã€‚ 

2ï¼Œé«˜æ•ˆç‡ï¼šç‰¹å¾äº¤å‰æ¨¡å—çš„é¢„æµ‹æ•ˆç‡æœ€å¥½æ˜¯O(n),å…¶ä¸­nä¸ºç‰¹å¾æ•°é‡ã€‚

3ï¼Œé«˜è¡¨è¾¾èƒ½åŠ›ï¼šç‰¹å¾äº¤å‰æ¨¡å—æœ‰è¶³å¤Ÿå¤§çš„å‚æ•°å®¹é‡æ¥æ•è·å„ç§å¯èƒ½çš„ç‰¹å¾äº¤å‰ã€‚

ä¸‹é¢æˆ‘ä»¬åˆ†åˆ«çœ‹çœ‹ DCN-vectorï¼Œ DCN-matrix, DCN-mixåœ¨ä¸‰é«˜é—®é¢˜çš„è§£å†³æ€è·¯å’Œè§£å†³ç¨‹åº¦ã€‚




### 1ï¼Œ DCN-vector 


DCN-vector ä¹Ÿå°±æ˜¯ 2017å¹´å‘å¸ƒçš„æœ€åˆç‰ˆæœ¬çš„DCNï¼Œ å¾ˆå¥½åœ°è§£å†³äº†ä¸‰é«˜é—®é¢˜ä¸­çš„ä¸¤é«˜ã€‚

1ï¼Œé«˜é˜¶ (DCN-vectorå¯ä»¥å¾ˆæ–¹ä¾¿åœ°æ”¯æŒä¸‰é˜¶åŠä»¥ä¸Šçš„æ˜¾å¼ç‰¹å¾äº¤å‰)

2ï¼Œé«˜æ•ˆç‡ (DCN-vectorç‰¹å¾äº¤å‰æ¨¡å—çš„æ¨ç†å¤æ‚åº¦æ˜¯O(n)ï¼Œéå¸¸é«˜æ•ˆï¼Œå’ŒFMä¸åˆ†ä¼¯ä»²)

æˆ‘ä»¬æ¥çœ‹çœ‹DCN-vectoræ€ä¹ˆåšçš„æ˜¾å¼ç‰¹å¾äº¤å‰ã€‚

å…ˆçœ‹å›¾å’Œå…¬å¼ã€‚

æœ‰ä¸¤ä¸ªè¦ç‚¹ï¼Œä¸€ä¸ªæ˜¯ç”¨å’Œx0ç­‰é•¿çš„å‚æ•°å‘é‡æ¥æ•è·äº¤å‰å…³ç³»ï¼Œç¬¬äºŒä¸ªæ˜¯å‚ç…§äº†æ®‹å·®æ¨¡å—çš„è®¾è®¡å°†ä½é˜¶é‡åŠ å›åˆ°è¾“å‡ºä¸­ã€‚


![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2wduan1hmj20a30570sv.jpg)


ä»£ç å’Œå›¾ä¸€æ ·å¥½æ‡‚ã€‚

```python
import torch 
from torch import nn 
class CrossNetVector(nn.Module):
    def __init__(self, d_in, n_cross=2):
        super().__init__()
        self.n_cross = n_cross
        self.linears = nn.ModuleList([nn.Linear(d_in,1,bias=False) for i in range(self.n_cross)])
        self.biases = nn.ParameterList(
            [nn.Parameter(torch.zeros(d_in)) for i in range(self.n_cross)])
        
    def forward(self, x):
        x0 = x
        xi = x
        for i in range(self.n_cross):
            xi = x0*self.linears[i](xi)+self.biases[i]+xi
        return xi
```

CrossNetVectorçš„ç»“æ„éå¸¸ç®€æ´ã€‚æ¯å‡é«˜ä¸€é˜¶ç‰¹å¾äº¤å‰ï¼Œä¸»è¦è¿ç®—æ˜¯å°†ä¸Šä¸€é˜¶ç‰¹å¾å‘é‡xiå’Œäº¤å‰æ¨¡å—å‚æ•°å‘é‡wåšç‚¹ç§¯ï¼Œå¹¶æ•°ä¹˜åŸå§‹ç‰¹å¾å‘é‡x0ã€‚

è¯¥è®¡ç®—çš„è®¡ç®—å‰åå‘é‡çš„ç»´åº¦ä¸å˜ï¼Œè®¡ç®—é‡å’Œç‰¹å¾å‘é‡çš„é•¿åº¦næˆæ­£æ¯”ï¼Œæ‰€ä»¥å¤æ‚åº¦æ˜¯O(n).

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè™½ç„¶CrossNetVectorçš„å¤æ‚åº¦å¾ˆä½ä»…ä»…æ˜¯O(n),  ä½†æ˜¯ $x_{0}*x^{'}*\omega$ è¿™ä¸€é¡¹å±•å¼€åæ˜¯åŒ…æ‹¬ä»»æ„ä¸¤ä¸ªç‰¹å¾çš„äº¤å‰ä¹˜ç§¯è´¡çŒ®çš„ã€‚

æˆ‘ä»¬çŸ¥é“ä»»æ„ä¸¤ä¸ªç‰¹å¾çš„äº¤å‰å…±æœ‰ n(n-1)/2 ç§ç»„åˆæ–¹å¼ï¼Œè¿™ä¸ªå¤æ‚åº¦æ˜¯O(n^2)çš„ï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆ CrossNetVector èƒ½å¤Ÿä»¥ O(n)çš„å¤æ‚åº¦å®ç°åŒ…æ‹¬O(n^2)é‡çº§çš„ç‰¹å¾äº¤å‰ç»„åˆè´¡çŒ®çš„å‘¢ï¼Ÿ

åŸå› æ˜¯CrossNetVectorè¿™ç§ç»“æ„å®é™…ä¸Šå…·æœ‰æƒé‡å…±äº«çš„ç‰¹æ€§ã€‚

å‡è®¾æœ‰5ä¸ªç‰¹å¾ x1,x2,x3,x4,x5, å¦‚æœè¦ç‹¬ç«‹åœ°æè¿°å®ƒä»¬ä¹‹é—´çš„ä¸¤ä¸¤äº¤å‰è¦10ä¸ªå‚æ•°ï¼Œä½†æ˜¯CrossNetVectorä¸­ä»…ä»…æœ‰5ä¸ªè¡¨è¿°ç‰¹å¾äº¤å‰ç³»æ•°çš„å‚æ•° w1,w2,w3,w4,w5

å…¶ä¸­ x1x2çš„äº¤å‰é¡¹çš„ç³»æ•°æ˜¯ (w1+w2), x1x3çš„äº¤å‰é¡¹ç³»æ•°æ—¶ (w1+w3),...,x1x5çš„äº¤å‰é¡¹ç³»æ•°æ˜¯ (w1+w5), å¯è§ï¼Œw1è¿™ä¸ªå‚æ•°è¢«ç”¨åœ¨äº† x1å’Œä»»ä½•å‚æ•°çš„äº¤å‰é¡¹ä¸­ä½œä¸ºç»„æˆéƒ¨åˆ†ã€‚

è¿™å°±æ˜¯ä¸€ç§æƒé‡å…±äº«çš„ç‰¹æ€§ï¼Œè¿™ç§ç‰¹æ€§æœ‰åŠ©äºDCNå˜å¾—è½»ä¾¿é«˜æ•ˆï¼Œå¹¶åƒFMé‚£æ ·å­¦ä¹ åˆ°ç¨€ç–ç‰¹å¾çš„äº¤å‰ã€‚



```python

```

### 2, DCN-matrix 


DCN-vector è™½ç„¶è§£å†³äº†ä¸‰é«˜ä¸­çš„ä¸¤é«˜: é«˜é˜¶ã€é«˜æ•ˆç‡ã€‚

ä½†æ˜¯å®ƒåœ¨å¦ä¸€é«˜ä¹Ÿå°±æ˜¯é«˜è¡¨è¾¾èƒ½åŠ›æ–¹é¢æœ‰äº›ç¼ºé™·ï¼Œå®ƒä»…ä»…ç”¨ä¸€ä¸ªå’Œè¾“å…¥ç‰¹å¾ç­‰é•¿çš„å‘é‡æ¥åˆ»ç”»ç‰¹å¾ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œä¸è¶³ä»¥è¡¨è¿°ä¸°å¯Œçš„ç‰¹å¾äº¤å‰æ¨¡å¼ã€‚

CrossNetVectorçš„å‚æ•°æ•°é‡ç›¸æ¯”Deepéƒ¨åˆ†çš„MLPçš„å‚æ•°æ•°é‡æ¥çœ‹å®åœ¨å¾®ä¸è¶³é“ï¼Œå¯èƒ½å­˜åœ¨è®°å¿†å®¹é‡ç“¶é¢ˆã€‚

æ¢è¨€ä¹‹ï¼Œå®ƒçš„æƒå€¼å…±äº«å¯èƒ½åšçš„æœ‰äº›è¿‡å¤´äº†ã€‚

æ­£æ˜¯åŸºäºè¿™æ ·çš„æ´å¯Ÿï¼ŒDCN-matrix åœ¨DCN-vectoråŸºç¡€ä¸Šåšäº†ä¸€äº›è½»å¾®çš„æ”¹åŠ¨ï¼Œç”¨çŸ©é˜µä»£æ›¿äº†å‘é‡ï¼Œå¹¶é€‚é…æ€§åœ°ä¿®æ”¹äº†ä¸€äº›è¿ç®—ç¬¦ï¼Œå¼ºåŒ–äº†æ˜¾å¼ç‰¹å¾äº¤å‰é¡¹çš„è¡¨è¾¾èƒ½åŠ›ã€‚



![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2wgsq1zcyj208u0473yj.jpg) 


ä»£ç æ¯”å›¾æ›´åŠ å¥½æ‡‚ã€‚

```python
import torch 
from torch import nn 
class CrossNetMatrix(nn.Module):
    def __init__(self, d_in, n_cross=2):
        super().__init__()
        self.n_cross = n_cross
        self.linears = nn.ModuleList([nn.Linear(d_in,d_in) for i in range(self.n_cross)])
        
    def forward(self, x):
        x0 = x
        xi = x
        for i in range(self.n_cross):
            xi = x0*self.linears[i](xi)+xi
        return xi
```

å¯ä»¥çœ‹åˆ° CrossNetMatrix ç”¨ä¸€ä¸ª $n\times n$ çš„äº¤äº’çŸ©é˜µ$W$æ¥åˆ»ç”» ç‰¹å¾ä¹‹é—´çš„äº¤äº’ï¼Œå®é™…ä¸Š$W$çš„ç¬¬iè¡Œç¬¬jåˆ—çš„å…ƒç´  $W_{ij}$

è¡¨è¾¾çš„å°±æ˜¯ç¬¬iä¸ªç‰¹å¾å’Œç¬¬jä¸ªç‰¹å¾ä¹‹é—´çš„äº¤äº’é¡¹ç³»æ•°ã€‚ å› æ­¤ CrossNetMatrix çš„å¤æ‚åº¦æ˜¯O(n^2)çš„ï¼Œå¹¶ä¸”å…·æœ‰å¾ˆå¥½çš„è§£é‡Šå‹ã€‚


äºæ˜¯ CrossNetMatrixæ•´ä½“æ¥è¯´æ˜¯ç‰ºç‰²äº† é«˜æ•ˆæ€§ï¼Œæ¢æ¥äº†é«˜è¡¨è¾¾èƒ½åŠ›ã€‚ä¸è¿‡ï¼Œåœ¨è®¸å¤šç‰¹å¾æ•°é‡ä¸ç®—ç‰¹åˆ«å¤šçš„æƒ…å†µä¸‹ï¼Œä¾‹å¦‚nåœ¨1000ä»¥ä¸‹çš„æ—¶å€™ï¼ŒCrossNetMatrixä¾æ—§æ˜¯éå¸¸é«˜æ•ˆçš„ã€‚





### 3, DCN-mix 


DCN-mixå¯ä»¥è¯´æ˜¯ DCN-matrixåŸºç¡€ä¸Šæå‡è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒé«˜è¡¨è¾¾èƒ½åŠ›çš„ä¸€ç§æ–¹æ¡ˆã€‚ 

å…¶ä¸»è¦æ€æƒ³æ´å¯Ÿå¦‚ä¸‹ã€‚

1ï¼ŒçŸ©é˜µåˆ†è§£ï¼šæ ¹æ®SVDä¸»æˆåˆ†åˆ†æç†è®ºï¼Œåºå¤§çš„äº¤äº’çŸ©é˜µWå¯ä»¥ç”±ä¸ºä¸¤ä¸ªä½ç§©çŸ©é˜µUå’ŒVçš„ä¹˜ç§¯æ¥è¿‘ä¼¼ã€‚è¿™æ ·å¯ä»¥å°†å‚æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦é™ä½åˆ°O(n)ã€‚

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2wid7h72rj209s01ga9v.jpg)

2ï¼Œä¸“å®¶èåˆï¼šä½¿ç”¨ä¸¤ä¸ªä½ç§©çŸ©é˜µUå’ŒVçš„ä¹˜ç§¯æ¥è¿‘ä¼¼Wæå‡äº†æ•ˆç‡ä½†æ˜¯é™ä½äº†è¡¨è¾¾èƒ½åŠ›ï¼Œå¯ä»¥ä½¿ç”¨MOEæ€æƒ³(Mixture of Experts)èåˆå¤šä¸ªä½ç§©ç©ºé—´çš„ä¸“å®¶ç½‘ç»œæ¥æå‡è¡¨è¾¾èƒ½åŠ›ã€‚
![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2wibupquej20eb0ayjrt.jpg)

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2wiet82zxj209302ma9y.jpg)

3ï¼Œä½ç§©å˜æ¢ï¼šå¯ä»¥åœ¨Uå’ŒVä¹‹é—´åœ¨ä½ç§©ç©ºé—´ä¸Šåšä¸€äº›å˜æ¢é€‚å½“å†æ‹‰ä¸€æ‹‰è¡¨è¾¾èƒ½åŠ›ã€‚

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2wifm6877j20ac01d744.jpg)



æ•´ä½“æ¥è¯´ï¼ŒDCN-mixç”¨åˆ°çš„è¿™3ä¸ªæŠ€å·§è¿˜æ˜¯æœ‰äº›éš¾åº¦çš„ï¼Œå¯ä»¥ç»“åˆä»£ç ç†è§£ä¸€ä¸‹ã€‚

```python
import torch 
from torch import nn 
class CrossNetMix(nn.Module):
    def __init__(self, d_in, n_cross =2, low_rank=32, n_experts=4):
        super().__init__()
        self.d_in = d_in
        self.n_cross = n_cross
        self.low_rank = low_rank
        self.n_experts = n_experts

        # U: (d_in, low_rank)
        self.U_list = nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(
            torch.empty(n_experts, d_in, low_rank))) for i in range(self.n_cross)])

        # V: (d_in, low_rank)
        self.V_list = nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(
            torch.empty(n_experts, d_in, low_rank))) for i in range(self.n_cross)])

        # C: (low_rank, low_rank)
        self.C_list = nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(
            torch.empty(n_experts, low_rank, low_rank))) for i in range(self.n_cross)])

        # G: (d_in, 1)
        self.gating = nn.ModuleList([nn.Linear(d_in, 1, bias=False) for i in range(self.n_experts)])

        # Bias 
        self.biases = nn.ParameterList([nn.Parameter(torch.zeros(d_in)) for i in range(self.n_cross)])


    def forward(self, x):
        x0 = x
        xi = x
        for i in range(self.n_cross):
            output_of_experts = []
            gating_score_of_experts = []
            for expert_id in range(self.n_experts):

                # (1) G(xi)
                # compute the gating score by xi
                gating_score_of_experts.append(self.gating[expert_id](xi))

                # (2) E(xi)
                # project the input xi to low_rank space
                v_x = xi@(self.V_list[i][expert_id])   # (batch_size, low_rank)

                # nonlinear activation in low rank space
                v_x = torch.tanh(v_x)
                v_x = v_x@self.C_list[i][expert_id]     # (batch_size, low_rank)
                v_x = torch.tanh(v_x)

                # project back to d_in space
                uv_x = v_x@(self.U_list[i][expert_id].T)  # (batch_size, d_in)
                expert_out = x0*(uv_x + self.biases[i])
                output_of_experts.append(expert_out)

            # (3) mixture of low-rank experts
            output_of_experts = torch.stack(output_of_experts, 2)  # (batch_size, d_in, n_experts)
            gating_score_of_experts = torch.stack(gating_score_of_experts, 1)  # (batch_size, n_experts, 1)
            moe_out = torch.bmm(output_of_experts, gating_score_of_experts.softmax(1))
            xi = torch.squeeze(moe_out) + xi  # (batch_size, d_in)

        return xi
```

```python

```

## äºŒï¼ŒDeepCrossçš„pytorchå®ç°


ä¸‹é¢æ˜¯DeepCrossçš„ä¸€ä¸ªpytorchå®Œæ•´å®ç°ã€‚

å¯ä»¥é€šè¿‡cross_type æ¥æŒ‡å®šæ˜¯å“ªä¸ªç‰ˆæœ¬çš„DCNæ¨¡å‹ã€‚

* cross_type = "vector" é€‰æ‹© DCNV1, ä¹Ÿå¯ä»¥ç§°ä¹‹ä¸º DCN-vector 

* cross_type = "matrix" é€‰æ‹© DCNV2, ä¹Ÿå¯ä»¥ç§°ä¹‹ä¸º DCN-matrix 

* cross_type = "mix" é€‰æ‹© DCN-mix 

é™¤äº†ä¸‰ç§CrossNetç»“æ„çš„å®ç°å¤–ï¼Œè¿˜æœ‰ä¸¤ç‚¹ç»†èŠ‚å€¼å¾—æ³¨æ„ï¼š

1ï¼ŒDeepCrosså¯¹ç±»åˆ«ç‰¹å¾çš„å¤„ç†ä¸DeepFMç­‰æ¨¡å‹ä¸å¤ªä¸€æ ·ï¼Œæ˜¯å…¨éƒ¨è½¬æ¢æˆembeddingåå†å’Œæ•°å€¼ç±»ç‰¹å¾æ‹¼åœ¨ä¸€èµ·ï¼Œè¿™ç§ç‰¹æ€§å¯ä»¥è®©å„ä¸ªç±»åˆ«ç‰¹å¾æ ¹æ®å…¶ç±»åˆ«æ•°é‡é€‰æ‹©é€‚å½“çš„embeddingé•¿åº¦ã€‚

2ï¼ŒDeepCrossä¸­Deepéƒ¨åˆ†å’ŒCrosséƒ¨åˆ†çš„å…³ç³»å¯ä»¥æ˜¯ä¸²è¡Œçš„(stacked=True)ï¼Œä¹Ÿå¯ä»¥æ˜¯å¹¶è¡Œçš„(stacked=False)ã€‚å…·ä½“å“ªç§æ•ˆæœæ›´å¥½ï¼Œå–å†³äºæ•°æ®é›†ã€‚


```python
import torch 
from torch import nn,Tensor 
import torch.nn.functional as F 

#ç¦»æ•£ç‰¹å¾ç¼–ç 
class CatEmbeddingSqrt(nn.Module):
    """
    ç¦»æ•£ç‰¹å¾ä½¿ç”¨Embeddingå±‚ç¼–ç , d_embedç­‰äºsqrt(category)
    è¾“å…¥shape: [batch_size,d_in], 
    è¾“å‡ºshape: [batch_size,d_out]
    """
    def __init__(self, categories, d_embed_max = 100):
        super().__init__()
        self.categories = categories
        self.d_embed_list = [min(max(int(x**0.5), 2),d_embed_max) for x in categories]
        self.embedding_list = nn.ModuleList([nn.Embedding(self.categories[i],self.d_embed_list[i])
                            for i in range(len(categories))])
        self.d_cat_sum = sum(self.d_embed_list)
        
    def forward(self, x_cat):
        """
        param x_cat: Long tensor of size ``(batch_size, d_in)``
        """
        x_out = torch.cat([self.embedding_list[i](x_cat[:,i]) 
                           for i in range(len(self.categories)) ],dim=1)
        return x_out
    
#deepéƒ¨åˆ†
class MLP(nn.Module):
    def __init__(self, d_in, d_layers, dropout):
        super().__init__()
        layers = []
        for d in d_layers:
            layers.append(nn.Linear(d_in, d))
            layers.append(nn.BatchNorm1d(d))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(p=dropout))
            d_in = d
        self.mlp = nn.Sequential(*layers)

    def forward(self, x):
        return self.mlp(x)
    

#3ç§CrossNetçš„å®ç°    
class CrossNetVector(nn.Module):
    def __init__(self, d_in, n_cross=2):
        super().__init__()
        self.n_cross = n_cross
        self.linears = nn.ModuleList([nn.Linear(d_in,1,bias=False) for i in range(self.n_cross)])
        self.biases = nn.ParameterList(
            [nn.Parameter(torch.zeros(d_in)) for i in range(self.n_cross)])
        
    def forward(self, x):
        x0 = x
        xi = x
        for i in range(self.n_cross):
            xi = x0*self.linears[i](xi)+self.biases[i]+xi
        return xi
    
    
class CrossNetMatrix(nn.Module):
    def __init__(self, d_in, n_cross=2):
        super().__init__()
        self.n_cross = n_cross
        self.linears = nn.ModuleList([nn.Linear(d_in,d_in) for i in range(self.n_cross)])
        
    def forward(self, x):
        x0 = x
        xi = x
        for i in range(self.n_cross):
            xi = x0*self.linears[i](xi)+xi
        return xi
    

class CrossNetMix(nn.Module):
    def __init__(self, d_in, n_cross =2, low_rank=32, n_experts=4):
        super().__init__()
        self.d_in = d_in
        self.n_cross = n_cross
        self.low_rank = low_rank
        self.n_experts = n_experts

        # U: (d_in, low_rank)
        self.U_list = nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(
            torch.empty(n_experts, d_in, low_rank))) for i in range(self.n_cross)])
        
        # V: (d_in, low_rank)
        self.V_list = nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(
            torch.empty(n_experts, d_in, low_rank))) for i in range(self.n_cross)])
        
        # C: (low_rank, low_rank)
        self.C_list = nn.ParameterList([nn.Parameter(nn.init.xavier_normal_(
            torch.empty(n_experts, low_rank, low_rank))) for i in range(self.n_cross)])
        
        # G: (d_in, 1)
        self.gating = nn.ModuleList([nn.Linear(d_in, 1, bias=False) for i in range(self.n_experts)])

        # Bias 
        self.biases = nn.ParameterList([nn.Parameter(torch.zeros(d_in)) for i in range(self.n_cross)])
        

    def forward(self, x):
        x0 = x
        xi = x
        for i in range(self.n_cross):
            output_of_experts = []
            gating_score_of_experts = []
            for expert_id in range(self.n_experts):
                
                # (1) G(xi)
                # compute the gating score by xi
                gating_score_of_experts.append(self.gating[expert_id](xi))

                # (2) E(xi)
                # project the input xi to low_rank space
                v_x = xi@(self.V_list[i][expert_id])   # (batch_size, low_rank)

                # nonlinear activation in low rank space
                v_x = torch.tanh(v_x)
                v_x = v_x@self.C_list[i][expert_id]     # (batch_size, low_rank)
                v_x = torch.tanh(v_x)

                # project back to d_in space
                uv_x = v_x@(self.U_list[i][expert_id].T)  # (batch_size, d_in)
                expert_out = x0*(uv_x + self.biases[i])
                output_of_experts.append(expert_out)

            # (3) mixture of low-rank experts
            output_of_experts = torch.stack(output_of_experts, 2)  # (batch_size, d_in, n_experts)
            gating_score_of_experts = torch.stack(gating_score_of_experts, 1)  # (batch_size, n_experts, 1)
            moe_out = torch.bmm(output_of_experts, gating_score_of_experts.softmax(1))
            xi = torch.squeeze(moe_out) + xi  # (batch_size, d_in)
            
        return xi
    
    
class DeepCross(nn.Module):
    """
    DeepCrossä¸‰ç§æ¨¡å‹(DCN-vec,DCN-matrix,DCN-mix)çš„ç»Ÿä¸€å®ç°ã€‚
    """

    def __init__(self, d_numerical, categories, d_embed_max = 8,
                 n_cross=2, cross_type = "matrix", low_rank=32, n_experts=4, 
                 mlp_layers = [128,64,32] ,mlp_dropout = 0.25, 
                 stacked = True, 
                 n_classes = 1):
        
        super().__init__()
        
        if cross_type=='mix':
            assert low_rank is not None and n_experts is not None
        
        if d_numerical is None:
            d_numerical = 0
        if categories is None:
            categories = []
            
        self.categories = categories
        self.n_classes = n_classes
        self.stacked = stacked
        
        
        self.cat_embedding = CatEmbeddingSqrt(categories, d_embed_max) if categories else None
        
        self.d_in = d_numerical 
        if self.cat_embedding:
            self.d_in+=self.cat_embedding.d_cat_sum
            
        if cross_type=="vector":
            self.cross_layer = CrossNetVector(self.d_in,n_cross)
        elif cross_type=="matrix":
            self.cross_layer = CrossNetMatrix(self.d_in,n_cross)
        elif cross_type=="mix":
            self.cross_layer = CrossNetMix(self.d_in,n_cross,low_rank,n_experts)
        else:
            raise NotImplementedError("cross_type should  be one of ('vector','matrix','mix') !")
        
        self.mlp = MLP(
            d_in= self.d_in,
            d_layers = mlp_layers,
            dropout = mlp_dropout
        )
        
        if self.stacked:
            self.last_linear = nn.Linear(mlp_layers[-1],n_classes)
        else:
            self.last_linear = nn.Linear(self.d_in+mlp_layers[-1],n_classes)
        

    def forward(self, x):
        
        """
        x_num: numerical features
        x_cat: category features
        """
        x_num,x_cat = x
        
        #embedding 
        x_total = []
        if x_num is not None:
            x_total.append(x_num)
        if self.cat_embedding is not None:
            x_total.append(self.cat_embedding(x_cat))
        x_total = torch.cat(x_total, dim=-1)
        
        
        #crosséƒ¨åˆ†
        x_cross = self.cross_layer(x_total)
        
        
        #deepéƒ¨åˆ†
        if self.stacked:
            x_deep = self.mlp(x_cross)
            x_out = self.last_linear(x_deep)
        else:
            x_deep = self.mlp(x_total)
            x_deep_cross = torch.cat([x_deep,x_cross],axis = 1)
            x_out = self.last_linear(x_deep_cross)
            
        if self.n_classes==1:
            x_out = x_out.squeeze(-1)
        
        return x_out 
```

```python
##æµ‹è¯• DeepCross

x_num = torch.randn(2,3)
x_cat = torch.randint(0,2,(2,3))

dcn_vec = DeepCross(d_numerical = 3, categories = [4,3,2], d_embed_max = 4,
        n_cross=2, cross_type = "vector", 
        mlp_layers = [20,20], mlp_dropout=0.25,
        stacked = False,
        n_classes = 1)

dcn_matrix = DeepCross(d_numerical = 3, categories = [4,3,2], d_embed_max = 4,
        n_cross=2, cross_type = "matrix", 
        mlp_layers = [20,20], mlp_dropout=0.25,
        stacked = True,
        n_classes = 1)

dcn_mix = DeepCross(d_numerical = 3, categories = [4,3,2], d_embed_max = 4,
        n_cross=2, cross_type = "mix", low_rank=32, n_experts=4, 
        mlp_layers = [20,20], mlp_dropout=0.25,
        stacked = False,
        n_classes = 1)


print(dcn_vec((x_num,x_cat)))
print(dcn_matrix((x_num,x_cat)))
print(dcn_mix((x_num,x_cat)))


```

```python

```

## ä¸‰ï¼ŒCriteoæ•°æ®é›†å®Œæ•´èŒƒä¾‹


Criteoæ•°æ®é›†æ˜¯ä¸€ä¸ªç»å…¸çš„å¹¿å‘Šç‚¹å‡»ç‡CTRé¢„æµ‹æ•°æ®é›†ã€‚

è¿™ä¸ªæ•°æ®é›†çš„ç›®æ ‡æ˜¯é€šè¿‡ç”¨æˆ·ç‰¹å¾å’Œå¹¿å‘Šç‰¹å¾æ¥é¢„æµ‹æŸæ¡å¹¿å‘Šæ˜¯å¦ä¼šä¸ºç”¨æˆ·ç‚¹å‡»ã€‚

æ•°æ®é›†æœ‰13ç»´æ•°å€¼ç‰¹å¾(I1-I13)å’Œ26ç»´ç±»åˆ«ç‰¹å¾(C14-C39), å…±39ç»´ç‰¹å¾, ç‰¹å¾ä¸­åŒ…å«ç€è®¸å¤šç¼ºå¤±å€¼ã€‚

è®­ç»ƒé›†4000ä¸‡ä¸ªæ ·æœ¬ï¼Œæµ‹è¯•é›†600ä¸‡ä¸ªæ ·æœ¬ã€‚æ•°æ®é›†å¤§å°è¶…è¿‡100G.

æ­¤å¤„ä½¿ç”¨çš„æ˜¯é‡‡æ ·100ä¸‡ä¸ªæ ·æœ¬åçš„cretio_smallæ•°æ®é›†ã€‚ 


```python

```

```python
import numpy as np 
import pandas as pd 
import datetime 

from sklearn.model_selection import train_test_split 

import torch 
from torch import nn 
from torch.utils.data import Dataset,DataLoader  
import torch.nn.functional as F 
import torchkeras 

def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(info+'...\n\n')

```

### 1ï¼Œå‡†å¤‡æ•°æ®

```python
from sklearn.preprocessing import LabelEncoder,QuantileTransformer
from sklearn.pipeline import Pipeline 
from sklearn.impute import SimpleImputer 

dfdata = pd.read_csv("./eat_pytorch_datasets/criteo_small.zip",sep="\t",header=None)
dfdata.columns = ["label"] + ["I"+str(x) for x in range(1,14)] + [
    "C"+str(x) for x in range(14,40)]

cat_cols = [x for x in dfdata.columns if x.startswith('C')]
num_cols = [x for x in dfdata.columns if x.startswith('I')]
num_pipe = Pipeline(steps = [('impute',SimpleImputer()),('quantile',QuantileTransformer())])

for col in cat_cols:
    dfdata[col]  = LabelEncoder().fit_transform(dfdata[col])

dfdata[num_cols] = num_pipe.fit_transform(dfdata[num_cols])

categories = [dfdata[col].max()+1 for col in cat_cols]

```

```python
import torch 
from torch.utils.data import Dataset,DataLoader 

#DataFrameè½¬æ¢æˆtorchæ•°æ®é›†Dataset, ç‰¹å¾åˆ†å‰²æˆX_num,X_catæ–¹å¼
class DfDataset(Dataset):
    def __init__(self,df,
                 label_col,
                 num_features,
                 cat_features,
                 categories,
                 is_training=True):
        
        self.X_num = torch.tensor(df[num_features].values).float() if num_features else None
        self.X_cat = torch.tensor(df[cat_features].values).long() if cat_features else None
        self.Y = torch.tensor(df[label_col].values).float() 
        self.categories = categories
        self.is_training = is_training
    
    def __len__(self):
        return len(self.Y)
    
    def __getitem__(self,index):
        if self.is_training:
            return ((self.X_num[index],self.X_cat[index]),self.Y[index])
        else:
            return (self.X_num[index],self.X_cat[index])
    
    def get_categories(self):
        return self.categories
    
```

```python
dftrain_val,dftest = train_test_split(dfdata,test_size=0.2)
dftrain,dfval = train_test_split(dftrain_val,test_size=0.2)

ds_train = DfDataset(dftrain,label_col = "label",num_features = num_cols,cat_features = cat_cols,
                    categories = categories, is_training=True)

ds_val = DfDataset(dfval,label_col = "label",num_features = num_cols,cat_features = cat_cols,
                    categories = categories, is_training=True)

ds_test = DfDataset(dftest,label_col = "label",num_features = num_cols,cat_features = cat_cols,
                    categories = categories, is_training=True)

```

```python
dl_train = DataLoader(ds_train,batch_size = 2048,shuffle=True)
dl_val = DataLoader(ds_val,batch_size = 2048,shuffle=False)
dl_test = DataLoader(ds_test,batch_size = 2048,shuffle=False)

for features,labels in dl_train:
    break 
    
```

### 2ï¼Œå®šä¹‰æ¨¡å‹

```python
# æ­¤å¤„æˆ‘ä»¬é€‰æ‹©çš„äº¤å‰æ¨¡å—æ˜¯CrossNetMatrix, ä¹Ÿå°±æ˜¯æ„å»ºçš„DCNV2æ¨¡å‹ 
# è¯»è€…ä¹Ÿå¯ä»¥å°è¯•CrossNetVectorå’ŒCrossNetMix 
def create_net():
    net = DeepCross(
        d_numerical= ds_train.X_num.shape[1],
        categories= ds_train.get_categories(),
        d_embed_max = 8, 
        n_cross = 2, cross_type = "matrix",
        mlp_layers = [128,64,32], mlp_dropout=0.25,
        stacked = True,
        n_classes = 1
        
    )
    return net 

from torchkeras import summary

net = create_net()


```

```python

```

### 3ï¼Œè®­ç»ƒæ¨¡å‹

```python
import os,sys,time
import numpy as np
import pandas as pd
import datetime 
from tqdm import tqdm 

import torch
from torch import nn 
from accelerate import Accelerator
from copy import deepcopy


def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(str(info)+"\n")
    
class StepRunner:
    def __init__(self, net, loss_fn,stage = "train", metrics_dict = None, 
                 optimizer = None, lr_scheduler = None,
                 accelerator = None
                 ):
        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage
        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler
        self.accelerator = accelerator
    
    def __call__(self, features, labels):
        #loss
        preds = self.net(features)
        loss = self.loss_fn(preds,labels)

        #backward()
        if self.optimizer is not None and self.stage=="train":
            if self.accelerator is  None:
                loss.backward()
            else:
                self.accelerator.backward(loss)
            self.optimizer.step()
            if self.lr_scheduler is not None:
                self.lr_scheduler.step()
            self.optimizer.zero_grad()
            
        #metrics
        step_metrics = {self.stage+"_"+name:metric_fn(preds, labels).item() 
                        for name,metric_fn in self.metrics_dict.items()}
        return loss.item(),step_metrics
    
    
class EpochRunner:
    def __init__(self,steprunner):
        self.steprunner = steprunner
        self.stage = steprunner.stage
        self.steprunner.net.train() if self.stage=="train" else self.steprunner.net.eval()
        
    def __call__(self,dataloader):
        total_loss,step = 0,0
        loop = tqdm(enumerate(dataloader), total =len(dataloader))
        for i, batch in loop:
            features,labels = batch
            if self.stage=="train":
                loss, step_metrics = self.steprunner(features,labels)
            else:
                with torch.no_grad():
                    loss, step_metrics = self.steprunner(features,labels)

            step_log = dict({self.stage+"_loss":loss},**step_metrics)

            total_loss += loss
            step+=1
            if i!=len(dataloader)-1:
                loop.set_postfix(**step_log)
            else:
                epoch_loss = total_loss/step
                epoch_metrics = {self.stage+"_"+name:metric_fn.compute().item() 
                                 for name,metric_fn in self.steprunner.metrics_dict.items()}
                epoch_log = dict({self.stage+"_loss":epoch_loss},**epoch_metrics)
                loop.set_postfix(**epoch_log)

                for name,metric_fn in self.steprunner.metrics_dict.items():
                    metric_fn.reset()
        return epoch_log

class KerasModel(torch.nn.Module):
    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None):
        super().__init__()
        self.accelerator = Accelerator()
        self.history = {}
        
        self.net = net
        self.loss_fn = loss_fn
        self.metrics_dict = nn.ModuleDict(metrics_dict) 
        
        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(
            self.parameters(), lr=1e-2)
        self.lr_scheduler = lr_scheduler
        
        self.net,self.loss_fn,self.metrics_dict,self.optimizer = self.accelerator.prepare(
            self.net,self.loss_fn,self.metrics_dict,self.optimizer)

    def forward(self, x):
        if self.net:
            return self.net.forward(x)
        else:
            raise NotImplementedError


    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint.pt', 
            patience=5, monitor="val_loss", mode="min"):
        
        train_data = self.accelerator.prepare(train_data)
        val_data = self.accelerator.prepare(val_data) if val_data else []

        for epoch in range(1, epochs+1):
            printlog("Epoch {0} / {1}".format(epoch, epochs))
            
            # 1ï¼Œtrain -------------------------------------------------  
            train_step_runner = StepRunner(net = self.net,stage="train",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    optimizer = self.optimizer, lr_scheduler = self.lr_scheduler,
                    accelerator = self.accelerator)
            train_epoch_runner = EpochRunner(train_step_runner)
            train_metrics = train_epoch_runner(train_data)
            
            for name, metric in train_metrics.items():
                self.history[name] = self.history.get(name, []) + [metric]

            # 2ï¼Œvalidate -------------------------------------------------
            if val_data:
                val_step_runner = StepRunner(net = self.net,stage="val",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    accelerator = self.accelerator)
                val_epoch_runner = EpochRunner(val_step_runner)
                with torch.no_grad():
                    val_metrics = val_epoch_runner(val_data)
                val_metrics["epoch"] = epoch
                for name, metric in val_metrics.items():
                    self.history[name] = self.history.get(name, []) + [metric]
            
            # 3ï¼Œearly-stopping -------------------------------------------------
            arr_scores = self.history[monitor]
            best_score_idx = np.argmax(arr_scores) if mode=="max" else np.argmin(arr_scores)
            if best_score_idx==len(arr_scores)-1:
                torch.save(self.net.state_dict(),ckpt_path)
                print("<<<<<< reach best {0} : {1} >>>>>>".format(monitor,
                     arr_scores[best_score_idx]),file=sys.stderr)
            if len(arr_scores)-best_score_idx>patience:
                print("<<<<<< {} without improvement in {} epoch, early stopping >>>>>>".format(
                    monitor,patience),file=sys.stderr)
                self.net.load_state_dict(torch.load(ckpt_path))
                break 
            
        return pd.DataFrame(self.history)

    @torch.no_grad()
    def evaluate(self, val_data):
        val_data = self.accelerator.prepare(val_data)
        val_step_runner = StepRunner(net = self.net,stage="val",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    accelerator = self.accelerator)
        val_epoch_runner = EpochRunner(val_step_runner)
        val_metrics = val_epoch_runner(val_data)
        return val_metrics
        
       
    @torch.no_grad()
    def predict(self, dataloader):
        dataloader = self.accelerator.prepare(dataloader)
        result = torch.cat([self.forward(t[0]) for t in dataloader])
        return result.data
    
```

```python
from torchkeras.metrics import AUC

loss_fn = nn.BCEWithLogitsLoss()

metrics_dict = {"auc":AUC()}

optimizer = torch.optim.Adam(net.parameters(), lr=0.002, weight_decay=0.001) 

model = KerasModel(net,
                   loss_fn = loss_fn,
                   metrics_dict= metrics_dict,
                   optimizer = optimizer
                  )         
```

```python
dfhistory = model.fit(train_data=dl_train,val_data=dl_val,epochs=100, patience=5,
                      monitor = "val_auc",mode="max",ckpt_path='checkpoint.pt')
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2wiwm0e3gj20mn0f8goa.jpg)


### 4ï¼Œè¯„ä¼°æ¨¡å‹

```python
%matplotlib inline
%config InlineBackend.figure_format = 'svg'

import matplotlib.pyplot as plt

def plot_metric(dfhistory, metric):
    train_metrics = dfhistory["train_"+metric]
    val_metrics = dfhistory['val_'+metric]
    epochs = range(1, len(train_metrics) + 1)
    plt.plot(epochs, train_metrics, 'bo--')
    plt.plot(epochs, val_metrics, 'ro-')
    plt.title('Training and validation '+ metric)
    plt.xlabel("Epochs")
    plt.ylabel(metric)
    plt.legend(["train_"+metric, 'val_'+metric])
    plt.show()
```

```python
plot_metric(dfhistory,"loss")
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2wizlzzsij20fv0a73yt.jpg)

```python
plot_metric(dfhistory,"auc")
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h2wiymw5nzj20fj0aaaad.jpg) 


### 5ï¼Œä½¿ç”¨æ¨¡å‹

```python
from sklearn.metrics import roc_auc_score
preds = torch.sigmoid(model.predict(dl_val))
labels = torch.cat([x[-1] for x in dl_val])

val_auc = roc_auc_score(labels.cpu().numpy(),preds.cpu().numpy())
print(val_auc)
```

0.7820486224544348



### 6ï¼Œä¿å­˜æ¨¡å‹

```python
torch.save(model.net.state_dict(),"best_dcn.pt")
net_clone = create_net()
net_clone.load_state_dict(torch.load("best_dcn.pt"))
```

```python
from sklearn.metrics import roc_auc_score
net_clone.eval()
preds = torch.cat([torch.sigmoid(net_clone(x[0])).data for x in dl_val]) 
labels = torch.cat([x[-1] for x in dl_val])

val_auc = roc_auc_score(labels.cpu().numpy(),preds.cpu().numpy())
print(val_auc)
```

0.7820486196785761



**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)
