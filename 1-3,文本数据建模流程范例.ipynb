{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37dfe75a",
   "metadata": {},
   "source": [
    "# 1-3,æ–‡æœ¬æ•°æ®å»ºæ¨¡æµç¨‹èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87488d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "#æ‰“å°æ—¶é—´\n",
    "def printbar():\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "#macç³»ç»Ÿä¸Špytorchå’Œmatplotlibåœ¨jupyterä¸­åŒæ—¶è·‘éœ€è¦æ›´æ”¹ç¯å¢ƒå˜é‡\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dfe3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchtext==0.11.0\n",
    "!pip install torchkeras==3.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95288a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchtext \n",
    "import torchkeras \n",
    "print(\"torch.__version__ = \", torch.__version__)\n",
    "print(\"torchtext.__version__ = \", torchtext.__version__) \n",
    "print(\"torchkeras.__version__ = \", torchkeras.__version__) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c47e0",
   "metadata": {},
   "source": [
    "```\n",
    "torch.__version__ =  1.10.0\n",
    "torchtext.__version__ =  0.11.0\n",
    "torchkeras.__version__ =  3.2.3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c4202e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=\"red\">\n",
    " \n",
    "å…¬ä¼—å· **ç®—æ³•ç¾é£Ÿå±‹** å›å¤å…³é”®è¯ï¼š**pytorch**ï¼Œ è·å–æœ¬é¡¹ç›®æºç å’Œæ‰€ç”¨æ•°æ®é›†ç™¾åº¦äº‘ç›˜ä¸‹è½½é“¾æ¥ã€‚\n",
    "    \n",
    "</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd0289f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be150a8a",
   "metadata": {},
   "source": [
    "### ä¸€ï¼Œå‡†å¤‡æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c21091b",
   "metadata": {},
   "source": [
    "imdbæ•°æ®é›†çš„ç›®æ ‡æ˜¯æ ¹æ®ç”µå½±è¯„è®ºçš„æ–‡æœ¬å†…å®¹é¢„æµ‹è¯„è®ºçš„æƒ…æ„Ÿæ ‡ç­¾ã€‚\n",
    "\n",
    "è®­ç»ƒé›†æœ‰20000æ¡ç”µå½±è¯„è®ºæ–‡æœ¬ï¼Œæµ‹è¯•é›†æœ‰5000æ¡ç”µå½±è¯„è®ºæ–‡æœ¬ï¼Œå…¶ä¸­æ­£é¢è¯„è®ºå’Œè´Ÿé¢è¯„è®ºéƒ½å„å ä¸€åŠã€‚\n",
    "\n",
    "æ–‡æœ¬æ•°æ®é¢„å¤„ç†è¾ƒä¸ºç¹çï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ‡è¯ï¼Œæ„å»ºè¯å…¸ï¼Œç¼–ç è½¬æ¢ï¼Œåºåˆ—å¡«å……ï¼Œæ„å»ºæ•°æ®ç®¡é“ç­‰ç­‰ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a8aa6",
   "metadata": {},
   "source": [
    "åœ¨torchä¸­é¢„å¤„ç†æ–‡æœ¬æ•°æ®å¯ä»¥å€ŸåŠ©torchtextä¸­çš„è¯å…¸å·¥å…·å¹¶è‡ªå®šä¹‰Datasetã€‚\n",
    "\n",
    "ä¸‹é¢è¿›è¡Œæ¼”ç¤ºã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132822a",
   "metadata": {},
   "source": [
    "![](./data/ç”µå½±è¯„è®º.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef3f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "MIN_FREQ = 30      #ä»…è€ƒè™‘è¯é¢‘è¶…è¿‡30çš„è¯\n",
    "MAX_LEN = 200      #æ¯ä¸ªæ ·æœ¬ä¿ç•™200ä¸ªè¯çš„é•¿åº¦\n",
    "BATCH_SIZE = 20 \n",
    "\n",
    "\n",
    "dftrain = pd.read_csv(\"./eat_pytorch_datasets/imdb/train.tsv\",sep=\"\\t\",header = None,names = [\"label\",\"text\"])\n",
    "dfval = pd.read_csv(\"./eat_pytorch_datasets/imdb/test.tsv\",sep=\"\\t\",header = None,names = [\"label\",\"text\"])\n",
    "\n",
    "\n",
    "#1ï¼Œæ–‡æœ¬åˆ‡è¯\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "\n",
    "#2ï¼Œæ„å»ºè¯å…¸        \n",
    "PAD_IDX,UNK_IDX = 0,1\n",
    "special_symbols = ['<pad>','<unk>']\n",
    "\n",
    "def yield_tokens(dfdata):\n",
    "    for text in dfdata[\"text\"]:\n",
    "        yield tokenizer(text)\n",
    "        \n",
    "\n",
    "        \n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(dftrain),\n",
    "    min_freq = MIN_FREQ,\n",
    "    specials=special_symbols,\n",
    "    special_first=True)\n",
    "\n",
    "vocab.set_default_index(UNK_IDX)\n",
    "vocab_size = len(vocab)\n",
    "print(\"vocab_size =\"+str(vocab_size)) \n",
    "\n",
    "#æŸ¥çœ‹è¯å…¸å‰20ä¸ªè¯\n",
    "#itos: index to string\n",
    "#stoi: string to index\n",
    "print(\"vocab.get_itos():\\n\",vocab.get_itos()[:20])\n",
    "print(\"vocab.get_stoi()['<pad>']:\\n\",vocab.get_stoi()['<pad>'])\n",
    "\n",
    "\n",
    "#3ï¼Œåºåˆ—å¡«å……\n",
    "def pad(seq,max_length,pad_value=0):\n",
    "    n = len(seq)\n",
    "    result = seq+[pad_value]*max_length\n",
    "    return result[:max_length]\n",
    "\n",
    "\n",
    "#4ï¼Œç¼–ç è½¬æ¢\n",
    "def text_pipeline(text):\n",
    "    words = tokenizer(text)\n",
    "    tokens = vocab(words)\n",
    "    result = pad(tokens,MAX_LEN,PAD_IDX)\n",
    "    return result \n",
    "\n",
    "print(text_pipeline(\"this is an example!\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6675f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8338e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5ï¼Œæ„å»ºç®¡é“\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class ImdbDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,index):\n",
    "        text = self.df[\"text\"].iloc[index]\n",
    "        label = torch.tensor([self.df[\"label\"].iloc[index]]).float()\n",
    "        tokens = torch.tensor(text_pipeline(text)).int() \n",
    "        return tokens,label\n",
    "    \n",
    "ds_train = ImdbDataset(dftrain)\n",
    "ds_val = ImdbDataset(dfval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698296a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train,batch_size = 50,shuffle = True)\n",
    "dl_val = DataLoader(ds_val,batch_size = 50,shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,labels in dl_train:\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5ae7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8971bba1",
   "metadata": {},
   "source": [
    "### äºŒï¼Œå®šä¹‰æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014a534",
   "metadata": {},
   "source": [
    "ä½¿ç”¨Pytorché€šå¸¸æœ‰ä¸‰ç§æ–¹å¼æ„å»ºæ¨¡å‹ï¼šä½¿ç”¨nn.SequentialæŒ‰å±‚é¡ºåºæ„å»ºæ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºè‡ªå®šä¹‰æ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºæ¨¡å‹å¹¶è¾…åŠ©åº”ç”¨æ¨¡å‹å®¹å™¨(nn.Sequential,nn.ModuleList,nn.ModuleDict)è¿›è¡Œå°è£…ã€‚\n",
    "\n",
    "æ­¤å¤„é€‰æ‹©ä½¿ç”¨ç¬¬ä¸‰ç§æ–¹å¼è¿›è¡Œæ„å»ºã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b42dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37193036",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #è®¾ç½®padding_idxå‚æ•°åå°†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°†å¡«å……çš„tokenå§‹ç»ˆèµ‹å€¼ä¸º0å‘é‡\n",
    "        self.embedding = nn.Embedding(num_embeddings = vocab_size,embedding_dim = 3,padding_idx = 0)\n",
    "        \n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.add_module(\"conv_1\",nn.Conv1d(in_channels = 3,out_channels = 16,kernel_size = 5))\n",
    "        self.conv.add_module(\"pool_1\",nn.MaxPool1d(kernel_size = 2))\n",
    "        self.conv.add_module(\"relu_1\",nn.ReLU())\n",
    "        self.conv.add_module(\"conv_2\",nn.Conv1d(in_channels = 16,out_channels = 128,kernel_size = 2))\n",
    "        self.conv.add_module(\"pool_2\",nn.MaxPool1d(kernel_size = 2))\n",
    "        self.conv.add_module(\"relu_2\",nn.ReLU())\n",
    "        \n",
    "        self.dense = nn.Sequential()\n",
    "        self.dense.add_module(\"flatten\",nn.Flatten())\n",
    "        self.dense.add_module(\"linear\",nn.Linear(6144,1))\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x).transpose(1,2)\n",
    "        x = self.conv(x)\n",
    "        y = self.dense(x)\n",
    "        return y\n",
    "        \n",
    "net = Net() \n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f34cc2",
   "metadata": {},
   "source": [
    "```\n",
    "Net(\n",
    "  (embedding): Embedding(8813, 3, padding_idx=0)\n",
    "  (conv): Sequential(\n",
    "    (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))\n",
    "    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (relu_1): ReLU()\n",
    "    (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))\n",
    "    (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (relu_2): ReLU()\n",
    "  )\n",
    "  (dense): Sequential(\n",
    "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
    "    (linear): Linear(in_features=6144, out_features=1, bias=True)\n",
    "  )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885dc4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57016b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from torchkeras import summary \n",
    "summary(net,input_data=features);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc09084",
   "metadata": {},
   "source": [
    "### ä¸‰ï¼Œè®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d476c85",
   "metadata": {},
   "source": [
    "è®­ç»ƒPytorché€šå¸¸éœ€è¦ç”¨æˆ·ç¼–å†™è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼Œè®­ç»ƒå¾ªç¯çš„ä»£ç é£æ ¼å› äººè€Œå¼‚ã€‚\n",
    "\n",
    "æœ‰3ç±»å…¸å‹çš„è®­ç»ƒå¾ªç¯ä»£ç é£æ ¼ï¼šè„šæœ¬å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œå‡½æ•°å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œç±»å½¢å¼è®­ç»ƒå¾ªç¯ã€‚\n",
    "\n",
    "æ­¤å¤„ä»‹ç»ä¸€ç§è¾ƒé€šç”¨çš„ä»¿ç…§Kerasé£æ ¼çš„ç±»å½¢å¼çš„è®­ç»ƒå¾ªç¯ã€‚\n",
    "\n",
    "è¯¥è®­ç»ƒå¾ªç¯çš„ä»£ç ä¹Ÿæ˜¯torchkerasåº“çš„æ ¸å¿ƒä»£ç ã€‚\n",
    "\n",
    "torchkerasè¯¦æƒ…:  https://github.com/lyhue1991/torchkeras \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "from copy import deepcopy\n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(str(info)+\"\\n\")\n",
    "\n",
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn,stage = \"train\", metrics_dict = None, \n",
    "                 optimizer = None, lr_scheduler = None\n",
    "                 ):\n",
    "        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n",
    "        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n",
    "    \n",
    "    def __call__(self, features, labels):\n",
    "        #loss\n",
    "        preds = self.net(features)\n",
    "        loss = self.loss_fn(preds,labels)\n",
    "\n",
    "        #backward()\n",
    "        if self.optimizer is not None and self.stage==\"train\":\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "        #metrics\n",
    "        step_metrics = {self.stage+\"_\"+name:metric_fn(preds, labels).item() \n",
    "                        for name,metric_fn in self.metrics_dict.items()}\n",
    "        return loss.item(),step_metrics\n",
    "\n",
    "\n",
    "class EpochRunner:\n",
    "    def __init__(self,steprunner):\n",
    "        self.steprunner = steprunner\n",
    "        self.stage = steprunner.stage\n",
    "        self.steprunner.net.train() if self.stage==\"train\" else self.steprunner.net.eval()\n",
    "        \n",
    "    def __call__(self,dataloader):\n",
    "        total_loss,step = 0,0\n",
    "        loop = tqdm(enumerate(dataloader), total =len(dataloader))\n",
    "        for i, batch in loop: \n",
    "            if self.stage==\"train\":\n",
    "                loss, step_metrics = self.steprunner(*batch)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    loss, step_metrics = self.steprunner(*batch)\n",
    "            step_log = dict({self.stage+\"_loss\":loss},**step_metrics)\n",
    "\n",
    "            total_loss += loss\n",
    "            step+=1\n",
    "            if i!=len(dataloader)-1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                epoch_loss = total_loss/step\n",
    "                epoch_metrics = {self.stage+\"_\"+name:metric_fn.compute().item() \n",
    "                                 for name,metric_fn in self.steprunner.metrics_dict.items()}\n",
    "                epoch_log = dict({self.stage+\"_loss\":epoch_loss},**epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name,metric_fn in self.steprunner.metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "        return epoch_log\n",
    "\n",
    "class KerasModel(torch.nn.Module):\n",
    "    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None):\n",
    "        super().__init__()\n",
    "        self.history = {}\n",
    "        \n",
    "        self.net = net\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metrics_dict = nn.ModuleDict(metrics_dict) \n",
    "        \n",
    "        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(\n",
    "            self.parameters(), lr=1e-2)\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.net:\n",
    "            return self.net.forward(x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint.pt', \n",
    "            patience=5, monitor=\"val_loss\", mode=\"min\"):\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "            printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "            \n",
    "            # 1ï¼Œtrain -------------------------------------------------  \n",
    "            train_step_runner = StepRunner(net = self.net,stage=\"train\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),\n",
    "                    optimizer = self.optimizer, lr_scheduler = self.lr_scheduler)\n",
    "            train_epoch_runner = EpochRunner(train_step_runner)\n",
    "            train_metrics = train_epoch_runner(train_data)\n",
    "            \n",
    "            for name, metric in train_metrics.items():\n",
    "                self.history[name] = self.history.get(name, []) + [metric]\n",
    "\n",
    "            # 2ï¼Œvalidate -------------------------------------------------\n",
    "            if val_data:\n",
    "                val_step_runner = StepRunner(net = self.net,stage=\"val\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict))\n",
    "                val_epoch_runner = EpochRunner(val_step_runner)\n",
    "                with torch.no_grad():\n",
    "                    val_metrics = val_epoch_runner(val_data)\n",
    "                val_metrics[\"epoch\"] = epoch\n",
    "                for name, metric in val_metrics.items():\n",
    "                    self.history[name] = self.history.get(name, []) + [metric]\n",
    "            \n",
    "            # 3ï¼Œearly-stopping -------------------------------------------------\n",
    "            if not val_data:\n",
    "                continue\n",
    "            arr_scores = self.history[monitor]\n",
    "            best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "            if best_score_idx==len(arr_scores)-1:\n",
    "                torch.save(self.net.state_dict(),ckpt_path)\n",
    "                print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "                     arr_scores[best_score_idx]),file=sys.stderr)\n",
    "            if len(arr_scores)-best_score_idx>patience:\n",
    "                print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "                    monitor,patience),file=sys.stderr)\n",
    "                break \n",
    "                \n",
    "        self.net.load_state_dict(torch.load(ckpt_path))  \n",
    "        return pd.DataFrame(self.history)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, val_data):\n",
    "        val_step_runner = StepRunner(net = self.net,stage=\"val\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict))\n",
    "        val_epoch_runner = EpochRunner(val_step_runner)\n",
    "        val_metrics = val_epoch_runner(val_data)\n",
    "        return val_metrics\n",
    "        \n",
    "       \n",
    "    @torch.no_grad()\n",
    "    def predict(self, dataloader):\n",
    "        self.net.eval()\n",
    "        result = torch.cat([self.forward(t[0]) for t in dataloader])\n",
    "        return result.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2900cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics \n",
    "\n",
    "class Accuracy(torchmetrics.Accuracy):\n",
    "    def __init__(self, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        \n",
    "    def update(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        super().update(torch.sigmoid(preds),targets.long())\n",
    "            \n",
    "    def compute(self):\n",
    "        return super().compute()\n",
    "    \n",
    "net = Net() \n",
    "model = KerasModel(net,\n",
    "                  loss_fn = nn.BCEWithLogitsLoss(),\n",
    "                  optimizer= torch.optim.Adam(net.parameters(),lr = 0.01),  \n",
    "                  metrics_dict = {\"acc\":Accuracy()}\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a04882",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dl_train,\n",
    "    val_data=dl_val,\n",
    "    epochs=10,\n",
    "    ckpt_path='checkpoint.pt',\n",
    "    patience=3,\n",
    "    monitor='val_acc',\n",
    "    mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c6be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe3458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff35951",
   "metadata": {},
   "source": [
    "### å››ï¼Œè¯„ä¼°æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "history = model.history\n",
    "dfhistory = pd.DataFrame(history) \n",
    "dfhistory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93107420",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(dfhistory, metric):\n",
    "    train_metrics = dfhistory[\"train_\"+metric]\n",
    "    val_metrics = dfhistory['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51029d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18385277",
   "metadata": {},
   "source": [
    "![](./data/1-3-lossæ›²çº¿.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94294cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2960e2b",
   "metadata": {},
   "source": [
    "![](./data/1-3-accuracyæ›²çº¿.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a148942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯„ä¼°\n",
    "model.evaluate(dl_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2796b76",
   "metadata": {},
   "source": [
    "```\n",
    "{'val_loss': 0.36953783154487607, 'val_acc': 0.848800003528595}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2045e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1bc62f0",
   "metadata": {},
   "source": [
    "### äº”ï¼Œä½¿ç”¨æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a67857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net,dl):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        result = nn.Sigmoid()(torch.cat([net.forward(t[0]) for t in dl]))\n",
    "    return(result.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f916311",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = predict(net,dl_val)\n",
    "y_pred_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9976d04f",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[0.5638],\n",
    "        [0.9990],\n",
    "        [0.9573],\n",
    "        ...,\n",
    "        [0.9188],\n",
    "        [0.8004],\n",
    "        [0.9998]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b69aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31c888a8",
   "metadata": {},
   "source": [
    "### å…­ï¼Œä¿å­˜æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee13dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ¨¡å‹æƒé‡å·²ç»è¢«ä¿å­˜åœ¨äº†ckpt_path='checkpoint.pt'\n",
    "net_clone = Net()\n",
    "net_clone.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6c7de",
   "metadata": {},
   "source": [
    "**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** \n",
    "\n",
    "å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·\"ç®—æ³•ç¾é£Ÿå±‹\"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚\n",
    "\n",
    "![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
