# 2-2,è‡ªåŠ¨å¾®åˆ†æœºåˆ¶


ç¥ç»ç½‘ç»œé€šå¸¸ä¾èµ–åå‘ä¼ æ’­æ±‚æ¢¯åº¦æ¥æ›´æ–°ç½‘ç»œå‚æ•°ï¼Œæ±‚æ¢¯åº¦è¿‡ç¨‹é€šå¸¸æ˜¯ä¸€ä»¶éå¸¸å¤æ‚è€Œå®¹æ˜“å‡ºé”™çš„äº‹æƒ…ã€‚

è€Œæ·±åº¦å­¦ä¹ æ¡†æ¶å¯ä»¥å¸®åŠ©æˆ‘ä»¬è‡ªåŠ¨åœ°å®Œæˆè¿™ç§æ±‚æ¢¯åº¦è¿ç®—ã€‚

Pytorchä¸€èˆ¬é€šè¿‡åå‘ä¼ æ’­ backward æ–¹æ³• å®ç°è¿™ç§æ±‚æ¢¯åº¦è®¡ç®—ã€‚è¯¥æ–¹æ³•æ±‚å¾—çš„æ¢¯åº¦å°†å­˜åœ¨å¯¹åº”è‡ªå˜é‡å¼ é‡çš„gradå±æ€§ä¸‹ã€‚

é™¤æ­¤ä¹‹å¤–ï¼Œä¹Ÿèƒ½å¤Ÿè°ƒç”¨torch.autograd.grad å‡½æ•°æ¥å®ç°æ±‚æ¢¯åº¦è®¡ç®—ã€‚

è¿™å°±æ˜¯Pytorchçš„è‡ªåŠ¨å¾®åˆ†æœºåˆ¶ã€‚


### ä¸€ï¼Œåˆ©ç”¨backwardæ–¹æ³•æ±‚å¯¼æ•°


backward æ–¹æ³•é€šå¸¸åœ¨ä¸€ä¸ªæ ‡é‡å¼ é‡ä¸Šè°ƒç”¨ï¼Œè¯¥æ–¹æ³•æ±‚å¾—çš„æ¢¯åº¦å°†å­˜åœ¨å¯¹åº”è‡ªå˜é‡å¼ é‡çš„gradå±æ€§ä¸‹ã€‚

å¦‚æœè°ƒç”¨çš„å¼ é‡éæ ‡é‡ï¼Œåˆ™è¦ä¼ å…¥ä¸€ä¸ªå’Œå®ƒåŒå½¢çŠ¶ çš„gradientå‚æ•°å¼ é‡ã€‚

ç›¸å½“äºç”¨è¯¥gradientå‚æ•°å¼ é‡ä¸è°ƒç”¨å¼ é‡ä½œå‘é‡ç‚¹ä¹˜ï¼Œå¾—åˆ°çš„æ ‡é‡ç»“æœå†åå‘ä¼ æ’­ã€‚



**1, æ ‡é‡çš„åå‘ä¼ æ’­**

```python
import numpy as np 
import torch 

# f(x) = a*x**2 + b*x + cçš„å¯¼æ•°

x = torch.tensor(0.0,requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼
a = torch.tensor(1.0)
b = torch.tensor(-2.0)
c = torch.tensor(1.0)
y = a*torch.pow(x,2) + b*x + c 

y.backward()
dy_dx = x.grad
print(dy_dx)

```

```
tensor(-2.)
```


**2, éæ ‡é‡çš„åå‘ä¼ æ’­**

```python
import numpy as np 
import torch 

# f(x) = a*x**2 + b*x + c

x = torch.tensor([[0.0,0.0],[1.0,2.0]],requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼
a = torch.tensor(1.0)
b = torch.tensor(-2.0)
c = torch.tensor(1.0)
y = a*torch.pow(x,2) + b*x + c 

gradient = torch.tensor([[1.0,1.0],[1.0,1.0]])

print("x:\n",x)
print("y:\n",y)
y.backward(gradient = gradient)
x_grad = x.grad
print("x_grad:\n",x_grad)
```

```
x:
 tensor([[0., 0.],
        [1., 2.]], requires_grad=True)
y:
 tensor([[1., 1.],
        [0., 1.]], grad_fn=<AddBackward0>)
x_grad:
 tensor([[-2., -2.],
        [ 0.,  2.]])
```


**3, éæ ‡é‡çš„åå‘ä¼ æ’­å¯ä»¥ç”¨æ ‡é‡çš„åå‘ä¼ æ’­å®ç°**

```python
import numpy as np 
import torch 

# f(x) = a*x**2 + b*x + c

x = torch.tensor([[0.0,0.0],[1.0,2.0]],requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼
a = torch.tensor(1.0)
b = torch.tensor(-2.0)
c = torch.tensor(1.0)
y = a*torch.pow(x,2) + b*x + c 

gradient = torch.tensor([[1.0,1.0],[1.0,1.0]])
z = torch.sum(y*gradient)

print("x:",x)
print("y:",y)
z.backward()
x_grad = x.grad
print("x_grad:\n",x_grad)
```

```
x: tensor([[0., 0.],
        [1., 2.]], requires_grad=True)
y: tensor([[1., 1.],
        [0., 1.]], grad_fn=<AddBackward0>)
x_grad:
 tensor([[-2., -2.],
        [ 0.,  2.]])
```

```python

```

### äºŒï¼Œåˆ©ç”¨autograd.gradæ–¹æ³•æ±‚å¯¼æ•°

```python
import numpy as np 
import torch 

# f(x) = a*x**2 + b*x + cçš„å¯¼æ•°

x = torch.tensor(0.0,requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼
a = torch.tensor(1.0)
b = torch.tensor(-2.0)
c = torch.tensor(1.0)
y = a*torch.pow(x,2) + b*x + c


# create_graph è®¾ç½®ä¸º True å°†å…è®¸åˆ›å»ºæ›´é«˜é˜¶çš„å¯¼æ•° 
dy_dx = torch.autograd.grad(y,x,create_graph=True)[0]
print(dy_dx.data)

# æ±‚äºŒé˜¶å¯¼æ•°
dy2_dx2 = torch.autograd.grad(dy_dx,x)[0] 

print(dy2_dx2.data)


```

```
tensor(-2.)
tensor(2.)
```

```python
import numpy as np 
import torch 

x1 = torch.tensor(1.0,requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼
x2 = torch.tensor(2.0,requires_grad = True)

y1 = x1*x2
y2 = x1+x2


# å…è®¸åŒæ—¶å¯¹å¤šä¸ªè‡ªå˜é‡æ±‚å¯¼æ•°
(dy1_dx1,dy1_dx2) = torch.autograd.grad(outputs=y1,inputs = [x1,x2],retain_graph = True)
print(dy1_dx1,dy1_dx2)

# å¦‚æœæœ‰å¤šä¸ªå› å˜é‡ï¼Œç›¸å½“äºæŠŠå¤šä¸ªå› å˜é‡çš„æ¢¯åº¦ç»“æœæ±‚å’Œ
(dy12_dx1,dy12_dx2) = torch.autograd.grad(outputs=[y1,y2],inputs = [x1,x2])
print(dy12_dx1,dy12_dx2)


```

```
tensor(2.) tensor(1.)
tensor(3.) tensor(2.)
```

```python

```

### ä¸‰ï¼Œåˆ©ç”¨è‡ªåŠ¨å¾®åˆ†å’Œä¼˜åŒ–å™¨æ±‚æœ€å°å€¼

```python
import numpy as np 
import torch 

# f(x) = a*x**2 + b*x + cçš„æœ€å°å€¼

x = torch.tensor(0.0,requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼
a = torch.tensor(1.0)
b = torch.tensor(-2.0)
c = torch.tensor(1.0)

optimizer = torch.optim.SGD(params=[x],lr = 0.01)


def f(x):
    result = a*torch.pow(x,2) + b*x + c 
    return(result)

for i in range(500):
    optimizer.zero_grad()
    y = f(x)
    y.backward()
    optimizer.step()
   
    
print("y=",f(x).data,";","x=",x.data)

```

```
y= tensor(0.) ; x= tensor(1.0000)
```

```python

```

**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](./data/ç®—æ³•ç¾é£Ÿå±‹äºŒç»´ç .jpg)
