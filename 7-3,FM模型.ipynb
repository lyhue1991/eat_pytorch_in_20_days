{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "545f38ff",
   "metadata": {},
   "source": [
    "# 7-3ï¼ŒFMæ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06ffa1c",
   "metadata": {},
   "source": [
    "FMç®—æ³•å…¨ç§°ä¸ºå› å­åˆ†è§£æœº (FactorizationMachine)ã€‚\n",
    "\n",
    "å®ƒæ˜¯å¹¿å‘Šå’Œæ¨èé¢†åŸŸéå¸¸è‘—åçš„ç®—æ³•ï¼Œåœ¨çº¿æ€§å›å½’æ¨¡å‹ä¸Šè€ƒè™‘äº†ç‰¹å¾çš„äºŒé˜¶äº¤äº’ã€‚\n",
    "\n",
    "é€‚åˆæ•æ‰å¤§è§„æ¨¡ç¨€ç–ç‰¹å¾(ç±»åˆ«ç‰¹å¾)å½“ä¸­çš„ç‰¹å¾äº¤äº’ã€‚\n",
    "\n",
    "FMåŠå…¶è¡ç”Ÿçš„ä¸€äº›è¾ƒæœ‰åçš„ç®—æ³•çš„ç®€è¦ä»‹ç»å¦‚ä¸‹ï¼š\n",
    "\n",
    "* FM(FactorizationMachine)ï¼šåœ¨LRåŸºç¡€ä¸Šç”¨éšå‘é‡ç‚¹ç§¯å®ç°è‡ªåŠ¨åŒ–ç‰¹å¾äºŒé˜¶äº¤å‰ï¼Œä¸”äº¤äº’é¡¹çš„è®¡ç®—å¤æ‚åº¦æ˜¯O(n)ï¼Œæ•ˆæœæ˜¾è‘—å¥½äºLRï¼Œé€Ÿåº¦æå¿«æ¥è¿‘LRã€‚\n",
    "\n",
    "* FFM(Field Aware FM): åœ¨FMçš„åŸºç¡€ä¸Šè€ƒè™‘å¯¹ä¸åŒçš„ç‰¹å¾åŸŸ(Fieldï¼Œå¯ä»¥ç†è§£æˆç‰¹å¾çš„åˆ†ç»„)ä½¿ç”¨ä¸åŒçš„éšå‘é‡ã€‚æ•ˆæœå¥½äºFMï¼Œä½†å‚æ•°é‡æ€¥å‰§å¢åŠ ï¼Œä¸”é¢„æµ‹æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚\n",
    "\n",
    "* Bilinear-FFM: åŒçº¿æ€§FFMã€‚ä¸ºäº†å‡å°‘FFMçš„å‚æ•°é‡ï¼Œè®¾è®¡å…±äº«çŸ©é˜µæ¥ä»£æ›¿é’ˆå¯¹ä¸åŒFieldçš„å¤šä¸ªéšå‘é‡ã€‚æ•ˆæœæ¥è¿‘FFMï¼Œä½†å‚æ•°é‡å¤§å¤§å‡å°‘ï¼Œä¸FMç›¸å½“ã€‚äº¤äº’åæ·»åŠ LayerNormlizationæ—¶æ•ˆæœå’Œç•¥å¥½äºFFM.\n",
    "\n",
    "* DeepFM: ä½¿ç”¨FMæ¨¡å‹ä»£æ›¿DeepWideä¸­çš„Wideéƒ¨åˆ†ï¼Œä¸”FMéƒ¨åˆ†çš„éšå‘é‡ä¸Deepéƒ¨åˆ†çš„Embeddingå‘é‡æ˜¯å…±äº«çš„ã€‚FMéƒ¨åˆ†å¯ä»¥æ•è·äºŒé˜¶æ˜¾å¼ç‰¹å¾äº¤å‰ï¼Œè€ŒDeepéƒ¨åˆ†èƒ½å¤Ÿæ•è·é«˜é˜¶éšå¼ç‰¹å¾ç»„åˆå’Œäº¤å‰ã€‚\n",
    "\n",
    "* FiBiNET: ä½¿ç”¨SEæ³¨æ„åŠ›(Squeeze-and-Excitation)æœºåˆ¶æ¥æ•è·ç‰¹å¾é‡è¦æ€§ï¼Œå¹¶ä¸”ä½¿ç”¨Bilinear-FFMæ¥æ•è·äºŒé˜¶ç‰¹å¾äº¤äº’ã€‚\n",
    "\n",
    "å‚è€ƒæ–‡ç« ï¼šå¼ ä¿Šæ—ã€ŠFFMåŠDeepFFMæ¨¡å‹åœ¨æ¨èç³»ç»Ÿçš„æ¢ç´¢ã€‹https://zhuanlan.zhihu.com/p/67795161\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=\"red\">\n",
    " \n",
    "å…¬ä¼—å· **ç®—æ³•ç¾é£Ÿå±‹** å›å¤å…³é”®è¯ï¼š**pytorch**ï¼Œ è·å–æœ¬é¡¹ç›®æºç å’Œæ‰€ç”¨æ•°æ®é›†ç™¾åº¦äº‘ç›˜ä¸‹è½½é“¾æ¥ã€‚\n",
    "    \n",
    "</font> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e9c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "print(\"torch.__version__=\"+torch.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bef545",
   "metadata": {},
   "source": [
    "```\n",
    "torch.__version__=1.10.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb862c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2740610c",
   "metadata": {},
   "source": [
    "##  ä¸€ï¼ŒFMåŸç†è§£æ\n",
    "\n",
    "FMæ¨¡å‹çš„è¡¨è¾¾å½¢å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "$$y_{FM} = x_0 + \\sum_{i=1}^n \\omega_i x_i + \\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} <\\vec{v_i},\\vec{v_j}> x_i x_j$$\n",
    "\n",
    "å…¶ä¸­ å‰ä¸¤é¡¹ä¸ çº¿æ€§å›å½’ä¸€è‡´ã€‚\n",
    "\n",
    "ç¬¬ä¸‰é¡¹ä¸ºç‰¹å¾äº¤äº’é¡¹ã€‚ç”¨éšå‘é‡çš„ç‚¹ç§¯æ¥è®¡ç®—äº¤äº’é¡¹çš„ç³»æ•°ã€‚è¿™æ ·åšæ¯”ç›´æ¥è®¾å®šä¸€ä¸ª$n\\times n$çš„äº¤äº’å‚æ•°çŸ©é˜µ$W$çš„å¥½å¤„æ˜¯å‡å°‘äº†å‚æ•°æ•°é‡ï¼Œå‚æ•°æ•°é‡ä» $n^2$å‡å°‘ä¸º $n\\times k$ï¼Œå…¶ä¸­kä¸ºéšå‘é‡$v_i$çš„é•¿åº¦ã€‚\n",
    "\n",
    "ä»æ•°å­¦ä¸Šï¼ŒFMç®—æ³•ç”¨ä¸€ç»„å‘é‡çš„ä¸¤ä¸¤å†…ç§¯ä»£æ›¿äº†äº¤äº’å‚æ•°çŸ©é˜µ$W$ï¼Œç­‰ä»·äºå°†å¯¹ç§°çŸ©é˜µWåˆ†è§£æˆå¦‚ä¸‹å½¢å¼$W=V^TV$ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆFMç®—æ³•è¢«å«åšå› å­åˆ†è§£æœºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c64fa",
   "metadata": {},
   "source": [
    "éå¸¸æœ‰æ„æ€çš„æ˜¯ï¼Œäº¤äº’é¡¹çš„è®¡ç®—å¤æ‚åº¦ä¹Ÿå¯ä»¥ç”± $O(n^2)$ é™ä½ä¸º $O(nk)$ï¼Œè¿™æ ·FMå‰å‘æ¨æ–­çš„è®¡ç®—å¤æ‚åº¦è¿‘ä¼¼ä¸ºçº¿æ€§å¤æ‚åº¦ã€‚å¯¹äºç‰¹å¾æ•°é‡néå¸¸å¤§è€Œç¨€ç–çš„æ¨¡å‹ï¼Œè®¡ç®—èµ·æ¥æ¯«æ— å‹åŠ›ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f8473",
   "metadata": {},
   "source": [
    "äº¤äº’é¡¹çš„ç®€åŒ–è®¡ç®—ç±»ä¼¼äº $ab+ac+bc =\\frac{1}{2} ((a+b+c)^2-(a^2+b^2+c^2))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47f917",
   "metadata": {},
   "source": [
    "$$\\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} <\\vec{v_i},\\vec{v_j}> x_i x_j\n",
    "= \\frac{1}{2}(\\sum_{i=1}^{n}\\sum_{j=1}^{n} <\\vec{v_i},\\vec{v_j}> x_i x_j - \\sum_{i=1}^{n} <\\vec{v_i},\\vec{v_i}> x_i x_i)$$\n",
    "$$= \\frac{1}{2}(\\sum_{i=1}^{n}\\sum_{j=1}^{n} \\sum_{f=1}^{k} v_{if}v_{jf} x_i x_j - \\sum_{i=1}^{n} \\sum_{f=1}^{k} v_{if}v_{if} x_i x_i)$$\n",
    "\n",
    "$$= \\frac{1}{2}\\sum_{f=1}^{k}(\\sum_{i=1}^{n}\\sum_{j=1}^{n}  v_{if}v_{jf} x_i x_j - \\sum_{i=1}^{n}  v_{if}v_{if} x_i x_i)$$\n",
    "\n",
    "$$= \\frac{1}{2}\\sum_{f=1}^{k}((\\sum_{i=1}^{n}v_{if}x_i)^2  - \\sum_{i=1}^{n}  (v_{if} x_i)^2)$$\n",
    "\n",
    "å¯ä»¥çœ‹åˆ°äº¤äº’é¡¹çš„è®¡ç®—å¤æ‚åº¦å·²ç»å˜æˆ $O(nk)$ äº†\n",
    "\n",
    "å› æ­¤ FMçš„æ¨¡å‹å½¢å¼ä¹Ÿå¯ä»¥æ”¹å†™æˆï¼š\n",
    "\n",
    "$$y_{FM} = x_0 + \\sum_{i=1}^n \\omega_i x_i +\\frac{1}{2}\\sum_{f=1}^{k}((\\sum_{i=1}^{n}v_{if}x_i)^2  - \\sum_{i=1}^{n}  (v_{if} x_i)^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c353cfc",
   "metadata": {},
   "source": [
    "æ³¨æ„åˆ° \n",
    "\n",
    "$$\\frac{\\partial{y_{FM}}}{\\partial{v_{if}}} = (\\sum_{j=1}^{n}v_{jf}x_j) x_i - v_{if}x_i^2$$\n",
    "$$= x_i((\\sum_{j=1}^{n}v_{jf}x_j)  - v_{if}x_i)$$\n",
    "\n",
    "å¯è§ï¼Œåªè¦è®­ç»ƒæ ·æœ¬ä¸­å­˜åœ¨ä¸ç­‰äº0çš„ $x_i$ ï¼Œå°±èƒ½å¤Ÿç»™éšå‘é‡$\\vec{v_{i}}$è´¡çŒ®æ¢¯åº¦ï¼Œä»è€Œå­¦åˆ°æœ‰æ•ˆçš„$\\vec{v_{i}}$è¡¨ç¤ºã€‚\n",
    "\n",
    "åŒç†ï¼Œåªè¦è®­ç»ƒæ ·æœ¬ä¸­å­˜åœ¨ä¸ç­‰äº0çš„ $x_j$ ï¼Œå°±èƒ½å¤Ÿç»™éšå‘é‡$\\vec{v_{j}}$è´¡çŒ®æ¢¯åº¦ï¼Œä»è€Œå­¦åˆ°æœ‰æ•ˆçš„$\\vec{v_{j}}$è¡¨ç¤ºã€‚\n",
    "\n",
    "ç„¶åï¼Œå°±å¯ä»¥è®¡ç®—å‡ºæœ‰æ„ä¹‰çš„äº¤äº’é¡¹çš„æƒé‡$<\\vec{v_{i}},\\vec{v_{j}}>$ã€‚\n",
    "\n",
    "è¿™éå¸¸é‡è¦ï¼Œè¿™è¯´æ˜éé›¶çš„äº¤äº’é¡¹æƒé‡å¯ä»¥åœ¨è®­ç»ƒæ ·æœ¬ä¸­ä¸å­˜åœ¨ $x_i$å’Œ$x_j$åŒæ—¶ä¸ä¸º0çš„æ ·æœ¬çš„å‘ç”Ÿã€‚\n",
    "\n",
    "è¿™æ˜¯FMé¢å¯¹ç¨€ç–ç‰¹å¾å…·æœ‰å¾ˆå¼ºæ³›åŒ–æ€§çš„åŸå› ã€‚\n",
    "\n",
    "è€ƒè™‘ä¸€ä¸ªå…¸å‹çš„ç»™ç”¨æˆ·æ¨èå•†å“çš„æ¨èåœºæ™¯ä¸­ï¼Œç”¨æˆ·æ‰€åœ¨åŸå¸‚ç‰¹å¾å’Œå•†å“ç±»ç›®ç‰¹å¾çš„äº¤äº’ã€‚\n",
    "\n",
    "è‘«èŠ¦å²›æ˜¯ä¸€ä¸ªå°åŸå¸‚ï¼Œæ¸”ç½‘æ˜¯ä¸€ç§å°ä¼—å•†å“ã€‚å®ƒä»¬éƒ½æ˜¯ç¨€ç–ç‰¹å¾ï¼Œç»å¤§éƒ¨åˆ†æ ·æœ¬åœ¨è¿™ä¸¤ä¸ªonehotä½ä¸Šçš„å–å€¼éƒ½æ˜¯0.\n",
    "\n",
    "ç¨€ç–ä¹˜ä»¥ç¨€ç–æ›´åŠ ç¨€ç–ï¼Œæ‰€ä»¥åœ¨è®­ç»ƒæ ·æœ¬ä¸­å¯èƒ½æ ¹æœ¬ä¸å­˜åœ¨è‘«èŠ¦å²›åŸå¸‚çš„ç”¨æˆ·è´­ä¹°æ¸”ç½‘è¿™æ ·çš„æ ·æœ¬ã€‚\n",
    "\n",
    "ä½†æ˜¯åªè¦è®­ç»ƒæ ·æœ¬ä¸­å­˜åœ¨ç€è‘«èŠ¦å²›çš„ç”¨æˆ·è´­ä¹°å…¶å®ƒå•†å“è¿™æ ·çš„æ ·æœ¬ï¼Œä¹Ÿå­˜åœ¨å…¶ä»–åŸå¸‚ç”¨æˆ·è´­ä¹°æ¸”ç½‘è¿™æ ·çš„æ ·æœ¬ï¼ŒFMæ¨¡å‹å°±å¯ä»¥ç»™è‘«èŠ¦å²›å¸‚çš„ç”¨æˆ·è´­ä¹°æ¸”ç½‘çš„å¯èƒ½æ€§ä½œå‡ºä¸€ä¸ªä¼°è®¡ï¼Œè¿™ä¸ªå€¼å¯èƒ½ä¸å°ï¼Œæœ€åç”šè‡³ä¼šç»™è‘«èŠ¦å²›çš„ç”¨æˆ·æ¨èæ¸”ç½‘ã€‚\n",
    "\n",
    "è¿™å°±æ˜¯FMé¢å¯¹ç¨€ç–ç‰¹å¾å…·æœ‰å¾ˆå¼ºæ³›åŒ–æ€§çš„ä¸€ä¸ªä¾‹å­ã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b3ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a3c6263",
   "metadata": {},
   "source": [
    "## äºŒï¼ŒPytorchä»£ç å®ç°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d007db0c",
   "metadata": {},
   "source": [
    "ä¸‹é¢æ˜¯FMæ¨¡å‹çš„ä¸€ä¸ªå®Œæ•´pytorchå®ç°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db12d6bb",
   "metadata": {},
   "source": [
    "$$\\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} <\\vec{v_i},\\vec{v_j}> x_i x_j = \\sum_{i=1}^{n-1}\\sum_{j=i+1}^{n} <x_i\\vec{v_i},x_j\\vec{v_j}> $$\n",
    "\n",
    "æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬ä»£ç ä¸­çš„embeddingå‘é‡æˆ–è€…çº¿æ€§å±‚ä½œç”¨ç»“æœå®é™…ä¸Šæ˜¯ $x_i\\vec{v_i}$ çš„ç»“æœã€‚è¿™æ˜¯è®¸å¤šè¯»è€…åŒ…æ‹¬æˆ‘åœ¨å­¦ä¹ FMæ—¶å€™æ„Ÿåˆ°å›°æƒ‘çš„ä¸€ä¸ªåœ°æ–¹ã€‚\n",
    "\n",
    "å¯¹äº ç¦»æ•£ç‰¹å¾ï¼Œonehotç¼–ç åå…¶ $x_i $ æ€»æ˜¯ç­‰äº1æˆ–è€…0ï¼Œ$x_i$ä¸ä¸º0çš„é‚£äº›é¡¹æ‰ä¼šä¿ç•™åˆ°ç»“æœä¸­ï¼Œæ­¤æ—¶$x_i$æ€»æ˜¯ç­‰äº1ï¼Œå› æ­¤$x_i\\vec{v_i}$å°±ç­‰äºå…¶embeddingå‘é‡ã€‚å¯¹äºè¿ç»­ç‰¹å¾ï¼Œé€šè¿‡ä¸€ä¸ªä¸å¸¦åç½®çš„Linearå±‚ä½œç”¨ï¼Œè·å–åˆ°çš„å®é™…ä¸Šå°±æ˜¯ $x_i\\vec{v_i}$ï¼ŒåŒ…å«äº†$x_i$å› å­ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a530e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch import nn,Tensor \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class NumEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    è¿ç»­ç‰¹å¾ç”¨linearå±‚ç¼–ç \n",
    "    è¾“å…¥shape: [batch_size,features_num(n), d_in], # d_in é€šå¸¸æ˜¯1\n",
    "    è¾“å‡ºshape: [batch_size,features_num(n), d_out]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n: int, d_in: int, d_out: int, bias: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(Tensor(n, d_in, d_out))\n",
    "        self.bias = nn.Parameter(Tensor(n, d_out)) if bias else None\n",
    "        with torch.no_grad():\n",
    "            for i in range(n):\n",
    "                layer = nn.Linear(d_in, d_out)\n",
    "                self.weight[i] = layer.weight.T\n",
    "                if self.bias is not None:\n",
    "                    self.bias[i] = layer.bias\n",
    "\n",
    "    def forward(self, x_num):\n",
    "        # x_num: batch_size, features_num, d_in\n",
    "        assert x_num.ndim == 3\n",
    "        #x = x_num[..., None] * self.weight[None]\n",
    "        #x = x.sum(-2)\n",
    "        x = torch.einsum(\"bfi,fij->bfj\",x_num,self.weight)\n",
    "        if self.bias is not None:\n",
    "            x = x + self.bias[None]\n",
    "        return x\n",
    "    \n",
    "class CatEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    ç¦»æ•£ç‰¹å¾ç”¨Embeddingå±‚ç¼–ç \n",
    "    è¾“å…¥shape: [batch_size,features_num], \n",
    "    è¾“å‡ºshape: [batch_size,features_num, d_embed]\n",
    "    \"\"\"\n",
    "    def __init__(self, categories, d_embed):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(sum(categories), d_embed)\n",
    "        self.offsets = nn.Parameter(\n",
    "                torch.tensor([0] + categories[:-1]).cumsum(0),requires_grad=False)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, x_cat):\n",
    "        \"\"\"\n",
    "        :param x_cat: Long tensor of size ``(batch_size, features_num)``\n",
    "        \"\"\"\n",
    "        x = x_cat + self.offsets[None]\n",
    "        return self.embedding(x) \n",
    "    \n",
    "class CatLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    ç¦»æ•£ç‰¹å¾ç”¨Embeddingå®ç°çº¿æ€§å±‚ï¼ˆç­‰ä»·äºå…ˆF.onehotå†nn.Linear()ï¼‰\n",
    "    è¾“å…¥shape: [batch_size,features_num], \n",
    "    è¾“å‡ºshape: [batch_size,d_out]\n",
    "    \"\"\"\n",
    "    def __init__(self, categories, d_out=1):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Embedding(sum(categories), d_out)\n",
    "        self.bias = nn.Parameter(torch.zeros((d_out,)))\n",
    "        self.offsets = nn.Parameter(\n",
    "                torch.tensor([0] + categories[:-1]).cumsum(0),requires_grad=False)\n",
    "\n",
    "    def forward(self, x_cat):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, features_num)``\n",
    "        \"\"\"\n",
    "        x = x_cat + self.offsets[None]\n",
    "        return torch.sum(self.fc(x), dim=1) + self.bias \n",
    "    \n",
    "    \n",
    "class FMLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    FMäº¤äº’é¡¹\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reduce_sum=True):\n",
    "        super().__init__()\n",
    "        self.reduce_sum = reduce_sum\n",
    "\n",
    "    def forward(self, x): #æ³¨æ„ï¼šè¿™é‡Œçš„xæ˜¯å…¬å¼ä¸­çš„ <v_i> * xi\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, num_features, k)``\n",
    "        \"\"\"\n",
    "        square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "        sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "        ix = square_of_sum - sum_of_square\n",
    "        if self.reduce_sum:\n",
    "            ix = torch.sum(ix, dim=1, keepdim=True)\n",
    "        return 0.5 * ix\n",
    "    \n",
    "class FM(nn.Module):\n",
    "    \"\"\"\n",
    "    å®Œæ•´FMæ¨¡å‹ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_numerical, categories=None, d_embed=4,\n",
    "                 n_classes = 1):\n",
    "        super().__init__()\n",
    "        if d_numerical is None:\n",
    "            d_numerical = 0\n",
    "        if categories is None:\n",
    "            categories = []\n",
    "        self.categories = categories\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.num_linear = nn.Linear(d_numerical,n_classes) if d_numerical else None\n",
    "        self.cat_linear = CatLinear(categories,n_classes) if categories else None\n",
    "        \n",
    "        self.num_embedding = NumEmbedding(d_numerical,1,d_embed) if d_numerical else None\n",
    "        self.cat_embedding = CatEmbedding(categories, d_embed) if categories else None\n",
    "        \n",
    "        if n_classes==1:\n",
    "            self.fm = FMLayer(reduce_sum=True)\n",
    "            self.fm_linear = None\n",
    "        else:\n",
    "            assert n_classes>=2\n",
    "            self.fm = FMLayer(reduce_sum=False)\n",
    "            self.fm_linear = nn.Linear(d_embed,n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \"\"\"\n",
    "        x_num: numerical features\n",
    "        x_cat: category features\n",
    "        \"\"\"\n",
    "        x_num,x_cat = x\n",
    "        \n",
    "        #linearéƒ¨åˆ†\n",
    "        x = 0.0\n",
    "        if self.num_linear:\n",
    "            x = x + self.num_linear(x_num) \n",
    "        if self.cat_linear:\n",
    "            x = x + self.cat_linear(x_cat)\n",
    "        \n",
    "        #äº¤å‰é¡¹éƒ¨åˆ†\n",
    "        x_embedding = []\n",
    "        if self.num_embedding:\n",
    "            x_embedding.append(self.num_embedding(x_num[...,None]))\n",
    "        if self.cat_embedding:\n",
    "            x_embedding.append(self.cat_embedding(x_cat))\n",
    "        x_embedding = torch.cat(x_embedding,dim=1)\n",
    "        \n",
    "        if self.n_classes==1:\n",
    "            x = x + self.fm(x_embedding)\n",
    "            x = x.squeeze(-1)\n",
    "        else: \n",
    "            x = x + self.fm_linear(self.fm(x_embedding)) \n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff538b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##æµ‹è¯• NumEmbedding\n",
    "\n",
    "num_embedding = NumEmbedding(2,1,4)\n",
    "x_num = torch.randn(2,2)\n",
    "x_out = (num_embedding(x_num.unsqueeze(-1)))\n",
    "print(x_out.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ef57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##æµ‹è¯• CatEmbedding\n",
    "\n",
    "cat_embedding = CatEmbedding(categories = [3,2,2],d_embed=4) \n",
    "x_cat = torch.randint(0,2,(2,3))\n",
    "x_out = cat_embedding(x_cat)\n",
    "print(x_cat.shape)\n",
    "print(x_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb503f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##æµ‹è¯• CatLinear\n",
    "\n",
    "cat_linear = CatLinear(categories = [3,2,2],d_out=1) \n",
    "x_cat = torch.randint(0,2,(2,3))\n",
    "x_out = cat_linear(x_cat)\n",
    "print(x_cat.shape)\n",
    "print(x_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09022e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##æµ‹è¯• FMLayer\n",
    "\n",
    "fm_layer = FMLayer(reduce_sum=False)\n",
    "\n",
    "x = torch.randn(2,3,4)\n",
    "x_out = fm_layer(x)\n",
    "print(x_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b8e23",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "##æµ‹è¯• FM\n",
    "\n",
    "fm = FM(d_numerical = 3, categories = [4,3,2],\n",
    "        d_embed = 4,n_classes = 2)\n",
    "self = fm \n",
    "x_num = torch.randn(2,3)\n",
    "x_cat = torch.randint(0,2,(2,3))\n",
    "fm((x_num,x_cat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2b226",
   "metadata": {},
   "source": [
    "## ä¸‰ï¼ŒCretioæ•°æ®é›†å®Œæ•´èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e89a2",
   "metadata": {},
   "source": [
    "Cretioæ•°æ®é›†æ˜¯ä¸€ä¸ªç»å…¸çš„å¹¿å‘Šç‚¹å‡»ç‡CTRé¢„æµ‹æ•°æ®é›†ã€‚\n",
    "\n",
    "è¿™ä¸ªæ•°æ®é›†çš„ç›®æ ‡æ˜¯é€šè¿‡ç”¨æˆ·ç‰¹å¾å’Œå¹¿å‘Šç‰¹å¾æ¥é¢„æµ‹æŸæ¡å¹¿å‘Šæ˜¯å¦ä¼šä¸ºç”¨æˆ·ç‚¹å‡»ã€‚\n",
    "\n",
    "æ•°æ®é›†æœ‰13ç»´æ•°å€¼ç‰¹å¾(I1è‡³I13)å’Œ26ç»´ç±»åˆ«ç‰¹å¾(C14è‡³C39), å…±39ç»´ç‰¹å¾, ç‰¹å¾ä¸­åŒ…å«ç€è®¸å¤šç¼ºå¤±å€¼ã€‚\n",
    "\n",
    "è®­ç»ƒé›†4000ä¸‡ä¸ªæ ·æœ¬ï¼Œæµ‹è¯•é›†600ä¸‡ä¸ªæ ·æœ¬ã€‚æ•°æ®é›†å¤§å°è¶…è¿‡100G.\n",
    "\n",
    "æ­¤å¤„ä½¿ç”¨çš„æ˜¯é‡‡æ ·100ä¸‡ä¸ªæ ·æœ¬åçš„cretio_smallæ•°æ®é›†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2680b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada2b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import datetime \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import torch \n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset,DataLoader  \n",
    "import torch.nn.functional as F \n",
    "import torchkeras \n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(info+'...\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5b451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa3283ff",
   "metadata": {},
   "source": [
    "### 1ï¼Œå‡†å¤‡æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72dcaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,QuantileTransformer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "dfdata = pd.read_csv(\"./eat_pytorch_datasets/criteo_small.zip\",sep=\"\\t\",header=None)\n",
    "dfdata.columns = [\"label\"] + [\"I\"+str(x) for x in range(1,14)] + [\n",
    "    \"C\"+str(x) for x in range(14,40)]\n",
    "\n",
    "cat_cols = [x for x in dfdata.columns if x.startswith('C')]\n",
    "num_cols = [x for x in dfdata.columns if x.startswith('I')]\n",
    "num_pipe = Pipeline(steps = [('impute',SimpleImputer()),('quantile',QuantileTransformer())])\n",
    "\n",
    "for col in cat_cols:\n",
    "    dfdata[col]  = LabelEncoder().fit_transform(dfdata[col])\n",
    "\n",
    "dfdata[num_cols] = num_pipe.fit_transform(dfdata[num_cols])\n",
    "\n",
    "categories = [dfdata[col].max()+1 for col in cat_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec01fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset,DataLoader \n",
    "\n",
    "#DataFrameè½¬æ¢æˆtorchæ•°æ®é›†Dataset, ç‰¹å¾åˆ†å‰²æˆX_num,X_catæ–¹å¼\n",
    "class DfDataset(Dataset):\n",
    "    def __init__(self,df,\n",
    "                 label_col,\n",
    "                 num_features,\n",
    "                 cat_features,\n",
    "                 categories,\n",
    "                 is_training=True):\n",
    "        \n",
    "        self.X_num = torch.tensor(df[num_features].values).float() if num_features else None\n",
    "        self.X_cat = torch.tensor(df[cat_features].values).long() if cat_features else None\n",
    "        self.Y = torch.tensor(df[label_col].values).float() \n",
    "        self.categories = categories\n",
    "        self.is_training = is_training\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        if self.is_training:\n",
    "            return ((self.X_num[index],self.X_cat[index]),self.Y[index])\n",
    "        else:\n",
    "            return (self.X_num[index],self.X_cat[index])\n",
    "    \n",
    "    def get_categories(self):\n",
    "        return self.categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain_val,dftest = train_test_split(dfdata,test_size=0.2)\n",
    "dftrain,dfval = train_test_split(dftrain_val,test_size=0.2)\n",
    "\n",
    "ds_train = DfDataset(dftrain,label_col = \"label\",num_features = num_cols,cat_features = cat_cols,\n",
    "                    categories = categories, is_training=True)\n",
    "\n",
    "ds_val = DfDataset(dfval,label_col = \"label\",num_features = num_cols,cat_features = cat_cols,\n",
    "                    categories = categories, is_training=True)\n",
    "\n",
    "ds_test = DfDataset(dftest,label_col = \"label\",num_features = num_cols,cat_features = cat_cols,\n",
    "                    categories = categories, is_training=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb40472b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train,batch_size = 2048,shuffle=True)\n",
    "dl_val = DataLoader(ds_val,batch_size = 2048,shuffle=False)\n",
    "dl_test = DataLoader(ds_test,batch_size = 2048,shuffle=False)\n",
    "\n",
    "for features,labels in dl_train:\n",
    "    break \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fffe25",
   "metadata": {},
   "source": [
    "### 2ï¼Œå®šä¹‰æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b54af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net():\n",
    "    net = FM(\n",
    "        d_numerical= ds_train.X_num.shape[1],\n",
    "        categories= ds_train.get_categories(),\n",
    "        d_embed = 8, \n",
    "        n_classes = 1\n",
    "    )\n",
    "    return net \n",
    "\n",
    "from torchkeras import summary\n",
    "\n",
    "net = create_net()\n",
    "summary(net,input_data=features);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9446731b",
   "metadata": {},
   "source": [
    "```\n",
    "--------------------------------------------------------------------------\n",
    "Layer (type)                            Output Shape              Param #\n",
    "==========================================================================\n",
    "Linear-1                                     [-1, 1]                   14\n",
    "Embedding-2                              [-1, 26, 1]            1,296,709\n",
    "NumEmbedding-3                           [-1, 13, 8]                  104\n",
    "Embedding-4                              [-1, 26, 8]           10,373,672\n",
    "FMLayer-5                                    [-1, 1]                    0\n",
    "==========================================================================\n",
    "Total params: 11,670,499\n",
    "Trainable params: 11,670,499\n",
    "Non-trainable params: 0\n",
    "--------------------------------------------------------------------------\n",
    "Input size (MB): 0.000084\n",
    "Forward/backward pass size (MB): 0.002594\n",
    "Params size (MB): 44.519421\n",
    "Estimated Total Size (MB): 44.522099\n",
    "--------------------------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c88de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9547e067",
   "metadata": {},
   "source": [
    "### 3ï¼Œè®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd40c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cdc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "from accelerate import Accelerator\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(str(info)+\"\\n\")\n",
    "    \n",
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn,stage = \"train\", metrics_dict = None, \n",
    "                 optimizer = None, lr_scheduler = None,\n",
    "                 accelerator = None\n",
    "                 ):\n",
    "        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n",
    "        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n",
    "        self.accelerator = accelerator\n",
    "    \n",
    "    def __call__(self, features, labels):\n",
    "        #loss\n",
    "        preds = self.net(features)\n",
    "        loss = self.loss_fn(preds,labels)\n",
    "\n",
    "        #backward()\n",
    "        if self.optimizer is not None and self.stage==\"train\":\n",
    "            if self.accelerator is  None:\n",
    "                loss.backward()\n",
    "            else:\n",
    "                self.accelerator.backward(loss)\n",
    "            self.optimizer.step()\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "        #metrics\n",
    "        step_metrics = {self.stage+\"_\"+name:metric_fn(preds, labels).item() \n",
    "                        for name,metric_fn in self.metrics_dict.items()}\n",
    "        return loss.item(),step_metrics\n",
    "    \n",
    "    \n",
    "class EpochRunner:\n",
    "    def __init__(self,steprunner):\n",
    "        self.steprunner = steprunner\n",
    "        self.stage = steprunner.stage\n",
    "        self.steprunner.net.train() if self.stage==\"train\" else self.steprunner.net.eval()\n",
    "        \n",
    "    def __call__(self,dataloader):\n",
    "        total_loss,step = 0,0\n",
    "        loop = tqdm(enumerate(dataloader), total =len(dataloader))\n",
    "        for i, batch in loop:\n",
    "            features,labels = batch\n",
    "            if self.stage==\"train\":\n",
    "                loss, step_metrics = self.steprunner(features,labels)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    loss, step_metrics = self.steprunner(features,labels)\n",
    "                    \n",
    "            step_log = dict({self.stage+\"_loss\":loss},**step_metrics)\n",
    "\n",
    "            total_loss += loss\n",
    "            step+=1\n",
    "            if i!=len(dataloader)-1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                epoch_loss = total_loss/step\n",
    "                epoch_metrics = {self.stage+\"_\"+name:metric_fn.compute().item() \n",
    "                                 for name,metric_fn in self.steprunner.metrics_dict.items()}\n",
    "                epoch_log = dict({self.stage+\"_loss\":epoch_loss},**epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name,metric_fn in self.steprunner.metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "        return epoch_log\n",
    "\n",
    "class KerasModel(torch.nn.Module):\n",
    "    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None):\n",
    "        super().__init__()\n",
    "        self.accelerator = Accelerator()\n",
    "        self.history = {}\n",
    "        \n",
    "        self.net = net\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metrics_dict = nn.ModuleDict(metrics_dict) \n",
    "        \n",
    "        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(\n",
    "            self.parameters(), lr=1e-2)\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        \n",
    "        self.net,self.loss_fn,self.metrics_dict,self.optimizer = self.accelerator.prepare(\n",
    "            self.net,self.loss_fn,self.metrics_dict,self.optimizer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.net:\n",
    "            return self.net.forward(x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint.pt', \n",
    "            patience=5, monitor=\"val_loss\", mode=\"min\"):\n",
    "        \n",
    "        train_data = self.accelerator.prepare(train_data)\n",
    "        val_data = self.accelerator.prepare(val_data) if val_data else []\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "            printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "            \n",
    "            # 1ï¼Œtrain -------------------------------------------------  \n",
    "            train_step_runner = StepRunner(net = self.net,stage=\"train\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),\n",
    "                    optimizer = self.optimizer, lr_scheduler = self.lr_scheduler,\n",
    "                    accelerator = self.accelerator)\n",
    "            train_epoch_runner = EpochRunner(train_step_runner)\n",
    "            train_metrics = train_epoch_runner(train_data)\n",
    "            \n",
    "            for name, metric in train_metrics.items():\n",
    "                self.history[name] = self.history.get(name, []) + [metric]\n",
    "\n",
    "            # 2ï¼Œvalidate -------------------------------------------------\n",
    "            if val_data:\n",
    "                val_step_runner = StepRunner(net = self.net,stage=\"val\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),\n",
    "                    accelerator = self.accelerator)\n",
    "                val_epoch_runner = EpochRunner(val_step_runner)\n",
    "                with torch.no_grad():\n",
    "                    val_metrics = val_epoch_runner(val_data)\n",
    "                val_metrics[\"epoch\"] = epoch\n",
    "                for name, metric in val_metrics.items():\n",
    "                    self.history[name] = self.history.get(name, []) + [metric]\n",
    "            \n",
    "            # 3ï¼Œearly-stopping -------------------------------------------------\n",
    "            arr_scores = self.history[monitor]\n",
    "            best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "            if best_score_idx==len(arr_scores)-1:\n",
    "                torch.save(self.net.state_dict(),ckpt_path)\n",
    "                print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "                     arr_scores[best_score_idx]),file=sys.stderr)\n",
    "            if len(arr_scores)-best_score_idx>patience:\n",
    "                print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "                    monitor,patience),file=sys.stderr)\n",
    "                break \n",
    "                \n",
    "        self.net.load_state_dict(torch.load(ckpt_path))\n",
    "            \n",
    "        return pd.DataFrame(self.history)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, val_data):\n",
    "        val_data = self.accelerator.prepare(val_data)\n",
    "        val_step_runner = StepRunner(net = self.net,stage=\"val\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),\n",
    "                    accelerator = self.accelerator)\n",
    "        val_epoch_runner = EpochRunner(val_step_runner)\n",
    "        val_metrics = val_epoch_runner(val_data)\n",
    "        return val_metrics\n",
    "        \n",
    "       \n",
    "    @torch.no_grad()\n",
    "    def predict(self, dataloader):\n",
    "        dataloader = self.accelerator.prepare(dataloader)\n",
    "        result = torch.cat([self.forward(t[0]) for t in dataloader])\n",
    "        return result.data\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5c1d4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from torchkeras.metrics import AUC\n",
    "\n",
    "net = create_net()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "metrics_dict = {\"auc\":AUC()}\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.005, weight_decay=0.001) \n",
    "\n",
    "model = KerasModel(net,\n",
    "                   loss_fn = loss_fn,\n",
    "                   metrics_dict= metrics_dict,\n",
    "                   optimizer = optimizer\n",
    "                  )         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhistory = model.fit(train_data = dl_train,val_data = dl_val,\n",
    "    epochs=20,\n",
    "    ckpt_path='checkpoint.pt',\n",
    "    patience=3,\n",
    "    monitor='val_auc',\n",
    "    mode='max')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3438d09",
   "metadata": {},
   "source": [
    "```\n",
    "================================================================================2022-08-11 19:39:44\n",
    "Epoch 7 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [01:14<00:00,  4.18it/s, train_auc=0.768, train_loss=0.475]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:03<00:00, 23.94it/s, val_auc=0.767, val_loss=0.477]\n",
    "<<<<<< reach best val_auc : 0.7665905952453613 >>>>>>\n",
    "\n",
    "================================================================================2022-08-11 19:41:02\n",
    "Epoch 8 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [01:13<00:00,  4.23it/s, train_auc=0.768, train_loss=0.475]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:03<00:00, 23.92it/s, val_auc=0.767, val_loss=0.477]\n",
    "<<<<<< reach best val_auc : 0.7671190500259399 >>>>>>\n",
    "\n",
    "================================================================================2022-08-11 19:42:20\n",
    "Epoch 9 / 20\n",
    "\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [01:13<00:00,  4.25it/s, train_auc=0.769, train_loss=0.475]\n",
    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:03<00:00, 23.37it/s, val_auc=0.768, val_loss=0.476]\n",
    "<<<<<< reach best val_auc : 0.768292248249054 >>>>>>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679352f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f81a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb0b24c6",
   "metadata": {},
   "source": [
    "### 4ï¼Œè¯„ä¼°æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540b7e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(dfhistory, metric):\n",
    "    train_metrics = dfhistory[\"train_\"+metric]\n",
    "    val_metrics = dfhistory['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036913fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ea78e",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h532tdrdvsj20f40a6dg3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92792236",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory,\"auc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c00a66",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/e6c9d24egy1h532uca1oij20f40a9aab.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5e739",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model.evaluate(dl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74c29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fbbd7a3",
   "metadata": {},
   "source": [
    "### 5ï¼Œä½¿ç”¨æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5720a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "model.eval()\n",
    "preds = F.sigmoid(model.predict(dl_val))\n",
    "labels = torch.cat([x[-1] for x in dl_val])\n",
    "\n",
    "val_auc = roc_auc_score(labels.numpy(),preds.numpy())\n",
    "print(val_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c71b32b",
   "metadata": {},
   "source": [
    "```\n",
    "0.768292257292055\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58e311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71ec3b4b",
   "metadata": {},
   "source": [
    "### 6ï¼Œä¿å­˜æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30747dc0",
   "metadata": {},
   "source": [
    "æ¨¡å‹æœ€ä½³æƒé‡å·²ç»ä¿å­˜åœ¨ model.fit(ckpt_path) ä¼ å…¥çš„å‚æ•°ä¸­äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55758fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_clone = create_net()\n",
    "net_clone.load_state_dict(torch.load(\"checkpoint.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a99c8a6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "preds = torch.cat([F.sigmoid(net_clone(x[0])).data for x in dl_val]) \n",
    "labels = torch.cat([x[-1] for x in dl_val])\n",
    "\n",
    "val_auc = roc_auc_score(labels.numpy(),preds.numpy())\n",
    "print(val_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e72ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b887ec5a",
   "metadata": {},
   "source": [
    "**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** \n",
    "\n",
    "å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·\"ç®—æ³•ç¾é£Ÿå±‹\"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚\n",
    "\n",
    "![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
