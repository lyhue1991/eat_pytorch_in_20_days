
# 7-8ï¼ŒDIENç½‘ç»œ


é˜¿é‡Œå¦ˆå¦ˆåœ¨CTRé¢„ä¼°é¢†åŸŸæœ‰3ç¯‡æ¯”è¾ƒæœ‰åçš„æ–‡ç« ã€‚

2017å¹´çš„æ·±åº¦å…´è¶£ç½‘ç»œ, DIN(DeepInterestNetwork)ã€‚ 

2018å¹´çš„æ·±åº¦å…´è¶£æ¼”åŒ–ç½‘ç»œ, DIEN(DeepInterestEvolutionNetWork)ã€‚

2019å¹´çš„æ·±åº¦ä¼šè¯å…´è¶£ç½‘ç»œ, DSIN(DeepSessionInterestNetWork)ã€‚

è¿™3ç¯‡æ–‡ç« çš„ä¸»è¦æ€æƒ³å’Œç›¸äº’å…³ç³»ç”¨ä¸€å¥è¯åˆ†åˆ«æ¦‚æ‹¬å¦‚ä¸‹ï¼š

ç¬¬1ç¯‡DINè¯´ï¼Œç”¨æˆ·çš„è¡Œä¸ºæ—¥å¿—ä¸­åªæœ‰ä¸€éƒ¨åˆ†å’Œå½“å‰å€™é€‰å¹¿å‘Šæœ‰å…³ã€‚å¯ä»¥åˆ©ç”¨Attentionæœºåˆ¶ä»ç”¨æˆ·è¡Œä¸ºæ—¥å¿—ä¸­å»ºæ¨¡å‡ºå’Œå½“å‰å€™é€‰å¹¿å‘Šç›¸å…³çš„ç”¨æˆ·å…´è¶£è¡¨ç¤ºã€‚æˆ‘ä»¬è¯•è¿‡æ¶¨ç‚¹äº†å˜»å˜»å˜»ã€‚

ç¬¬2ç¯‡DIENè¯´ï¼Œç”¨æˆ·æœ€è¿‘çš„è¡Œä¸ºå¯èƒ½æ¯”è¾ƒè¿œçš„è¡Œä¸ºæ›´åŠ é‡è¦ã€‚å¯ä»¥ç”¨å¾ªç¯ç¥ç»ç½‘ç»œGRUå»ºæ¨¡ç”¨æˆ·å…´è¶£éšæ—¶é—´çš„æ¼”åŒ–ã€‚æˆ‘ä»¬è¯•è¿‡ä¹Ÿæ¶¨ç‚¹äº†å˜¿å˜¿å˜¿ã€‚

ç¬¬3ç¯‡DSINè¯´ï¼Œç”¨æˆ·åœ¨åŒä¸€æ¬¡ä¼šè¯ä¸­çš„è¡Œä¸ºé«˜åº¦ç›¸å…³ï¼Œåœ¨ä¸åŒä¼šè¯é—´çš„è¡Œä¸ºåˆ™ç›¸å¯¹ç‹¬ç«‹ã€‚å¯ä»¥æŠŠç”¨æˆ·è¡Œä¸ºæ—¥å¿—æŒ‰ç…§æ—¶é—´é—´éš”åˆ†å‰²æˆä¼šè¯å¹¶ç”¨SelfAttentionæœºåˆ¶å»ºæ¨¡å®ƒä»¬ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚æˆ‘ä»¬è¯•è¿‡åˆæ¶¨ç‚¹äº†å“ˆå“ˆå“ˆã€‚


å‚è€ƒææ–™ï¼š

* DIENè®ºæ–‡ï¼š https://arxiv.org/pdf/1809.03672.pdf 

* DIN+DIENï¼Œæœºå™¨å­¦ä¹ å”¯ä¸€æŒ‡å®šæ¶¨ç‚¹æŠ€Attentionï¼š https://zhuanlan.zhihu.com/p/431131396

* ä»DINåˆ°DIENçœ‹é˜¿é‡ŒCTRç®—æ³•çš„è¿›åŒ–è„‰ç»œï¼š https://zhuanlan.zhihu.com/p/78365283

* ä»£ç å®ç°å‚è€ƒï¼š https://github.com/GitHub-HongweiZhang/prediction-flow

ä¸Šä¸€ç¯‡æ–‡ç« æˆ‘ä»¬ä»‹ç»äº†DIN, æœ¬ç¯‡æ–‡ç« æˆ‘ä»¬ä»‹ç»DIENã€‚


DIENè¿™ç¯‡æ–‡ç« çš„ä¸»è¦åˆ›æ–°ä¹‹å¤„æœ‰3ç‚¹ï¼š

* ä¸€æ˜¯å¼•å…¥GRUæ¥ä»ç”¨æˆ·è¡Œä¸ºæ—¥å¿—åºåˆ—ä¸­è‡ªç„¶åœ°æŠ½å–æ¯ä¸ªè¡Œä¸ºæ—¥å¿—å¯¹åº”çš„ç”¨æˆ·å…´è¶£è¡¨ç¤º(å…´è¶£æŠ½å–å±‚)ã€‚

* äºŒæ˜¯è®¾è®¡äº†ä¸€ä¸ªè¾…åŠ©losså±‚ï¼Œé€šè¿‡åšä¸€ä¸ªè¾…åŠ©ä»»åŠ¡(åŒºåˆ†çœŸå®çš„ç”¨æˆ·å†å²ç‚¹å‡»è¡Œä¸ºå’Œè´Ÿé‡‡æ ·çš„éç”¨æˆ·ç‚¹å‡»è¡Œä¸º)æ¥å¼ºåŒ–ç”¨æˆ·å…´è¶£è¡¨ç¤ºçš„å­¦ä¹ ã€‚

* ä¸‰æ˜¯å°†æ³¨æ„åŠ›æœºåˆ¶å’ŒGRUç»“æ„ç»“åˆèµ·æ¥(AUGRU: Attention UPdate GRU)ï¼Œæ¥å»ºæ¨¡ç”¨æˆ·å…´è¶£çš„æ—¶é—´æ¼”åŒ–å¾—åˆ°æœ€ç»ˆçš„ç”¨æˆ·è¡¨ç¤º(å…´è¶£æ¼”åŒ–å±‚)ã€‚


å…¶ä¸­å¼•å…¥è¾…åŠ©Lossçš„æŠ€å·§æ˜¯ç¥ç»ç½‘ç»œæ¶¨ç‚¹éå¸¸é€šç”¨çš„ä¸€ç§é«˜çº§æŠ€å·§ï¼Œå€¼å¾—æˆ‘ä»¬å­¦ä¹ ã€‚



<br>

<font color="red">
 
å…¬ä¼—å· **ç®—æ³•ç¾é£Ÿå±‹** å›å¤å…³é”®è¯ï¼š**pytorch**ï¼Œ è·å–æœ¬é¡¹ç›®æºç å’Œæ‰€ç”¨æ•°æ®é›†ç™¾åº¦äº‘ç›˜ä¸‹è½½é“¾æ¥ã€‚
    
</font> 



## ä¸€ï¼ŒDIENåŸç†è§£æ


DIENçš„ä¸»è¦å‡ºå‘ç‚¹æ˜¯ï¼Œç”¨æˆ·æœ€è¿‘çš„è¡Œä¸ºå¯èƒ½æ¯”è¾ƒè¿œçš„è¡Œä¸ºæ›´åŠ é‡è¦ã€‚å¯ä»¥ç”¨å¾ªç¯ç¥ç»ç½‘ç»œGRUå»ºæ¨¡ç”¨æˆ·å…´è¶£éšæ—¶é—´çš„æ¼”åŒ–ã€‚

DIENé€‰æ‹©çš„æ˜¯ä¸å®¹æ˜“æ¢¯åº¦æ¶ˆå¤±ä¸”è¾ƒå¿«çš„GRUã€‚

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h3x1brptqij20k10b8jsp.jpg)


### 1, å…´è¶£æŠ½å–å±‚


å›¾ä¸­çš„ $b(t)$ æ˜¯ç”¨æˆ·çš„è¡Œä¸ºåºåˆ—ï¼Œè€Œ $e(t)$æ˜¯å¯¹åº”çš„embeddingã€‚éšç€è‡ªç„¶å‘ç”Ÿçš„é¡ºåºï¼Œ $e(t)$è¢«è¾“å…¥GRUä¸­ï¼Œè¿™å°±æ˜¯å…´è¶£æŠ½å–å±‚ã€‚

ä¹Ÿæ˜¯DIENçš„ç¬¬ä¸€æ¡åˆ›æ–°ï¼šå¼•å…¥GRUæ¥ä»ç”¨æˆ·è¡Œä¸ºæ—¥å¿—åºåˆ—ä¸­è‡ªç„¶åœ°æŠ½å–æ¯ä¸ªè¡Œä¸ºæ—¥å¿—å¯¹åº”çš„ç”¨æˆ·å…´è¶£è¡¨ç¤º(å…´è¶£æŠ½å–å±‚)ã€‚




### 2ï¼Œè¾…åŠ©loss 


å¦‚æœå¿½ç•¥ä¸Šé¢çš„AUGRUç¯èŠ‚ï¼ŒGRUä¸­çš„éšçŠ¶æ€ $h(t)$å°±åº”è¯¥æˆä¸ºç”¨æˆ·çš„è¡Œä¸ºåºåˆ—æœ€åçš„è¡¨ç¤ºã€‚

å¦‚æœç›´æ¥å°±è¿™æ ·åšï¼Œä¹Ÿä¸æ˜¯ä¸å¯ä»¥ï¼Œä½†æ˜¯$h(t)$å­¦ä¹ åˆ°çš„ä¸œè¥¿å¯èƒ½ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ç”¨æˆ·å…´è¶£è¡¨ç¤ºï¼Œæˆ–è€…è¯´$h(t)$å¾ˆéš¾å­¦ä¹ åˆ°æœ‰æ„ä¹‰çš„ä¿¡æ¯ã€‚

å› ä¸º$h(t)$ çš„è¿­ä»£ç»è¿‡äº†å¾ˆå¤šæ­¥ï¼Œç„¶åè¿˜è¦å’Œå…¶ä»–ç‰¹å¾åšæ‹¼æ¥ï¼Œç„¶åè¿˜è¦ç»è¿‡MLPï¼Œæœ€åæ‰å¾—åˆ°è¾“å‡ºå»è®¡ç®—Lossã€‚

è¿™æ ·çš„ç»“æœå°±æ˜¯æœ€åæ¥äº†ä¸€ä¸ªæ­£æ ·æœ¬æˆ–è´Ÿæ ·æœ¬ï¼Œåå‘ä¼ æ’­å¾ˆéš¾å½’å› åˆ° $h(t)$ ä¸Šã€‚

åŸºäºæ­¤DIENç»™å‡ºäº†ç¬¬äºŒä¸ªè¦ç‚¹ï¼šä½¿ç”¨è¾…åŠ©Lossæ¥å¼ºåŒ–$h(t)$çš„å­¦ä¹ ã€‚

æˆ‘ä»¬æ¥çœ‹çœ‹è¿™ä¸ªè¾…åŠ©Lossæ˜¯æ€ä¹ˆåšçš„ï¼Ÿè¿™é‡Œè®¾è®¡äº†ä¸€ä¸ªè¾…åŠ©ä»»åŠ¡ï¼Œä½¿ç”¨$h(t)$æ¥åŒºåˆ†çœŸå®çš„ç”¨æˆ·å†å²ç‚¹å‡»è¡Œä¸ºå’Œè´Ÿé‡‡æ ·çš„éç”¨æˆ·ç‚¹å‡»è¡Œä¸ºã€‚

ç”±äº$h(t)$ ä»£è¡¨ç€ t æ—¶åˆ»çš„ç”¨æˆ·å…´è¶£è¡¨ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥é¢„æµ‹ t+1æ—¶åˆ»çš„å¹¿å‘Šç”¨æˆ·æ˜¯å¦ç‚¹å‡»ã€‚

å› ä¸ºç”¨æˆ·è¡Œä¸ºæ—¥å¿—ä¸­éƒ½æ˜¯ç”¨æˆ·ç‚¹å‡»è¿‡çš„å¹¿å‘Š(æ­£æ ·æœ¬, $e(t)$)ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä»å…¨éƒ¨çš„å¹¿å‘Šä¸­ç»™ç”¨æˆ·é‡‡æ ·åŒæ ·æ•°é‡çš„ç”¨æˆ·æ²¡æœ‰ç‚¹å‡»è¿‡çš„å¹¿å‘Šä½œä¸ºè´Ÿæ ·æœ¬$e'(t)$ã€‚

ç»“åˆ$h(t)$å’Œ $e(t)$, $e'(t)$ä½œä¸ºè¾“å…¥, æˆ‘ä»¬å¯ä»¥åšä¸€ä¸ªäºŒåˆ†ç±»çš„è¾…åŠ©ä»»åŠ¡ã€‚

è¿™ä¸ªè¾…åŠ©ä»»åŠ¡ç»™$h(t)$åœ¨æ¯ä¸ªtæ—¶åˆ»éƒ½æä¾›äº†ä¸€ä¸ªç›‘ç£ä¿¡å·ï¼Œä½¿å¾—$h(t)$èƒ½å¤Ÿæ›´å¥½åœ°æˆä¸ºç”¨æˆ·å…´è¶£çš„æŠ½å–è¡¨ç¤ºã€‚

çœŸå®åº”ç”¨åœºåˆä¸‹ï¼Œä½ æŠŠå¼€å§‹çš„è¾“å…¥å’Œæœ€åçš„è¦æ±‚å‘Šè¯‰ç½‘ç»œï¼Œå®ƒå°±èƒ½ç»™ä½ ä¸€ä¸ªå¥½çš„ç»“æœçš„æƒ…å†µéå¸¸å°‘ã€‚

å¤§å¤šæ•°æ—¶å€™æ˜¯éœ€è¦ä½ å»æ§åˆ¶æ¯ä¸€æ­¥çš„è¾“å…¥è¾“å‡ºï¼Œæ¯ä¸€æ­¥çš„lossæ‰èƒ½é˜²æ­¢ç½‘ç»œå„ç§å·æ‡’ä½œå¼Šã€‚

è¾…åŠ©lossèƒ½å¤Ÿä½¿å¾—ç½‘ç»œæ›´å—æ§åˆ¶ï¼Œå‘æˆ‘ä»¬éœ€è¦çš„æ–¹å‘å‘å±•ï¼Œéå¸¸å»ºè®®å¤§å®¶åœ¨å®é™…ä¸šåŠ¡ä¸­å¤šè¯•è¯•è¾…åŠ©lossã€‚




### 3ï¼Œå…´è¶£æ¼”åŒ–å±‚

é€šè¿‡å…´è¶£æŠ½å–å±‚å’Œè¾…åŠ©lossï¼Œæˆ‘ä»¬å¾—åˆ°äº†æ¯ä¸ªtæ—¶åˆ»ç”¨æˆ·çš„ä¸€èˆ¬å…´è¶£è¡¨ç¤ºã€‚

æ³¨æ„è¿™ä¸ªå…´è¶£è¡¨ç¤ºæ˜¯ä¸€èˆ¬æ€§çš„ï¼Œè¿˜æ²¡æœ‰å’Œæˆ‘ä»¬çš„å€™é€‰å¹¿å‘ŠåšAttentionå…³è”ã€‚

åœ¨DINä¸­ï¼Œæˆ‘ä»¬é€šè¿‡Attentionæœºåˆ¶æ„å»ºäº†å’Œå€™é€‰å¹¿å‘Šç›¸å…³çš„ç”¨æˆ·å…´è¶£è¡¨ç¤ºã€‚

è€Œåœ¨DIENä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›å»ºç«‹çš„æ˜¯å’Œå’Œå€™é€‰å¹¿å‘Šç›¸å…³ï¼Œå¹¶ä¸”å’Œæ—¶é—´æ¼”åŒ–ç›¸å…³çš„ç”¨æˆ·å…´è¶£è¡¨ç¤ºã€‚

DIENé€šè¿‡ç»“åˆAttentionæœºåˆ¶å’ŒGRUç»“æ„æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œè¿™å°±æ˜¯ç¬¬ä¸‰ç‚¹åˆ›æ–°AUGRU : Attention UPdate Gate GRUã€‚

ä¸‹é¢æˆ‘ä»¬è¿›è¡Œè¯¦ç»†è®²è§£ã€‚


ä¸€èˆ¬åœ°ï¼Œå„ç§RNNåºåˆ—æ¨¡å‹å±‚(SimpleRNN,GRU,LSTMç­‰)å¯ä»¥ç”¨å‡½æ•°è¡¨ç¤ºå¦‚ä¸‹:

$$h_t = f(h_{t-1},i_t)$$

è¿™ä¸ªå…¬å¼çš„å«ä¹‰æ˜¯ï¼štæ—¶åˆ»å¾ªç¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºå‘é‡$h_t$ç”±t-1æ—¶åˆ»çš„è¾“å‡ºå‘é‡$h_{t-1}$å’Œtæ—¶åˆ»çš„è¾“å…¥$i_t$å˜æ¢è€Œæ¥ã€‚

ä¸ºäº†ç»“åˆAttentionæœºåˆ¶å’ŒGRUç»“æ„ï¼Œæˆ‘ä»¬éœ€è¦è®¾è®¡è¿™æ ·çš„ä¸€ä¸ªæœ‰ä¸‰ç§è¾“å…¥çš„åºåˆ—æ¨¡å‹

$$h_t = g(h_{t-1},i_t, a_t)$$

è¿™é‡Œçš„$a_t$æ˜¯ tæ—¶åˆ»çš„ç”¨æˆ·å…´è¶£è¡¨ç¤ºè¾“å…¥ $i_t$å’Œå€™é€‰å¹¿å‘Šè®¡ç®—å‡ºçš„attention å¾—åˆ†ï¼Œæ˜¯ä¸ªæ ‡é‡ã€‚


æˆ‘ä»¬å…ˆçœ‹çœ‹ GRUçš„ å…·ä½“å‡½æ•°å½¢å¼ï¼š 

$$
\begin{align}
u_t &= \sigma(W^u i_t + U^u h_{t-1} + b^u) \tag{1} \\
r_t &= \sigma(W^r i_t + U^r h_{t-1} + b^r) \tag{2} \\
n_t &= \tanh(W^n i_t + r_t \circ U^n h_{t-1} + b^n) \tag{3} \\
h_t &= h_{t-1} - u_t 	\circ h_{t-1} + u_t \circ n_t \tag{4} \\
\end{align}
$$



å…¬å¼ä¸­çš„å°åœˆè¡¨ç¤ºå“ˆè¾¾ç›ç§¯ï¼Œä¹Ÿå°±æ˜¯ä¸¤ä¸ªå‘é‡é€ä½ç›¸ä¹˜ã€‚

å…¶ä¸­(1)å¼å’Œ(2)å¼è®¡ç®—çš„æ˜¯æ›´æ–°é—¨$u_t$å’Œé‡ç½®é—¨$r_t$ï¼Œæ˜¯ä¸¤ä¸ªé•¿åº¦å’Œ$h_t$ç›¸åŒçš„å‘é‡ã€‚

æ›´æ–°é—¨ç”¨äºæ§åˆ¶æ¯ä¸€æ­¥$h_t$è¢«æ›´æ–°çš„æ¯”ä¾‹ï¼Œæ›´æ–°é—¨è¶Šå¤§ï¼Œ$h_t$æ›´æ–°å¹…åº¦è¶Šå¤§ã€‚

é‡ç½®é—¨ç”¨äºæ§åˆ¶æ›´æ–°å€™é€‰å‘é‡$n_t$ä¸­å‰ä¸€æ­¥çš„çŠ¶æ€$h_{t-1}$è¢«é‡æ–°æ”¾å…¥çš„æ¯”ä¾‹ï¼Œé‡ç½®é—¨è¶Šå¤§ï¼Œæ›´æ–°å€™é€‰å‘é‡ä¸­$h_{t-1}$è¢«é‡æ–°æ”¾è¿›æ¥çš„æ¯”ä¾‹è¶Šå¤§ã€‚

æ³¨æ„åˆ°(4)å¼ å®é™…ä¸Šå’ŒResNetçš„æ®‹å·®ç»“æ„æ˜¯ç›¸ä¼¼çš„ï¼Œéƒ½æ˜¯ f(x) = x + g(x) çš„å½¢å¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°é˜²æ­¢é•¿åºåˆ—å­¦ä¹ åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚

å¦‚ä½•åœ¨GRUçš„åŸºç¡€ä¸ŠæŠŠattentionå¾—åˆ†èå…¥è¿›æ¥å‘¢ï¼Ÿæœ‰ä»¥ä¸‹ä¸€äº›éå¸¸è‡ªç„¶çš„æƒ³æ³•ï¼š

* 1ï¼Œ ç”¨$a_t$ç¼©æ”¾è¾“å…¥$i_t$, è¿™å°±æ˜¯AIGRU: Attention Input GRUã€‚å…¶å«ä¹‰æ˜¯ç›¸å…³æ€§é«˜çš„åœ¨è¾“å…¥ç«¯è¿›è¡Œæ”¾å¤§ã€‚

* 2ï¼Œ ç”¨$a_t$ä»£æ›¿GRUçš„æ›´æ–°é—¨ï¼Œè¿™å°±æ˜¯AGRU: Attention based GRUã€‚å…¶å«ä¹‰æ˜¯ç”¨ç›´æ¥ç”¨ç›¸å…³æ€§ä½œä¸ºæ›´æ–°å¹…åº¦ã€‚

* 3ï¼Œ ç”¨$a_t$ç¼©æ”¾GRUçš„æ›´æ–°é—¨$u_t$ï¼Œè¿™å°±æ˜¯AUGRU:  Attention Update Gate GRUã€‚å…¶å«ä¹‰æ˜¯ç”¨ç”¨ç›¸å…³æ€§ç¼©æ”¾æ›´æ–°å¹…åº¦ã€‚


AIGRUå®é™…ä¸Šå¹¶æ²¡æœ‰æ”¹å˜GRUçš„ç»“æ„ï¼Œåªæ˜¯æ”¹å˜äº†å…¶è¾“å…¥ï¼Œè¿™ç§æ–¹å¼å¯¹Attentionçš„ä½¿ç”¨æ¯”è¾ƒå«è“„ï¼Œæˆ‘æŠŠæ¯ä¸ªå†å²å¹¿å‘Šçš„ç›¸å…³æ€§å¼ºå¼±é€šè¿‡è¾“å…¥å‘Šè¯‰GRUï¼ŒGRUä½ å°±ç»™æˆ‘å¥½å¥½å­¦å§ï¼Œå¸Œæœ›ä½ æŠŠç›¸å…³æ€§å¼ºçš„å¹¿å‘Šå¤šé•¿ç‚¹åˆ°è„‘å­é‡Œã€‚ä½†æ˜¯è¿™ç§æ–¹å¼æ•ˆæœä¸æ˜¯å¾ˆç†æƒ³ï¼Œå³ä½¿æ˜¯ç›¸å…³æ€§ä¸º0çš„å†å²å¹¿å‘Šï¼Œä¹Ÿä¼šå¯¹è¿›è¡Œæ›´æ–°ã€‚

AGRUæ˜¯æ”¹å˜äº†GRUçš„ç»“æ„çš„ï¼Œå¹¶ä¸”å¯¹Attentionçš„ä½¿ç”¨éå¸¸æ¿€è¿›ï¼Œå®Œå…¨åˆ æ‰äº†GRUåŸæœ‰çš„çš„æ›´æ–°é—¨ï¼ŒGRUä½ çš„è„‘å­å½’Attentionç®¡äº†ï¼Œé‡åˆ°ç›¸å…³æ€§é«˜çš„å¹¿å‘Šï¼Œä¸€å®šå¤§å¤§åœ°è®°ä¸Šä¸€ç¬”ã€‚ä¸è¿‡AGRUä¹Ÿæœ‰ä¸€ä¸ªç¼ºé™·ï¼Œé‚£å°±æ˜¯Attentionå¾—åˆ†å®é™…ä¸Šæ˜¯ä¸ªæ ‡é‡ï¼Œæ— æ³•ååº”ä¸åŒç»´åº¦çš„å·®å¼‚ã€‚

AUGRUä¹Ÿæ˜¯æ”¹å˜äº†GRUçš„ç»“æ„çš„ï¼Œå¹¶ä¸”å¯¹Attentionçš„ä½¿ç”¨æ¯”è¾ƒæŠ˜è¡·ï¼Œè®©Attentionç¼©æ”¾GRUåŸæœ‰çš„æ›´æ–°å¹…åº¦ã€‚GRUæˆ‘ç»™ä½ æ‰¾äº†ä¸ªæ­æ¡£Attentionï¼Œä½ æ›´æ–°å‰å…ˆé—®é—®å®ƒï¼Œä½ ä¸¤ä¸€èµ·å†³å®šè¯¥è¿ˆå¤šå¤§çš„æ­¥å­å§ã€‚

DIENè®ºæ–‡ä¸­é€šè¿‡å¯¹æ¯”å®éªŒå‘ç°AUGRUçš„æ•ˆæœæœ€å¥½ã€‚

æˆ‘ä»¬çœ‹çœ‹AUGRUçš„æ ¸å¿ƒå®ç°ä»£ç ã€‚åŸºæœ¬ä¸Šå’Œå…¬å¼æ˜¯ä¸€è‡´çš„ï¼Œåº”ç”¨äº†F.linearå‡½æ•°æ¥å®ç°çŸ©é˜µä¹˜æ³•å’ŒåŠ åç½®ã€‚


```python
import torch 
from torch import nn 

class AttentionUpdateGateGRUCell(nn.Module):
    def __init__(self, input_size, hidden_size, bias=True):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.bias = bias
        # (Wu|Wr|Wn)
        self.weight_ih = nn.Parameter(
            torch.Tensor(3 * hidden_size, input_size))
        # (Uu|Ur|Un)
        self.weight_hh = nn.Parameter(
            torch.Tensor(3 * hidden_size, hidden_size))
        if bias:
            # (b_iu|b_ir|b_in)
            self.bias_ih = nn.Parameter(torch.Tensor(3 * hidden_size))
            # (b_hu|b_hr|b_hn)
            self.bias_hh = nn.Parameter(torch.Tensor(3 * hidden_size))
        else:
            self.register_parameter('bias_ih', None)
            self.register_parameter('bias_hh', None)
        self.reset_parameters()

    def reset_parameters(self):
        stdv = 1.0 / (self.hidden_size)**0.5
        for weight in self.parameters():
            nn.init.uniform_(weight, -stdv, stdv)
            
    def forward(self, x, hx, att_score):
        gi = F.linear(x, self.weight_ih, self.bias_ih)
        gh = F.linear(hx, self.weight_hh, self.bias_hh)
        i_r, i_u, i_n = gi.chunk(3, 1)
        h_r, h_u, h_n = gh.chunk(3, 1)

        resetgate = torch.sigmoid(i_r + h_r)
        updategate = torch.sigmoid(i_u + h_u)
        newgate = torch.tanh(i_n + resetgate * h_n)

        updategate = att_score.view(-1, 1) * updategate
        hy = (1-updategate)*hx +  updategate*newgate

        return hy

```


## äºŒï¼ŒDIENçš„pytorchå®ç°


ä¸‹é¢æ˜¯ä¸€ä¸ªDIENæ¨¡å‹çš„å®Œæ•´pytorchå®ç°ã€‚è®¸å¤šä»£ç å’ŒDINçš„å®ç°æ˜¯ä¸€æ ·çš„ã€‚

è¿™é‡Œçš„AttentionGroupç±»ç”¨æ¥å»ºç«‹å€™é€‰å¹¿å‘Šå±æ€§ï¼Œå†å²å¹¿å‘Šå±æ€§ï¼Œä»¥åŠè´Ÿé‡‡æ ·çš„å¹¿å‘Šå±æ€§çš„pairå…³ç³»ã€‚



```python
import torch
import torch.nn as nn
import torch.nn.functional as F 
from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence
from collections import OrderedDict

class MaxPooling(nn.Module):
    def __init__(self, dim):
        super(MaxPooling, self).__init__()
        self.dim = dim

    def forward(self, input):
        return torch.max(input, self.dim)[0]


class SumPooling(nn.Module):
    def __init__(self, dim):
        super(SumPooling, self).__init__()
        self.dim = dim

    def forward(self, input):
        return torch.sum(input, self.dim)

class Dice(nn.Module):
    """
    The Data Adaptive Activation Function in DIN, a generalization of PReLu.
    """
    def __init__(self, emb_size, dim=2, epsilon=1e-8):
        super(Dice, self).__init__()
        assert dim == 2 or dim == 3

        self.bn = nn.BatchNorm1d(emb_size, eps=epsilon)
        self.sigmoid = nn.Sigmoid()
        self.dim = dim
        
        # wrap alpha in nn.Parameter to make it trainable
        self.alpha = nn.Parameter(torch.zeros((emb_size,))) if self.dim == 2 else nn.Parameter(
            torch.zeros((emb_size, 1)))


    def forward(self, x):
        assert x.dim() == self.dim
        if self.dim == 2:
            x_p = self.sigmoid(self.bn(x))
            out = self.alpha * (1 - x_p) * x + x_p * x
        else:
            x = torch.transpose(x, 1, 2)
            x_p = self.sigmoid(self.bn(x))
            out = self.alpha * (1 - x_p) * x + x_p * x
            out = torch.transpose(out, 1, 2)
        return out

    
class Identity(nn.Module):
    def __init__(self):
        super().__init__()
    def forward(self, x):
        return x
    
def get_activation_layer(name, hidden_size=None, dice_dim=2):
    name = name.lower()
    name_dict = {x.lower():x for x in dir(nn) if '__' not in x and 'Z'>=x[0]>='A'}
    if name=="linear":
        return Identity()
    elif name=="dice":
        assert dice_dim
        return Dice(hidden_size, dice_dim)
    else:
        assert name in name_dict, f'activation type {name} not supported!'
        return getattr(nn,name_dict[name])()
    
def init_weights(model):
    if isinstance(model, nn.Linear):
        if model.weight is not None:
            nn.init.kaiming_uniform_(model.weight.data)
        if model.bias is not None:
            nn.init.normal_(model.bias.data)
    elif isinstance(model, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):
        if model.weight is not None:
            nn.init.normal_(model.weight.data, mean=1, std=0.02)
        if model.bias is not None:
            nn.init.constant_(model.bias.data, 0)
    else:
        pass


class MLP(nn.Module):
    def __init__(self, input_size, hidden_layers,
                 dropout=0.0, batchnorm=True, activation='relu'):
        super(MLP, self).__init__()
        modules = OrderedDict()
        previous_size = input_size
        for index, hidden_layer in enumerate(hidden_layers):
            modules[f"dense{index}"] = nn.Linear(previous_size, hidden_layer)
            if batchnorm:
                modules[f"batchnorm{index}"] = nn.BatchNorm1d(hidden_layer)
            if activation:
                modules[f"activation{index}"] = get_activation_layer(activation,hidden_layer,2)
            if dropout:
                modules[f"dropout{index}"] = nn.Dropout(dropout)
            previous_size = hidden_layer
        self.mlp = nn.Sequential(modules)

    def forward(self, x):
        return self.mlp(x)


class AttentionGRUCell(nn.Module):
    def __init__(self, input_size, hidden_size, bias=True):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.bias = bias
        # (Wr|Wn)
        self.weight_ih = nn.Parameter(
            torch.Tensor(2 * hidden_size, input_size))
        # (Ur|Un)
        self.weight_hh = nn.Parameter(
            torch.Tensor(2 * hidden_size, hidden_size))
        if bias:
            # (b_ir|b_in)
            self.bias_ih = nn.Parameter(torch.Tensor(2 * hidden_size))
            # (b_hr|b_hn)
            self.bias_hh = nn.Parameter(torch.Tensor(2 * hidden_size))
        else:
            self.register_parameter('bias_ih', None)
            self.register_parameter('bias_hh', None)
        self.reset_parameters()

    def reset_parameters(self):
        stdv = 1.0 / (self.hidden_size)**0.5
        for weight in self.parameters():
            nn.init.uniform_(weight, -stdv, stdv)

    def forward(self, x, hx, att_score):

        gi = F.linear(x, self.weight_ih, self.bias_ih)
        gh = F.linear(hx, self.weight_hh, self.bias_hh)
        i_r, i_n = gi.chunk(2, 1)
        h_r, h_n = gh.chunk(2, 1)

        resetgate = torch.sigmoid(i_r + h_r)
        newgate = torch.tanh(i_n + resetgate * h_n)
        att_score = att_score.view(-1, 1)
        hy = (1. - att_score) * hx + att_score * newgate
        
        return hy


class AttentionUpdateGateGRUCell(nn.Module):
    def __init__(self, input_size, hidden_size, bias=True):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.bias = bias
        # (Wu|Wr|Wn)
        self.weight_ih = nn.Parameter(
            torch.Tensor(3 * hidden_size, input_size))
        # (Uu|Ur|Un)
        self.weight_hh = nn.Parameter(
            torch.Tensor(3 * hidden_size, hidden_size))
        if bias:
            # (b_iu|b_ir|b_in)
            self.bias_ih = nn.Parameter(torch.Tensor(3 * hidden_size))
            # (b_hu|b_hr|b_hn)
            self.bias_hh = nn.Parameter(torch.Tensor(3 * hidden_size))
        else:
            self.register_parameter('bias_ih', None)
            self.register_parameter('bias_hh', None)
        self.reset_parameters()

    def reset_parameters(self):
        stdv = 1.0 / (self.hidden_size)**0.5
        for weight in self.parameters():
            nn.init.uniform_(weight, -stdv, stdv)
            
    def forward(self, x, hx, att_score):
        gi = F.linear(x, self.weight_ih, self.bias_ih)
        gh = F.linear(hx, self.weight_hh, self.bias_hh)
        i_u,i_r, i_n = gi.chunk(3, 1)
        h_u,h_r, h_n = gh.chunk(3, 1)

        updategate = torch.sigmoid(i_u + h_u)
        resetgate = torch.sigmoid(i_r + h_r)
        newgate = torch.tanh(i_n + resetgate * h_n)

        updategate = att_score.view(-1, 1) * updategate
        hy = (1-updategate)*hx +  updategate*newgate

        return hy



class DynamicGRU(nn.Module):
    def __init__(self, input_size, hidden_size, bias=True, gru_type='AGRU'):
        super(DynamicGRU, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size

        if gru_type == 'AGRU':
            self.rnn = AttentionGRUCell(input_size, hidden_size, bias)
        elif gru_type == 'AUGRU':
            self.rnn = AttentionUpdateGateGRUCell(
                input_size, hidden_size, bias)

    def forward(self, x, att_scores, hx=None):
        is_packed_input = isinstance(x, nn.utils.rnn.PackedSequence)
        if not is_packed_input:
            raise NotImplementedError(
                "DynamicGRU only supports packed input")

        is_packed_att_scores = isinstance(att_scores, nn.utils.rnn.PackedSequence)
        if not is_packed_att_scores:
            raise NotImplementedError(
                "DynamicGRU only supports packed att_scores")

        x, batch_sizes, sorted_indices, unsorted_indices = x
        att_scores, _, _, _ = att_scores

        max_batch_size = batch_sizes[0]
        max_batch_size = int(max_batch_size)

        if hx is None:
            hx = torch.zeros(
                max_batch_size, self.hidden_size,
                dtype=x.dtype, device=x.device)

        outputs = torch.zeros(
            x.size(0), self.hidden_size,
            dtype=x.dtype, device=x.device)

        begin = 0
        for batch in batch_sizes:
            new_hx = self.rnn(
                x[begin: begin + batch],
                hx[0:batch],
                att_scores[begin: begin + batch])
            outputs[begin: begin + batch] = new_hx
            hx = new_hx
            begin += batch

        return nn.utils.rnn.PackedSequence(
            outputs, batch_sizes, sorted_indices, unsorted_indices)
    

class Attention(nn.Module):
    def __init__(
            self,
            input_size,
            hidden_layers,
            dropout=0.0,
            batchnorm=True,
            activation='prelu',
            return_scores=False):
        
        super().__init__()
        self.return_scores = return_scores
        
        self.mlp = MLP(
            input_size=input_size * 4,
            hidden_layers=hidden_layers,
            dropout=dropout,
            batchnorm=batchnorm,
            activation=activation)
        self.fc = nn.Linear(hidden_layers[-1], 1)

    def forward(self, query, keys, keys_length):
        """
        Parameters
        ----------
        query: 2D tensor, [Batch, Hidden]
        keys: 3D tensor, [Batch, Time, Hidden]
        keys_length: 1D tensor, [Batch]

        Returns
        -------
        outputs: 2D tensor, [Batch, Hidden]
        """
        batch_size, max_length, dim = keys.size()

        query = query.unsqueeze(1).expand(-1, max_length, -1)

        din_all = torch.cat(
            [query, keys, query - keys, query * keys], dim=-1)

        din_all = din_all.view(batch_size * max_length, -1)

        outputs = self.mlp(din_all)

        outputs = self.fc(outputs).view(batch_size, max_length)  # [B, T]

        # Scale
        outputs = outputs / (dim ** 0.5)

        # Mask
        mask = (torch.arange(max_length, device=keys_length.device).repeat(
            batch_size, 1) < keys_length.view(-1, 1))
        outputs[~mask] = -np.inf

        # Activation
        outputs = F.softmax(outputs, dim=1)  #DIN uses sigmoid,DIEN uses softmax; [B, T]

        if not self.return_scores:
            # Weighted sum
            outputs = torch.matmul(
                outputs.unsqueeze(1), keys).squeeze()  # [B, H]
        return outputs 
    
class AuxiliaryNet(nn.Module):
    def __init__(self, input_size, hidden_layers, activation='sigmoid'):
        super().__init__()
        modules = OrderedDict()
        previous_size = input_size
        for index, hidden_layer in enumerate(hidden_layers):
            modules[f"dense{index}"] = nn.Linear(previous_size, hidden_layer)
            if activation:
                modules[f"activation{index}"] = get_activation_layer(activation)
            previous_size = hidden_layer
        modules["final_layer"] = nn.Linear(previous_size, 1)
        self.mlp = nn.Sequential(modules)

    def forward(self, x):
        return torch.sigmoid(self.mlp(x))


class Interest(nn.Module):
    SUPPORTED_GRU_TYPE = ['GRU', 'AIGRU', 'AGRU', 'AUGRU']

    def __init__(
            self,
            input_size,
            gru_type='AUGRU',
            gru_dropout=0.0,
            att_hidden_layers=[80, 40],
            att_dropout=0.0,
            att_batchnorm=True,
            att_activation='prelu',
            use_negsampling=False):
        super(Interest, self).__init__()
        if gru_type not in Interest.SUPPORTED_GRU_TYPE:
            raise NotImplementedError(f"gru_type: {gru_type} is not supported")

        self.gru_type = gru_type
        self.use_negsampling = use_negsampling

        self.interest_extractor = nn.GRU(
            input_size=input_size,
            hidden_size=input_size,
            batch_first=True,
            bidirectional=False)

        if self.use_negsampling:
            self.auxiliary_net = AuxiliaryNet(
                input_size * 2, hidden_layers=[100, 50])

        if gru_type == 'GRU':
            self.attention = Attention(
                input_size=input_size,
                hidden_layers=att_hidden_layers,
                dropout=att_dropout,
                batchnorm=att_batchnorm,
                activation=att_activation)
            
            self.interest_evolution = nn.GRU(
                input_size=input_size,
                hidden_size=input_size,
                batch_first=True,
                bidirectional=False)
                
        elif gru_type == 'AIGRU':
            self.attention = Attention(
                input_size=input_size,
                hidden_layers=att_hidden_layers,
                dropout=att_dropout,
                batchnorm=att_batchnorm,
                activation=att_activation,
                return_scores=True)

            self.interest_evolution = nn.GRU(
                input_size=input_size,
                hidden_size=input_size,
                batch_first=True,
                bidirectional=False)
            
        elif gru_type == 'AGRU' or gru_type == 'AUGRU':
            self.attention = Attention(
                input_size=input_size,
                hidden_layers=att_hidden_layers,
                dropout=att_dropout,
                batchnorm=att_batchnorm,
                activation=att_activation,
                return_scores=True)

            self.interest_evolution = DynamicGRU(
                input_size=input_size,
                hidden_size=input_size,
                gru_type=gru_type)

    @staticmethod
    def get_last_state(states, keys_length):
        # states [B, T, H]
        batch_size, max_seq_length, hidden_size = states.size()

        mask = (torch.arange(max_seq_length, device=keys_length.device).repeat(
            batch_size, 1) == (keys_length.view(-1, 1) - 1))

        return states[mask]

    def cal_auxiliary_loss(
            self, states, click_seq, noclick_seq, keys_length):
        # states [B, T, H]
        # click_seq [B, T, H]
        # noclick_seq [B, T, H]
        # keys_length [B]
        batch_size, max_seq_length, embedding_size = states.size()

        mask = (torch.arange(max_seq_length, device=states.device).repeat(
            batch_size, 1) < keys_length.view(-1, 1)).float()

        click_input = torch.cat([states, click_seq], dim=-1)
        noclick_input = torch.cat([states, noclick_seq], dim=-1)
        embedding_size = embedding_size * 2

        click_p = self.auxiliary_net(
            click_input.view(
                batch_size * max_seq_length, embedding_size)).view(
                    batch_size, max_seq_length)[mask > 0].view(-1, 1)
        click_target = torch.ones(
            click_p.size(), dtype=torch.float, device=click_p.device)

        noclick_p = self.auxiliary_net(
            noclick_input.view(
                batch_size * max_seq_length, embedding_size)).view(
                    batch_size, max_seq_length)[mask > 0].view(-1, 1)
        noclick_target = torch.zeros(
            noclick_p.size(), dtype=torch.float, device=noclick_p.device)

        loss = F.binary_cross_entropy(
            torch.cat([click_p, noclick_p], dim=0),
            torch.cat([click_target, noclick_target], dim=0))

        return loss

    def forward(self, query, keys, keys_length, neg_keys=None):
        """
        Parameters
        ----------
        query: 2D tensor, [Batch, Hidden]
        keys: 3D tensor, [Batch, Time, Hidden]
        keys_length: 1D tensor, [Batch]
        neg_keys: 3D tensor, [Batch, Time, Hidden]

        Returns
        -------
        outputs: 2D tensor, [Batch, Hidden]
        """
        batch_size, max_length, dim = keys.size()

        packed_keys = pack_padded_sequence(
            keys,
            lengths=keys_length.squeeze().cpu(),
            batch_first=True,
            enforce_sorted=False)

        packed_interests, _ = self.interest_extractor(packed_keys)

        aloss = None
        if (self.gru_type != 'GRU') or self.use_negsampling:
            interests, _ = pad_packed_sequence(
                packed_interests,
                batch_first=True,
                padding_value=0.0,
                total_length=max_length)

            if self.use_negsampling:
                aloss = self.cal_auxiliary_loss(
                    interests[:, :-1, :],
                    keys[:, 1:, :],
                    neg_keys[:, 1:, :],
                    keys_length - 1)

        if self.gru_type == 'GRU':
            packed_interests, _ = self.interest_evolution(packed_interests)

            interests, _ = pad_packed_sequence(
                packed_interests,
                batch_first=True,
                padding_value=0.0,
                total_length=max_length)

            outputs = self.attention(query, interests, keys_length)

        elif self.gru_type == 'AIGRU':
            # attention
            scores = self.attention(query, interests, keys_length)
            interests = interests * scores.unsqueeze(-1)

            packed_interests = pack_padded_sequence(
                interests,
                lengths=keys_length.squeeze().cpu(),
                batch_first=True,
                enforce_sorted=False)
            _, outputs = self.interest_evolution(packed_interests)
            outputs = outputs.squeeze()

        elif self.gru_type == 'AGRU' or self.gru_type == 'AUGRU':
            # attention
            scores = self.attention(query, interests, keys_length)

            packed_interests = pack_padded_sequence(
                interests,
                lengths=keys_length.squeeze().cpu(),
                batch_first=True,
                enforce_sorted=False)

            packed_scores = pack_padded_sequence(
                scores,
                lengths=keys_length.squeeze().cpu(),
                batch_first=True,
                enforce_sorted=False)

            outputs, _ = pad_packed_sequence(
                self.interest_evolution(
                    packed_interests, packed_scores), batch_first=True)
            # pick last state
            outputs = Interest.get_last_state(
                outputs, keys_length.squeeze())

        return outputs, aloss
    
class AttentionGroup(object):
    def __init__(self, name, pairs,
                 hidden_layers, activation='dice', att_dropout=0.0,
                 gru_type='AUGRU', gru_dropout=0.0):
        self.name = name
        self.pairs = pairs
        self.hidden_layers = hidden_layers
        self.activation = activation
        self.att_dropout = att_dropout
        self.gru_type = gru_type
        self.gru_dropout = gru_dropout

        self.related_feature_names = set()
        self.neg_feature_names = set()
        for pair in pairs:
            self.related_feature_names.add(pair['ad'])
            self.related_feature_names.add(pair['pos_hist'])
            if 'neg_hist' in pair:
                self.related_feature_names.add(pair['neg_hist'])
                self.neg_feature_names.add(pair['neg_hist'])

    def is_attention_feature(self, feature_name):
        if feature_name in self.related_feature_names:
            return True
        return False

    def is_neg_sampling_feature(self, feature_name):
        if feature_name in self.neg_feature_names:
            return True
        return False

    @property
    def pairs_count(self):
        return len(self.pairs)
    
class DIEN(nn.Module):
    def __init__(self, num_features,cat_features,seq_features, 
                 cat_nums,embedding_size, attention_groups,
                 mlp_hidden_layers, mlp_activation='prelu', mlp_dropout=0.0,
                 use_negsampling = False,
                 d_out = 1
                 ):
        super().__init__()
        self.num_features = num_features
        self.cat_features = cat_features
        self.seq_features = seq_features
        self.cat_nums = cat_nums 
        self.embedding_size = embedding_size
        
        self.attention_groups = attention_groups
        
        self.mlp_hidden_layers = mlp_hidden_layers
        self.mlp_activation = mlp_activation
        self.mlp_dropout = mlp_dropout
        
        self.d_out = d_out
        self.use_negsampling = use_negsampling
        
        #embedding
        self.embeddings = OrderedDict()
        for feature in self.cat_features+self.seq_features:
            self.embeddings[feature] = nn.Embedding(
                self.cat_nums[feature], self.embedding_size, padding_idx=0)
            self.add_module(f"embedding:{feature}",self.embeddings[feature])

        self.sequence_poolings = OrderedDict()
        self.attention_poolings = OrderedDict()
        total_embedding_sizes = 0
        for feature in self.cat_features:
            total_embedding_sizes += self.embedding_size
        for feature in self.seq_features:
            if not self.is_neg_sampling_feature(feature):
                total_embedding_sizes += self.embedding_size
        
        #sequence_pooling
        for feature in self.seq_features:
            if not self.is_attention_feature(feature):
                self.sequence_poolings[feature] = MaxPooling(1)
                self.add_module(f"pooling:{feature}",self.sequence_poolings[feature])

        #attention_pooling
        for attention_group in self.attention_groups:
            self.attention_poolings[attention_group.name] = (
                self.create_attention_fn(attention_group))
            self.add_module(f"attention_pooling:{attention_group.name}",
                self.attention_poolings[attention_group.name])

        total_input_size = total_embedding_sizes+len(self.num_features)
        
        self.mlp = MLP(
            total_input_size,
            mlp_hidden_layers,
            dropout=mlp_dropout, batchnorm=True, activation=mlp_activation)
        
        self.final_layer = nn.Linear(mlp_hidden_layers[-1], self.d_out)
        self.apply(init_weights)
        
        
    def forward(self, x):
        final_layer_inputs = list()

        # linear
        number_inputs = list()
        for feature in self.num_features:
            number_inputs.append(x[feature].view(-1, 1))

        embeddings = OrderedDict()
        for feature in self.cat_features:
            embeddings[feature] = self.embeddings[feature](x[feature])

        for feature in self.seq_features:
            if not self.is_attention_feature(feature):
                embeddings[feature] = self.sequence_poolings[feature](
                    self.embeddings[feature](x[feature]))

        auxiliary_losses = []
        for attention_group in self.attention_groups:
            query = torch.cat(
                [embeddings[pair['ad']]
                 for pair in attention_group.pairs],
                dim=-1)
            pos_hist = torch.cat(
                [self.embeddings[pair['pos_hist']](
                    x[pair['pos_hist']]) for pair in attention_group.pairs],
                dim=-1)
            
            #hist_length = torch.sum(hist>0,axis=1)
            keys_length = torch.min(torch.cat(
                [torch.sum(x[pair['pos_hist']]>0,axis=1).view(-1, 1)
                 for pair in attention_group.pairs],
                dim=-1), dim=-1)[0]
    
            neg_hist = None
            if self.use_negsampling:
                neg_hist = torch.cat(
                    [self.embeddings[pair['neg_hist']](
                        x[pair['neg_hist']])
                     for pair in attention_group.pairs],
                    dim=-1)
                
            embeddings[attention_group.name], tmp_loss = (
                self.attention_poolings[attention_group.name](
                    query, pos_hist, keys_length, neg_hist))
            if tmp_loss is not None:
                auxiliary_losses.append(tmp_loss)

        emb_concat = torch.cat(number_inputs + [
            emb for emb in embeddings.values()], dim=-1)

        final_layer_inputs = self.mlp(emb_concat)

        output = self.final_layer(final_layer_inputs)
        
        auxiliary_avg_loss = None
        if auxiliary_losses:
            auxiliary_avg_loss = auxiliary_losses[0]
            size = len(auxiliary_losses)
            for i in range(1, size):
                auxiliary_avg_loss += auxiliary_losses[i]
            auxiliary_avg_loss /= size
            
        if  self.d_out==1:
            output = output.squeeze() 
            
        return output, auxiliary_avg_loss

    def create_attention_fn(self, attention_group):
        return Interest(
            attention_group.pairs_count * self.embedding_size,
            gru_type=attention_group.gru_type,
            gru_dropout=attention_group.gru_dropout,
            att_hidden_layers=attention_group.hidden_layers,
            att_dropout=attention_group.att_dropout,
            att_activation=attention_group.activation,
            use_negsampling=self.use_negsampling)
    
    def is_attention_feature(self, feature):
        for group in self.attention_groups:
            if group.is_attention_feature(feature):
                return True
        return False

    def is_neg_sampling_feature(self, feature):
        for group in self.attention_groups:
            if group.is_neg_sampling_feature(feature):
                return True
        return False


```

```python

```

## ä¸‰ï¼ŒMovielensæ•°æ®é›†å®Œæ•´èŒƒä¾‹


ä¸‹é¢æ˜¯ä¸€ä¸ªåŸºäºMovielensè¯„ä»·æ•°æ®é›†çš„DIENå®Œæ•´èŒƒä¾‹ï¼Œæ ¹æ®ç”¨æˆ·è¿‡å»å¯¹ä¸€äº›ç”µå½±çš„è¯„ä»·ç»“æœï¼Œæ¥é¢„æµ‹ç”¨æˆ·å¯¹å€™é€‰ç”µå½±æ˜¯å¦ä¼šç»™å¥½è¯„ã€‚

è¿™ä¸ªæ•°æ®é›†ä¸å¤§ï¼Œç”¨CPUå°±èƒ½è·‘ã€‚ğŸ˜

```python

```

### 1ï¼Œå‡†å¤‡æ•°æ®

```python
import numpy as np 
import pandas as pd 
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import QuantileTransformer
from sklearn.pipeline import Pipeline, FeatureUnion 
from sklearn.impute import SimpleImputer 
from collections import Counter

class CategoryEncoder(BaseEstimator, TransformerMixin):
    
    def __init__(self, min_cnt=5, word2idx=None, idx2word=None):
        super().__init__() 
        self.min_cnt = min_cnt
        self.word2idx = word2idx if word2idx else dict()
        self.idx2word = idx2word if idx2word else dict()

    def fit(self, x, y=None):
        if not self.word2idx:
            counter = Counter(np.asarray(x).ravel())

            selected_terms = sorted(
                list(filter(lambda x: counter[x] >= self.min_cnt, counter)))

            self.word2idx = dict(
                zip(selected_terms, range(1, len(selected_terms) + 1)))
            self.word2idx['__PAD__'] = 0
            if '__UNKNOWN__' not in self.word2idx:
                self.word2idx['__UNKNOWN__'] = len(self.word2idx)

        if not self.idx2word:
            self.idx2word = {
                index: word for word, index in self.word2idx.items()}

        return self

    def transform(self, x):
        transformed_x = list()
        for term in np.asarray(x).ravel():
            try:
                transformed_x.append(self.word2idx[term])
            except KeyError:
                transformed_x.append(self.word2idx['__UNKNOWN__'])

        return np.asarray(transformed_x, dtype=np.int64)

    def dimension(self):
        return len(self.word2idx)

class SequenceEncoder(BaseEstimator, TransformerMixin):
    def __init__(self, sep=' ', min_cnt=5, max_len=None,
                 word2idx=None, idx2word=None):
        super().__init__() 
        self.sep = sep
        self.min_cnt = min_cnt
        self.max_len = max_len

        self.word2idx = word2idx if word2idx else dict()
        self.idx2word = idx2word if idx2word else dict()

    def fit(self, x, y=None):
        if not self.word2idx:
            counter = Counter()

            max_len = 0
            for sequence in np.array(x).ravel():
                words = sequence.split(self.sep)
                counter.update(words)
                max_len = max(max_len, len(words))

            if self.max_len is None:
                self.max_len = max_len

            # drop rare words
            words = sorted(
                list(filter(lambda x: counter[x] >= self.min_cnt, counter)))

            self.word2idx = dict(zip(words, range(1, len(words) + 1)))
            self.word2idx['__PAD__'] = 0
            if '__UNKNOWN__' not in self.word2idx:
                self.word2idx['__UNKNOWN__'] = len(self.word2idx)

        if not self.idx2word:
            self.idx2word = {
                index: word for word, index in self.word2idx.items()}

        if not self.max_len:
            max_len = 0
            for sequence in np.array(x).ravel():
                words = sequence.split(self.sep)
                max_len = max(max_len, len(words))
            self.max_len = max_len

        return self

    def transform(self, x):
        transformed_x = list()

        for sequence in np.asarray(x).ravel():
            words = list()
            for word in sequence.split(self.sep):
                try:
                    words.append(self.word2idx[word])
                except KeyError:
                    words.append(self.word2idx['__UNKNOWN__'])

            transformed_x.append(
                np.asarray(words[0:self.max_len], dtype=np.int64))

        return np.asarray(transformed_x, dtype=object)
    
    def dimension(self):
        return len(self.word2idx)

    def max_length(self):
        return self.max_len
    
```

```python

```

```python
from sklearn.preprocessing import QuantileTransformer
from sklearn.pipeline import Pipeline 
from sklearn.impute import SimpleImputer 
from tqdm import tqdm 

dftrain = pd.read_csv("./eat_pytorch_datasets/ml_1m/train.csv")
dfval = pd.read_csv("./eat_pytorch_datasets/ml_1m/test.csv")

for col in ["movieId","histHighRatedMovieIds","negHistMovieIds","genres"]:
    dftrain[col] = dftrain[col].astype(str)
    dfval[col] = dfval[col].astype(str)

num_features = ['age']
cat_features = ['gender', 'movieId', 'occupation', 'zipCode']
seq_features = ['genres', 'histHighRatedMovieIds', 'negHistMovieIds']

num_pipe = Pipeline(steps = [('impute',SimpleImputer()),('quantile',QuantileTransformer())])

encoders = {}

print("preprocess number features...")
dftrain[num_features] = num_pipe.fit_transform(dftrain[num_features]).astype(np.float32)
dfval[num_features] = num_pipe.transform(dfval[num_features]).astype(np.float32)

print("preprocess category features...")
for col in tqdm(cat_features):
    encoders[col] = CategoryEncoder(min_cnt=5)
    dftrain[col]  = encoders[col].fit_transform(dftrain[col])
    dfval[col] =  encoders[col].transform(dfval[col])
    
print("preprocess sequence features...")
for col in tqdm(seq_features):
    encoders[col] = SequenceEncoder(sep="|",min_cnt=5)
    dftrain[col]  = encoders[col].fit_transform(dftrain[col])
    dfval[col] =  encoders[col].transform(dfval[col])
    
from collections import OrderedDict
from itertools import chain
from torch.utils.data import Dataset,DataLoader 

class Df2Dataset(Dataset):
    def __init__(self, dfdata, num_features, cat_features,
                 seq_features, encoders, label_col="label"):
        self.dfdata = dfdata
        self.num_features = num_features
        self.cat_features = cat_features 
        self.seq_features = seq_features
        self.encoders = encoders
        self.label_col = label_col
        self.size = len(self.dfdata)

    def __len__(self):
        return self.size

    @staticmethod
    def pad_sequence(sequence,max_length):
        #zero is special index for padding
        padded_seq = np.zeros(max_length, np.int32)
        padded_seq[0: sequence.shape[0]] = sequence
        return padded_seq

    def __getitem__(self, idx):
        record = OrderedDict()
        for col in self.num_features:
            record[col] = self.dfdata[col].iloc[idx].astype(np.float32)
            
        for col in self.cat_features:
            record[col] = self.dfdata[col].iloc[idx].astype(np.int64)
            
        for col in self.seq_features:
            seq = self.dfdata[col].iloc[idx]
            max_length = self.encoders[col].max_length()
            record[col] = Df2Dataset.pad_sequence(seq,max_length)

        if self.label_col is not None:
            record['label'] = self.dfdata[self.label_col].iloc[idx].astype(np.float32)
        return record

    def get_num_batches(self, batch_size):
        return np.ceil(self.size / batch_size)
    
ds_train = Df2Dataset(dftrain, num_features, cat_features, seq_features, encoders)
ds_val = Df2Dataset(dfval,num_features, cat_features, seq_features, encoders)
dl_train = DataLoader(ds_train, batch_size=128,shuffle=True)
dl_val = DataLoader(ds_val,batch_size=128,shuffle=False)

cat_nums = {k:v.dimension() for k,v in encoders.items()} 


```

```python
for batch in dl_train:
    break 
```

```python
print(cat_nums)
```

```python

```

### 2ï¼Œå®šä¹‰æ¨¡å‹

```python


def create_net():
    augru_attention_groups_with_neg = [
    AttentionGroup(
        name='group1',
        pairs=[{'ad': 'movieId', 'pos_hist': 'histHighRatedMovieIds', 'neg_hist': 'negHistMovieIds'}],
        hidden_layers=[16, 8], att_dropout=0.1, gru_type='AUGRU')
    ]

    net = DIEN(num_features=num_features,
           cat_features=cat_features,
           seq_features=seq_features,
           cat_nums = cat_nums,
           embedding_size=16,
           attention_groups=augru_attention_groups_with_neg,
           mlp_hidden_layers=[32,16],
           mlp_activation="prelu",
           mlp_dropout=0.25,
           use_negsampling=True,
           d_out=1
           )
    
    return net 

net = create_net() 

out,aloss = net.forward(batch)

from torchkeras.summary import summary 
summary(net,input_data=batch);


```

```python

```

### 3ï¼Œè®­ç»ƒæ¨¡å‹

```python

```

```python
import os,sys,time
import numpy as np
import pandas as pd
import datetime 
from tqdm import tqdm 

import torch
from torch import nn 
from accelerate import Accelerator
from copy import deepcopy


def printlog(info):
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("\n"+"=========="*8 + "%s"%nowtime)
    print(str(info)+"\n")
    
class StepRunner:
    def __init__(self, net, loss_fn,stage = "train", metrics_dict = None, 
                 optimizer = None, lr_scheduler = None,
                 accelerator = None
                 ):
        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage
        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler
        self.accelerator = accelerator
    
    def __call__(self, batch):
        #loss
        preds,aloss = self.net(batch)
        loss = self.loss_fn(preds,batch["label"])+aloss

        #backward()
        if self.optimizer is not None and self.stage=="train":
            if self.accelerator is  None:
                loss.backward()
            else:
                self.accelerator.backward(loss)
            self.optimizer.step()
            if self.lr_scheduler is not None:
                self.lr_scheduler.step()
            self.optimizer.zero_grad()
            
        #metrics
        step_metrics = {self.stage+"_"+name:metric_fn(preds, batch["label"]).item() 
                        for name,metric_fn in self.metrics_dict.items()}
        return loss.item(),step_metrics
    
    
class EpochRunner:
    def __init__(self,steprunner):
        self.steprunner = steprunner
        self.stage = steprunner.stage
        self.steprunner.net.train() if self.stage=="train" else self.steprunner.net.eval()
        
    def __call__(self,dataloader):
        total_loss,step = 0,0
        loop = tqdm(enumerate(dataloader), total =len(dataloader))
        for i, batch in loop:
            if self.stage=="train":
                loss, step_metrics = self.steprunner(batch)
            else:
                with torch.no_grad():
                    loss, step_metrics = self.steprunner(batch)

            step_log = dict({self.stage+"_loss":loss},**step_metrics)

            total_loss += loss
            step+=1
            if i!=len(dataloader)-1:
                loop.set_postfix(**step_log)
            else:
                epoch_loss = total_loss/step
                epoch_metrics = {self.stage+"_"+name:metric_fn.compute().item() 
                                 for name,metric_fn in self.steprunner.metrics_dict.items()}
                epoch_log = dict({self.stage+"_loss":epoch_loss},**epoch_metrics)
                loop.set_postfix(**epoch_log)

                for name,metric_fn in self.steprunner.metrics_dict.items():
                    metric_fn.reset()
        return epoch_log

class KerasModel(torch.nn.Module):
    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None):
        super().__init__()
        self.accelerator = Accelerator()
        self.history = {}
        
        self.net = net
        self.loss_fn = loss_fn
        self.metrics_dict = nn.ModuleDict(metrics_dict) 
        
        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(
            self.parameters(), lr=1e-2)
        self.lr_scheduler = lr_scheduler
        
        self.net,self.loss_fn,self.metrics_dict,self.optimizer = self.accelerator.prepare(
            self.net,self.loss_fn,self.metrics_dict,self.optimizer)

    def forward(self, x):
        if self.net:
            return self.net.forward(x)[0]
        else:
            raise NotImplementedError


    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint.pt', 
            patience=5, monitor="val_loss", mode="min"):
        
        train_data = self.accelerator.prepare(train_data)
        val_data = self.accelerator.prepare(val_data) if val_data else []

        for epoch in range(1, epochs+1):
            printlog("Epoch {0} / {1}".format(epoch, epochs))
            
            # 1ï¼Œtrain -------------------------------------------------  
            train_step_runner = StepRunner(net = self.net,stage="train",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    optimizer = self.optimizer, lr_scheduler = self.lr_scheduler,
                    accelerator = self.accelerator)
            train_epoch_runner = EpochRunner(train_step_runner)
            train_metrics = train_epoch_runner(train_data)
            
            for name, metric in train_metrics.items():
                self.history[name] = self.history.get(name, []) + [metric]

            # 2ï¼Œvalidate -------------------------------------------------
            if val_data:
                val_step_runner = StepRunner(net = self.net,stage="val",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    accelerator = self.accelerator)
                val_epoch_runner = EpochRunner(val_step_runner)
                with torch.no_grad():
                    val_metrics = val_epoch_runner(val_data)
                val_metrics["epoch"] = epoch
                for name, metric in val_metrics.items():
                    self.history[name] = self.history.get(name, []) + [metric]
            
            # 3ï¼Œearly-stopping -------------------------------------------------
            arr_scores = self.history[monitor]
            best_score_idx = np.argmax(arr_scores) if mode=="max" else np.argmin(arr_scores)
            if best_score_idx==len(arr_scores)-1:
                torch.save(self.net.state_dict(),ckpt_path)
                print("<<<<<< reach best {0} : {1} >>>>>>".format(monitor,
                     arr_scores[best_score_idx]),file=sys.stderr)
            if len(arr_scores)-best_score_idx>patience:
                print("<<<<<< {} without improvement in {} epoch, early stopping >>>>>>".format(
                    monitor,patience),file=sys.stderr)
                break 
                
        self.net.load_state_dict(torch.load(ckpt_path))
        return pd.DataFrame(self.history)

    @torch.no_grad()
    def evaluate(self, val_data):
        val_data = self.accelerator.prepare(val_data)
        val_step_runner = StepRunner(net = self.net,stage="val",
                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),
                    accelerator = self.accelerator)
        val_epoch_runner = EpochRunner(val_step_runner)
        val_metrics = val_epoch_runner(val_data)
        return val_metrics
        
       
    @torch.no_grad()
    def predict(self, dataloader):
        dataloader = self.accelerator.prepare(dataloader)
        self.net.eval()
        result = torch.cat([self.forward(t) for t in dataloader])
        return result.data

```

```python

```

```python
from torchkeras.metrics import AUC

loss_fn = nn.BCEWithLogitsLoss()

metrics_dict = {"auc":AUC()}
optimizer = torch.optim.Adam(net.parameters(), lr=0.002, weight_decay=0.001) 

model = KerasModel(net,
                   loss_fn = loss_fn,
                   metrics_dict= metrics_dict,
                   optimizer = optimizer
                  )    

```

```python
dfhistory = model.fit(train_data=dl_train,val_data=dl_val,epochs=100, patience=10,
                      monitor = "val_auc",mode="max",ckpt_path='checkpoint.pt')

```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h3z8ccgn9ij20p507qmy7.jpg)

```python

```

### 4ï¼Œè¯„ä¼°æ¨¡å‹

```python
%matplotlib inline
%config InlineBackend.figure_format = 'svg'

import matplotlib.pyplot as plt

def plot_metric(dfhistory, metric):
    train_metrics = dfhistory["train_"+metric]
    val_metrics = dfhistory['val_'+metric]
    epochs = range(1, len(train_metrics) + 1)
    plt.plot(epochs, train_metrics, 'bo--')
    plt.plot(epochs, val_metrics, 'ro-')
    plt.title('Training and validation '+ metric)
    plt.xlabel("Epochs")
    plt.ylabel(metric)
    plt.legend(["train_"+metric, 'val_'+metric])
    plt.show()
```

```python
plot_metric(dfhistory,"loss")
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h3z8afwf3zj20f20aiglx.jpg)

```python

```

```python
plot_metric(dfhistory,"auc")
```

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h3z8ddym3bj20f20ab74o.jpg)

```python
model.evaluate(dl_val)
```

{'val_loss': 0.7020544648170471, 'val_auc': 0.6469045281410217}

```python

```

### 5ï¼Œä½¿ç”¨æ¨¡å‹

```python
from sklearn.metrics import roc_auc_score 

labels = torch.tensor([x["label"] for x in ds_val])
preds = model.predict(dl_val)
val_auc = roc_auc_score(labels.cpu().numpy(),preds.cpu().numpy())
print(val_auc)
```

```
0.6469045283797497
```

```python

```

### 6ï¼Œä¿å­˜æ¨¡å‹

```python
torch.save(model.net.state_dict(),"best_dien.pt")
net_clone = create_net()
net_clone.load_state_dict(torch.load("best_dien.pt"))
```

```python
net_clone.eval()
labels = torch.tensor([x["label"] for x in ds_val])
preds = torch.cat([net_clone(x)[0].data for x in dl_val]) 
val_auc = roc_auc_score(labels.cpu().numpy(),preds.cpu().numpy())
print(val_auc)
```

```
0.6469045283797497
```


**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** 

å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·"ç®—æ³•ç¾é£Ÿå±‹"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚

ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚

![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)

